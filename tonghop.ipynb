{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " BƯỚC 0: TÍNH TOÁN TỔNG SỐ CONFERENCE DUY NHẤT TRÊN TẤT CẢ CÁC FILE\n",
      "================================================================================\n",
      "Đã xử lý file: evaluate_recrawl_batch_2_3_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_8_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_12_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_13_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_16_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_19_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_1_50.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_51_100.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_101_150.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_151_159.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_1_50_lan_2.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_51_100_lan_2.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_101_139_lan_2.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_lan_3.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_1_50_lan_4.csv\n",
      "Đã xử lý file: evaluate_crawl_not_crawl_1_50.csv\n",
      "Đã xử lý file: evaluate_crawl_not_crawl_51_end.csv\n",
      "Đã xử lý file: batch2.csv\n",
      "Đã xử lý file: batch3.csv\n",
      "Đã xử lý file: batch8.csv\n",
      "Đã xử lý file: batch12.csv\n",
      "Đã xử lý file: batch13.csv\n",
      "Đã xử lý file: batch16.csv\n",
      "Đã xử lý file: batch19.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_2_3_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_8_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_12_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_13_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_16_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_batch_19_lan_1.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_1_50.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_51_100.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_101_150.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_151_159.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_1_50_lan_2.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_51_100_lan_2.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_101_139_lan_2.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_lan_3.csv\n",
      "Đã xử lý file: evaluate_recrawl_all_tung_1_50_lan_4.csv\n",
      "Đã xử lý file: evaluate_crawl_not_crawl_1_50.csv\n",
      "Đã xử lý file: evaluate_crawl_not_crawl_51_end.csv\n",
      "\n",
      "----------------------------------------\n",
      ">>> TỔNG SỐ CONFERENCE DUY NHẤT (dựa trên title và acronym đã chuẩn hóa) trong tất cả các file là: 349\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      " BẮT ĐẦU KỊCH BẢN: PHÂN LOẠI CHỈ DỰA VÀO CỘT 'Note'\n",
      "================================================================================\n",
      "\n",
      "--- BƯỚC 1: Đọc và gộp tất cả các file đầu vào ---\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_2_3_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_8_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_12_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_13_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_16_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_19_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_1_50.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_51_100.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_101_150.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_151_159.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_1_50_lan_2.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_51_100_lan_2.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_101_139_lan_2.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_lan_3.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_1_50_lan_4.csv\n",
      "Đã đọc thành công file: evaluate_crawl_not_crawl_1_50.csv\n",
      "Đã đọc thành công file: evaluate_crawl_not_crawl_51_end.csv\n",
      "Đã đọc thành công file: batch2.csv\n",
      "Đã đọc thành công file: batch3.csv\n",
      "Đã đọc thành công file: batch8.csv\n",
      "Đã đọc thành công file: batch12.csv\n",
      "Đã đọc thành công file: batch13.csv\n",
      "Đã đọc thành công file: batch16.csv\n",
      "Đã đọc thành công file: batch19.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_2_3_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_8_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_12_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_13_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_16_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_batch_19_lan_1.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_1_50.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_51_100.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_101_150.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_151_159.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_1_50_lan_2.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_51_100_lan_2.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_101_139_lan_2.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_lan_3.csv\n",
      "Đã đọc thành công file: evaluate_recrawl_all_tung_1_50_lan_4.csv\n",
      "Đã đọc thành công file: evaluate_crawl_not_crawl_1_50.csv\n",
      "Đã đọc thành công file: evaluate_crawl_not_crawl_51_end.csv\n",
      "\n",
      "Đã gộp thành công. Tổng số dòng ban đầu: 1351\n",
      "\n",
      "--- BƯỚC 2: Phân loại dữ liệu dựa trên sự tồn tại của nội dung trong cột 'Note' ---\n",
      "Số dòng được xác định là 'Đúng' (Note trống): 700\n",
      "Số dòng được xác định là 'Cần Recrawl' (Note có nội dung): 651\n",
      "\n",
      "--- BƯỚC 3: Lọc bỏ các acronym non-link khỏi danh sách recrawl ---\n",
      "Đã tải 42 acronym non-link từ './non_link.txt'.\n",
      "Đã loại bỏ 28 dòng có acronym non-link khỏi danh sách recrawl.\n",
      "\n",
      "--- BƯỚC 4: Hoàn tất và lưu file tổng hợp cuối cùng ---\n",
      "Đã lưu 334 dòng ĐÚNG DUY NHẤT vào './src/conference/evaluate/ALL_BATCHES_correct_by_note.csv'\n",
      "Đã lưu 177 dòng CẦN RECRAWL DUY NHẤT vào './src/conference/evaluate/ALL_BATCHES_recrawl_by_note.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ==============================================================================\n",
    "# HÀM CHUẨN HÓA VÀ HÀM TRỢ GIÚP\n",
    "# ==============================================================================\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Chuẩn hóa văn bản bằng cách loại bỏ nội dung bên trong cặp dấu ngoặc đơn,\n",
    "    đảm bảo chỉ có một khoảng trắng giữa các từ và chuyển thành chữ thường.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    cleaned_text = re.sub(r'\\s*\\(.*?\\)\\s*', ' ', str(text))\n",
    "    final_text = re.sub(r'\\s+', ' ', cleaned_text).strip().lower()\n",
    "    return final_text\n",
    "\n",
    "def add_normalized_keys(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Thêm các cột khóa đã được chuẩn hóa ('key_title', 'key_acronym') vào DataFrame.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    if 'title' in df_copy.columns:\n",
    "        df_copy['key_title'] = df_copy['title'].apply(normalize_text)\n",
    "    else:\n",
    "        print(\"Cảnh báo: DataFrame không có cột 'title'. Không thể tạo key_title.\")\n",
    "        df_copy['key_title'] = ''\n",
    "\n",
    "    if 'acronym' in df_copy.columns:\n",
    "        df_copy['key_acronym'] = df_copy['acronym'].apply(normalize_text)\n",
    "    else:\n",
    "        df_copy['key_acronym'] = ''\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "def load_non_link_acronyms(filepath: str) -> set:\n",
    "    \"\"\"\n",
    "    Đọc file TXT chứa các acronym của conference non-link.\n",
    "    \"\"\"\n",
    "    non_link_acronyms = set()\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Cảnh báo: File non-link acronym không tồn tại tại '{filepath}'. Bỏ qua bước lọc này.\")\n",
    "        return non_link_acronyms\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                acronym = line.strip()\n",
    "                if acronym:\n",
    "                    non_link_acronyms.add(normalize_text(acronym))\n",
    "        print(f\"Đã tải {len(non_link_acronyms)} acronym non-link từ '{filepath}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file non-link acronym '{filepath}': {e}\")\n",
    "    return non_link_acronyms\n",
    "\n",
    "# ==============================================================================\n",
    "# HÀM TÍNH TỔNG SỐ CONFERENCE DUY NHẤT\n",
    "# ==============================================================================\n",
    "\n",
    "def calculate_and_print_total_unique_count(all_files: list):\n",
    "    \"\"\"\n",
    "    Đọc tất cả các file, tính toán và in ra tổng số conference duy nhất\n",
    "    dựa trên title và acronym đã được chuẩn hóa.\n",
    "    \"\"\"\n",
    "    total_unique_conferences = set()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" BƯỚC 0: TÍNH TOÁN TỔNG SỐ CONFERENCE DUY NHẤT TRÊN TẤT CẢ CÁC FILE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig', na_values=['', ' '], dtype=str, low_memory=False)\n",
    "            df_normalized = add_normalized_keys(df)\n",
    "\n",
    "            if 'key_title' not in df_normalized.columns or 'key_acronym' not in df_normalized.columns:\n",
    "                print(f\"Cảnh báo: Bỏ qua file {os.path.basename(file_path)} vì không thể tạo cột khóa.\")\n",
    "                continue\n",
    "            \n",
    "            unique_keys_in_file = set(zip(df_normalized['key_title'], df_normalized['key_acronym']))\n",
    "            total_unique_conferences.update(unique_keys_in_file)\n",
    "            print(f\"Đã xử lý file: {os.path.basename(file_path)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi đọc file {os.path.basename(file_path)} trong quá trình đếm, sẽ bỏ qua file này: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(f\">>> TỔNG SỐ CONFERENCE DUY NHẤT (dựa trên title và acronym đã chuẩn hóa) trong tất cả các file là: {len(total_unique_conferences)}\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "# ==============================================================================\n",
    "# HÀM XỬ LÝ CHÍNH (CHỈ DỰA VÀO CỘT 'Note')\n",
    "# ==============================================================================\n",
    "\n",
    "def process_files_by_note(\n",
    "    all_input_files: list,\n",
    "    aggregated_correct_path: str,\n",
    "    aggregated_recrawl_path: str,\n",
    "    non_link_acronyms_file: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Hàm xử lý chính, chỉ dựa vào cột 'Note' để phân loại đúng/sai.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" BẮT ĐẦU KỊCH BẢN: PHÂN LOẠI CHỈ DỰA VÀO CỘT 'Note'\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    # --- BƯỚC 1: ĐỌC VÀ GỘP TẤT CẢ CÁC FILE ---\n",
    "    print(\"--- BƯỚC 1: Đọc và gộp tất cả các file đầu vào ---\")\n",
    "    for file_path in all_input_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig', na_values=['', ' '], dtype=str, low_memory=False)\n",
    "            df = add_normalized_keys(df)\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Đã đọc thành công file: {os.path.basename(file_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi đọc file {file_path}: {e}\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"Không có dữ liệu để xử lý. Dừng chương trình.\")\n",
    "        return\n",
    "\n",
    "    master_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"\\nĐã gộp thành công. Tổng số dòng ban đầu: {len(master_df)}\")\n",
    "\n",
    "    # --- BƯỚC 2: PHÂN LOẠI DỰA TRÊN CỘT 'Note' ---\n",
    "    print(\"\\n--- BƯỚC 2: Phân loại dữ liệu dựa trên sự tồn tại của nội dung trong cột 'Note' ---\")\n",
    "    \n",
    "    # Mặc định tất cả là đúng, sau đó xác định các dòng cần recrawl\n",
    "    if 'Note' in master_df.columns:\n",
    "        # Điều kiện để một dòng cần recrawl là cột 'Note' không rỗng (notna) và không phải là chuỗi trống\n",
    "        is_recrawl = master_df['Note'].notna() & (master_df['Note'].astype(str).str.strip() != '')\n",
    "    else:\n",
    "        # Nếu không có cột 'Note', không có gì để đưa vào recrawl\n",
    "        is_recrawl = pd.Series([False] * len(master_df), index=master_df.index)\n",
    "        print(\"Cảnh báo: Không tìm thấy cột 'Note' trong dữ liệu tổng hợp.\")\n",
    "\n",
    "    recrawl_df = master_df[is_recrawl].copy()\n",
    "    correct_df = master_df[~is_recrawl].copy()\n",
    "\n",
    "    print(f\"Số dòng được xác định là 'Đúng' (Note trống): {len(correct_df)}\")\n",
    "    print(f\"Số dòng được xác định là 'Cần Recrawl' (Note có nội dung): {len(recrawl_df)}\")\n",
    "\n",
    "    # --- BƯỚC 3: LỌC BỎ CÁC ACRONYM NON-LINK KHỎI DANH SÁCH RECRAWL ---\n",
    "    print(\"\\n--- BƯỚC 3: Lọc bỏ các acronym non-link khỏi danh sách recrawl ---\")\n",
    "    if non_link_acronyms_file:\n",
    "        non_link_acronyms = load_non_link_acronyms(non_link_acronyms_file)\n",
    "        if non_link_acronyms and not recrawl_df.empty:\n",
    "            initial_recrawl_count = len(recrawl_df)\n",
    "            recrawl_df = recrawl_df[\n",
    "                ~recrawl_df['key_acronym'].isin(non_link_acronyms)\n",
    "            ].copy()\n",
    "            print(f\"Đã loại bỏ {initial_recrawl_count - len(recrawl_df)} dòng có acronym non-link khỏi danh sách recrawl.\")\n",
    "\n",
    "    # --- BƯỚC 4: LƯU FILE CUỐI CÙNG (LOẠI BỎ TRÙNG LẶP) ---\n",
    "    print(\"\\n--- BƯỚC 4: Hoàn tất và lưu file tổng hợp cuối cùng ---\")\n",
    "    subset_keys = ['key_title', 'key_acronym']\n",
    "    key_cols_to_drop = ['key_title', 'key_acronym']\n",
    "\n",
    "    if not correct_df.empty:\n",
    "        # Giữ lại bản ghi đầu tiên cho mỗi conference được coi là đúng\n",
    "        final_correct_df = correct_df.drop_duplicates(subset=subset_keys, keep='first').drop(columns=key_cols_to_drop, errors='ignore')\n",
    "        final_correct_df.to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu {len(final_correct_df)} dòng ĐÚNG DUY NHẤT vào '{aggregated_correct_path}'\")\n",
    "    \n",
    "    if not recrawl_df.empty:\n",
    "        # Giữ lại bản ghi đầu tiên cho mỗi conference cần recrawl\n",
    "        final_recrawl_df = recrawl_df.drop_duplicates(subset=subset_keys, keep='first').drop(columns=key_cols_to_drop, errors='ignore')\n",
    "        final_recrawl_df.to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu {len(final_recrawl_df)} dòng CẦN RECRAWL DUY NHẤT vào '{aggregated_recrawl_path}'\")\n",
    "    else:\n",
    "        print(f\"Không có dòng nào cần recrawl sau khi lọc. File '{aggregated_recrawl_path}' sẽ không được tạo hoặc sẽ trống.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# KHU VỰC THỰC THI\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- CẤU HÌNH ---\n",
    "    input_csv_files = [\n",
    "        './src/conference/evaluate/batch2.csv',\n",
    "        './src/conference/evaluate/batch3.csv',\n",
    "        './src/conference/evaluate/batch8.csv',\n",
    "        './src/conference/evaluate/batch12.csv',\n",
    "        './src/conference/evaluate/batch13.csv',\n",
    "        './src/conference/evaluate/batch16.csv',\n",
    "        './src/conference/evaluate/batch19.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_2_3_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_8_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_12_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_13_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_16_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_19_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_51_100.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_101_150.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_151_159.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_51_100_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_101_139_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_lan_3.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50_lan_4.csv',\n",
    "        './src/conference/evaluate/evaluate_crawl_not_crawl_1_50.csv',\n",
    "        './src/conference/evaluate/evaluate_crawl_not_crawl_51_end.csv',\n",
    "    \n",
    "    ]\n",
    "    recrawled_results_files = [\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_2_3_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_8_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_12_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_13_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_16_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_19_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_51_100.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_101_150.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_151_159.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_51_100_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_101_139_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_lan_3.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50_lan_4.csv',\n",
    "        './src/conference/evaluate/evaluate_crawl_not_crawl_1_50.csv',\n",
    "        './src/conference/evaluate/evaluate_crawl_not_crawl_51_end.csv',\n",
    "    ]\n",
    "    \n",
    "    # Gộp hai danh sách file lại thành một để xử lý\n",
    "    all_files_to_process = recrawled_results_files + input_csv_files\n",
    "\n",
    "    aggregated_correct_file = './src/conference/evaluate/ALL_BATCHES_correct_by_note.csv'\n",
    "    aggregated_recrawl_file = './src/conference/evaluate/ALL_BATCHES_recrawl_by_note.csv'\n",
    "    \n",
    "    non_link_acronyms_txt_file = './non_link.txt'\n",
    "\n",
    "    # --- BƯỚC 0: TÍNH TOÁN VÀ IN RA TỔNG SỐ CONFERENCE DUY NHẤT ---\n",
    "    calculate_and_print_total_unique_count(all_files_to_process)\n",
    "\n",
    "    # --- Chạy kịch bản xử lý chính ---\n",
    "    process_files_by_note(\n",
    "        all_input_files=all_files_to_process,\n",
    "        aggregated_correct_path=aggregated_correct_file,\n",
    "        aggregated_recrawl_path=aggregated_recrawl_file,\n",
    "        non_link_acronyms_file=non_link_acronyms_txt_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BƯỚC 1: Xử lý các file input gốc ---\n",
      "\n",
      "--- BƯỚC 2: Gộp kết quả từ các file gốc ---\n",
      "Tổng hợp ban đầu: 155 dòng đúng, 177 dòng cần recrawl.\n",
      "\n",
      "--- BƯỚC 3: Đối chiếu và cập nhật từ các file đã recrawl ---\n",
      "Đã đọc 335 dòng từ các file đã recrawl.\n",
      "Trong đó: 177 dòng đã được sửa (hết note), 158 dòng vẫn còn note.\n",
      "Đã cập nhật danh sách recrawl: loại bỏ các dòng cũ đã xử lý và thêm vào phiên bản mới nhất của các dòng vẫn còn note.\n",
      "\n",
      "--- BƯỚC 4: Hoàn tất và lưu file tổng hợp cuối cùng ---\n",
      "Đã lưu tổng cộng 302 dòng đúng (không có ghi chú) vào './src/conference/evaluate/tri_all_correct_final.csv'.\n",
      "Đã lưu tổng cộng 120 dòng cần recrawl (có ghi chú) vào './src/conference/evaluate/tri_all_recrawl_final.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Hàm split_df_by_note giữ nguyên, nó đã hoạt động đúng\n",
    "def split_df_by_note(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Tách một DataFrame thành hai phần dựa trên sự tồn tại của giá trị trong cột 'note'.\n",
    "    \"\"\"\n",
    "    if 'note' not in df.columns:\n",
    "        print(\"Cảnh báo: Không tìm thấy cột 'note'. Coi như tất cả các dòng đều 'đúng'.\")\n",
    "        return df.copy(), pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    condition_recrawl = df['note'].notna() & (df['note'].astype(str).str.strip() != '')\n",
    "    recrawl_df = df[condition_recrawl].copy()\n",
    "    correct_df = df[~condition_recrawl].copy()\n",
    "    return correct_df, recrawl_df\n",
    "\n",
    "# ==============================================================================\n",
    "# HÀM process_files_by_note ĐÃ ĐƯỢC CẬP NHẬT THEO LOGIC MỚI\n",
    "# ==============================================================================\n",
    "def process_files_by_note(\n",
    "    input_files: list,\n",
    "    output_dir: str,\n",
    "    aggregated_correct_path: str,\n",
    "    aggregated_recrawl_path: str,\n",
    "    recrawled_files: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Xử lý file dựa trên cột 'note', đối chiếu với kết quả đã recrawl,\n",
    "    và cập nhật danh sách recrawl với dữ liệu mới nhất.\n",
    "    \"\"\"\n",
    "    all_correct_dfs = []\n",
    "    all_recrawl_dfs = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # --- BƯỚC 1: XỬ LÝ CÁC FILE INPUT BAN ĐẦU ---\n",
    "    print(\"--- BƯỚC 1: Xử lý các file input gốc ---\")\n",
    "    for file_path in input_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig', na_values=[''], dtype=str).fillna('')\n",
    "            if 'title' in df.columns:\n",
    "                df = df[df['title'].notna() & (df['title'].astype(str).str.strip() != '')].copy()\n",
    "            \n",
    "            if not df.empty:\n",
    "                correct_df, recrawl_df = split_df_by_note(df)\n",
    "                all_correct_dfs.append(correct_df)\n",
    "                all_recrawl_dfs.append(recrawl_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi xử lý file {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # --- BƯỚC 2: GỘP KẾT QUẢ TỪ FILE GỐC ---\n",
    "    print(\"\\n--- BƯỚC 2: Gộp kết quả từ các file gốc ---\")\n",
    "    master_correct_df = pd.concat(all_correct_dfs, ignore_index=True) if all_correct_dfs else pd.DataFrame()\n",
    "    master_recrawl_df = pd.concat(all_recrawl_dfs, ignore_index=True) if all_recrawl_dfs else pd.DataFrame()\n",
    "    print(f\"Tổng hợp ban đầu: {len(master_correct_df)} dòng đúng, {len(master_recrawl_df)} dòng cần recrawl.\")\n",
    "\n",
    "    # --- BƯỚC 3: ĐỐI CHIẾU VÀ CẬP NHẬT TỪ CÁC FILE ĐÃ RECRAWL (LOGIC MỚI) ---\n",
    "    print(\"\\n--- BƯỚC 3: Đối chiếu và cập nhật từ các file đã recrawl ---\")\n",
    "    if recrawled_files:\n",
    "        recrawled_dfs_list = []\n",
    "        for r_file in recrawled_files:\n",
    "            try:\n",
    "                df_recrawled = pd.read_csv(r_file, encoding='utf-8-sig', na_values=[''], dtype=str).fillna('')\n",
    "                if 'title' in df_recrawled.columns:\n",
    "                    df_recrawled = df_recrawled[df_recrawled['title'].notna() & (df_recrawled['title'].astype(str).str.strip() != '')].copy()\n",
    "                if not df_recrawled.empty:\n",
    "                    recrawled_dfs_list.append(df_recrawled)\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi đọc file recrawl {r_file}: {e}\")\n",
    "\n",
    "        if recrawled_dfs_list:\n",
    "            recrawled_master_df = pd.concat(recrawled_dfs_list, ignore_index=True)\n",
    "            print(f\"Đã đọc {len(recrawled_master_df)} dòng từ các file đã recrawl.\")\n",
    "\n",
    "            # 1. Tách dữ liệu recrawl thành 2 phần: phần đã đúng và phần vẫn còn sai\n",
    "            newly_correct_df, still_incorrect_df = split_df_by_note(recrawled_master_df)\n",
    "            print(f\"Trong đó: {len(newly_correct_df)} dòng đã được sửa (hết note), {len(still_incorrect_df)} dòng vẫn còn note.\")\n",
    "\n",
    "            # 2. Cập nhật danh sách CORRECT: thêm các dòng vừa được sửa\n",
    "            if not newly_correct_df.empty:\n",
    "                master_correct_df = pd.concat([master_correct_df, newly_correct_df], ignore_index=True)\n",
    "\n",
    "            # 3. CẬP NHẬT DANH SÁCH RECRAWL THEO LOGIC MỚI\n",
    "            # 3a. Xác định các cột khóa (ưu tiên title và acronym)\n",
    "            subset_keys = ['title']\n",
    "            if 'acronym' in recrawled_master_df.columns and 'acronym' in master_recrawl_df.columns:\n",
    "                subset_keys.append('acronym')\n",
    "\n",
    "            # 3b. Tạo một tập hợp các khóa của TẤT CẢ các dòng đã được recrawl\n",
    "            recrawled_master_df['key_title'] = recrawled_master_df['title'].astype(str).str.strip()\n",
    "            if 'acronym' in subset_keys:\n",
    "                recrawled_master_df['key_acronym'] = recrawled_master_df['acronym'].astype(str).str.strip().fillna('')\n",
    "                key_cols_for_tuple = ['key_title', 'key_acronym']\n",
    "            else:\n",
    "                key_cols_for_tuple = ['key_title']\n",
    "            \n",
    "            recrawled_keys = set(tuple(x) for x in recrawled_master_df[key_cols_for_tuple].values)\n",
    "\n",
    "            # 3c. Trong danh sách recrawl gốc, loại bỏ TẤT CẢ những dòng có trong tập khóa trên\n",
    "            if not master_recrawl_df.empty:\n",
    "                master_recrawl_df['key_title'] = master_recrawl_df['title'].astype(str).str.strip()\n",
    "                if 'acronym' in subset_keys:\n",
    "                    master_recrawl_df['key_acronym'] = master_recrawl_df['acronym'].astype(str).str.strip().fillna('')\n",
    "\n",
    "                mask_to_remove = master_recrawl_df.apply(\n",
    "                    lambda row: tuple(row[key_cols_for_tuple]) in recrawled_keys,\n",
    "                    axis=1\n",
    "                )\n",
    "                \n",
    "                # Giữ lại những dòng từ file gốc mà không được recrawl\n",
    "                recrawl_from_original = master_recrawl_df[~mask_to_remove].copy()\n",
    "                \n",
    "                # 3d. Gộp danh sách trên với danh sách các dòng VẪN CÒN SAI từ file recrawl\n",
    "                master_recrawl_df = pd.concat([recrawl_from_original, still_incorrect_df], ignore_index=True)\n",
    "                \n",
    "                # Dọn dẹp các cột khóa tạm thời\n",
    "                master_recrawl_df.drop(columns=key_cols_for_tuple, inplace=True, errors='ignore')\n",
    "                print(\"Đã cập nhật danh sách recrawl: loại bỏ các dòng cũ đã xử lý và thêm vào phiên bản mới nhất của các dòng vẫn còn note.\")\n",
    "\n",
    "    # --- BƯỚC 4: LOẠI BỎ TRÙNG LẶP LẦN CUỐI VÀ LƯU FILE ---\n",
    "    print(\"\\n--- BƯỚC 4: Hoàn tất và lưu file tổng hợp cuối cùng ---\")\n",
    "\n",
    "    # Hàm trợ giúp để chuẩn hóa và loại bỏ trùng lặp\n",
    "    def finalize_and_save(df, path, subset_keys, file_type):\n",
    "        if df.empty:\n",
    "            pd.DataFrame().to_csv(path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Không có dòng '{file_type}' nào. Đã tạo file rỗng '{path}'.\")\n",
    "            return\n",
    "\n",
    "        # Chuẩn hóa các cột khóa\n",
    "        df['title'] = df['title'].astype(str).str.strip()\n",
    "        if 'acronym' in subset_keys:\n",
    "            df['acronym'] = df['acronym'].astype(str).str.strip()\n",
    "\n",
    "        # Loại bỏ các dòng có khóa rỗng\n",
    "        df.dropna(subset=['title'], inplace=True)\n",
    "        df = df[df['title'] != '']\n",
    "        \n",
    "        final_df = df.drop_duplicates(subset=subset_keys, keep='first')\n",
    "        final_df.to_csv(path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_df)} dòng {file_type} vào '{path}'.\")\n",
    "\n",
    "    # Xác định các cột khóa cuối cùng\n",
    "    final_subset_keys = ['title']\n",
    "    if 'acronym' in master_correct_df.columns and 'acronym' in master_recrawl_df.columns:\n",
    "        final_subset_keys.append('acronym')\n",
    "    \n",
    "    # Lưu file\n",
    "    finalize_and_save(master_correct_df, aggregated_correct_path, final_subset_keys, \"đúng (không có ghi chú)\")\n",
    "    finalize_and_save(master_recrawl_df, aggregated_recrawl_path, final_subset_keys, \"cần recrawl (có ghi chú)\")\n",
    "\n",
    "\n",
    "# --- Cách sử dụng (giữ nguyên như của bạn) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Danh sách các file input ban đầu (ví dụ: các file batch_X_check.csv)\n",
    "    input_csv_files_for_note_check = [\n",
    "        './src/conference/evaluate/batch4.csv',\n",
    "        './src/conference/evaluate/batch5.csv',\n",
    "        './src/conference/evaluate/batch9.csv',\n",
    "        './src/conference/evaluate/batch14.csv',\n",
    "        './src/conference/evaluate/batch15.csv',\n",
    "        './src/conference/evaluate/batch18.csv',\n",
    "        './src/conference/evaluate/batch20.csv',\n",
    "        './src/conference/evaluate/recrawl_all_thang_1_50_lan_1_check.csv',\n",
    "        './src/conference/evaluate/recrawl_all_thang_51_58_lan_1_check.csv',\n",
    "    ]\n",
    "\n",
    "    # 2. Danh sách các file là KẾT QUẢ của lần recrawl trước đó (sau khi đã được sửa)\n",
    "    recrawled_results_files = [\n",
    "        './src/conference/evaluate/recrawl_batch_4_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_5_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_9_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_14_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_15_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_18_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_20_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_all_tri_1_50.csv',\n",
    "        './src/conference/evaluate/recrawl_all_tri_51_100.csv',\n",
    "        './src/conference/evaluate/recrawl_all_tri_101_150.csv',\n",
    "        './src/conference/evaluate/recrawl_all_tri_1_32_lan_2.csv',\n",
    "        './src/conference/evaluate/recrawl_all_tri_lan_3.csv',\n",
    "    ]\n",
    "\n",
    "    # 3. Thư mục để chứa các file output riêng lẻ\n",
    "    individual_output_directory_note = './src/conference/evaluate/tri_check_outputs'\n",
    "\n",
    "    # 4. Đường dẫn cho 2 file tổng hợp cuối cùng\n",
    "    aggregated_correct_file_note = './src/conference/evaluate/tri_all_correct_final.csv'\n",
    "    aggregated_recrawl_file_note = './src/conference/evaluate/tri_all_recrawl_final.csv'\n",
    "\n",
    "    # 5. Gọi hàm xử lý chính\n",
    "    process_files_by_note(\n",
    "        input_files=input_csv_files_for_note_check,\n",
    "        output_dir=individual_output_directory_note,\n",
    "        aggregated_correct_path=aggregated_correct_file_note,\n",
    "        aggregated_recrawl_path=aggregated_recrawl_file_note,\n",
    "        recrawled_files=recrawled_results_files\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu quá trình merge các file CSV...\n",
      "Đã đọc thành công: ./src/conference/evaluate/ALL_BATCHES_correct_by_note.csv (có 34 cột)\n",
      "Đã đọc thành công: ./src/conference/evaluate/tri_all_correct_final.csv (có 29 cột)\n",
      "Đã đọc thành công: ./src/conference/evaluate/correctFiles/batch_1_6_7_10_11_17.csv (có 25 cột)\n",
      "\n",
      "Tìm thấy 24 cột chung ở tất cả các file:\n",
      "Thứ tự cột trong file output sẽ dựa trên file cuối cùng: ./src/conference/evaluate/correctFiles/batch_1_6_7_10_11_17.csv\n",
      "Thứ tự các cột: ['requestId', 'originalRequestId', 'title', 'acronym', 'mainLink', 'cfpLink', 'impLink', 'information', 'conferenceDates', 'year', 'location', 'cityStateProvince', 'country', 'continent', 'type', 'submissionDate', 'notificationDate', 'cameraReadyDate', 'registrationDate', 'otherDate', 'topics', 'publisher', 'summary', 'callForPapers']\n",
      "\n",
      "Đã hợp nhất thành công các file vào './src/conference/evaluate/full.csv'.\n",
      "File kết quả có 841 dòng và 24 cột.\n",
      "\n",
      "--- Bắt đầu kiểm tra định dạng JSON trong các cột 'Date' ---\n",
      "Các cột sẽ được kiểm tra: ['submissionDate', 'notificationDate', 'cameraReadyDate', 'registrationDate', 'otherDate']\n",
      "\n",
      ">>> KIỂM TRA THÀNH CÔNG: Tất cả các giá trị trong các cột 'Date' đều là JSON hợp lệ (hoặc rỗng).\n",
      "\n",
      "--- Hoàn thành chương trình ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "def merge_csv_common_columns_ordered(file_paths, output_filename):\n",
    "    \"\"\"\n",
    "    Đọc nhiều file CSV, tìm các cột chung (phân biệt hoa thường),\n",
    "    sau đó hợp nhất các file chỉ với các cột chung đó.\n",
    "    Thứ tự các cột trong file kết quả sẽ theo thứ tự của các cột chung\n",
    "    trong file CSV cuối cùng trong danh sách input.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list): Danh sách các đường dẫn đầy đủ đến các file CSV.\n",
    "        output_filename (str): Đường dẫn và tên file CSV đầu ra.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True nếu merge thành công, False nếu có lỗi.\n",
    "    \"\"\"\n",
    "    if not file_paths:\n",
    "        print(\"Lỗi: Danh sách đường dẫn file CSV trống. Không có gì để xử lý.\")\n",
    "        return False\n",
    "\n",
    "    dataframes = []\n",
    "    # Bước 1: Đọc tất cả các file CSV vào DataFrame\n",
    "    for fp in file_paths:\n",
    "        try:\n",
    "            # Thêm dtype=str để đảm bảo mọi thứ được đọc vào dưới dạng chuỗi,\n",
    "            # tránh việc pandas tự động chuyển đổi kiểu dữ liệu có thể làm hỏng JSON.\n",
    "            df = pd.read_csv(fp, dtype=str)\n",
    "            dataframes.append(df)\n",
    "            print(f\"Đã đọc thành công: {fp} (có {len(df.columns)} cột)\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Lỗi: Không tìm thấy file tại đường dẫn: {fp}. Bỏ qua file này.\")\n",
    "            continue\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Cảnh báo: File trống hoặc không có header: {fp}. Bỏ qua file này.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc file {fp}: {e}. Bỏ qua file này.\")\n",
    "            continue\n",
    "\n",
    "    if not dataframes:\n",
    "        print(\"Không có file CSV nào được đọc thành công. Không thể thực hiện merge.\")\n",
    "        return False\n",
    "\n",
    "    # Bước 2: Tìm danh sách các cột chung có ở tất cả các file\n",
    "    common_columns_set = set(dataframes[0].columns)\n",
    "    for i in range(1, len(dataframes)):\n",
    "        common_columns_set.intersection_update(set(dataframes[i].columns))\n",
    "\n",
    "    if not common_columns_set:\n",
    "        print(\"Không tìm thấy cột chung nào ở TẤT CẢ các file CSV đã đọc. Không tạo file mới.\")\n",
    "        return False\n",
    "\n",
    "    # Bước 3: Lấy thứ tự cột từ file cuối cùng trong danh sách\n",
    "    last_df = dataframes[-1]\n",
    "    ordered_common_columns = [col for col in last_df.columns if col in common_columns_set]\n",
    "    \n",
    "    if len(ordered_common_columns) != len(common_columns_set):\n",
    "        print(\"Cảnh báo: Thứ tự cột từ file cuối cùng không chứa tất cả các cột chung. Sẽ sắp xếp theo alphabet.\")\n",
    "        ordered_common_columns = sorted(list(common_columns_set))\n",
    "\n",
    "    print(f\"\\nTìm thấy {len(ordered_common_columns)} cột chung ở tất cả các file:\")\n",
    "    print(f\"Thứ tự cột trong file output sẽ dựa trên file cuối cùng: {file_paths[-1]}\")\n",
    "    print(f\"Thứ tự các cột: {ordered_common_columns}\")\n",
    "\n",
    "    # Bước 4: Tạo danh sách các DataFrame mới, chỉ chứa các cột chung\n",
    "    filtered_dataframes = [df[ordered_common_columns] for df in dataframes]\n",
    "\n",
    "    # Bước 5: Hợp nhất tất cả các DataFrame đã lọc lại với nhau\n",
    "    try:\n",
    "        merged_df = pd.concat(filtered_dataframes, ignore_index=True)\n",
    "\n",
    "        # Bước 6: Lưu DataFrame đã hợp nhất vào file CSV mới\n",
    "        merged_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nĐã hợp nhất thành công các file vào '{output_filename}'.\")\n",
    "        print(f\"File kết quả có {merged_df.shape[0]} dòng và {merged_df.shape[1]} cột.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi hợp nhất các DataFrame hoặc ghi file: {e}\")\n",
    "        return False\n",
    "\n",
    "def validate_json_in_date_columns(csv_filepath):\n",
    "    \"\"\"\n",
    "    Kiểm tra các cột kết thúc bằng \"Date\" trong một file CSV để xem mỗi ô\n",
    "    có chứa một chuỗi JSON hợp lệ hay không.\n",
    "\n",
    "    Args:\n",
    "        csv_filepath (str): Đường dẫn đến file CSV cần kiểm tra.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Bắt đầu kiểm tra định dạng JSON trong các cột 'Date' ---\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filepath, dtype=str).fillna('') # Đọc mọi thứ dạng chuỗi, và thay NaN bằng chuỗi rỗng\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file '{csv_filepath}' để kiểm tra.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file '{csv_filepath}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Tìm các cột có tên kết thúc bằng \"Date\"\n",
    "    date_columns = [col for col in df.columns if col.endswith(\"Date\")]\n",
    "\n",
    "    if not date_columns:\n",
    "        print(\"Không tìm thấy cột nào kết thúc bằng 'Date' để kiểm tra.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Các cột sẽ được kiểm tra: {date_columns}\")\n",
    "\n",
    "    invalid_entries = []\n",
    "    # Lặp qua từng cột cần kiểm tra\n",
    "    for col_name in date_columns:\n",
    "        # Lặp qua từng dòng (index và value) trong cột đó\n",
    "        for index, value in df[col_name].items():\n",
    "            # Bỏ qua các ô rỗng hoặc chỉ có khoảng trắng\n",
    "            if not value or value.isspace():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Thử phân tích chuỗi thành JSON\n",
    "                json.loads(value)\n",
    "            except json.JSONDecodeError:\n",
    "                # Nếu thất bại, ghi lại thông tin lỗi\n",
    "                invalid_entries.append({\n",
    "                    \"row_index\": index,\n",
    "                    \"column\": col_name,\n",
    "                    \"value\": value\n",
    "                })\n",
    "\n",
    "    # In kết quả\n",
    "    if not invalid_entries:\n",
    "        print(\"\\n>>> KIỂM TRA THÀNH CÔNG: Tất cả các giá trị trong các cột 'Date' đều là JSON hợp lệ (hoặc rỗng).\")\n",
    "    else:\n",
    "        print(f\"\\n>>> KIỂM TRA THẤT BẠI: Tìm thấy {len(invalid_entries)} giá trị không phải là JSON hợp lệ:\")\n",
    "        print(\"-\" * 50)\n",
    "        for error in invalid_entries:\n",
    "            print(f\"  - Dòng (chỉ số 0): {error['row_index']}\")\n",
    "            print(f\"    Cột              : '{error['column']}'\")\n",
    "            print(f\"    Giá trị không hợp lệ: {error['value']}\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "# --- Cách sử dụng ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Đặt danh sách các đường dẫn đến file CSV của bạn vào đây.\n",
    "    input_files = [\n",
    "        './src/conference/evaluate/ALL_BATCHES_correct_by_note.csv',\n",
    "        './src/conference/evaluate/tri_all_correct_final.csv',\n",
    "        './src/conference/evaluate/correctFiles/batch_1_6_7_10_11_17.csv'\n",
    "    ]\n",
    "\n",
    "    # Đặt tên cho file CSV kết quả đầu ra\n",
    "    output_merged_file = './src/conference/evaluate/full.csv'\n",
    "\n",
    "    # # Gọi hàm để thực hiện việc merge\n",
    "    print(\"Bắt đầu quá trình merge các file CSV...\")\n",
    "    merge_successful = merge_csv_common_columns_ordered(input_files, output_merged_file)\n",
    "\n",
    "    # Nếu việc merge thành công, thực hiện kiểm tra file kết quả\n",
    "    if merge_successful:\n",
    "        validate_json_in_date_columns(output_merged_file)\n",
    "\n",
    "    print(\"\\n--- Hoàn thành chương trình ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BƯỚC 1: ĐỌC DỮ LIỆU ---\n",
      "Đang đọc file full.csv từ: ./src/conference/evaluate/full.csv\n",
      "Đã đọc full.csv thành công. 5 dòng đầu tiên:\n",
      "                      requestId originalRequestId                                                                                                                                                     title        acronym                                                  mainLink                                                                               cfpLink                                                   impLink                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  information          conferenceDates    year                                            location     cityStateProvince        country      continent     type                                                                                                                                                                                                                                 submissionDate                                                                                                                                                                                                                                            notificationDate                                                                                                                                        cameraReadyDate registrationDate                            otherDate                                                                                                                                                                                                                                                                                                                                                                                                                                                      topics     publisher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   callForPapers\n",
      "0  req-conf-1751537158192-i48ha               NaN  International Workshop on Approximation Algorithms for Combinatorial Optimization Problems and International Conference on Randomization and Computation  APPROX/RANDOM                             https://approxconference.com/  https://approxconference.com/wp-content/uploads/2025/03/approx-random-2025-cfp-1.pdf                             https://approxconference.com/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Conference dates: August 11 - 13, 2025\\nYear: 2025\\nLocation: UC Berkeley, Berkeley, California, USA\\nCity-State-Province: Berkeley, California\\nCountry: United States\\nContinent: North America\\nType: Offline\\nSubmission Date.Submissions: May 8, 2025\\nNotification Date.Notifications: July 1, 2025\\nCamera-ready Date.Camera ready: July 15, 2025\\nTopics: Approximation Algorithms, Hardness of Approximation, Small Space, Sub-linear Time and Streaming Algorithms, Online Algorithms, Approaches that go beyond worst-case analysis, Distributed and Parallel Approximation, Embeddings and Metric Space Methods, Mathematical Programming Methods, Spectral Methods, Combinatorial Optimization, Algorithmic Game Theory, Mechanism Design and Economics, Computational Geometric Problems, Approximate Learning     August 11 - 13, 2025  2025.0              UC Berkeley, Berkeley, California, USA  Berkeley, California  United States  North America  Offline                                                                                                                                                                                                                  {\"Submissions\":\"May 8, 2025\"}                                                                                                                                                                                                                            {\"Notifications\":\"July 1, 2025\"}                                                                                                                       {\"Camera ready\":\"July 15, 2025\"}               {}                                   {}  Approximation Algorithms, Hardness of Approximation, Small Space, Sub-linear Time and Streaming Algorithms, Online Algorithms, Approaches that go beyond worst-case analysis, Distributed and Parallel Approximation, Embeddings and Metric Space Methods, Mathematical Programming Methods, Spectral Methods, Combinatorial Optimization, Algorithmic Game Theory, Mechanism Design and Economics, Computational Geometric Problems, Approximate Learning  No publisher                                                                                                                                                                                                                                                                                                                                                             The International Conference on Approximation Algorithms for Combinatorial Optimization Problems (APPROX 2025), co-located with RANDOM 2025, will take place at UC Berkeley, California, USA, from August 11-13, 2025. The conference focuses on research in approximation algorithms for combinatorial optimization problems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          # Call for Papers\\n\\nThe **International Conference on Approximation Algorithms for Combinatorial Optimization Problems (APPROX 2025)**, co-located with **RANDOM 2025**, will take place at **UC Berkeley, Berkeley, California, USA, on August 11-13, 2025**.\\n\\nWe invite submissions of papers presenting original research in all areas related to approximation algorithms for combinatorial optimization problems.\\n\\n## Submission Guidelines\\n\\nSubmissions, in PDF, should start with a title page containing the title of the paper, each author’s name, affiliation, and e-mail address, and a 1-2 paragraph abstract summarizing the paper’s contributions. The title page should be followed by a technical exposition on single-spaced, single-column pages, letter-size paper, using page numbers, at least 1-inch margins all around, and at least 11-point font. The first 10 pages, following the title page, should contain a clear presentation of the main technical and conceptual ideas underlying the results, including the motivation behind the paper and a clear comparison with related work (not including the references). The submission should be accessible to a wide variety of researchers in theoretical computer science and discrete mathematics. There is no page limit, but any material beyond the title page and the following 10 pages will be read at the sole discretion of the program committee.\\n\\nWork that has been previously published in another conference proceedings or journal, or which will be published before the end of the conference, will not be considered for acceptance. Simultaneous submission of the same (or an overlapping) paper to RANDOM/APPROX and to another conference with published proceedings is not allowed.\\n\\nYou can find the official call for papers [here](https://approxconference.com/wp-content/uploads/2025/03/approx-random-2025-cfp-1.pdf).\\n\\n## Important Deadlines\\n\\n1.  **Submissions:** May 8, 2025, AoE Time Zone\\n2.  **Notifications:** July 1, 2025\\n3.  **Camera ready:** July 15, 2025\\n\\n## Scope\\n\\nPapers are solicited in all research areas related to approximation, including but not limited to:\\n\\n*   approximation algorithms\\n*   hardness of approximation\\n*   small space, sub-linear time and streaming algorithms\\n*   online algorithms\\n*   approaches that go beyond worst-case analysis\\n*   distributed and parallel approximation​\\n*   embeddings and metric space methods\\n*   mathematical programming methods\\n*   spectral methods\\n*   combinatorial optimization\\n*   algorithmic game theory, mechanism design and economics\\n*   computational geometric problems\\n*   approximate learning\\n\\n## Program Committee\\n\\n*   Jose Correa, Universidad de Chile\\n*   Yotam Dikstein, IAS\\n*   Michael Dinitz, Johns Hopkins University\\n*   Alina Ene (PC Chair), Boston University\\n*   D Ellis Hershkowitz, Brown University\\n*   Billy Jin, University of Chicago\\n*   Nathan Klein, Boston University\\n*   Jochen Koenemann, University of Waterloo\\n*   Jason Li, CMU\\n*   Quanquan Liu, Yale University\\n*   Vasilis Livanos, Universidad de Chile\\n*   Viswanath Nagarajan, University of Michigan\\n*   Martin Naegele, ETH Zurich\\n*   Liren Shan, TTI Chicago\\n*   Zihan Tan, Rutgers University\\n*   Vera Traub, ETH Zurich\\n*   Laura Vargas Koch, RWTH Aachen University\\n*   Samson Zhou, Texas A&M University\n",
      "1  req-conf-1751537158192-i48ha               NaN                                                                                                                                          Web and Big Data          APWEB                             https://apweb2025.sau.edu.cn/                                     https://apweb2025.sau.edu.cn/call_for_papers.html          https://apweb2025.sau.edu.cn/important_date.html  Conference dates: August 28-30, 2025\\nYear: 2025\\nLocation: Shenyang, China\\nCity-State-Province: Shenyang\\nCountry: China\\nContinent: Asia\\nType: Offline\\nSubmission Date.Full paper submission (1st Round): March 9, 2025\\nSubmission Date.Full paper submission (2nd Round): May 18, 2025\\nSubmission Date.Full paper submission (Industry Papers and Demo Papers): May 18, 2025\\nSubmission Date.Proposal submission (Workshop Proposals): April 11, 2025\\nNotification Date.Acceptance Notification (1st Round): April 21, 2025\\nNotification Date.Acceptance Notification (2nd Round): June 23, 2025\\nNotification Date.Acceptance Notification (Industry Papers and Demo Papers): June 23, 2025\\nNotification Date.Acceptance Notification (Workshop Proposals): April 21, 2025\\nCamera-ready Date.Camera Ready (1st Round): May 18, 2025\\nCamera-ready Date.Camera Ready (2nd Round): July 6, 2025\\nCamera-ready Date.Camera Ready (Industry Papers and Demo Papers): July 6, 2025\\nOther Date.Workshop Date: August 28, 2025\\nTopics: Web technologies, data management, web-based systems, semantic web, web mining, social networks, database systems, big data, data mining, information retrieval, artificial intelligence, machine learning, cloud computing, distributed systems, security and privacy\\nPublisher: Springer       August 28-30, 2025  2025.0                                     Shenyang, China              Shenyang          China           Asia  Offline  {\"Full paper submission (1st Round)\":\"March 9, 2025\",\"Full paper submission (2nd Round)\":\"May 18, 2025\",\"Full paper submission (Industry Papers and Demo Papers)\":\"May 18, 2025\",\"Proposal submission (Workshop Proposals)\":\"April 11, 2025\"}  {\"Acceptance Notification (1st Round)\":\"April 21, 2025\",\"Acceptance Notification (2nd Round)\":\"June 23, 2025\",\"Acceptance Notification (Industry Papers and Demo Papers)\":\"June 23, 2025\",\"Acceptance Notification (Workshop Proposals)\":\"April 21, 2025\"}  {\"Camera Ready (1st Round)\":\"May 18, 2025\",\"Camera Ready (2nd Round)\":\"July 6, 2025\",\"Camera Ready (Industry Papers and Demo Papers)\":\"July 6, 2025\"}               {}  {\"Workshop Date\":\"August 28, 2025\"}                                                                                                                                                                                      Web technologies, data management, web-based systems, semantic web, web mining, social networks, database systems, big data, data mining, information retrieval, artificial intelligence, machine learning, cloud computing, distributed systems, security and privacy      Springer  The 9th APWeb-WAIM joint International Conference on Web and Big Data (APWeb-WAIM 2025) will be held in Shenyang, China, from August 28-30, 2025. This conference merges the Asia-Pacific Web Conference (APWeb) and the International Conference on Web-Age Information Management (WAIM), providing a platform for researchers and practitioners to share ideas in web technologies, data management, and big data. The conference is recognized as a CCF-C conference and is known for attracting over 300 participants globally. Proceedings will be published by Springer in Lecture Notes in Computer Science (LNCS) and Communications in Computer and Information Science (CCIS).  # Call for Papers: APWeb-WAIM 2025\\n\\nThe 9th APWeb-WAIM Joint International Conference on Web and Big Data (APWeb-WAIM 2025) will be held in Shenyang, China, from **August 28-30, 2025**. This premier annual event aims to attract professionals from various communities related to Web and Big Data to share and exchange ideas, experience, and techniques in areas including Web technologies, database systems, information management, software engineering, and big data.\\n\\n## Topics of Interest\\n\\n*   Advanced database and Web applications\\n*   Big data management and analytics\\n*   Block chain and distributed systems\\n*   Cloud computing and Crowd sourcing\\n*   Content management\\n*   Data and information quality\\n*   Data management on new hardware\\n*   Data mining\\n*   Data warehousing and OLAP\\n*   Data security and privacy\\n*   E-learning analytics\\n*   Graph data management, RDF, social networks\\n*   Information retrieval\\n*   Information security\\n*   Knowledge extraction and managements\\n*   LLM for data management\\n*   Machine Learning and security\\n*   Multimedia information systems\\n*   Parallel and distributed data management\\n*   Query processing and optimization\\n*   Semantic Web and ontology\\n*   Sensing data management\\n*   Sensor networks\\n*   Spatial and temporal databases\\n*   Streams, complex event processing\\n*   Text database, keyword search\\n*   Trusted and interpretable AI\\n*   Uncertain data\\n*   Web advertising and community analysis\\n*   Web information quality and fusion\\n*   Web security\\n*   Web search and meta-search\\n*   Web service management\\n*   XML and semi-structured data\\n\\n## Important Dates\\n\\nAll deadlines are **23:59 Anywhere on Pacific time**.\\n\\n### Research Papers\\n\\n**1st Round:**\\n\\n*   **Full paper submission:** March 2, 2025 → **March 9, 2025**\\n*   **Acceptance Notification:** **April 21, 2025**\\n*   **Camera Ready:** **May 18, 2025**\\n\\n**2nd Round:**\\n\\n*   **Full paper submission:** May 4, 2025 → **May 18, 2025**\\n*   **Acceptance Notification:** **June 23, 2025**\\n*   **Camera Ready:** **July 6, 2025**\\n\\n### Industry Papers and Demo Papers\\n\\n*   **Full paper submission:** May 11, 2025 → **May 18, 2025**\\n*   **Acceptance Notification:** **June 23, 2025**\\n*   **Camera Ready:** **July 6, 2025**\\n\\n### Workshop Proposals\\n\\n*   **Proposal submission:** **April 11, 2025**\\n*   **Acceptance Notification:** **April 21, 2025**\\n\\n### Workshop Papers\\n\\n*   **Full paper submission:** Please see the workshop webpage\\n*   **Acceptance Notification:** Please see the workshop webpage\\n*   **Camera Ready:** Please see the workshop webpage\\n*   **Workshop Date:** August 28, 2025\\n\\n## Submission Guidelines\\n\\n*   All submissions must be in English and conform to the Springer LNCS proceedings format.\\n*   **Page Limits:** 15 pages for regular papers (including references). A maximum of 4 extra pages are allowed at an additional cost.\\n*   **Review Process:** Submitted papers will undergo a \"double-blind\" review process. Authors must ensure anonymity, with no author names, affiliations, funding, or other identifying information appearing on the title page or elsewhere in the paper.\\n*   **Resubmission:** Submissions rejected in the 1st round cannot be resubmitted for the 2nd round.\\n*   **Authorship:** Authors must provide the complete and final list of authors at the submission stage. No addition, removal, or change in the order of authors is allowed after submission.\\n\\n## Submission Website\\n\\n[https://cmt3.research.microsoft.com/APWebWAIM2025](https://cmt3.research.microsoft.com/APWebWAIM2025)\\n\\n## Formatting Template\\n\\nPlease use the Springer LNCS (Lecture Notes in Computer Science) format templates available at: [https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines](https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines)\\n\\n## Publication\\n\\n*   The proceedings of the main conference and workshops will be published by Springer in **Lecture Notes in Computer Science (LNCS)** and **Communications in Computer and Information Science (CCIS)** respectively.\\n*   Authors of selected excellent papers will be recommended to SCI indexed journals, including **World Wide Web Journal** (IF 3.7, JCR Q2), **ARRAY** (IF 2.7, JCR Q2), and **Data Science Engineering** (IF 5.1, JCR Q1), for fast-track publication in special issues.\\n\\n## Contact Us\\n\\nAPWeb 2025 office: [apwebwaim2025@sau.edu.cn](mailto:apwebwaim2025@sau.edu.cn)\n",
      "2  req-conf-1751537158192-i48ha               NaN                                                                                                  Asia-Pacific Network Operations and Management Symposium         APNOMS                 https://sites.google.com/view/apnoms2025/                              https://sites.google.com/view/apnoms2025/call-for-papers  https://sites.google.com/view/apnoms2025/call-for-papers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Conference dates: September 22 - 24, 2025\\nYear: 2025\\nLocation: National Sun Yat-sen University, Kaohsiung, Taiwan\\nCity-State-Province: Kaohsiung\\nCountry: Taiwan\\nContinent: Asia\\nType: Hybrid\\nSubmission Date.Paper submission deadline: June 23, 2025\\nNotification Date.Notification of acceptance: August 4, 2025\\nCamera-ready Date.Camera-ready paper submission: August 15, 2025\\nTopics: Network Operations, Management, 6G Networks  September 22 - 24, 2025  2025.0  National Sun Yat-sen University, Kaohsiung, Taiwan             Kaohsiung         Taiwan           Asia   Hybrid                                                                                                                                                                                                  {\"Paper submission deadline\":\"June 23, 2025\"}                                                                                                                                                                                                             {\"Notification of acceptance\":\"August 4, 2025\"}                                                                                                    {\"Camera-ready paper submission\":\"August 15, 2025\"}               {}                                   {}                                                                                                                                                                                                                                                                                                                                                                                                                 Network Operations, Management, 6G Networks  No publisher                                                                                                                                                                                                                                        The 25th Asia-Pacific Network Operations and Management Symposium (APNOMS 2025) will be held from September 22-24, 2025, at the National Sun Yat-sen University in Kaohsiung, Taiwan. This premier conference on network operations and management in the Asia-Pacific region will adopt a hybrid system, allowing for both online and on-site participation, under the theme 'Towards Smarter and Pervasive Management in the Era of 6G Networks'.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       # APNOMS 2025: Call for Papers\\n\\nThe **25th Asia-Pacific Network Operations and Management Symposium (APNOMS 2025)** will be held from **September 22-24, 2025**, at the **National Sun Yat-sen University, Kaohsiung, Taiwan**. The symposium will feature a **hybrid system** (online and on-site) participation option.\\n\\nThe theme for APNOMS 2025 is \"**Towards Smarter and Pervasive Management in the Era of 6G Networks**\".\\n\\nAPNOMS is a premier conference on **network operations and management** in the Asia-Pacific region, providing a forum for research, standards, development, and user communities.\\n\\n## Important Dates\\n\\n*   **Paper submission deadline:** ~~May 26, 2025~~ ~~June 9, 2025~~ **June 23, 2025** (Final Extension, Firm)\\n*   **Notification of acceptance:** ~~July 14, 2025~~ **August 4, 2025**\\n*   **Camera-ready paper submission:** ~~August 4, 2025~~ **August 15, 2025**\\n\\n## Further Information\\n\\nFor detailed information regarding submission guidelines, manuscript formatting, contribution types, and specific topics of interest, please refer to the official conference links:\\n*   [Call for Papers](/view/apnoms2025/call-for-papers)\\n*   [Call for Tutorials](https://drive.google.com/file/d/16qJ9FU4OhfYgWnvFp_kOZcpR4z_H8whI/view?usp=drive_link)\\n*   [Manuscript Guidelines](/view/apnoms2025/authors/manuscript-guidelines)\\n*   [Presentation Instructions](/view/apnoms2025/authors/presentation-instructions)\n",
      "3  req-conf-1751537158192-i48ha               NaN                                                                                        International Conference on Availability, Reliability and Security           ARES                          https://2025.ares-conference.eu/                                                 https://2025.ares-conference.eu/calls                          https://2025.ares-conference.eu/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Conference dates: August 11-14, 2025\\nYear: 2025\\nLocation: Ghent, Belgium\\nCity-State-Province: Ghent\\nCountry: Belgium\\nContinent: Europe\\nType: Offline\\nSubmission Date.Extended Submission Deadline Main Conference: March 11, 2025\\nSubmission Date.Submission Deadline Workshops vary from workshop to workshop: April 15 - May 16, 2025\\nNotification Date.Author Notification Main Conference: May 2, 2025\\nNotification Date.Author Notification Workshops: May 30, 2025\\nCamera-ready Date.Camera Read Upload: June 13, 2025\\nTopics: dependability, computer and information security, IT security and privacy, safety, confidentiality, integrity, maintainability, security\\nPublisher: IEEE       August 11-14, 2025  2025.0                                      Ghent, Belgium                 Ghent        Belgium         Europe  Offline                                                                                     {\"Extended Submission Deadline Main Conference\":\"March 11, 2025\",\"Submission Deadline Workshops vary from workshop to workshop\":\"April 15 - May 16, 2025\"}                                                                                                                                                        {\"Author Notification Main Conference\":\"May 2, 2025\",\"Author Notification Workshops\":\"May 30, 2025\"}                                                                                                                 {\"Camera Read Upload\":\"June 13, 2025\"}               {}                                   {}                                                                                                                                                                                                                                                                                                                    dependability, computer and information security, IT security and privacy, safety, confidentiality, integrity, maintainability, security          IEEE                                                                                                                                                                                                                                                                                                                           The 20th International Conference on Availability, Reliability and Security (ARES 2025) will be held in Ghent, Belgium, from August 11-14, 2025. Established in 2006, ARES focuses on rigorous and novel research in dependability, computer, and information security. The conference also features co-located events, workshops, and an EU Projects Symposium.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    No call for papers available\n",
      "4  req-conf-1751537158192-i48ha               NaN                                            International Conference on Probabilistic, Combinatorial, and Asymptotic Methods in the Analysis of Algorithms           AofA  http://www.fields.utoronto.ca/activities/24-25/AofA-2025                                                                                   NaN                                                       NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Conference dates: May 5 - 9, 2025\\nYear: 2025\\nLocation: Fields Institute, Room 230, Toronto, Canada\\nCity-State-Province: Toronto, Ontario\\nCountry: Canada\\nContinent: North America\\nType: Offline\\nTopics: Analysis of Algorithms, data structures, graphs, networks, random branching processes, permutations, trees, strings, discrete mathematics, combinatorics, probability theory, analytic number theory, asymptotic analysis, complexity theory\\nInvited Speakers: Omer Angel, Yuliy Baryshnikov, Anna Ben-Hamou, Laura Eslava, Vincent Jugé, Greta Panova, Sebastian Wild, Karen Yeats          May 5 - 9, 2025  2025.0         Fields Institute, Room 230, Toronto, Canada      Toronto, Ontario         Canada  North America  Offline                                                                                                                                                                                                                                             {}                                                                                                                                                                                                                                                          {}                                                                                                                                                     {}               {}                                   {}                                                                                                                                                                                                                Analysis of Algorithms, data structures, graphs, networks, random branching processes, permutations, trees, strings, discrete mathematics, combinatorics, probability theory, analytic number theory, asymptotic analysis, complexity theory  No publisher                                                                                                                                                                                                                                            The International Conference on Probabilistic, Combinatorial, and Asymptotic Methods for the Analysis of Algorithms (AofA 2025) will be held from May 5-9, 2025, at The Fields Institute in Toronto, Canada. This conference, the 36th edition of the AofA series, focuses on the precise understanding of asymptotic, average-case characteristics of algorithms and data structures using probabilistic, combinatorial, and analytic methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        # AofA 2025: Call for Papers\\n\\nThe **International Conference on Probabilistic, Combinatorial, and Asymptotic Methods for the Analysis of Algorithms (AofA 2025)** will be held from **May 5 to May 9, 2025**, at **The Fields Institute, Room 230, Toronto, Canada**.\\n\\nThis conference is the 36th edition of the AofA series and the second one held in Canada.\\n\\n## About Analysis of Algorithms (AofA)\\n\\nAnalysis of Algorithms (AofA) is a field at the boundary of computer science and mathematics. Its goal is to obtain a precise understanding of the asymptotic, average-case characteristics of algorithms and data structures, employing a unifying theme of probabilistic, combinatorial, and analytic methods. The objects studied include random branching processes, graphs, permutations, trees, and strings.\\n\\n## Topics of Interest\\n\\nThe conference aims to study discrete objects that appear as data structures or algorithms using mathematical methods, particularly probabilistic, combinatorial, and asymptotic methods. Topics include, but are not limited to:\\n\\n*   Properties of large random data structures\\n*   Probabilistic methods for the analysis of algorithms\\n*   Combinatorial methods for the analysis of algorithms\\n*   Analytic tools for the analysis of algorithms\\n*   Average case analysis of classical or new algorithms\\n*   Analytic and enumerative combinatorics\\n*   Random trees and graphs\\n*   Branching processes\\n*   Stochastic processes in relation to random discrete structures\\n*   Random walks\\n*   Discrete probabilities\\n*   Random generation of combinatorial structures\\n*   Performance evaluation\\n\\n## Invited Speakers\\n\\n*   Omer Angel (University of British Columbia)\\n*   Yuliy Baryshnikov (University of Illinois Urbana-Champaign)\\n*   Anna Ben-Hamou (Sorbonne Université)\\n*   Laura Eslava (UNAM)\\n*   Vincent Jugé (Université Gustave Eiffel and CNRS)\\n*   Greta Panova (University of Southern California)\\n*   Sebastian Wild (University of Marburg)\\n*   Karen Yeats (University of Waterloo)\\n\\n## Participation\\n\\nParticipation is encouraged from students and early-career researchers, both domestic and international.\\n\\n## Organizing Committee\\n\\n*   Stephen Melczer - University of Waterloo\\n*   Daniel Panario - Carleton University\\n*   Shane Liu - Toronto Metropolitan University\\n\\n## Registration\\n\\n[Register Here](SubmitACHI25.html) (Note: This link appears to be from a different conference in the provided text. Please refer to the Fields Institute website for actual registration details.)\n",
      "Tổng số dòng trong full.csv: 783\n",
      "\n",
      "Đang đọc file CORE_2023.csv từ: ./src/conference/csv/CORE_2023.csv\n",
      "Đã đọc CORE_2023.csv thành công. 5 dòng đầu tiên (cột 1 là title, cột 2 là acronym):\n",
      "      0                                                                                                                                                               title acronym         3   4    5     6     7       8\n",
      "0  1772                                                                                                       Symposium of Asian Association for Algorithms and Computation    AAAC  CORE2023   C   No  4613   NaN     NaN\n",
      "1  1629                                                                                         National Conference of the American Association for Artificial Intelligence    AAAI  CORE2023  A*  Yes  4602  4603  4611.0\n",
      "2   356                                                                                                     Conference on Algorithmic Aspects in Information and Management    AAIM  CORE2023   C   No  4613   NaN     NaN\n",
      "3   922  International Joint Conference on Autonomous Agents and Multiagent Systems (previously the International Conference on Multiagent Systems, ICMAS, changed in 2000)   AAMAS  CORE2023  A*  Yes  4602   NaN     NaN\n",
      "4   882             International Conference Abstract State Machines, Alloy, B, TLA, VDM, and Z (Previously International Conference of B and Z Users, ZB, changed in 2008)     ABZ  CORE2023   C   No  4612  4613     NaN\n",
      "Tổng số dòng trong CORE_2023.csv: 955\n",
      "\n",
      "--- BƯỚC 2: CHUẨN HÓA DỮ LIỆU ---\n",
      "Áp dụng hàm normalize_text cho cột 'title' và 'acronym' của cả hai DataFrame.\n",
      "\n",
      "5 dòng đầu tiên của full.csv sau khi chuẩn hóa:\n",
      "                                                                                                                                                      title                                                                                                                                          normalized_title        acronym normalized_acronym\n",
      "0  International Workshop on Approximation Algorithms for Combinatorial Optimization Problems and International Conference on Randomization and Computation  International Workshop on Approximation Algorithms for Combinatorial Optimization Problems and International Conference on Randomization and Computation  APPROX/RANDOM      APPROX/RANDOM\n",
      "1                                                                                                                                          Web and Big Data                                                                                                                                          Web and Big Data          APWEB              APWEB\n",
      "2                                                                                                  Asia-Pacific Network Operations and Management Symposium                                                                                                  Asia-Pacific Network Operations and Management Symposium         APNOMS             APNOMS\n",
      "3                                                                                        International Conference on Availability, Reliability and Security                                                                                        International Conference on Availability, Reliability and Security           ARES               ARES\n",
      "4                                            International Conference on Probabilistic, Combinatorial, and Asymptotic Methods in the Analysis of Algorithms                                            International Conference on Probabilistic, Combinatorial, and Asymptotic Methods in the Analysis of Algorithms           AofA               AofA\n",
      "\n",
      "5 dòng đầu tiên của CORE_2023.csv sau khi chuẩn hóa:\n",
      "                                                                                                                                                                title                                                             normalized_title acronym normalized_acronym\n",
      "0                                                                                                       Symposium of Asian Association for Algorithms and Computation                Symposium of Asian Association for Algorithms and Computation    AAAC               AAAC\n",
      "1                                                                                         National Conference of the American Association for Artificial Intelligence  National Conference of the American Association for Artificial Intelligence    AAAI               AAAI\n",
      "2                                                                                                     Conference on Algorithmic Aspects in Information and Management              Conference on Algorithmic Aspects in Information and Management    AAIM               AAIM\n",
      "3  International Joint Conference on Autonomous Agents and Multiagent Systems (previously the International Conference on Multiagent Systems, ICMAS, changed in 2000)   International Joint Conference on Autonomous Agents and Multiagent Systems   AAMAS              AAMAS\n",
      "4             International Conference Abstract State Machines, Alloy, B, TLA, VDM, and Z (Previously International Conference of B and Z Users, ZB, changed in 2008)  International Conference Abstract State Machines, Alloy, B, TLA, VDM, and Z     ABZ                ABZ\n",
      "\n",
      "--- BƯỚC 3: TẠO KHÓA SO SÁNH (KEY) ---\n",
      "Tạo cột 'key' từ cặp (normalized_title, normalized_acronym) cho cả hai DataFrame.\n",
      "\n",
      "5 dòng đầu tiên của full.csv với cột 'key':\n",
      "                                                                                                                                                      title        acronym                                                                                                                                                                        key\n",
      "0  International Workshop on Approximation Algorithms for Combinatorial Optimization Problems and International Conference on Randomization and Computation  APPROX/RANDOM  (International Workshop on Approximation Algorithms for Combinatorial Optimization Problems and International Conference on Randomization and Computation, APPROX/RANDOM)\n",
      "1                                                                                                                                          Web and Big Data          APWEB                                                                                                                                                  (Web and Big Data, APWEB)\n",
      "2                                                                                                  Asia-Pacific Network Operations and Management Symposium         APNOMS                                                                                                         (Asia-Pacific Network Operations and Management Symposium, APNOMS)\n",
      "3                                                                                        International Conference on Availability, Reliability and Security           ARES                                                                                                 (International Conference on Availability, Reliability and Security, ARES)\n",
      "4                                            International Conference on Probabilistic, Combinatorial, and Asymptotic Methods in the Analysis of Algorithms           AofA                                                     (International Conference on Probabilistic, Combinatorial, and Asymptotic Methods in the Analysis of Algorithms, AofA)\n",
      "\n",
      "5 dòng đầu tiên của CORE_2023.csv với cột 'key':\n",
      "                                                                                                                                                                title acronym                                                                                  key\n",
      "0                                                                                                       Symposium of Asian Association for Algorithms and Computation    AAAC                (Symposium of Asian Association for Algorithms and Computation, AAAC)\n",
      "1                                                                                         National Conference of the American Association for Artificial Intelligence    AAAI  (National Conference of the American Association for Artificial Intelligence, AAAI)\n",
      "2                                                                                                     Conference on Algorithmic Aspects in Information and Management    AAIM              (Conference on Algorithmic Aspects in Information and Management, AAIM)\n",
      "3  International Joint Conference on Autonomous Agents and Multiagent Systems (previously the International Conference on Multiagent Systems, ICMAS, changed in 2000)   AAMAS  (International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS)\n",
      "4             International Conference Abstract State Machines, Alloy, B, TLA, VDM, and Z (Previously International Conference of B and Z Users, ZB, changed in 2008)     ABZ   (International Conference Abstract State Machines, Alloy, B, TLA, VDM, and Z, ABZ)\n",
      "\n",
      "--- BƯỚC 4: TẠO TẬP HỢP CÁC KEY TỪ full.csv ---\n",
      "Tổng số key duy nhất trong full.csv: 772\n",
      "Một vài key mẫu từ full.csv (đã chuẩn hóa):\n",
      "  - ('International Symposium on Modelling and Optimization in Mobile, Ad Hoc, and Wireless Networks', 'WiOpt')\n",
      "  - ('Developments in Language Theory', 'DLT')\n",
      "  - ('International Conference on Model Driven Engineering Languages and Systems', 'MODELS')\n",
      "  - ('International Conference on Hardware/Software Codesign and System Synthesis', 'CODES+ISSS')\n",
      "  - ('Mobile and Ubiquitous Multimedia', 'MUM')\n",
      "\n",
      "--- BƯỚC 5: LỌC CÁC DÒNG CHỈ CÓ TRONG CORE_2023.csv ---\n",
      "Lọc df_core để tìm các dòng mà 'key' của chúng KHÔNG có trong tập hợp key của full.csv.\n",
      "\n",
      "Tìm thấy 183 dòng chỉ có trong CORE_2023.csv.\n",
      "5 dòng đầu tiên của kết quả (các dòng chỉ có trong CORE_2023.csv):\n",
      "       0                                                                                                                                                 title acronym         3               4    5     6     7   8                                                     normalized_title normalized_acronym                                                                          key\n",
      "7   2295                                                                                   International Workshop on Algebraic and Combinatorial Coding Theory    ACCT  CORE2023        National  Yes  4613  4604 NaN  International Workshop on Algebraic and Combinatorial Coding Theory               ACCT  (International Workshop on Algebraic and Combinatorial Coding Theory, ACCT)\n",
      "8    167                                                                                                                   Asian Conference on Computer Vision    ACCV  CORE2023               B   No  4603   NaN NaN                                  Asian Conference on Computer Vision               ACCV                                  (Asian Conference on Computer Vision, ACCV)\n",
      "9     23  ACM International Conference on Advances in Computer Entertainment (merged with DIMEA, Digital Interactive Media in Entertainment and Arts, in 2009)     ACE  CORE2023               C   No  4607  4608 NaN   ACM International Conference on Advances in Computer Entertainment                ACE    (ACM International Conference on Advances in Computer Entertainment, ACE)\n",
      "14   212                                                                                           Australasian Conference on Information Security and Privacy   ACISP  CORE2023  Australasian B  Yes  4604   NaN NaN          Australasian Conference on Information Security and Privacy              ACISP         (Australasian Conference on Information Security and Privacy, ACISP)\n",
      "23   189                                                                                                 Asilomar Conference on Signals, Systems and Computing   ACSSC  CORE2023   National: USA   No  4606   NaN NaN                Asilomar Conference on Signals, Systems and Computing              ACSSC               (Asilomar Conference on Signals, Systems and Computing, ACSSC)\n",
      "\n",
      "--- BƯỚC 6: DỌN DẸP CÁC CỘT TẠM THỜI ---\n",
      "Đã xóa các cột 'normalized_title', 'normalized_acronym', 'key' khỏi DataFrame kết quả.\n",
      "Quá trình so sánh hoàn tất.\n",
      "\n",
      "--- KẾT QUẢ CUỐI CÙNG ---\n",
      "Tổng số dòng duy nhất trong CORE_2023.csv: 183\n",
      "Kết quả đã được lưu vào file: ./src/conference/evaluate/recrawl_all_core.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Chuẩn hóa văn bản bằng cách loại bỏ nội dung bên trong cặp dấu ngoặc đơn\n",
    "    và chính cặp dấu ngoặc đơn, đồng thời đảm bảo chỉ có một khoảng trắng\n",
    "    giữa các từ.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Bước 1: Loại bỏ nội dung trong ngoặc đơn và các khoảng trắng xung quanh\n",
    "    # r'\\s*\\(.*?\\)\\s*' sẽ khớp với 0 hoặc nhiều khoảng trắng trước (, nội dung, và 0 hoặc nhiều khoảng trắng sau )\n",
    "    cleaned_text = re.sub(r'\\s*\\(.*?\\)\\s*', ' ', str(text)) # Thay thế bằng MỘT khoảng trắng\n",
    "\n",
    "    # Bước 2: Chuẩn hóa khoảng trắng: thay thế nhiều khoảng trắng bằng một khoảng trắng duy nhất\n",
    "    # và loại bỏ khoảng trắng ở đầu/cuối.\n",
    "    # re.sub(r'\\s+', ' ', cleaned_text): thay thế 1 hoặc nhiều khoảng trắng bằng 1 khoảng trắng\n",
    "    # .strip(): loại bỏ khoảng trắng ở đầu và cuối chuỗi\n",
    "    final_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return final_text\n",
    "\n",
    "def find_unique_in_core_detailed(full_csv_path, core_csv_path):\n",
    "    \"\"\"\n",
    "    Tìm các dòng chỉ có trong file CORE_2023.csv dựa trên cặp (title, acronym)\n",
    "    sau khi chuẩn hóa, và in ra các bước chi tiết.\n",
    "\n",
    "    Args:\n",
    "        full_csv_path (str): Đường dẫn đến file full.csv.\n",
    "        core_csv_path (str): Đường dẫn đến file CORE_2023.csv.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame chứa các dòng chỉ có trong CORE_2023.csv.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--- BƯỚC 1: ĐỌC DỮ LIỆU ---\")\n",
    "    print(f\"Đang đọc file full.csv từ: {full_csv_path}\")\n",
    "    try:\n",
    "        df_full = pd.read_csv(full_csv_path)\n",
    "        if 'title' not in df_full.columns or 'acronym' not in df_full.columns:\n",
    "            raise ValueError(\"File full.csv phải có các cột 'title' và 'acronym'.\")\n",
    "        print(\"Đã đọc full.csv thành công. 5 dòng đầu tiên:\")\n",
    "        print(df_full.head().to_string()) # to_string() để in toàn bộ cột\n",
    "        print(f\"Tổng số dòng trong full.csv: {len(df_full)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file full.csv tại đường dẫn: {full_csv_path}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc full.csv: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"\\nĐang đọc file CORE_2023.csv từ: {core_csv_path}\")\n",
    "    try:\n",
    "        df_core = pd.read_csv(core_csv_path, header=None)\n",
    "        if df_core.shape[1] < 3:\n",
    "            raise ValueError(\"File CORE_2023.csv phải có ít nhất 3 cột để lấy title và acronym.\")\n",
    "        df_core.rename(columns={1: 'title', 2: 'acronym'}, inplace=True)\n",
    "        print(\"Đã đọc CORE_2023.csv thành công. 5 dòng đầu tiên (cột 1 là title, cột 2 là acronym):\")\n",
    "        print(df_core.head().to_string())\n",
    "        print(f\"Tổng số dòng trong CORE_2023.csv: {len(df_core)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file CORE_2023.csv tại đường dẫn: {core_csv_path}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc CORE_2023.csv: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(\"\\n--- BƯỚC 2: CHUẨN HÓA DỮ LIỆU ---\")\n",
    "    print(\"Áp dụng hàm normalize_text cho cột 'title' và 'acronym' của cả hai DataFrame.\")\n",
    "\n",
    "    df_full['normalized_title'] = df_full['title'].apply(normalize_text)\n",
    "    df_full['normalized_acronym'] = df_full['acronym'].apply(normalize_text)\n",
    "    print(\"\\n5 dòng đầu tiên của full.csv sau khi chuẩn hóa:\")\n",
    "    print(df_full[['title', 'normalized_title', 'acronym', 'normalized_acronym']].head().to_string())\n",
    "\n",
    "    df_core['normalized_title'] = df_core['title'].apply(normalize_text)\n",
    "    df_core['normalized_acronym'] = df_core['acronym'].apply(normalize_text)\n",
    "    print(\"\\n5 dòng đầu tiên của CORE_2023.csv sau khi chuẩn hóa:\")\n",
    "    print(df_core[['title', 'normalized_title', 'acronym', 'normalized_acronym']].head().to_string())\n",
    "\n",
    "    print(\"\\n--- BƯỚC 3: TẠO KHÓA SO SÁNH (KEY) ---\")\n",
    "    print(\"Tạo cột 'key' từ cặp (normalized_title, normalized_acronym) cho cả hai DataFrame.\")\n",
    "    df_full['key'] = list(zip(df_full['normalized_title'], df_full['normalized_acronym']))\n",
    "    df_core['key'] = list(zip(df_core['normalized_title'], df_core['normalized_acronym']))\n",
    "\n",
    "    print(\"\\n5 dòng đầu tiên của full.csv với cột 'key':\")\n",
    "    print(df_full[['title', 'acronym', 'key']].head().to_string())\n",
    "    print(\"\\n5 dòng đầu tiên của CORE_2023.csv với cột 'key':\")\n",
    "    print(df_core[['title', 'acronym', 'key']].head().to_string())\n",
    "\n",
    "    print(\"\\n--- BƯỚC 4: TẠO TẬP HỢP CÁC KEY TỪ full.csv ---\")\n",
    "    keys_in_full = set(df_full['key'])\n",
    "    print(f\"Tổng số key duy nhất trong full.csv: {len(keys_in_full)}\")\n",
    "    # In ra một vài key mẫu để kiểm tra\n",
    "    print(\"Một vài key mẫu từ full.csv (đã chuẩn hóa):\")\n",
    "    for i, key in enumerate(list(keys_in_full)[:5]):\n",
    "        print(f\"  - {key}\")\n",
    "\n",
    "    print(\"\\n--- BƯỚC 5: LỌC CÁC DÒNG CHỈ CÓ TRONG CORE_2023.csv ---\")\n",
    "    print(\"Lọc df_core để tìm các dòng mà 'key' của chúng KHÔNG có trong tập hợp key của full.csv.\")\n",
    "    unique_in_core_df = df_core[~df_core['key'].isin(keys_in_full)].copy()\n",
    "\n",
    "    print(f\"\\nTìm thấy {len(unique_in_core_df)} dòng chỉ có trong CORE_2023.csv.\")\n",
    "    if not unique_in_core_df.empty:\n",
    "        print(\"5 dòng đầu tiên của kết quả (các dòng chỉ có trong CORE_2023.csv):\")\n",
    "        print(unique_in_core_df.head().to_string())\n",
    "    else:\n",
    "        print(\"Không tìm thấy dòng nào chỉ có trong CORE_2023.csv.\")\n",
    "\n",
    "    print(\"\\n--- BƯỚC 6: DỌN DẸP CÁC CỘT TẠM THỜI ---\")\n",
    "    # Xóa các cột tạm thời đã tạo\n",
    "    unique_in_core_df.drop(columns=['normalized_title', 'normalized_acronym', 'key'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(\"Đã xóa các cột 'normalized_title', 'normalized_acronym', 'key' khỏi DataFrame kết quả.\")\n",
    "    print(\"Quá trình so sánh hoàn tất.\")\n",
    "\n",
    "    return unique_in_core_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Cấu hình đường dẫn file của bạn ---\n",
    "    FULL_CSV_FILE = './src/conference/evaluate/full.csv'\n",
    "    CORE_CSV_FILE = './src/conference/csv/CORE_2023.csv'\n",
    "    OUTPUT_CSV_FILE = './src/conference/evaluate/recrawl_all_core.csv'\n",
    "\n",
    "    # Gọi hàm để tìm các dòng duy nhất với chi tiết\n",
    "    result_df = find_unique_in_core_detailed(FULL_CSV_FILE, CORE_CSV_FILE)\n",
    "\n",
    "    if not result_df.empty:\n",
    "        print(f\"\\n--- KẾT QUẢ CUỐI CÙNG ---\")\n",
    "        print(f\"Tổng số dòng duy nhất trong CORE_2023.csv: {len(result_df)}\")\n",
    "        print(f\"Kết quả đã được lưu vào file: {OUTPUT_CSV_FILE}\")\n",
    "        result_df.to_csv(OUTPUT_CSV_FILE, index=False)\n",
    "    else:\n",
    "        print(\"\\n--- KẾT QUẢ CUỐI CÙNG ---\")\n",
    "        print(\"Không tìm thấy dòng nào chỉ có trong CORE_2023.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BƯỚC 1: ĐỌC DANH SÁCH CẦN RECRAWL TỪ recrawl_all_core.csv ---\n",
      "Đã đọc 183 dòng từ ./src/conference/evaluate/recrawl_all_core.csv.\n",
      "\n",
      "--- BƯỚC 2: CHUẨN HÓA VÀ TẠO KEY CHO DANH SÁCH RECRAWL ---\n",
      "Tổng số key duy nhất trong recrawl_all_core: 183\n",
      "\n",
      "--- BƯỚC 3: ĐỌC VÀ TỔNG HỢP CÁC CONFERENCE ĐANG ĐƯỢC CRAWL ---\n",
      "Đang đọc file crawling 1/2: ./src/conference/evaluate/ALL_BATCHES_recrawl_final.csv\n",
      "  Đã thêm 45 key từ ./src/conference/evaluate/ALL_BATCHES_recrawl_final.csv. Tổng số key đang crawl: 45\n",
      "Đang đọc file crawling 2/2: ./src/conference/evaluate/tri_all_recrawl_final.csv\n",
      "  Đã thêm 30 key từ ./src/conference/evaluate/tri_all_recrawl_final.csv. Tổng số key đang crawl: 75\n",
      "\n",
      "Tổng số key duy nhất từ tất cả các file đang crawl: 75\n",
      "\n",
      "--- BƯỚC 4: ĐỌC DANH SÁCH ACRONYM NON-LINK ---\n",
      "Đã đọc 35 acronym non-link từ ./non_link.txt.\n",
      "\n",
      "--- BƯỚC 5: LỌC DANH SÁCH RECRAWL CUỐI CÙNG ---\n",
      "Tìm các conference trong recrawl_all_core mà KHÔNG có trong danh sách đang crawl\n",
      "VÀ KHÔNG có acronym trong danh sách non-link.\n",
      "Số dòng ban đầu trong danh sách recrawl: 183\n",
      "Số dòng sau khi loại bỏ các conference đang crawl: 108 (Đã loại bỏ 75 dòng).\n",
      "Số dòng sau khi loại bỏ các conference non-link: 79 (Đã loại bỏ 29 dòng).\n",
      "\n",
      "Tìm thấy 79 conference cần recrawl cuối cùng.\n",
      "\n",
      "--- BƯỚC 6: DỌN DẸP VÀ LƯU KẾT QUẢ ---\n",
      "5 dòng đầu tiên của danh sách recrawl cuối cùng:\n",
      "     0                                                  title acronym         3              4    5     6    7   8\n",
      "1  167                    Asian Conference on Computer Vision    ACCV  CORE2023              B   No  4603  NaN NaN\n",
      "4  189  Asilomar Conference on Signals, Systems and Computing   ACSSC  CORE2023  National: USA   No  4606  NaN NaN\n",
      "7   97                                Advances in Modal Logic    AiML  CORE2023              B  Yes  4613  NaN NaN\n",
      "8  175                 Asia-Pacific Bioinformatics Conference    APBC  CORE2023              B   No  4601  NaN NaN\n",
      "9  159              Asia Pacific Conference on Communications    APCC  CORE2023              C  Yes  4606  NaN NaN\n",
      "\n",
      "Kết quả đã được lưu vào file: ./src/conference/evaluate/final_recrawl_list.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sử dụng lại hàm normalize_text đã được cải tiến\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Chuẩn hóa văn bản bằng cách loại bỏ nội dung bên trong cặp dấu ngoặc đơn\n",
    "    và chính cặp dấu ngoặc đơn, đồng thời đảm bảo chỉ có một khoảng trắng\n",
    "    giữa các từ.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    cleaned_text = re.sub(r'\\s*\\(.*?\\)\\s*', ' ', str(text))\n",
    "    final_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return final_text\n",
    "\n",
    "def filter_recrawl_list_with_non_links(recrawl_all_core_path, crawling_files_paths, non_link_acronyms_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Lọc danh sách recrawl_all_core.csv bằng cách loại bỏ các conference\n",
    "    đang được crawl (dựa trên 3 file CSV khác) và các conference\n",
    "    có acronym trong danh sách non-link từ file TXT.\n",
    "\n",
    "    Args:\n",
    "        recrawl_all_core_path (str): Đường dẫn đến file recrawl_all_core.csv.\n",
    "        crawling_files_paths (list): Danh sách các đường dẫn đến các file CSV\n",
    "                                      chứa danh sách conference đang được crawl.\n",
    "        non_link_acronyms_path (str): Đường dẫn đến file TXT chứa các acronym non-link.\n",
    "        output_csv_path (str): Đường dẫn để lưu file CSV kết quả cuối cùng.\n",
    "    \"\"\"\n",
    "    print(\"--- BƯỚC 1: ĐỌC DANH SÁCH CẦN RECRAWL TỪ recrawl_all_core.csv ---\")\n",
    "    try:\n",
    "        df_recrawl = pd.read_csv(recrawl_all_core_path)\n",
    "        if 'title' not in df_recrawl.columns or 'acronym' not in df_recrawl.columns:\n",
    "            raise ValueError(f\"File {recrawl_all_core_path} phải có các cột 'title' và 'acronym'.\")\n",
    "        print(f\"Đã đọc {len(df_recrawl)} dòng từ {recrawl_all_core_path}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file: {recrawl_all_core_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc {recrawl_all_core_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- BƯỚC 2: CHUẨN HÓA VÀ TẠO KEY CHO DANH SÁCH RECRAWL ---\")\n",
    "    df_recrawl['normalized_title'] = df_recrawl['title'].apply(normalize_text)\n",
    "    df_recrawl['normalized_acronym'] = df_recrawl['acronym'].apply(normalize_text)\n",
    "    df_recrawl['key'] = list(zip(df_recrawl['normalized_title'], df_recrawl['normalized_acronym']))\n",
    "    recrawl_keys = set(df_recrawl['key'])\n",
    "    print(f\"Tổng số key duy nhất trong recrawl_all_core: {len(recrawl_keys)}\")\n",
    "\n",
    "    print(\"\\n--- BƯỚC 3: ĐỌC VÀ TỔNG HỢP CÁC CONFERENCE ĐANG ĐƯỢC CRAWL ---\")\n",
    "    all_crawling_keys = set()\n",
    "    for i, file_path in enumerate(crawling_files_paths):\n",
    "        print(f\"Đang đọc file crawling {i+1}/{len(crawling_files_paths)}: {file_path}\")\n",
    "        try:\n",
    "            df_crawling = pd.read_csv(file_path)\n",
    "            if 'title' not in df_crawling.columns or 'acronym' not in df_crawling.columns:\n",
    "                print(f\"Cảnh báo: File {file_path} không có cột 'title' hoặc 'acronym'. Bỏ qua file này.\")\n",
    "                continue\n",
    "\n",
    "            df_crawling['normalized_title'] = df_crawling['title'].apply(normalize_text)\n",
    "            df_crawling['normalized_acronym'] = df_crawling['acronym'].apply(normalize_text)\n",
    "            df_crawling['key'] = list(zip(df_crawling['normalized_title'], df_crawling['normalized_acronym']))\n",
    "\n",
    "            all_crawling_keys.update(set(df_crawling['key']))\n",
    "            print(f\"  Đã thêm {len(set(df_crawling['key']))} key từ {file_path}. Tổng số key đang crawl: {len(all_crawling_keys)}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Lỗi: Không tìm thấy file crawling tại đường dẫn: {file_path}. Bỏ qua file này.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc file crawling {file_path}: {e}. Bỏ qua file này.\")\n",
    "\n",
    "    print(f\"\\nTổng số key duy nhất từ tất cả các file đang crawl: {len(all_crawling_keys)}\")\n",
    "\n",
    "    print(\"\\n--- BƯỚC 4: ĐỌC DANH SÁCH ACRONYM NON-LINK ---\")\n",
    "    non_link_acronyms = set()\n",
    "    try:\n",
    "        with open(non_link_acronyms_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                acronym = line.strip() # Loại bỏ khoảng trắng và ký tự xuống dòng\n",
    "                if acronym: # Đảm bảo không thêm dòng trống\n",
    "                    non_link_acronyms.add(normalize_text(acronym)) # Chuẩn hóa acronym trước khi thêm\n",
    "        print(f\"Đã đọc {len(non_link_acronyms)} acronym non-link từ {non_link_acronyms_path}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file non-link acronyms tại đường dẫn: {non_link_acronyms_path}. Bỏ qua bước lọc này.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file non-link acronyms: {e}. Bỏ qua bước lọc này.\")\n",
    "\n",
    "    print(\"\\n--- BƯỚC 5: LỌC DANH SÁCH RECRAWL CUỐI CÙNG ---\")\n",
    "    print(\"Tìm các conference trong recrawl_all_core mà KHÔNG có trong danh sách đang crawl\")\n",
    "    print(\"VÀ KHÔNG có acronym trong danh sách non-link.\")\n",
    "\n",
    "    # Bắt đầu với danh sách recrawl_all_core\n",
    "    current_recrawl_df = df_recrawl.copy()\n",
    "    initial_count = len(current_recrawl_df)\n",
    "    print(f\"Số dòng ban đầu trong danh sách recrawl: {initial_count}\")\n",
    "\n",
    "    # Lọc bỏ các conference đang được crawl\n",
    "    filtered_by_crawling = current_recrawl_df[~current_recrawl_df['key'].isin(all_crawling_keys)].copy()\n",
    "    print(f\"Số dòng sau khi loại bỏ các conference đang crawl: {len(filtered_by_crawling)} (Đã loại bỏ {initial_count - len(filtered_by_crawling)} dòng).\")\n",
    "\n",
    "    # Lọc bỏ các conference có acronym trong danh sách non-link\n",
    "    # Chúng ta cần chuẩn hóa acronym của df_recrawl trước khi so sánh với non_link_acronyms\n",
    "    final_recrawl_list_df = filtered_by_crawling[~filtered_by_crawling['normalized_acronym'].isin(non_link_acronyms)].copy()\n",
    "    print(f\"Số dòng sau khi loại bỏ các conference non-link: {len(final_recrawl_list_df)} (Đã loại bỏ {len(filtered_by_crawling) - len(final_recrawl_list_df)} dòng).\")\n",
    "\n",
    "\n",
    "    print(f\"\\nTìm thấy {len(final_recrawl_list_df)} conference cần recrawl cuối cùng.\")\n",
    "\n",
    "    print(\"\\n--- BƯỚC 6: DỌN DẸP VÀ LƯU KẾT QUẢ ---\")\n",
    "    # Xóa các cột tạm thời đã tạo\n",
    "    final_recrawl_list_df.drop(columns=['normalized_title', 'normalized_acronym', 'key'], inplace=True, errors='ignore')\n",
    "\n",
    "    if not final_recrawl_list_df.empty:\n",
    "        print(f\"5 dòng đầu tiên của danh sách recrawl cuối cùng:\")\n",
    "        print(final_recrawl_list_df.head().to_string())\n",
    "        print(f\"\\nKết quả đã được lưu vào file: {output_csv_path}\")\n",
    "        final_recrawl_list_df.to_csv(output_csv_path, index=False)\n",
    "    else:\n",
    "        print(\"Không tìm thấy conference nào cần recrawl cuối cùng sau khi lọc.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Cấu hình đường dẫn file của bạn ---\n",
    "    RECRAWL_ALL_CORE_FILE = './src/conference/evaluate/recrawl_all_core.csv'\n",
    "\n",
    "    # Danh sách các file CSV chứa conference đang được crawl\n",
    "    # Đảm bảo các file này có cột 'title' và 'acronym'\n",
    "    CRAWLING_FILES = [\n",
    "        './src/conference/evaluate/ALL_BATCHES_recrawl_final.csv',\n",
    "        './src/conference/evaluate/tri_all_recrawl_final.csv',\n",
    "        # Thêm các file khác nếu có\n",
    "    ]\n",
    "\n",
    "    # Đường dẫn đến file TXT chứa các acronym non-link\n",
    "    NON_LINK_ACRONYMS_FILE = './non_link.txt' # Ví dụ: non_link_acronyms.txt\n",
    "\n",
    "    OUTPUT_FINAL_RECRAWL_FILE = './src/conference/evaluate/final_recrawl_list.csv'\n",
    "\n",
    "    # Gọi hàm để lọc danh sách recrawl\n",
    "    filter_recrawl_list_with_non_links(RECRAWL_ALL_CORE_FILE, CRAWLING_FILES, NON_LINK_ACRONYMS_FILE, OUTPUT_FINAL_RECRAWL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc file full.csv từ: ./src/conference/evaluate/full.csv\n",
      "Đã đọc full.csv thành công.\n",
      "Đang đọc file unique_in_CORE_2023.csv từ: ./src/conference/evaluate/recrawl_all_core.csv\n",
      "Đã đọc unique_in_CORE_2023.csv thành công.\n",
      "Đang chọn các cột 'title' và 'acronym' từ cả hai DataFrame...\n",
      "Đang gộp hai DataFrame...\n",
      "Tổng số dòng sau khi gộp: 966\n",
      "Đang loại bỏ các dòng trùng lặp (nếu có)...\n",
      "Số dòng sau khi loại bỏ trùng lặp: 955 (Đã loại bỏ 11 dòng trùng lặp).\n",
      "Đang lưu kết quả vào file: ./src/conference/evaluate/merged_full_and_unique.csv\n",
      "Đã lưu file thành công.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_and_select_columns(full_csv_path, unique_csv_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Gộp hai file CSV (full.csv và unique_in_CORE_2023.csv) và chỉ giữ lại\n",
    "    các cột 'title' và 'acronym', sau đó lưu vào một file CSV mới.\n",
    "\n",
    "    Args:\n",
    "        full_csv_path (str): Đường dẫn đến file full.csv.\n",
    "        unique_csv_path (str): Đường dẫn đến file unique_in_CORE_2023.csv.\n",
    "        output_csv_path (str): Đường dẫn để lưu file CSV kết quả.\n",
    "    \"\"\"\n",
    "    print(f\"Đang đọc file full.csv từ: {full_csv_path}\")\n",
    "    try:\n",
    "        df_full = pd.read_csv(full_csv_path)\n",
    "        # Đảm bảo các cột 'title' và 'acronym' tồn tại\n",
    "        if 'title' not in df_full.columns or 'acronym' not in df_full.columns:\n",
    "            raise ValueError(f\"File {full_csv_path} phải có các cột 'title' và 'acronym'.\")\n",
    "        print(\"Đã đọc full.csv thành công.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file full.csv tại đường dẫn: {full_csv_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc full.csv: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Đang đọc file unique_in_CORE_2023.csv từ: {unique_csv_path}\")\n",
    "    try:\n",
    "        df_unique = pd.read_csv(unique_csv_path)\n",
    "        # Đảm bảo các cột 'title' và 'acronym' tồn tại\n",
    "        if 'title' not in df_unique.columns or 'acronym' not in df_unique.columns:\n",
    "            raise ValueError(f\"File {unique_csv_path} phải có các cột 'title' và 'acronym'.\")\n",
    "        print(\"Đã đọc unique_in_CORE_2023.csv thành công.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file unique_in_CORE_2023.csv tại đường dẫn: {unique_csv_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc unique_in_CORE_2023.csv: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"Đang chọn các cột 'title' và 'acronym' từ cả hai DataFrame...\")\n",
    "    # Chọn chỉ các cột 'title' và 'acronym' từ mỗi DataFrame\n",
    "    df_full_selected = df_full[['title', 'acronym']]\n",
    "    df_unique_selected = df_unique[['title', 'acronym']]\n",
    "\n",
    "    print(\"Đang gộp hai DataFrame...\")\n",
    "    # Gộp hai DataFrame theo chiều dọc (thêm hàng)\n",
    "    # ignore_index=True để reset index của DataFrame kết quả\n",
    "    merged_df = pd.concat([df_full_selected, df_unique_selected], ignore_index=True)\n",
    "\n",
    "    print(f\"Tổng số dòng sau khi gộp: {len(merged_df)}\")\n",
    "\n",
    "    # Tùy chọn: Xóa các dòng trùng lặp nếu bạn muốn một danh sách duy nhất\n",
    "    # Dòng trùng lặp ở đây có nghĩa là cả title và acronym đều giống hệt nhau\n",
    "    # Nếu bạn muốn giữ lại tất cả các dòng, kể cả trùng lặp, hãy bỏ qua bước này\n",
    "    print(\"Đang loại bỏ các dòng trùng lặp (nếu có)...\")\n",
    "    initial_rows = len(merged_df)\n",
    "    merged_df.drop_duplicates(inplace=True)\n",
    "    rows_after_dedup = len(merged_df)\n",
    "    print(f\"Số dòng sau khi loại bỏ trùng lặp: {rows_after_dedup} (Đã loại bỏ {initial_rows - rows_after_dedup} dòng trùng lặp).\")\n",
    "\n",
    "\n",
    "    print(f\"Đang lưu kết quả vào file: {output_csv_path}\")\n",
    "    try:\n",
    "        merged_df.to_csv(output_csv_path, index=False)\n",
    "        print(\"Đã lưu file thành công.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi lưu file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FULL_CSV_FILE = './src/conference/evaluate/full.csv'\n",
    "    UNIQUE_CSV_FILE = './src/conference/evaluate/recrawl_all_core.csv'\n",
    "    OUTPUT_MERGED_FILE = './src/conference/evaluate/merged_full_and_unique.csv'\n",
    "\n",
    "    # Gọi hàm để gộp các file\n",
    "    merge_and_select_columns(FULL_CSV_FILE, UNIQUE_CSV_FILE, OUTPUT_MERGED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc file CSV từ: ./src/conference/evaluate/full.csv\n",
      "Đã đọc 783 dòng từ ./src/conference/evaluate/full.csv.\n",
      "Đang tìm kiếm các dòng trùng lặp...\n",
      "Tìm thấy 22 dòng trùng lặp.\n",
      "Đang lưu các dòng trùng lặp vào file: full_duplicates.csv\n",
      "Đã lưu file trùng lặp thành công.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_and_export_duplicates(input_csv_path, output_csv_path, subset_columns=None):\n",
    "    \"\"\"\n",
    "    Tìm và xuất các dòng trùng lặp trong một file CSV.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): Đường dẫn đến file CSV đầu vào (ví dụ: full.csv).\n",
    "        output_csv_path (str): Đường dẫn để lưu file CSV chứa các dòng trùng lặp.\n",
    "        subset_columns (list, optional): Danh sách các tên cột để kiểm tra trùng lặp.\n",
    "                                         Nếu None, tất cả các cột sẽ được sử dụng.\n",
    "                                         Ví dụ: ['title', 'acronym']\n",
    "    \"\"\"\n",
    "    print(f\"Đang đọc file CSV từ: {input_csv_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "        print(f\"Đã đọc {len(df)} dòng từ {input_csv_path}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file CSV tại đường dẫn: {input_csv_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"Đang tìm kiếm các dòng trùng lặp...\")\n",
    "\n",
    "    # Tìm các dòng trùng lặp\n",
    "    # keep=False: Đánh dấu TẤT CẢ các lần xuất hiện của một dòng trùng lặp là True\n",
    "    #             (bao gồm cả lần xuất hiện đầu tiên).\n",
    "    #             Nếu muốn chỉ đánh dấu các bản sao (không bao gồm bản gốc đầu tiên),\n",
    "    #             sử dụng keep='first' hoặc keep='last'.\n",
    "    # subset: Các cột để kiểm tra trùng lặp. Nếu None, kiểm tra tất cả các cột.\n",
    "    duplicate_rows = df[df.duplicated(subset=subset_columns, keep=False)]\n",
    "\n",
    "    if not duplicate_rows.empty:\n",
    "        print(f\"Tìm thấy {len(duplicate_rows)} dòng trùng lặp.\")\n",
    "        print(f\"Đang lưu các dòng trùng lặp vào file: {output_csv_path}\")\n",
    "        try:\n",
    "            duplicate_rows.to_csv(output_csv_path, index=False)\n",
    "            print(\"Đã lưu file trùng lặp thành công.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi lưu file trùng lặp: {e}\")\n",
    "    else:\n",
    "        print(\"Không tìm thấy dòng trùng lặp nào.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Cấu hình đường dẫn file của bạn ---\n",
    "    INPUT_CSV_FILE = './src/conference/evaluate/full.csv'\n",
    "    OUTPUT_DUPLICATES_FILE = 'full_duplicates.csv'\n",
    "\n",
    "    # --- Cấu hình các cột để kiểm tra trùng lặp ---\n",
    "    # Nếu bạn muốn kiểm tra trùng lặp dựa trên TẤT CẢ các cột, hãy để là None\n",
    "    # COLUMNS_TO_CHECK = None\n",
    "\n",
    "    # Nếu bạn muốn kiểm tra trùng lặp chỉ dựa trên 'title' và 'acronym', hãy sử dụng:\n",
    "    COLUMNS_TO_CHECK = ['title', 'acronym']\n",
    "\n",
    "    # Gọi hàm để tìm và xuất các dòng trùng lặp\n",
    "    find_and_export_duplicates(INPUT_CSV_FILE, OUTPUT_DUPLICATES_FILE, COLUMNS_TO_CHECK)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
