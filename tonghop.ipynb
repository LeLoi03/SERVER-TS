{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Hàm split_dataframe giữ nguyên như cũ\n",
    "def split_dataframe(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Nhận một DataFrame, tách nó thành hai phần (đúng và cần crawl lại)\n",
    "    dựa trên các điều kiện đã xác định và trả về hai DataFrame đã được\n",
    "    loại bỏ trùng lặp.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    main_link_correct = df_copy['MainLinkCorrect'].fillna('').astype(str).str.strip().str.upper()\n",
    "    date_correct = df_copy['ConferenceDateCorrect'].fillna('').astype(str).str.strip().str.upper()\n",
    "    location_correct = df_copy['LocationCorrect'].fillna('').astype(str).str.strip().str.upper()\n",
    "    type_correct = df_copy['TypeCorrect'].fillna('').astype(str).str.strip().str.upper()\n",
    "\n",
    "    condition1 = (\n",
    "        (main_link_correct == 'FALSE') |\n",
    "        (date_correct == 'FALSE') |\n",
    "        (location_correct == 'FALSE') |\n",
    "        (type_correct == 'FALSE')\n",
    "    )\n",
    "\n",
    "    percent_cols = ['Percent', 'Percent_1', 'Percent_2', 'Percent_3', 'Percent_4']\n",
    "    for col in percent_cols:\n",
    "        df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "\n",
    "    condition2_parts = [df_copy[col].notna() & (df_copy[col] != 100) for col in percent_cols]\n",
    "    condition2 = False\n",
    "    for part in condition2_parts:\n",
    "        condition2 = condition2 | part\n",
    "\n",
    "    recrawl_condition = condition1 | condition2\n",
    "    recrawl_df = df_copy[recrawl_condition]\n",
    "    correct_df = df_copy[~recrawl_condition]\n",
    "\n",
    "    subset_cols = ['title', 'acronym']\n",
    "    unique_recrawl_df = recrawl_df.drop_duplicates(subset=subset_cols, keep='first')\n",
    "    unique_correct_df = correct_df.drop_duplicates(subset=subset_cols, keep='first')\n",
    "\n",
    "    return unique_correct_df, unique_recrawl_df\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# HÀM process_file_list ĐÃ ĐƯỢC CẬP NHẬT\n",
    "# ==============================================================================\n",
    "def process_file_list(\n",
    "    input_files: list,\n",
    "    output_dir: str,\n",
    "    aggregated_correct_path: str,\n",
    "    aggregated_recrawl_path: str,\n",
    "    recrawled_files: list = None,\n",
    "    definitive_correct_path: str = None  # <-- THAM SỐ MỚI\n",
    "):\n",
    "    \"\"\"\n",
    "    Xử lý một danh sách các file CSV, đối chiếu với kết quả đã recrawl,\n",
    "    và tạo ra hai file tổng hợp cuối cùng.\n",
    "    Sử dụng file definitive_correct_path làm bộ lọc cuối cùng cho file recrawl.\n",
    "    \"\"\"\n",
    "    # --- CÁC BƯỚC 1, 2, 3, 4 GIỮ NGUYÊN NHƯ TRƯỚC ---\n",
    "    # (Code từ bước 1 đến 4 được rút gọn ở đây để dễ đọc, bạn chỉ cần copy cả hàm)\n",
    "    all_correct_dfs = []\n",
    "    all_recrawl_dfs = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # --- BƯỚC 1: XỬ LÝ CÁC FILE INPUT BAN ĐẦU ---\n",
    "    for file_path in input_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig', na_values=['', ' '], dtype=str)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi đọc file {file_path}: {e}\")\n",
    "            continue\n",
    "        correct_df, recrawl_df = split_dataframe(df)\n",
    "        all_correct_dfs.append(correct_df)\n",
    "        all_recrawl_dfs.append(recrawl_df)\n",
    "    # --- BƯỚC 2: GỘP KẾT QUẢ ---\n",
    "    master_correct_df = pd.concat(all_correct_dfs, ignore_index=True) if all_correct_dfs else pd.DataFrame()\n",
    "    master_recrawl_df = pd.concat(all_recrawl_dfs, ignore_index=True) if all_recrawl_dfs else pd.DataFrame()\n",
    "    # --- BƯỚC 3: ĐỐI CHIẾU VỚI CÁC FILE ĐÃ RECRAWL ---\n",
    "    if recrawled_files:\n",
    "        recrawled_dfs_list = []\n",
    "        for r_file in recrawled_files:\n",
    "            try:\n",
    "                df_recrawled = pd.read_csv(r_file, encoding='utf-8-sig', na_values=['', ' '], dtype=str)\n",
    "                recrawled_dfs_list.append(df_recrawled)\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi đọc file recrawl {r_file}: {e}\")\n",
    "        if recrawled_dfs_list:\n",
    "            recrawled_master_df = pd.concat(recrawled_dfs_list, ignore_index=True)\n",
    "            newly_correct_df_from_recrawl, _ = split_dataframe(recrawled_master_df)\n",
    "            if not newly_correct_df_from_recrawl.empty:\n",
    "                newly_correct_df_from_recrawl['title'] = newly_correct_df_from_recrawl['title'].str.strip()\n",
    "                newly_correct_df_from_recrawl['acronym'] = newly_correct_df_from_recrawl['acronym'].astype(str).str.strip()\n",
    "                corrected_keys = set(tuple(x) for x in newly_correct_df_from_recrawl[['title', 'acronym']].values)\n",
    "                \n",
    "                master_recrawl_df['title_stripped'] = master_recrawl_df['title'].str.strip()\n",
    "                master_recrawl_df['acronym_stripped'] = master_recrawl_df['acronym'].astype(str).str.strip()\n",
    "                mask_to_remove = master_recrawl_df.apply(lambda row: (row['title_stripped'], row['acronym_stripped']) in corrected_keys, axis=1)\n",
    "                \n",
    "                master_recrawl_df = master_recrawl_df[~mask_to_remove].copy()\n",
    "                master_correct_df = pd.concat([master_correct_df, newly_correct_df_from_recrawl], ignore_index=True)\n",
    "                master_recrawl_df.drop(columns=['title_stripped', 'acronym_stripped'], inplace=True, errors='ignore')\n",
    "    # --- BƯỚC 4: LỌC CUỐI CÙNG DỰA TRÊN CỘT 'Note' ---\n",
    "    if 'Note' in master_correct_df.columns:\n",
    "        note_exists_condition_final = master_correct_df['Note'].notna() & (master_correct_df['Note'].astype(str).str.strip() != '')\n",
    "        rows_to_move_final = master_correct_df[note_exists_condition_final].copy()\n",
    "        if not rows_to_move_final.empty:\n",
    "            master_recrawl_df = pd.concat([master_recrawl_df, rows_to_move_final], ignore_index=True)\n",
    "            master_correct_df = master_correct_df[~note_exists_condition_final].copy()\n",
    "\n",
    "    # ==============================================================================\n",
    "    # BƯỚC 4.5 (MỚI): LỌC FILE RECRAWL DỰA TRÊN FILE CORRECT THỦ CÔNG\n",
    "    # ==============================================================================\n",
    "    if definitive_correct_path and os.path.exists(definitive_correct_path):\n",
    "        print(f\"\\n--- BƯỚC 4.5: Lọc danh sách recrawl dựa trên file '{definitive_correct_path}' ---\")\n",
    "        try:\n",
    "            # Đọc file correct thủ công mà bạn cung cấp\n",
    "            definitive_correct_df = pd.read_csv(definitive_correct_path, encoding='utf-8-sig', dtype=str).fillna('')\n",
    "\n",
    "            # Tạo một tập hợp các khóa (title, acronym) từ file này để tra cứu nhanh\n",
    "            definitive_correct_df['title'] = definitive_correct_df['title'].str.strip()\n",
    "            definitive_correct_df['acronym'] = definitive_correct_df['acronym'].str.strip()\n",
    "            keys_to_exclude = set(tuple(x) for x in definitive_correct_df[['title', 'acronym']].values)\n",
    "\n",
    "            print(f\"Đã xác định {len(keys_to_exclude)} dòng 'chắc chắn đúng' từ file thủ công.\")\n",
    "\n",
    "            if not master_recrawl_df.empty:\n",
    "                initial_recrawl_count = len(master_recrawl_df)\n",
    "\n",
    "                # Tạo các khóa tạm thời trong danh sách recrawl để so sánh\n",
    "                master_recrawl_df['temp_title'] = master_recrawl_df['title'].astype(str).str.strip()\n",
    "                master_recrawl_df['temp_acronym'] = master_recrawl_df['acronym'].astype(str).str.strip().fillna('')\n",
    "\n",
    "                # Tạo một \"mặt nạ\" boolean để xác định những dòng cần XÓA\n",
    "                # (những dòng có khóa nằm trong tập hợp keys_to_exclude)\n",
    "                mask_to_remove = master_recrawl_df.apply(\n",
    "                    lambda row: (row['temp_title'], row['temp_acronym']) in keys_to_exclude,\n",
    "                    axis=1\n",
    "                )\n",
    "\n",
    "                # Áp dụng mặt nạ ngược (~) để GIỮ LẠI những dòng KHÔNG cần xóa\n",
    "                master_recrawl_df = master_recrawl_df[~mask_to_remove].copy()\n",
    "\n",
    "                # Dọn dẹp các cột tạm thời\n",
    "                master_recrawl_df.drop(columns=['temp_title', 'temp_acronym'], inplace=True)\n",
    "\n",
    "                final_recrawl_count = len(master_recrawl_df)\n",
    "                print(f\"Đã loại bỏ {initial_recrawl_count - final_recrawl_count} dòng khỏi danh sách recrawl vì chúng đã có trong file correct thủ công.\")\n",
    "            else:\n",
    "                print(\"Danh sách recrawl đã rỗng, không cần lọc.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Cảnh báo: Không tìm thấy file correct thủ công '{definitive_correct_path}'. Bỏ qua bước lọc này.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xử lý file correct thủ công: {e}. Bỏ qua bước lọc này.\")\n",
    "    else:\n",
    "        print(\"\\nKhông có file correct thủ công nào được cung cấp, bỏ qua bước lọc 4.5.\")\n",
    "\n",
    "\n",
    "    # --- BƯỚC 5: LOẠI BỎ TRÙNG LẶP LẦN CUỐI VÀ LƯU FILE ---\n",
    "    print(\"\\n--- Hoàn tất và lưu file tổng hợp cuối cùng ---\")\n",
    "\n",
    "    # Xử lý và lưu file CORRECT tổng\n",
    "    # Lưu ý: Script vẫn sẽ tạo ra file correct dựa trên logic của nó.\n",
    "    # Bạn có thể bỏ qua file này và chỉ sử dụng file correct thủ công của mình.\n",
    "    if not master_correct_df.empty:\n",
    "        final_correct_df = master_correct_df.drop_duplicates(subset=['title', 'acronym'], keep='first')\n",
    "        final_correct_df.to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu {len(final_correct_df)} dòng đúng (dựa trên logic script) vào '{aggregated_correct_path}'\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'đúng' nào theo logic script. Đã tạo file rỗng '{aggregated_correct_path}'\")\n",
    "\n",
    "    # Xử lý và lưu file RECRAWL tổng (đã được lọc ở bước 4.5)\n",
    "    if not master_recrawl_df.empty:\n",
    "        final_recrawl_df = master_recrawl_df.drop_duplicates(subset=['title', 'acronym'], keep='first')\n",
    "        final_recrawl_df.to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_recrawl_df)} dòng cần crawl lại (sau khi lọc) vào '{aggregated_recrawl_path}'\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'cần recrawl' nào. Đã tạo file rỗng '{aggregated_recrawl_path}'.\")\n",
    "\n",
    "\n",
    "# --- Cách sử dụng ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Danh sách các file input ban đầu\n",
    "    input_csv_files = [\n",
    "        './src/conference/evaluate/batch2.csv',\n",
    "        './src/conference/evaluate/batch3.csv',\n",
    "        './src/conference/evaluate/batch8.csv',\n",
    "        './src/conference/evaluate/batch12.csv',\n",
    "        './src/conference/evaluate/batch13.csv',\n",
    "        './src/conference/evaluate/batch16.csv',\n",
    "        './src/conference/evaluate/batch19.csv',\n",
    "    ]\n",
    "\n",
    "    # 2. Danh sách các file là kết quả của lần recrawl trước đó\n",
    "    recrawled_results_files = [\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_2_3_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_8_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_12_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_13_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_16_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_19_lan_1.csv',\n",
    "        \n",
    "        # THÊM CÁC FILE RECRAWL MỚI VÀO ĐÂY\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_51_100.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_101_150.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_151_159.csv',\n",
    "\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_1_50_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_51_100_lan_2.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_all_tung_101_139_lan_2.csv',\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "    # 3. Thư mục để chứa các file output riêng lẻ (giữ nguyên)\n",
    "    individual_output_directory = './src/conference/evaluate/individual_outputs'\n",
    "\n",
    "    # 4. Đường dẫn cho 2 file tổng hợp cuối cùng (giữ nguyên)\n",
    "    aggregated_correct_file = './src/conference/evaluate/ALL_BATCHES_correct_generated_by_script.csv'\n",
    "    aggregated_recrawl_file = './src/conference/evaluate/ALL_BATCHES_recrawl_final.csv'\n",
    "\n",
    "    # 5. (QUAN TRỌNG) Đường dẫn đến file correct thủ công của bạn\n",
    "    # Đây là file \"chân lý\" mà bạn đã tạo\n",
    "    definitive_correct_file_path = './src/conference/evaluate/ALL_BATCHES_correct_final.csv'\n",
    "\n",
    "    # 6. Gọi hàm xử lý chính với tham số mới\n",
    "    process_file_list(\n",
    "        input_files=input_csv_files,\n",
    "        output_dir=individual_output_directory,\n",
    "        aggregated_correct_path=aggregated_correct_file,\n",
    "        aggregated_recrawl_path=aggregated_recrawl_file,\n",
    "        recrawled_files=recrawled_results_files,\n",
    "        definitive_correct_path=definitive_correct_file_path # <-- TRUYỀN VÀO ĐÂY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_df_by_note(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Tách một DataFrame thành hai phần dựa trên sự tồn tại của giá trị trong cột 'Note'.\n",
    "\n",
    "    - Dữ liệu \"cần recrawl\": Các dòng có giá trị trong cột 'Note'.\n",
    "    - Dữ liệu \"đúng\": Các dòng không có giá trị trong cột 'Note' (trống hoặc NaN).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame đầu vào.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.DataFrame]: Một tuple chứa (correct_df, recrawl_df).\n",
    "    \"\"\"\n",
    "    # Kiểm tra an toàn để đảm bảo cột 'Note' tồn tại\n",
    "    # Lưu ý: Sửa 'Note' thành 'note' nếu tên cột thực sự là chữ thường\n",
    "    if 'note' not in df.columns: \n",
    "        print(\"Cảnh báo: Không tìm thấy cột 'note'. Coi như tất cả các dòng đều 'đúng'.\")\n",
    "        return df.copy(), pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    # Điều kiện: cột 'note' có giá trị (không phải NaN và không phải chuỗi rỗng sau khi strip)\n",
    "    # Áp dụng .str.strip() trước khi so sánh\n",
    "    condition_recrawl = df['note'].notna() & (df['note'].astype(str).str.strip() != '')\n",
    "\n",
    "    recrawl_df = df[condition_recrawl].copy()\n",
    "    correct_df = df[~condition_recrawl].copy()\n",
    "\n",
    "    return correct_df, recrawl_df\n",
    "\n",
    "def process_files_by_note(\n",
    "    input_files: list, \n",
    "    output_dir: str,\n",
    "    aggregated_correct_path: str, \n",
    "    aggregated_recrawl_path: str,\n",
    "    recrawled_files: list = None # THÊM THAM SỐ MỚI\n",
    "):\n",
    "    \"\"\"\n",
    "    Xử lý một danh sách file, lọc từng file dựa trên cột 'Note'\n",
    "    và chỉ xét những dòng có cột 'title' có giá trị.\n",
    "    Sau đó đối chiếu với các file đã recrawl để loại bỏ những dòng đã được sửa đúng.\n",
    "    Lưu output riêng lẻ và hai file tổng hợp cuối cùng.\n",
    "    \"\"\"\n",
    "    all_correct_dfs = []\n",
    "    all_recrawl_dfs = []\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # --- BƯỚC 1: XỬ LÝ CÁC FILE INPUT BAN ĐẦU ---\n",
    "    for file_path in input_files:\n",
    "        print(f\"\\n--- Đang xử lý file input: {file_path} ---\")\n",
    "        try:\n",
    "            # Đọc file với dtype=str để đảm bảo cột 'note' và 'title' được đọc đúng dạng chuỗi\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig', na_values=[''], dtype=str).fillna('')\n",
    "            print(f\"Đã đọc thành công {len(df)} dòng.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Lỗi: Không tìm thấy file '{file_path}'. Bỏ qua file này.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi khi đọc file '{file_path}': {e}. Bỏ qua file này.\")\n",
    "            continue\n",
    "\n",
    "        # Chỉ xét những dòng có cột 'title' có giá trị\n",
    "        if 'title' in df.columns:\n",
    "            initial_rows = len(df)\n",
    "            df = df[df['title'].notna() & (df['title'].astype(str).str.strip() != '')].copy()\n",
    "            if len(df) < initial_rows:\n",
    "                print(f\"Đã loại bỏ {initial_rows - len(df)} dòng do cột 'title' trống.\")\n",
    "        else:\n",
    "            print(\"Cảnh báo: Không tìm thấy cột 'title'. Không thể lọc theo tiêu chí 'title có giá trị'.\")\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"Không còn dòng nào sau khi lọc theo 'title'. Bỏ qua file này.\")\n",
    "            continue\n",
    "\n",
    "        correct_df, recrawl_df = split_df_by_note(df)\n",
    "        \n",
    "        print(f\"Kết quả tách ban đầu: {len(correct_df)} dòng không có ghi chú, {len(recrawl_df)} dòng có ghi chú.\")\n",
    "\n",
    "        if not correct_df.empty:\n",
    "            all_correct_dfs.append(correct_df)\n",
    "        if not recrawl_df.empty:\n",
    "            all_recrawl_dfs.append(recrawl_df)\n",
    "\n",
    "        # --- Lưu các file output riêng lẻ ---\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        individual_correct_path = os.path.join(output_dir, f\"{base_name}_note_correct.csv\")\n",
    "        individual_recrawl_path = os.path.join(output_dir, f\"{base_name}_note_recrawl.csv\")\n",
    "\n",
    "        correct_df.to_csv(individual_correct_path, index=False, encoding='utf-8-sig')\n",
    "        recrawl_df.to_csv(individual_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu output riêng lẻ vào thư mục '{output_dir}'\")\n",
    "\n",
    "    # --- BƯỚC 2: GỘP CÁC DATAFRAME BAN ĐẦU ---\n",
    "    if not all_correct_dfs and not all_recrawl_dfs:\n",
    "        print(\"\\nKhông có dữ liệu từ các file input để xử lý. Kết thúc.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Đang tổng hợp kết quả từ các file input ---\")\n",
    "    master_correct_df = pd.concat(all_correct_dfs, ignore_index=True) if all_correct_dfs else pd.DataFrame()\n",
    "    master_recrawl_df = pd.concat(all_recrawl_dfs, ignore_index=True) if all_recrawl_dfs else pd.DataFrame()\n",
    "\n",
    "    # --- BƯỚC 3 (MỚI): ĐỐI CHIẾU VỚI KẾT QUẢ ĐÃ RECRAWL DỰA TRÊN 'note' ---\n",
    "    if recrawled_files:\n",
    "        print(\"\\n--- Đang đối chiếu với kết quả đã recrawl (dựa trên cột 'note') ---\")\n",
    "        recrawled_dfs_list = []\n",
    "        for r_file in recrawled_files:\n",
    "            try:\n",
    "                # Đọc file đã recrawl, đảm bảo dtype=str cho 'note' và 'title'\n",
    "                df = pd.read_csv(r_file, encoding='utf-8-sig', na_values=[''], dtype=str).fillna('')\n",
    "                # Lọc title cho file đã recrawl cũng\n",
    "                if 'title' in df.columns:\n",
    "                    df = df[df['title'].notna() & (df['title'].astype(str).str.strip() != '')].copy()\n",
    "                else:\n",
    "                    print(f\"Cảnh báo: File đã recrawl '{r_file}' không có cột 'title'.\")\n",
    "\n",
    "                if not df.empty:\n",
    "                    recrawled_dfs_list.append(df)\n",
    "                    print(f\"Đã đọc file đã recrawl: {r_file}\")\n",
    "                else:\n",
    "                    print(f\"File đã recrawl '{r_file}' trống sau khi lọc 'title'.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Cảnh báo: Không tìm thấy file đã recrawl '{r_file}'. Bỏ qua.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi đọc file đã recrawl '{r_file}': {e}. Bỏ qua.\")\n",
    "        \n",
    "        if recrawled_dfs_list:\n",
    "            recrawled_master_df = pd.concat(recrawled_dfs_list, ignore_index=True)\n",
    "            \n",
    "            # Tái sử dụng split_df_by_note để xác định những dòng nào giờ đã \"đúng\" (không có note)\n",
    "            newly_correct_after_recrawl_df, _ = split_df_by_note(recrawled_master_df)\n",
    "            \n",
    "            if not newly_correct_after_recrawl_df.empty:\n",
    "                print(f\"Tìm thấy {len(newly_correct_after_recrawl_df)} dòng đã không còn ghi chú sau khi recrawl.\")\n",
    "                \n",
    "                # Chuẩn bị keys để đối chiếu\n",
    "                # Đảm bảo title/acronym không trống trước khi tạo keys\n",
    "                newly_correct_after_recrawl_df['title'] = newly_correct_after_recrawl_df['title'].str.strip()\n",
    "                if 'acronym' in newly_correct_after_recrawl_df.columns:\n",
    "                    newly_correct_after_recrawl_df['acronym'] = newly_correct_after_recrawl_df['acronym'].str.strip()\n",
    "\n",
    "                subset_keys = ['title']\n",
    "                if 'acronym' in newly_correct_after_recrawl_df.columns:\n",
    "                    subset_keys.append('acronym')\n",
    "\n",
    "                # Loại bỏ các dòng có title/acronym rỗng sau khi strip trước khi tạo keys\n",
    "                newly_correct_after_recrawl_df = newly_correct_after_recrawl_df[newly_correct_after_recrawl_df['title'] != '']\n",
    "                if 'acronym' in newly_correct_after_recrawl_df.columns:\n",
    "                    newly_correct_after_recrawl_df = newly_correct_after_recrawl_df[newly_correct_after_recrawl_df['acronym'] != '']\n",
    "\n",
    "                # Tạo set các khóa của những dòng đã được sửa đúng\n",
    "                corrected_keys_after_recrawl = set(\n",
    "                    tuple(x) for x in newly_correct_after_recrawl_df[subset_keys].values\n",
    "                )\n",
    "                \n",
    "                # --- CẬP NHẬT master_recrawl_df và master_correct_df ---\n",
    "                # 1. Loại bỏ các dòng đã được sửa đúng khỏi danh sách recrawl tổng\n",
    "                # Tạo một Series với các khóa (title, acronym) của master_recrawl_df để so sánh\n",
    "                master_recrawl_keys = master_recrawl_df[subset_keys].apply(tuple, axis=1)\n",
    "                is_now_correct_mask = master_recrawl_keys.isin(corrected_keys_after_recrawl)\n",
    "                \n",
    "                # Giữ lại những dòng KHÔNG có trong danh sách đã sửa đúng\n",
    "                master_recrawl_df_kept = master_recrawl_df[~is_now_correct_mask].copy()\n",
    "                master_recrawl_df_moved = master_recrawl_df[is_now_correct_mask].copy() # Các dòng bị di chuyển\n",
    "                \n",
    "                master_recrawl_df = master_recrawl_df_kept\n",
    "                print(f\"Đã loại bỏ {len(master_recrawl_df_moved)} dòng khỏi danh sách recrawl tổng vì đã được sửa đúng.\")\n",
    "\n",
    "                # 2. Thêm các dòng vừa được sửa đúng vào danh sách correct tổng\n",
    "                master_correct_df = pd.concat([master_correct_df, newly_correct_after_recrawl_df], ignore_index=True)\n",
    "                print(f\"Đã thêm {len(newly_correct_after_recrawl_df)} dòng vào danh sách đúng tổng.\")\n",
    "            else:\n",
    "                print(\"Không có dòng nào được coi là 'đúng' trong các file đã recrawl (theo cột 'note').\")\n",
    "        else:\n",
    "            print(\"Không có file đã recrawl nào hợp lệ để đối chiếu.\")\n",
    "\n",
    "    # --- BƯỚC 4: LOẠI BỎ TRÙNG LẶP LẦN CUỐI VÀ LƯU FILE ---\n",
    "    print(\"\\n--- Hoàn tất và lưu file tổng hợp cuối cùng ---\")\n",
    "    \n",
    "    # Chuẩn bị cột cho drop_duplicates lần cuối\n",
    "    subset_for_dedup = ['title']\n",
    "    \n",
    "    # Xử lý và lưu file CORRECT tổng\n",
    "    if not master_correct_df.empty:\n",
    "        # Chuẩn hóa title/acronym và loại bỏ các dòng rỗng trước khi final dedup\n",
    "        master_correct_df['title'] = master_correct_df['title'].astype(str).str.strip()\n",
    "        if 'acronym' in master_correct_df.columns:\n",
    "            master_correct_df['acronym'] = master_correct_df['acronym'].astype(str).str.strip()\n",
    "            subset_for_dedup_correct = ['title', 'acronym']\n",
    "        else:\n",
    "            subset_for_dedup_correct = ['title']\n",
    "\n",
    "        master_correct_df = master_correct_df[master_correct_df['title'] != '']\n",
    "        if 'acronym' in master_correct_df.columns:\n",
    "             master_correct_df = master_correct_df[master_correct_df['acronym'] != '']\n",
    "\n",
    "        final_correct_df = master_correct_df.drop_duplicates(subset=subset_for_dedup_correct, keep='first')\n",
    "        final_correct_df.to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_correct_df)} dòng đúng (không có ghi chú) vào '{aggregated_correct_path}'.\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'đúng' nào. Đã tạo file rỗng '{aggregated_correct_path}'.\")\n",
    "\n",
    "    # Xử lý và lưu file RECRAWL tổng\n",
    "    if not master_recrawl_df.empty:\n",
    "        # Chuẩn hóa title/acronym và loại bỏ các dòng rỗng trước khi final dedup\n",
    "        master_recrawl_df['title'] = master_recrawl_df['title'].astype(str).str.strip()\n",
    "        if 'acronym' in master_recrawl_df.columns:\n",
    "            master_recrawl_df['acronym'] = master_recrawl_df['acronym'].astype(str).str.strip()\n",
    "            subset_for_dedup_recrawl = ['title', 'acronym']\n",
    "        else:\n",
    "            subset_for_dedup_recrawl = ['title']\n",
    "\n",
    "        master_recrawl_df = master_recrawl_df[master_recrawl_df['title'] != '']\n",
    "        if 'acronym' in master_recrawl_df.columns:\n",
    "             master_recrawl_df = master_recrawl_df[master_recrawl_df['acronym'] != '']\n",
    "             \n",
    "        final_recrawl_df = master_recrawl_df.drop_duplicates(subset=subset_for_dedup_recrawl, keep='first')\n",
    "        final_recrawl_df.to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_recrawl_df)} dòng cần recrawl (có ghi chú) vào '{aggregated_recrawl_path}'.\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'cần recrawl' nào. Đã tạo file rỗng '{aggregated_recrawl_path}'.\")\n",
    "\n",
    "\n",
    "# --- Cách sử dụng ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Danh sách các file input ban đầu (ví dụ: các file batch_X_check.csv)\n",
    "    input_csv_files_for_note_check = [\n",
    "        './src/conference/evaluate/batch4.csv',\n",
    "        './src/conference/evaluate/batch5.csv',\n",
    "        './src/conference/evaluate/batch9.csv',\n",
    "        './src/conference/evaluate/batch14.csv',\n",
    "        './src/conference/evaluate/batch15.csv',\n",
    "        './src/conference/evaluate/batch18.csv',\n",
    "        './src/conference/evaluate/batch20.csv'\n",
    "    ]\n",
    "\n",
    "    # 2. Danh sách các file là KẾT QUẢ của lần recrawl trước đó (sau khi đã được sửa)\n",
    "    # Ví dụ: nếu bạn đã chạy recrawl cho batch4 và nhận được file recrawl_batch_4_result.csv\n",
    "    recrawled_results_files = [\n",
    "        './src/conference/evaluate/recrawl_batch_4_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_5_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_9_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_14_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_15_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_18_check_lan_1.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_20_check_lan_1.csv',\n",
    "\n",
    "        './src/conference/evaluate/recrawl_all_tri_1_50.csv',\n",
    "        './src/conference/evaluate/recrawl_all_tri_51_100.csv',\n",
    "        './src/conference/evaluate/recrawl_all_tri_101_150.csv',\n",
    "\n",
    "        './src/conference/evaluate/recrawl_all_tri_1_32_lan_2.csv',\n",
    "\n",
    "        './src/conference/evaluate/recrawl_all_tri_lan_3.csv',\n",
    "\n",
    "    ]\n",
    "\n",
    "    # 3. Thư mục để chứa các file output riêng lẻ\n",
    "    individual_output_directory_note = './src/conference/evaluate/tri_check_outputs'\n",
    "\n",
    "    # 4. Đường dẫn cho 2 file tổng hợp cuối cùng\n",
    "    aggregated_correct_file_note = './src/conference/evaluate/tri_all_correct_final.csv'\n",
    "    aggregated_recrawl_file_note = './src/conference/evaluate/tri_all_recrawl_final.csv'\n",
    "\n",
    "    # 5. Gọi hàm xử lý chính\n",
    "    process_files_by_note(\n",
    "        input_files=input_csv_files_for_note_check,\n",
    "        output_dir=individual_output_directory_note,\n",
    "        aggregated_correct_path=aggregated_correct_file_note,\n",
    "        aggregated_recrawl_path=aggregated_recrawl_file_note,\n",
    "        recrawled_files=recrawled_results_files # TRUYỀN THAM SỐ MỚI VÀO ĐÂY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu quá trình merge các file CSV...\n",
      "Đã đọc thành công: ./src/conference/evaluate/ALL_BATCHES_correct_final.csv (có 34 cột)\n",
      "Đã đọc thành công: ./src/conference/evaluate/tri_all_correct_final.csv (có 29 cột)\n",
      "Đã đọc thành công: ./src/conference/evaluate/correctFiles/batch_1_6_7_10_11_17.csv (có 25 cột)\n",
      "\n",
      "Tìm thấy 24 cột chung ở tất cả các file:\n",
      "Thứ tự cột trong file output sẽ dựa trên file cuối cùng: ./src/conference/evaluate/correctFiles/batch_1_6_7_10_11_17.csv\n",
      "Thứ tự các cột: ['requestId', 'originalRequestId', 'title', 'acronym', 'mainLink', 'cfpLink', 'impLink', 'information', 'conferenceDates', 'year', 'location', 'cityStateProvince', 'country', 'continent', 'type', 'submissionDate', 'notificationDate', 'cameraReadyDate', 'registrationDate', 'otherDate', 'topics', 'publisher', 'summary', 'callForPapers']\n",
      "\n",
      "Đã hợp nhất thành công các file vào './src/conference/evaluate/full.csv'.\n",
      "File kết quả có 746 dòng và 24 cột.\n",
      "\n",
      "--- Bắt đầu kiểm tra định dạng JSON trong các cột 'Date' ---\n",
      "Các cột sẽ được kiểm tra: ['submissionDate', 'notificationDate', 'cameraReadyDate', 'registrationDate', 'otherDate']\n",
      "\n",
      ">>> KIỂM TRA THÀNH CÔNG: Tất cả các giá trị trong các cột 'Date' đều là JSON hợp lệ (hoặc rỗng).\n",
      "\n",
      "--- Hoàn thành chương trình ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "def merge_csv_common_columns_ordered(file_paths, output_filename):\n",
    "    \"\"\"\n",
    "    Đọc nhiều file CSV, tìm các cột chung (phân biệt hoa thường),\n",
    "    sau đó hợp nhất các file chỉ với các cột chung đó.\n",
    "    Thứ tự các cột trong file kết quả sẽ theo thứ tự của các cột chung\n",
    "    trong file CSV cuối cùng trong danh sách input.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list): Danh sách các đường dẫn đầy đủ đến các file CSV.\n",
    "        output_filename (str): Đường dẫn và tên file CSV đầu ra.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True nếu merge thành công, False nếu có lỗi.\n",
    "    \"\"\"\n",
    "    if not file_paths:\n",
    "        print(\"Lỗi: Danh sách đường dẫn file CSV trống. Không có gì để xử lý.\")\n",
    "        return False\n",
    "\n",
    "    dataframes = []\n",
    "    # Bước 1: Đọc tất cả các file CSV vào DataFrame\n",
    "    for fp in file_paths:\n",
    "        try:\n",
    "            # Thêm dtype=str để đảm bảo mọi thứ được đọc vào dưới dạng chuỗi,\n",
    "            # tránh việc pandas tự động chuyển đổi kiểu dữ liệu có thể làm hỏng JSON.\n",
    "            df = pd.read_csv(fp, dtype=str)\n",
    "            dataframes.append(df)\n",
    "            print(f\"Đã đọc thành công: {fp} (có {len(df.columns)} cột)\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Lỗi: Không tìm thấy file tại đường dẫn: {fp}. Bỏ qua file này.\")\n",
    "            continue\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Cảnh báo: File trống hoặc không có header: {fp}. Bỏ qua file này.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc file {fp}: {e}. Bỏ qua file này.\")\n",
    "            continue\n",
    "\n",
    "    if not dataframes:\n",
    "        print(\"Không có file CSV nào được đọc thành công. Không thể thực hiện merge.\")\n",
    "        return False\n",
    "\n",
    "    # Bước 2: Tìm danh sách các cột chung có ở tất cả các file\n",
    "    common_columns_set = set(dataframes[0].columns)\n",
    "    for i in range(1, len(dataframes)):\n",
    "        common_columns_set.intersection_update(set(dataframes[i].columns))\n",
    "\n",
    "    if not common_columns_set:\n",
    "        print(\"Không tìm thấy cột chung nào ở TẤT CẢ các file CSV đã đọc. Không tạo file mới.\")\n",
    "        return False\n",
    "\n",
    "    # Bước 3: Lấy thứ tự cột từ file cuối cùng trong danh sách\n",
    "    last_df = dataframes[-1]\n",
    "    ordered_common_columns = [col for col in last_df.columns if col in common_columns_set]\n",
    "    \n",
    "    if len(ordered_common_columns) != len(common_columns_set):\n",
    "        print(\"Cảnh báo: Thứ tự cột từ file cuối cùng không chứa tất cả các cột chung. Sẽ sắp xếp theo alphabet.\")\n",
    "        ordered_common_columns = sorted(list(common_columns_set))\n",
    "\n",
    "    print(f\"\\nTìm thấy {len(ordered_common_columns)} cột chung ở tất cả các file:\")\n",
    "    print(f\"Thứ tự cột trong file output sẽ dựa trên file cuối cùng: {file_paths[-1]}\")\n",
    "    print(f\"Thứ tự các cột: {ordered_common_columns}\")\n",
    "\n",
    "    # Bước 4: Tạo danh sách các DataFrame mới, chỉ chứa các cột chung\n",
    "    filtered_dataframes = [df[ordered_common_columns] for df in dataframes]\n",
    "\n",
    "    # Bước 5: Hợp nhất tất cả các DataFrame đã lọc lại với nhau\n",
    "    try:\n",
    "        merged_df = pd.concat(filtered_dataframes, ignore_index=True)\n",
    "\n",
    "        # Bước 6: Lưu DataFrame đã hợp nhất vào file CSV mới\n",
    "        merged_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nĐã hợp nhất thành công các file vào '{output_filename}'.\")\n",
    "        print(f\"File kết quả có {merged_df.shape[0]} dòng và {merged_df.shape[1]} cột.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi hợp nhất các DataFrame hoặc ghi file: {e}\")\n",
    "        return False\n",
    "\n",
    "def validate_json_in_date_columns(csv_filepath):\n",
    "    \"\"\"\n",
    "    Kiểm tra các cột kết thúc bằng \"Date\" trong một file CSV để xem mỗi ô\n",
    "    có chứa một chuỗi JSON hợp lệ hay không.\n",
    "\n",
    "    Args:\n",
    "        csv_filepath (str): Đường dẫn đến file CSV cần kiểm tra.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Bắt đầu kiểm tra định dạng JSON trong các cột 'Date' ---\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filepath, dtype=str).fillna('') # Đọc mọi thứ dạng chuỗi, và thay NaN bằng chuỗi rỗng\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file '{csv_filepath}' để kiểm tra.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file '{csv_filepath}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Tìm các cột có tên kết thúc bằng \"Date\"\n",
    "    date_columns = [col for col in df.columns if col.endswith(\"Date\")]\n",
    "\n",
    "    if not date_columns:\n",
    "        print(\"Không tìm thấy cột nào kết thúc bằng 'Date' để kiểm tra.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Các cột sẽ được kiểm tra: {date_columns}\")\n",
    "\n",
    "    invalid_entries = []\n",
    "    # Lặp qua từng cột cần kiểm tra\n",
    "    for col_name in date_columns:\n",
    "        # Lặp qua từng dòng (index và value) trong cột đó\n",
    "        for index, value in df[col_name].items():\n",
    "            # Bỏ qua các ô rỗng hoặc chỉ có khoảng trắng\n",
    "            if not value or value.isspace():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Thử phân tích chuỗi thành JSON\n",
    "                json.loads(value)\n",
    "            except json.JSONDecodeError:\n",
    "                # Nếu thất bại, ghi lại thông tin lỗi\n",
    "                invalid_entries.append({\n",
    "                    \"row_index\": index,\n",
    "                    \"column\": col_name,\n",
    "                    \"value\": value\n",
    "                })\n",
    "\n",
    "    # In kết quả\n",
    "    if not invalid_entries:\n",
    "        print(\"\\n>>> KIỂM TRA THÀNH CÔNG: Tất cả các giá trị trong các cột 'Date' đều là JSON hợp lệ (hoặc rỗng).\")\n",
    "    else:\n",
    "        print(f\"\\n>>> KIỂM TRA THẤT BẠI: Tìm thấy {len(invalid_entries)} giá trị không phải là JSON hợp lệ:\")\n",
    "        print(\"-\" * 50)\n",
    "        for error in invalid_entries:\n",
    "            print(f\"  - Dòng (chỉ số 0): {error['row_index']}\")\n",
    "            print(f\"    Cột              : '{error['column']}'\")\n",
    "            print(f\"    Giá trị không hợp lệ: {error['value']}\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "# --- Cách sử dụng ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Đặt danh sách các đường dẫn đến file CSV của bạn vào đây.\n",
    "    input_files = [\n",
    "        './src/conference/evaluate/ALL_BATCHES_correct_final.csv',\n",
    "        './src/conference/evaluate/tri_all_correct_final.csv',\n",
    "        './src/conference/evaluate/correctFiles/batch_1_6_7_10_11_17.csv'\n",
    "    ]\n",
    "\n",
    "    # Đặt tên cho file CSV kết quả đầu ra\n",
    "    output_merged_file = './src/conference/evaluate/full.csv'\n",
    "\n",
    "    # # Gọi hàm để thực hiện việc merge\n",
    "    print(\"Bắt đầu quá trình merge các file CSV...\")\n",
    "    merge_successful = merge_csv_common_columns_ordered(input_files, output_merged_file)\n",
    "\n",
    "    # Nếu việc merge thành công, thực hiện kiểm tra file kết quả\n",
    "    if merge_successful:\n",
    "        validate_json_in_date_columns(output_merged_file)\n",
    "\n",
    "    print(\"\\n--- Hoàn thành chương trình ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
