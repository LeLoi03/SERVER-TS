Conference full name: ACM/SIAM Symposium on Discrete Algorithms (SODA)

1. Website of SODA_1: https://www.siam.org/conferences-events/past-event-archive/soda25/
Website information of SODA_1:

Skip to main contentJoin SIAM 
 Donate 
 Log In 
 Journals 
 Books 
 SIAM Engage 
 Join SIAM 
 Donate 
 Log In 
 SIAM News 
 Activity Groups 
 Prizes & Awards 
 Log In 
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
 Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
 SIAM Journal on Applied Algebra and Geometry 
 SIAM Journal on Applied Dynamical Systems 
 SIAM Journal on Applied Mathematics 
 SIAM Journal on Computing 
 SIAM Journal on Control and Optimization 
 SIAM Journal on Discrete Mathematics 
 SIAM Journal on Financial Mathematics 
 SIAM Journal on Imaging Sciences 
 SIAM Journal on Life Sciences 
 SIAM Journal on Mathematical Analysis 
 SIAM Journal on Mathematics of Data Science 
 SIAM Journal on Matrix Analysis and Applications 
 SIAM Journal on Numerical Analysis 
 SIAM Journal on Optimization 
 SIAM Journal on Scientific Computing 
 SIAM / ASA Journal on Uncertainty Quantification 
 Theory of Probability and Its Applications 
 href="/publications/siam-journals/siam-undergraduate-research-online-siuro/" - SIAM Undergraduate Research Online 
 SIAM Books 
 Our textbooks and monographs are indispensable to researchers, faculty, and students around the world. 
 SIAM Books 
 SIAM News 
 The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science. 
 SIAM News 
 Reports 
 Proceedings 
 Subscriptions & Ordering 
 Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
 Visiting Lecturer Program 
 MathWorks Math Modeling (M3) Challenge 
 href="/programs-initiatives/programs/siam-simons-undergraduate-summer-research-program/" - SIAM-Simons Undergraduate Summer Research Program 
 SIAM Science Policy Fellowship 
 MGB-SIAM Early Career Fellowship 
 SIAM Postdoctoral Support Program 
 Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
 See All Programs 
 Professional Development | Careers in Applied Mathematics 
 Career Resources 
 Job Board 
 Internships 
 Prizes and Awards | Deadline Calendar 
 SIAM Fellows Program 
 Policy & Procedures 
 Congratulations to the 2025 Class of SIAM Fellows! 
 These distinguished members were nominated in recognition of their outstanding research and service to the community. 
 href="/publications/siam-news/articles/siam-announces-2025-class-of-fellows/" - Congratulations to the 2025 Class of SIAM Fellows! 
 Industry 
 Equity, Diversity, & Inclusion 
 Education Resources 
 Science Policy 
 Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
 Section Meetings 
 Webinars & Seminars 
 Workshops 
 Career Fairs 
 Cooperating Conferences 
 Archive 
 See all Events 
 Conference Support | Travel & Registration Support 
 Child Care Grants 
 About SIAM Conferences & Events | For Sponsors & Exhibitors 
 Conference Guidelines 
 Featured Videos & Lectures 
 Save the Date for AN25! 
 The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada. 
 Save the Date for AN25! 
 Membership | Toggle sub-menu | Individual Membership | Join 13,000+ applied mathematicians and computational and data scientists from around the world. 
 Learn More 
 Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
 Learn More 
 Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
 Get Your Questions Answered 
 Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
 Sections 
 Student Chapters 
 SIAM Engage Online Community 
 Ways to Participate | Advocate to Support Our Community 
 href="/publications/siam-journals/" - Become an Author, Editor, or Referee 
 Network and Present at a Conference 
 Nominate for Prizes 
 Serve on Committees 
 href="/publications/siam-news/about-siam-news/submission-guidelines/" - Write for SIAM News 
 Ways to Support | Become a Sponsor 
 Donate to SIAM 
 Spread the Word 
 About Us | Toggle sub-menu | Overview 
 Mission & History 
 Governance & Leadership 
 Committees 
 Staff 
 Collaborations 
 Bylaws & Reports 
 Policies & Guidelines 
 Join SIAM 
 Contact Us 
 Back to topHome 
 Conferences & Events 
 Past Event Archive 
 SODA25 
 In Person 
 SIAM Conferences 
 ACM-SIAM Symposium on Discrete Algorithms (SODA25) 
 href="/conferences-events/past-event-archive/soda25/lodging-support/" - Reserve Your Room
Event Details 
 January 12–15 , 2025 
 New Orleans, Louisiana, U.S. 
 Astor Crowne Plaza - New Orleans French Quarter 
 Stay Connected 
 Facebook 
 #SIAMDA25 
 In This Section 
 href="/conferences-events/past-event-archive/soda25/registration/" - Registration 
 href="/conferences-events/past-event-archive/soda25/lodging-support/" - Lodging & Support 
 href="/conferences-events/past-event-archive/soda25/program/" - Program 
 href="/conferences-events/past-event-archive/soda25/submissions/" - Submissions 
 More 
 Announcement 
 href="/conferences-events/past-event-archive/soda25/program/program-abstracts/" - Visit the Program & Abstracts page to view the At-a-Glance Schedule & Online Programs, Mobile App, Searchable Abstracts and Proceedings. 
 The ACM-SIAM Symposium on Discrete Algorithms (SODA25) and its co-located conferences will proceed as scheduled and be held in a fully in-person format. City officials are working with the FBI, NOPD, and Louisiana State Police to investigate and reopen the Bourbon Street area as soon as possible after the recent tragedy; the area is expected to be completely re-opened by the beginning of the conference. The Astor Crowne Plaza is fully operational. 
 Deadlines 
 href="/conferences-events/past-event-archive/soda25/registration/" - Early Registration Deadline | December 9, 2024 
 href="/conferences-events/past-event-archive/soda25/lodging-support/hotel-transportation/" - Reserve Now: Hotel Reservation Deadline Extended! | December 13, 2024 
 href="/conferences-events/past-event-archive/soda25/submissions/" - Deadline Passed: Submissions Due | July 5, 2024 
 About the Conference 
 SODA is sponsored by theSIAM Activity Group on Discrete Mathematicsand theACM Special Interest Group on Algorithms and Computation Theory. 
 This symposium focuses on research topics related to the design and analysis of efficient algorithms and data structures for discrete problems. The scope includes theoretical analysis, as well as experimental validation, of discrete algorithms, and the mathematical problems related to their development or limitations. The scope also includes aspects of combinatorics and discrete mathematics related to discrete algorithms. Papers that raise important algorithmic problems that can benefit from theoretical investigation and analysis, are encouraged. 
 SODA will be held jointly with: 
 SIAM Symposium on Algorithm Engineering and Experiments (ALENEX) 
 SIAM Symposium on Simplicity in Algorithms (SOSA) 
 Connect to others attending the event onLinkedIn. 
 Included Themes 
 Aspects of combinatorics and discrete mathematics, such as: 
 Combinatorial structures 
 Discrete optimization 
 Graph theory 
 Random structures 
 Core topics in discrete algorithms, such as: 
 Algorithm analysis 
 Data structures 
 Experimental algorithmics 
 Lower bounds 
 Mathematical programming 
 Algorithmic aspects of other areas of computer science, such as: 
 Algorithmic fairness 
 Combinatorial scientific computing 
 Communication networks and the internet 
 Computational geometry and topology 
 Computer systems 
 Cryptography, security and privacy 
 Databases and information retrieval 
 Distributed and parallel computing 
 Game theory and mechanism design 
 Machine learning 
 Quantum computing 
 Scheduling and resource allocation 
 Program Committee Co-chairs 
 Yossi Azar 
 Tel-Aviv University, Israel 
 Debmalya Panigrahi 
 Duke University, U.S. 
 Program Committee 
 Amir Abboud 
 Weizmann Institute of Science, Israel 
 Alexandr Andoni 
 Columbia University, U.S. 
 Soheil Behnezad 
 Northeastern University, U.S. 
 Sayan Bhattacharya 
 University of Warwick, United Kingdom 
 Arnab Bhattacharyya 
 National University of Singapore, Singapore 
 Luca Becchetti 
 University of Rome, Italy 
 Petra Berenbrink 
 University of Hamburg, Germany 
 Niv Buchbinder 
 Tel Aviv University, Israel 
 Harry Buhrman 
 Quantinuum (UK), QuSoft and University of Amsterdam, The Netherlands 
 Sergio Cabello 
 University of Ljubljana, Slovenia 
 Yang Cai 
 Yale University, U.S. 
 Parinya Chalermsook 
 Aalto University, Finland 
 Eshan Chattopadhyay 
 Cornell University, U.S. 
 Chandra Chekuri 
 University of Illinois, Urbana-Champaign, U.S. 
 Keerti Choudhary 
 IIT Delhi, India 
 Maria Chudnovsky 
 Princeton University, U.S. 
 Ilan Cohen 
 Bar-Ilan University, Israel 
 Vincent Cohen-Addad 
 Google Research, Switzerland 
 Andrea Coladangelo 
 University of Washington, Seattle, U.S. 
 Jose Correa 
 University of Chile, Chile 
 Rachel Cummings 
 Columbia University, U.S. 
 Jelena Diakonikolas 
 University of Wisconsin, Madison, U.S. 
 Shahar Dobzinski 
 Weizmann Institute of Science, Israel 
 Anne Driemel 
 University of Bonn, Germany 
 Esther Ezra 
 Bar-Ilan University, Israel 
 Emily Fox 
 University of Texas, Dallas, U.S. 
 Nick Gravin 
 Shanghai University of Finance and Economics, China 
 Kasper Green Larsen 
 Aarhus University, Denmark 
 Anupam Gupta 
 New York University, U.S. 
 Tom Gur 
 University of Cambridge, United Kingdom 
 Sungjin Im 
 University of California, Merced, U.S. 
 Michael Kapralov 
 EPFL, Switzerland 
 Telikepalli Kavitha 
 Tata Institute of Fundamental Research, India 
 Dominik Kempa 
 Stony Brook University, U.S. 
 Arindam Khan 
 Indian Institute of Science, India 
 Samir Khuller 
 Northwestern University, U.S. 
 Ravi Kumar 
 Google Research, U.S. 
 O-joung Kwon 
 Hanyang University, South Korea 
 Bundit Lakhenukit 
 Shanghai University of Finance and Economics, China 
 Hung Le 
 University of Massachusetts, Amherst, U.S. 
 Jian Li 
 Tsinghua University, China 
 Yang Liu 
 Institute for Advanced Studies, U.S. 
 William Kuszmaul 
 Harvard University, U.S. 
 Shachar Lovett 
 University of California, San Diego, U.S. 
 Sepideh Mahabadi 
 Microsoft Research, U.S. 
 Nicole Megow 
 University of Bremen, Germany 
 Raghu Meka 
 University of California, Los Angeles, U.S. 
 Divyarthi Mohan 
 Tel Aviv University, Israel 
 Ankur Moitra 
 Massachusetts Institute of Technology, U.S. 
 Shay Mozes 
 Reichman University, Israel 
 Bento Natura 
 Columbia University, U.S. 
 Neil Olver 
 London School of Economics, United Kingdom 
 Krzysztof Onak 
 Boston University, U.S. 
 Seth Pettie 
 University of Michigan, Ann Arbor, U.S. 
 Michał Pilipczuk 
 University of Warsaw, Poland 
 Max Probst Gutenberg 
 ETH Zurich, Switzerland 
 Rajmohan Rajaraman 
 Northeastern University, U.S. 
 Aviad Rubinstein 
 Aviad Rubinstein, 
 Barna Saha 
 University of California, San Diego, U.S. 
 Laura Sanita 
 Bocconi University, Italy 
 Piotr Sankowski 
 IDEAS NCBR and University of Warsaw, Poland 
 Aravind Srinivasan 
 University of Maryland, College Park, U.S. 
 Vera Traub 
 University of Bonn, Germany 
 Madhur Tulsiani 
 Toyota Technological Institute at Chicago, U.S. 
 Seeun William Umboh 
 The University of Melbourne, Australia 
 Sergei Vassilvitskii 
 Google Research, U.S. 
 Magnus Wahlstrom 
 Royal Holloway, University of London, United Kingdom 
 Kangning Wang 
 Stanford University, U.S. 
 Fan Wei 
 Duke University, U.S. 
 Nicole Wein 
 University of Michigan, Ann Arbor, U.S. 
 Mary Wootters 
 Stanford University, U.S. 
 Steering Committee Chair 
 Piotr Indyk 
 Massachusetts Institute of Technology, U.S. 
 Steering Committee 
 Julia Chuzhoy 
 Toyota Technological Institute at Chicago, U.S. 
 Robert Krauthgamer 
 The Weizmann Institute of Science, Israel 
 Sang-il Oum 
 KAIST, South Korea 
 Blair Sullivan 
 The University of Utah, U.S. 
 Shanghua Teng 
 University of Southern California, U.S. 
 Thank You to Our Sponsors 
 href="https://www.microsoft.com/en-us/research/" - 
Special Thanks To 
 Get Involved 
 Sponsor, exhibit, or check out past content in our video and presentation archive. 
 Ways to Sponsor 
 SIAM invites you to show support of this conference through sponsorship opportunities ranging from support of receptions, audio-video needs, to awards for student travel, and more. 
 Ways to Exhibit 
 Learn about opportunities to become an exhibitor at a SIAM conference. 
 Featured Lectures & Videos 
 View slides, recordings, and video from past SIAM conferences. 
 Become a Member 
 SIAM members get 20-30% off registration for our conferences, plus deep discounts on SIAM books, journals, activity group membership, and more. Start reaping the benefits! 
 Funding Agency Support 
 SIAM and the Organizing Committee wish to extend their thanks and appreciation to theU.S. National Science Foundationfor their support. 
 Make the Most of Your Experience 
 About SIAM Conferences 
 Find all of the information you'll need to prepare for and navigate SIAM conferences, including conference guidelines and how to propose a new conference. 
 Explore Conferences 
 Statement on Equity, Diversity, and Inclusion 
 As a professional society, SIAM is committed to empowering equitable, diverse, and inclusive participation in all aspects of our community. SIAM will provide a climate that encourages the open expression and exchange of ideas, that is free from all forms of discrimination, harassment, and retaliation, and that is welcoming and comfortable to all members and to those who participate in its activities. 
 In pursuit of this commitment, SIAM is dedicated to the philosophy of equality of opportunity and treatment for all participants regardless of gender, gender identity or expression, sexual orientation, race, color, national or ethnic origin, religion or religious belief, age, marital status, disabilities, veteran status, and field of expertise. 
 This philosophy extends from SIAM’s governing structures and bodies to its conferences, publications, awards, and to all its organized activities. 
 We expect all members of SIAM and participants in SIAM activities to work towards this commitment to equity, diversity, and inclusion. 
 If you have experienced or observed behavior that is not consistent with the principles expressed above, you are encouraged to report any violation using the SIAM hotline, hosted by the third-party hotline provider, EthicsPoint. The information you provide will be sent to us by EthicsPoint on a totally confidential and anonymous basis if you should choose. You have our guarantee that your comments will be heard.Please submit reports. 
 Read all ofSIAM's conference guidelines and policies, including the Statement on Potentially Offensive Material. 
 Read more about thehref="/publications/siam-news/articles/acm-siam-soda-code-of-conduct/" - ACM-SIAM SODA Code of Conduct
. 
 Contact Us 
 Questions about SIAM conferences? Get in touch with our staff. 
 Contact SIAM Conferences StaffStay Up-to-Date with Email Alerts 
 Sign up for our monthly newsletter and emails about other topics of your choosing. 
 Email AddressSign Up Now 
 3600 Market Street6th FloorPhiladelphia, PA 19104 USAFacebook 
 Twitter 
 Youtube 
 LinkedIn 
 About SIAM | Mission & History 
 Governance & Leadership 
 Committees 
 Staff 
 Collaborations 
 Code of Conduct 
 Policies & Guidelines 
 Jobs at SIAM 
 Contact Us 
 Membership | Member Benefits 
 Become a Member 
 Renew Your Membership 
 Connect with a Community 
 Ways to Participate 
 Jobs in STEM 
 Share & Support | Newsroom 
 Advertise with Us 
 Become a Sponsor 
 Post a Job 
 Information for Librarians 
 Subscribe to Our Emails 
 © 2025 Society for Industrial and Applied Mathematics 
 Terms & Conditions 
 Privacy

2. Website of SODA_1: https://epubs.siam.org/doi/10.1137/1.9781611977912
Website information of SODA_1:

Skip to main content 
 SearchSearch 
 This BookThis Book 
 Anywhere 
 Books 
 Journals 
 Proceedings 
 Quick Search in BooksEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Advanced Search 
 0Register / Sign In 
 Access via your Institution 
 Skip main navigationClose Drawer MenuOpen Drawer MenuMenuJournals | SIAM Review 
 Multiscale Modeling & Simulation 
 SIAM Journal on Applied Algebra and Geometry 
 SIAM Journal on Applied Dynamical Systems 
 SIAM Journal on Applied Mathematics 
 SIAM Journal on Computing 
 SIAM Journal on Control and Optimization 
 SIAM Journal on Discrete Mathematics 
 SIAM Journal on Financial Mathematics 
 SIAM Journal on Imaging Sciences 
 SIAM Journal on Mathematical Analysis 
 SIAM Journal on Mathematics of Data Science 
 SIAM Journal on Matrix Analysis and Applications 
 SIAM Journal on Numerical Analysis 
 SIAM Journal on Optimization 
 SIAM Journal on Scientific Computing 
 SIAM/ASA Journal on Uncertainty Quantification 
 Theory of Probability & Its Applications 
 Locus 
 E-books 
 Bookstore 
 Proceedings 
 href="#" - For Authors | href="/journal-authors" - Journal Authors 
 href="/book-authors" - Book Authors 
 For Librarians 
 Collections | href="/topic/topics/topic-epidemiology" - Epidemiology Collection 
 href="/topic/topics/topic-highimpact" - High Impact Article Collection 
 JOIN SIAM 
 HELP/CONTACT US 
 Proceedings 
 Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) 
 Editor(s):href="/author/Woodruff%2C+David+P" - David P. Woodruff 
 Proceedings Series | Algorithm Engineering & Experiments (ALENEX) 
 Algorithmic Principles of Computer Systems-APOCS 
 Analytic Algorithmics and Combinatorics (ANALCO) 
 Applied and Computational Discrete Algorithms (ACDA) 
 Combinatorial Scientific Computing (CSC) 
 Control and its Applications 
 Data Mining 
 href="/action/showPublications?pubType=proceedings&category=10.1555/category.40105908&expand=10.1555/category.40105908" - Discrete Algorithms (SODA) 
 International Congress of Industrial and Applied Mathematics (ICIAM) 
 International Meshing Roundtable (IMR) 
 Mathematics for Industry 
 Parallel Processing for Scientific Computing (PP) 
 Simplicity in Algorithms-SOSA 
 ShareShare onFacebook 
 Twitter 
 LinkedIn 
 Email 
 HomeProceedingshref="/doi/book/10.1137/1.9781611977912" - Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)
Description | This symposium focuses on research topics related to efficient algorithms and data structures for discrete problems. In addition to the design of such methods and structures, the scope also includes their use, performance analysis, and the mathematical problems related to their development or limitations. Performance analyses may be analytical or experimental and may address worst-case or expected-case performance. Studies can be theoretical or based on data sets that have arisen in practice and may address methodological issues involved in performance analysis. 
 Purchase a print copy (link) 
 CHAPTERS 
 CHAPTERS 
 Select AllFor selected items: 
 Full Access 
 Front Matter 
 pp.i–xx 
 Abstract 
 PDF 
 AbstractFrontmatter includes preface and acknowledgments and table of contents 
 Full Access 
 Prior-Independent Auctions for Heterogeneous Bidders 
 href="/author/Guruganesh%2C+Guru" - Guru Guruganesh | , 
 href="/author/Mehta%2C+Aranyak" - Aranyak Mehta | , 
 href="/author/Wang%2C+Di" - Di Wang | , 
 href="/author/Wang%2C+Kangning" - Kangning Wang 
 pp.1–18 
 Abstract 
 PDF 
 AbstractWe study the design of prior-independent auctions in a setting with heterogeneous bidders. In particular, we consider the setting of selling tonbidders whose values are drawn fromnindependent but not necessarily identical distributions. We work in the robust auction design regime, where we assume the seller has no knowledge of the bidders’ value distributions and must design a mechanism that is prior-independent. While there have been many strong results on prior-independent auction design in the i.i.d. setting, not much is known for the heterogeneous setting, even though the latter is of significant practical importance. Unfortunately, no prior-independent mechanism can hope to always guarantee any approximation to Myerson's revenue in the heterogeneous setting; similarly, no prior-independent mechanism can consistently do better than the second-price auction. In light of this, we design a family of (parametrized) randomized auctions which approximates at least one of these benchmarks: For heterogeneous bidders with regular value distributions, our mechanisms either achieve a good approximation of the expected revenue of an optimal mechanism (which knows the bidders’ distributions) or exceeds that of the second-price auction by a certain multiplicative factor. The factor in the latter case naturally trades off with the approximation ratio of the former case. We show that our mechanism is optimal for such a trade-off between the two cases by establishing a matching lower bound. Our result extends to sellingkidentical items to heterogeneous bidders with an additionalO(ln2k)-factor in our trade-off between the two cases. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2207.09429. 
 Full Access 
 Impossibilities for Obviously Strategy-Proof Mechanisms 
 href="/author/Ron%2C+Shiri" - Shiri Ron 
 pp.19–40 
 Abstract 
 PDF 
 AbstractWe explore the approximation power of deterministic obviously strategy-proof mechanisms in auctions, where the objective is welfare maximization. A trivial ascending auction on the grand bundle guarantees an approximation of min{m,n} for all valuation classes, where m is the number of items andnis the number of bidders. We focus on two classes of valuations considered “simple”: additive valuations and unit-demand valuations. For additive valuations, Bade and Gonczarowski [EC’17] have shown that exact welfare maximization is impossible. No impossibilities are known for unit-demand valuations. 
 We show that if bidders’ valuations are additive or unit-demand, then no obviously strategy-proof mechanism gives an approximation better than min{m,n}. Thus, the aforementioned trivial ascending auction on the grand bundle is the optimal obviously strategy-proof mechanism. These results illustrate a stark separation between the power of dominant-strategy and obviously strategy-proof mechanisms. The reason for it is that for both of these classes the dominant-strategy VCG mechanism does not only optimize the welfare exactly, but is also “easy” both from a computation and communication perspective. 
 In addition, we prove tight impossibilities for unknown single-minded bidders in a multi-unit auction and in a combinatorial auction. We show that in these environments as well, a trivial ascending auction on the grand bundle is optimal. 
 Full Access 
 Revenue Maximization for Buyers with Costly Participation 
 href="/author/Gonczarowski%2C+Yannai+A" - Yannai A. Gonczarowski | , 
 href="/author/Immorlica%2C+Nicole" - Nicole Immorlica | , 
 href="/author/Li%2C+Yingkai" - Yingkai Li | , 
 href="/author/Lucier%2C+Brendan" - Brendan Lucier 
 pp.41–73 
 Abstract 
 PDF 
 AbstractWe study mechanisms for selling a single item when buyers have private costs for participating in the mechanism. An agent's participation cost can also be interpreted as an outside option value that she must forego to participate. This substantially changes the revenue maximization problem, which becomes non- convex in the presence of participation costs. For multiple buyers, we show how to construct a (2 + ɛ)- approximately revenue-optimal mechanism in polynomial time. Our approach makes use of a many-buyers-to-single-buyer reduction, and in the single-buyer case our mechanism improves to an FPTAS. We also bound the menu size and the sample complexity for the optimal single-buyer mechanism. Moreover, we show that posting a single price in the single-buyer case is in fact optimal under the assumption that either (1) the participation cost is independent of the value, and the value distribution has decreasing marginal revenue or monotone hazard rate; or (2) the participation cost is a concave function of the value. When there are multiple buyers, we show that sequential posted pricing guarantees a large fraction of the optimal revenue under similar conditions. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2103.03980 
 Full Access 
 Breaking the 3/4 Barrier for Approximate Maximin Share 
 href="/author/Akrami%2C+Hannaneh" - Hannaneh Akrami | , 
 href="/author/Garg%2C+Jugal" - Jugal Garg 
 pp.74–91 
 Abstract 
 PDF 
 AbstractWe study the fundamental problem of fairly allocating a set of indivisible goods among n agents with additive valuations using the desirable fairness notion of maximin share (MMS). MMS is the most popular share-based notion, in which an agent finds an allocation fair to her if she receives goods worth at least her MMS value. An allocation is called MMS if all agents receive at least their MMS value. However, since MMS allocations need not exist whenn> 2, a series of works showed the existence of approximate MMS allocations with the current best factor of 
 . The recent work [3] showed the limitations of existing approaches and proved that they cannot improve this factor to 3/4 + Ω(1). In this paper, we bypass these barriers to show the existence of ()-MMS allocations by developing new reduction rules and analysis techniques.*Jugal Garg was supported by NSF Grant CCF-1942321. 
 Full Access 
 Combinatorial Contracts Beyond Gross Substitutes 
 href="/author/Dutting%2C+Paul" - Paul Dutting | , 
 href="/author/Feldman%2C+Michal" - Michal Feldman | , 
 href="/author/Gal+Tzur%2C+Yoav" - Yoav Gal Tzur 
 pp.92–108 
 Abstract 
 PDF 
 AbstractWe study the combinatorial contracting problem of Dütting et al. [13], in which a principal seeks to incentivize an agent to take a set of costly actions. In their model, there is a binary outcome (the agent can succeed or fail), and the success probability and the costs depend on the set of actions taken. The optimal contract is linear, paying the agent an α fraction of the reward. For gross substitutes (GS) rewards and additive costs, they give a poly-time algorithm for finding the optimal contract. They use the properties of GS functions to argue that there are poly-many “critical values” of α, and that one can iterate through all of them efficiently in order to find the optimal contract. 
 In this work we study to which extent GS rewards and additive costs constitute a tractability frontier for combinatorial contracts. We present an algorithm that foranyrewards and costs, enumerates all critical values, with poly-many demand queries (in the number of critical values). This implies the tractability of the optimal contract for any setting with poly-many critical values and efficient demand oracle. A direct corollary is a poly-time algorithm for the optimal contract in settings with supermodular rewards and submodular costs. We also study a natural class of matching-based instances with XOS rewards and additive costs. While the demand problem for this setting is tractable, we show that it admits an super-polynomial number of critical values. On the positive side, we present (pseudo-) polynomial-time algorithms for two natural special cases of this setting. Our work unveils a profound connection to sensitivity analysis, and designates matching-based instances as a crucial focal point for gaining a deeper understanding of combinatorial contract settings. 
 *Accepted as a “soft merge” with Deo-Campo Vuong, Dughmi, Patel, and Prasad [12]. This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program (grant agreement No. 866132), by the Israel Science Foundation (grant number 317/17), by an Amazon Research Award, and by the NSF-BSF (grant number 2020788). The full version of the paper can be accessed at https://arxiv.org/pdf/2309.10766.pdf 
 Full Access 
 On Supermodular Contracts and Dense Subgraphs 
 href="/author/Deo-Campo+Vuong%2C+Ramiro" - Ramiro Deo-Campo Vuong | , 
 href="/author/Dughmi%2C+Shaddin" - Shaddin Dughmi | , 
 href="/author/Patel%2C+Neel" - Neel Patel | , 
 href="/author/Prasad%2C+Aditya" - Aditya Prasad 
 pp.109–132 
 Abstract 
 PDF 
 AbstractWe study the combinatorial contract design problem, introduced and studied by Dütting et al. (2021, 2022), in both the single and multi-agent settings. Prior work has examined the problem when the principal's utility function is submodular or XOS in the actions chosen by the agent(s). We complement this emerging literature with an examination of the problem when the principal's utility is supermodular. Our results apply to the unconstrained contract design problem in the binary outcome case (i.e., the principal's task succeeds or fails), and to the linear contract design problem more generally. 
 In the single-agent setting, we obtain a strongly polynomial time algorithm for the optimal contract. This stands in contrast to the NP-hardness of the problem with submodular principal utility due to Dutting et al. (2021). This result has two technical components, the first of which applies beyond supermodular or submodular utilities. First, we describe a simple divide-and-conquer algorithm that enumerates all the “breakpoints” of the principal's utility function in strongly polynomial time. This result strengthens and simplifies analogous enumeration algorithms from Dütting et al. (2021), and applies to any nondecreasing valuation function for the principal. Second, we show that supermodular valuations lead to a polynomial number of breakpoints, analogous to a similar result by Dutting et al. (2021) for gross substitutes valuations. 
 In the multi-agent setting, we obtain a mixed bag of positive and negative results. First, we show that it is NP-hard to obtain any finite multiplicative approximation, or an additive FPTAS. This stands in contrast to the submodular case, where efficient computation of approximately optimal contracts was shown by Dutting et al. (2022). Second, we derive an additive PTAS for the problem in the instructive special case of graph-based supermodular valuations, and equal costs. En-route to this result, we discover an intimate connection between the multi-agent contract problem and the notorious k-densest subgraph problem. We build on and combine techniques from the literature on dense subgraph problems to obtain our additive PTAS. We leave open the intriguing, and seemingly quite challenging, question of whether an additive PTAS exists more generally for multi-agent supermodular contracts. 
 *The full version of this paper can be accessed at https://arxiv.org/abs/2308.07473. 
 Full Access 
 Sorting Pattern-Avoiding Permutations via 0-1 Matrices Forbidding Product Patterns 
 href="/author/Chalermsook%2C+Parinya" - Parinya Chalermsook | , 
 href="/author/Pettie%2C+Seth" - Seth Pettie | , 
 href="/author/Yingchareonthawornchai%2C+Sorrachai" - Sorrachai Yingchareonthawornchai 
 pp.133–149 
 Abstract 
 PDF 
 AbstractWe consider the problem of comparison-sorting ann-permutationSthatavoidssomek-permutation π. Chalermsook, Goswami, Kozma, Mehlhorn, and Saranurak [CGK+15b] prove that whenSis sorted by inserting the elements into the GreedyFuture [DHI+09] binary search tree, the running time is linear in theextremal functionEx(Pπ⊗ (∴),n). This is the maximum number of 1s in ann × n0-1 matrix avoidingPπ⊗ (∴), wherePπis thek × kpermutation matrix of π, andPπ⊗ (∴) is the2k × 3kKronecker product ofPπand the “hat” pattern (∴). The same time bound can be achieved by sortingSwith Kozma and Saranurak's SmoothHeap [KS20]. 
 Applying off-the-shelf results on the extremal functions of 0-1 matrices, it was known that 
 where α(n) is the inverse-Ackermann function. In this paper we givenearly tightupper and lower bounds on the density ofPπ⊗ (∴)-free matrices in terms of “n“, and improve the dependence on “k“ from doubly exponential to singly exponential. 
 As a consequence, sorting π-free sequences can be performed inO(n2(1+o(1))α(n)) time. For many corollaries of the dynamic optimality conjecture, the best analysis uses forbidden 0-1 matrix theory. Our analysis may be useful in analyzing other classes of access sequences on binary search trees. 
 *Supported by NSF grants CCF-1815316 and CCF-2221980 and by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under grant agreement No 759557. 
 Full Access 
 Vertical Decomposition in 3D and 4D with Applications to Line Nearest-Neighbor Searching in 3D 
 href="/author/K.+Agarwal%2C+Pankaj" - Pankaj K. Agarwal | , 
 href="/author/Ezra%2C+Esther" - Esther Ezra | , 
 href="/author/Sharir%2C+Micha" - Micha Sharir 
 pp.150–170 
 Abstract 
 PDF 
 AbstractVertical decomposition is a widely used general technique for decomposing the cells of arrangements of semi-algebraic sets inℝdinto constant-complexity subcells. In this paper, we settle in the affirmative a few long-standing open problems involving the vertical decomposition of substructures of arrangements ford= 3,4: (i) LetSbe a collection of n semi-algebraic sets of constant complexity in ℝ3, and letU(m) be an upper bound on the complexity of the unionU(S‘) of any subsetS’ ⊆ Sof size at mostm. We prove that the complexity of the vertical decomposition of the complement ofU(S) isO* (n2+U(n)) (where theO* (·) notation hides subpolynomial factors). We also show that the complexity of the vertical decomposition of the entire arrangementA(S) isO*(n2+X), whereXis the number of vertices inA(S). (ii) LetFbe a collection ofntrivariate functions whose graphs are semi-algebraic sets of constant complexity. We show that the complexity of the vertical decomposition of the portion of the arrangementA(F) in ℝ4lying below the lower envelope of F isO*(n3). 
 These results lead to efficient algorithms for a variety of problems involving these decompositions, including algorithms for constructing the decompositions themselves, and for constructing (1/r)-cuttings of substructures of arrangements of the kinds considered above. One additional algorithm of interest is for output-sensitive point enclosure queries amid semi-algebraic sets in three or four dimensions. 
 In addition, as a main domain of applications, we study various proximity problems involving points and lines in ℝ3: We first present a linear-size data structure for answering nearest-neighbor queries, with points, amid n lines in ℝ3inO*(n2/3) time per query. We also study the converse problem, where we return the nearest neighbor of a query line amid n input points, or lines, in ℝ3. We obtain a data structure ofO*(n4) size that answers a nearest-neighbor query inO(logn) time. 
 *Work by Pankaj Agarwal has been partially supported by NSF grants IIS-18-14493, CCF-20-07556, and CCF-22-23870. Work by Esther Ezra has been partially supported by Israel Science Foundation Grant 800/22, and also by US-Israel Binational Science Foundation under Grant 2022131. Work by Micha Sharir has been partially supported by Israel Science Foundation Grant 260/18. 
 Full Access 
 Dynamic Dictionary with Subconstant Wasted Bits per Key 
 href="/author/Li%2C+Tianxiao" - Tianxiao Li | , 
 href="/author/Liang%2C+Jingxun" - Jingxun Liang | , 
 href="/author/Yu%2C+Huacheng" - Huacheng Yu | , 
 href="/author/Zhou%2C+Renfei" - Renfei Zhou 
 pp.171–207 
 Abstract 
 PDF 
 AbstractDictionaries have been one of the central questions in data structures. A dictionary data structure maintains a set of key-value pairs under insertions and deletions such that given a query key, the data structure efficiently returns its value. The state-of-the-art dictionaries [4] store n key-value pairs with onlyO(nlog(k)n) bits of redundancy, and support all operations inO(k) time, fork≤ log*n. It was recently shown to be optimal [16]. 
 In this paper, we study the regime where the number of redundant bits isR=o(n), and show that whenRis at leastn/poly logn, all operations can be supported inO(log*n+ log(n/R)) time, matching the lower bound in this regime [16]. We present two data structures based on which rangeRis in. The data structure forR<n/log0.1nutilizes a generalization ofadaptersstudied in [5, 15]. The data structure forR≥n/log0.1nis based on recursively hashing into buckets with logarithmic sizes. 
 Full Access 
 Dynamic Dynamic Time Warping 
 href="/author/Bringmann%2C+Karl" - Karl Bringmann | , 
 href="/author/Fischer%2C+Nick" - Nick Fischer | , 
 href="/author/van+der+Hoog%2C+Ivor" - Ivor van der Hoog | , 
 href="/author/Kipouridis%2C+Evangelos" - Evangelos Kipouridis | , 
 href="/author/Kociumaka%2C+Tomasz" - Tomasz Kociumaka | , 
 href="/author/Rotenberg%2C+Eva" - Eva Rotenberg 
 pp.208–242 
 Abstract 
 PDF 
 AbstractThe Dynamic Time Warping (DTW) distance is a popular similarity measure for polygonal curves (i.e., sequences of points). It finds many theoretical and practical applications, especially for temporal data, and is known to be a robust, outlier-insensitive alternative to the Fréchet distance. For static curves of at most n points, the DTW distance can be computed inO(n2)time in constant dimension. This tightly matches a SETH-based lower bound, even for curves in ℝ1. 
 In this work, we studydynamicalgorithms for the DTW distance. Here, the goal is to design a data structure that can be efficiently updated to accommodate local changes to one or both curves, such as inserting or deleting vertices and, after each operation, reports the updated DTW distance. We give such a data structure with update and query time O(n15logn), where n is the maximum length of the curves. 
 As our main result, we prove that our data structure is conditionallyoptimal,up to subpolynomial factors. More precisely, we prove that, already for curves in ℝ1, there is no dynamic algorithm to maintain the DTW distance with update and query timeO(n1.5-δ) for any constant δ > 0, unless the Negative-k-Clique Hypothesis fails. In fact, we give matching upper and lower bounds for various trade-offs between update and query time, even in cases where the lengths of the curves differ. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.18128 
 Full Access 
 href="/doi/10.1137/1.9781611977912.11" - Dynamically Maintaining the Persistent Homology of Time Series
href="/author/Cultrera+Di+Montesano%2C+Sebastiano" - Sebastiano Cultrera di Montesano | , 
 href="/author/Edelsbrunner%2C+Herbert" - Herbert Edelsbrunner | , 
 href="/author/Henzinger%2C+Monika" - Monika Henzinger | , 
 href="/author/Ost%2C+Lara" - Lara Ost 
 pp.243–295 
 Abstract 
 PDF 
 AbstractWe present a dynamic data structure for maintaining the persistent homology of a time series of real numbers. The data structure supports local operations, including the insertion and deletion of an item and the cutting and concatenating of lists, each in timeO(logn+k), in which n counts the critical items andkthe changes in the augmented persistence diagram. To achieve this, we design a tailor-made tree structure with an unconventional representation, referred to as banana tree, which may be useful in its own right. 
 Full Access 
 Fully dynamic approximation schemes on planar and apex-minor-free graphs 
 href="/author/Korhonen%2C+Tuukka" - Tuukka Korhonen | , 
 href="/author/Nadara%2C+Wojciech" - Wojciech Nadara | , 
 href="/author/Pilipczuk%2C+Micha%C5%82" - Michał Pilipczuk | , 
 href="/author/Soko%C5%82owski%2C+Marek" - Marek Sokołowski 
 pp.296–313 
 Abstract 
 PDF 
 AbstractThe classic technique of Baker [J. ACM ‘94] is the most fundamental approach for designing approximation schemes on planar, or more generally topologically-constrained graphs, and it has been applied in a myriad of different variants and settings throughout the last 30 years. In this work we propose a dynamic variant of Baker's technique, where instead of finding an approximate solution in a given static graph, the task is to design a data structure for maintaining an approximate solution in a fully dynamic graph, that is, a graph that is changing over time by edge deletions and edge insertions. Specifically, we address the two most basic problems — Maximum Weight Independent Set and Minimum Weight Dominating Set — and we prove the following: for a fully dynamicn-vertex planar graphG, one can 
 • maintain a (1 —ɛ)-approximation of the maximum weight of an independent set inGwith amortized update timef (ɛ) · no(1);and, 
 • under the additional assumption that the maximum degree of the graph is bounded at all times by a constant, also maintain a (1 + ɛ)-approximation of the minimum weight of a dominating set in G with amortized update timef(ɛ) · no(1). 
 In both cases,f(ɛ) is doubly-exponential in poly(1/ɛ) and the data structure can be initialized in timef(ɛ) · n1+o(1). All our results in fact hold in the larger generality of any graph class that excludes a fixed apex-graph as a minor. 
 *This work is a part of the project BOBR (WN, MP, MS) that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 948057). Tuukka Korhonen was supported by the Research Council of Norway via the project BWCA (grant no. 314528). The full version of the paper can be accessed at https://arxiv.org/abs/2310.20623 
 Full Access 
 Optimally Repurposing Existing Algorithms to Obtain Exponential-Time Approximations 
 href="/author/Can+Esmer%2C+Bar%C4%B1%C5%9F" - Barış Can Esmer | , 
 href="/author/Kulik%2C+Ariel" - Ariel Kulik | , 
 href="/author/Marx%2C+D%C3%A1niel" - Dániel Marx | , 
 href="/author/Neuen%2C+Daniel" - Daniel Neuen | , 
 href="/author/Sharma%2C+Roohani" - Roohani Sharma 
 pp.314–345 
 Abstract 
 PDF 
 AbstractThe goal of this paper is to understand how exponential-time approximation algorithms can be obtained from existing polynomial-time approximation algorithms, existing parameterized exact algorithms, and existing parameterized approximation algorithms. More formally, we consider a monotone subset minimization problem over a universe of size n (e.g., VERTEX COVER or FEEDBACK VERTEX Set). We have access to an algorithm that finds an α-approximate solution in timeck·nO(1)if a solution of size k exists (and more generally, an extension algorithm that can approximate in a similar way if a set can be extended to a solution with k further elements). Our goal is to obtain adn·nO(1)time β-approximation algorithm for the problem withdas small as possible. That is, for every fixedα,c,β≥ 1, we would like to determine the smallest possibledthat can be achieved in a model where our problem-specific knowledge is limited to checking the feasibility of a solution and invoking the α-approximate extension algorithm. Our results completely resolve this question: 
 1. For every fixed α, c,β≥ 1, a simple algorithm (“approximate monotone local search”) achieves the optimum value ofd. 
 2. Given α, c, β ≥ 1, we can efficiently compute the optimumdup to any precision ɛ > 0. 
 Our technique gives novel results for a wide range of problems including FEEDBACK VERTEX Set, DIRECTED Feedback Vertex Set, Odd Cycle Traversal and Partial Vertex Cover. 
 The monotone local search algorithm we use is a simple adaptation of [Fomin et al., J. ACM 2019, Esmer et al., ESA 2022, Gaspers and Lee, ICALP 2017]. Still, attaining the above results required us to frame the result in a different way, and overcome a major technical challenge. First, we introduce an oracle based computational model which allows for a simple derivation of lower bounds that, unexpectedly, show that the running time of the monotone local search algorithm is optimal. Second, while it easy to express the running time of the monotone local search algorithm in various forms, it is unclear how to actually numerically evaluate it for given values of α,βandc. We show how the running time of the algorithm can be evaluated via a convex analysis of a continuous max-min optimization problem, overcoming the limitations of previous approaches to the α = β case [Fomin et al., J. ACM 2019, Esmer et al., ESA 2022, Gaspers and Lee, ICALP 2017]. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2306.15331. Research supported by the European Research Council (ERC) consolidator grant No. 725978 SYSTEMATICGRAPH. 
 Full Access 
 Shortest Disjoint Paths on a Grid 
 href="/author/Mari%2C+Mathieu" - Mathieu Mari | , 
 href="/author/Mukherjee%2C+Anish" - Anish Mukherjee | , 
 href="/author/Pilipczuk%2C+Micha%C5%82" - Michał Pilipczuk | , 
 href="/author/Sankowski%2C+Piotr" - Piotr Sankowski 
 pp.346–365 
 Abstract 
 PDF 
 AbstractThe well-knownk-disjoint paths problem involves finding pairwise vertex-disjoint paths between k specified pairs of vertices within a given graph if they exist. In the shortestk-disjoint paths problem one looks for such paths of minimum total length. Despite nearly 50 years of active research on thek-disjoint paths problem, many open problems and complexity gaps still persist. A particularly well-defined scenario, inspired by VLSI design, focuses on infinite rectangular grids where the terminals are placed at arbitrary grid points. While the decision problem in this context remains NP-hard, no prior research has provided any positive results for the optimization version. The main result of this paper is a fixed-parameter tractable (FPT) algorithm for this scenario. It is important to stress that this is the first result achieving the FPT complexity of the shortest disjoint paths problem in any, even very restricted classes of graphs where we do not put any restriction on the placements of the terminals. 
 Full Access 
 Tree Containment Above Minimum Degree is FPT 
 href="/author/Fomin%2C+Fedor+V" - Fedor V. Fomin | , 
 href="/author/Golovach%2C+Petr+A" - Petr A. Golovach | , 
 href="/author/Sagunov%2C+Danil" - Danil Sagunov | , 
 href="/author/Simonov%2C+Kirill" - Kirill Simonov 
 pp.366–376 
 Abstract 
 PDF 
 AbstractAccording to the classic Chvátal's Lemma from 1977, a graph of minimum degreeδ(G)contains every tree onδ(G)+ 1 vertices. Our main result is the following algorithmic “extension” of Chvátal's Lemma: For anyn-vertex graphG, integerk, and a treeTon at mostδ(G)+kvertices, deciding whetherGcontains a subgraph isomorphic toT, can be done in timef(k) ·nO(1)for some functionfofkonly. 
 The proof of our main result is based on an interplay between extremal graph theory and parameterized algorithms. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.09678 
 Full Access 
 Determinantal Sieving 
 href="/author/Eiben%2C+Eduard" - Eduard Eiben | , 
 href="/author/Koana%2C+Tomohiro" - Tomohiro Koana | , 
 href="/author/Wahlstr%C3%B6m%2C+Magnus" - Magnus Wahlström 
 pp.377–423 
 Abstract 
 PDF 
 AbstractWe introduce a new, remarkably powerful tool to the toolbox of algebraic FPT algorithms,determinantal sieving.Given a polynomialP (x1,…,xn) over a field 𝔽 of characteristic 2, on a set of variablesX = [x1,. ..,xn},and a linear matroidM = (X, I)over 𝔽 of rankk, in 2kevaluations ofPwe can sieve for those terms in the monomial expansion ofPwhich are multilinear and whose support is a basis forM. The known tools ofmultilinear detectionandconstrained multilinear detectionthen correspond to the case whereMis a uniform matroid and the truncation of a disjoint union of uniform matroids, respectively. More generally, let theodd supportof a monomialmbe the set of variables which have odd degree inm. Using 2kevaluations ofP, we can sieve for those termsmwhose odd support spansM. Applying this framework to well-known efficiently computable polynomial families allows us to simplify, generalize and improve on a range of algebraic FPT algorithms, such as: 
 • Solvingq-Matroid Intersection in timeO*(2(q-2)k) andq-Matroid Parity in timeO*(2qk), improving onO* (4qk) for matroids represented over general fields (Brand and Pratt, ICALP 2021) 
 • T-Cycle, Colourful (s,t)-Path, Colourful(S, T)-Linkage in undirected graphs, and the more general Rankk (S, T)-Linkage problem over so-calledframeworks(see Fomin et al., SODA 2023), all inO*(2k) time, improving onO*(2k+|S|) andO*(2|S|+O(k2log(k+|𝔽|))), respectively 
 • Many instances of the Diverse X paradigm, finding a collection ofrsolutions to a problem with a minimum mutual distance ofdin timeO*(2r2d/2), improving solutions fork-Distinct Branchings from time 2O(klogk)toO*(2k) (Bang-Jensen et al., ESA 2021), and for Diverse Perfect Matchings fromO*(22O(rd)) toO*(2r2d/2) (Fomin et al., STACS 2021) 
 For several other problems, such as Set Cover, Steiner Tree, Graph Motif and Subgraph Isomorphism, where the current algorithms are either believed to be optimal or are proving exceedingly difficult to improve, we show matroid-based generalisations at no increased cost to the running time. In the above, all matroids are assumed to be represented over fields of characteristic 2 and all algorithms use polynomial space. Over general fields, we achieve similar results at the cost of using exponential space by working over theexterior algebra.For a class of arithmetic circuits we callstrongly monotone,this is even achieved without any loss of running time. However, theodd supportsieving result appears to be specific to working over characteristic 2. 
 Full Access 
 Minimization is Harder in the Prophet World 
 href="/author/Livanos%2C+Vasilis" - Vasilis Livanos | , 
 href="/author/Mehta%2C+Ruta" - Ruta Mehta 
 pp.424–461 
 Abstract 
 PDF 
 AbstractWe study I.I.D. prophet inequalities forcost minimization,where the problem is to pick acostfrom a sequenceX1,…, Xndrawn independently from a known distribution in an online manner, and compete against the prophet who can see all the realizations upfront and select the minimum. In contrast to the well-studiedrewards maximizationsetting where a simple threshold strategy achieves a competitive ratio of ≈ 0.745 for all distributions, the cost minimization setting turns out to be much more complex. 
 In our main result, we obtain a complete and nuanced characterization of the I.I.D. cost prophet inequality: if the expected value of the given distribution is infinite, then the competitive ratio is also infinite. On the other hand, when the expected value is finite, we show that the competitive ratio of theoptimal stopping strategyis a (distribution-dependent) constant, which we characterize precisely as the solution to a simple inequality. Furthermore, we obtain a closed form for this constant for a broad class of distributions we callentire distributions,we show that the constant is 2 for MHR distributions and obtain matching lower bounds for all our results. To the best of our knowledge, these are the first optimal distribution-sensitive guarantees for the prophet inequality setting. 
 We then focus on single-threshold strategies and design a single threshold that achieves a tightO(polylogn)- factor approximation. 
 In terms of techniques, we characterize the expected value of order statistics using thehazard rateof the distribution, which facilitates our analysis. Our results may also be used to design approximately optimal posted price-style mechanisms. We believe both of these may be of independent interest. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2209.07988. Work on this paper partially supported by NSF grant CCF-1750436. 
 Full Access 
 Bandit Algorithms for Prophet Inequality and Pandora's Box 
 href="/author/Gatmiry%2C+Khashayar" - Khashayar Gatmiry | , 
 href="/author/Kesselheim%2C+Thomas" - Thomas Kesselheim | , 
 href="/author/Singla%2C+Sahil" - Sahil Singla | , 
 href="/author/Wang%2C+Yifan" - Yifan Wang 
 pp.462–500 
 Abstract 
 PDF 
 AbstractThe Prophet Inequality and Pandora's Box problems are fundamental stochastic problem with applications in Mechanism Design, Online Algorithms, Stochastic Optimization, Optimal Stopping, and Operations Research. A usual assumption in these works is that the probability distributions of the n underlying random variables are given as input to the algorithm. Since in practice these distributions need to be learned under limited feedback, we initiate the study of such stochastic problems in the Multi-Armed Bandits model. 
 In the Multi-Armed Bandits model we interact withnunknown distributions overTrounds: in roundtwe play a policyx(t)and only receive the value ofx(t)as feedback. The goal is to minimize the regret, which is the difference overTrounds in the total value of the optimal algorithm that knows the distributions vs. the total value of our algorithm that learns the distributions from the limited feedback. Our main results give near-optimalÕ(poly (n) √T) total regret algorithms for both Prophet Inequality and Pandora's Box. 
 Our proofs proceed by maintaining confidence intervals on the unknown indices of the optimal policy. The exploration-exploitation tradeoff prevents us from directly refining these confidence intervals, so the main technique is to design a regret upper bound function that is learnable while playing low-regret Bandit policies. 
 Full Access 
 Rationality-Robust Information Design: Bayesian Persuasion under Quantal Response 
 href="/author/Feng%2C+Yiding" - Yiding Feng | , 
 href="/author/Ho%2C+Chien-Ju" - Chien-Ju Ho | , 
 href="/author/Tang%2C+Wei" - Wei Tang 
 pp.501–546 
 Abstract 
 PDF 
 AbstractClassic mechanism/information design imposes the assumption that agents arefully rational,meaning each of them always selects the action that maximizes her expected utility. Yet many empirical evidence suggests that human decisions may deviate from this full rationality assumption. In this work, we attempt to relax the full rationality assumption withbounded rationality.Specifically, we formulate the bounded rationality of an agent by adopting the quantal response model (McKelvey and Palfrey, 1995). 
 We develop a theory of rationality-robust information design in the canonical setting of Bayesian persuasion (Kamenica and Gentzkow, 2011) with binary receiver action. We first identify conditions under which the optimal signaling scheme structure for a fully rational receiver remains optimal or approximately optimal for a boundedly rational receiver. In practice, it might be costly for the designer to estimate the degree of the receiver's bounded rationality level. Motivated by this practical consideration, we then study the existence and construction ofrobustsignaling schemes when there is uncertainty about the receiver's bounded rationality level. 
 Full Access 
 Equilibrium Dynamics in Market Games with Exchangeable and Divisible Resources 
 href="/author/Correa%2C+Jos%C3%A9" - José Correa | , 
 href="/author/Harks%2C+Tobias" - Tobias Harks | , 
 href="/author/Schedel%2C+Anja" - Anja Schedel | , 
 href="/author/Verschae%2C+Jos%C3%A9" - José Verschae 
 pp.547–568 
 Abstract 
 PDF 
 AbstractWe study a market game withn≥ 2 players competing overm≥ 1 divisible resources of different finite capacities. Resources are traded via the proportional sharing mechanism, where players are price-anticipating, meaning that they can influence the prices with their bids. Additionally, each player has an initial endowment of the resources which are sold at market prices. Although the players’ total profit functions may be discontinuous in the bids, we prove existence and uniqueness of pure Nash equilibria of the resulting market game. Then, we study a discrete dynamic arising from repeatedly taking the (unique) equilibrium resource allocation as initial endowments for the next market game. We prove that the total utility value of the dynamic converges to either an optimal allocation value (maximizing total utility over the allocation space) or to a restricted optimal allocation value, where the restriction is defined by fixing some tight resources which are exclusively allocated to a single player. As a corollary, it follows that for strictly concave utility functions, the aggregated allocation vector of the dynamic converges to the unique (possibly restricted) optimal aggregated allocation, and for linear utility functions, we even get convergence of the dynamic to a (possibly restricted) optimal solution in the (non-aggregated) original allocation space. 
 *This manuscript was partially funded by Basal CMM FB210005 and by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)—HA 8041/4-1. We are grateful to the anonymous reviewers for their valuable feedback on this paper. 
 Full Access 
 Simple Delegated Choice 
 href="/author/Khodabakhsh%2C+Ali" - Ali Khodabakhsh | , 
 href="/author/Pountourakis%2C+Emmanouil" - Emmanouil Pountourakis | , 
 href="/author/Taggart%2C+Samuel" - Samuel Taggart 
 pp.569–590 
 Abstract 
 PDF 
 AbstractThis paper studies delegation in a model of discrete choice. In the delegation problem, an uninformed principal must consult an informed agent to make a decision. Both the agent and principal have preferences over the decided-upon action which vary based on the state of the world, and which may not be aligned. The principal may commit to a mechanism, which maps reports of the agent to actions. When this mechanism is deterministic, it can take the form of a menu of actions, from which the agent simply chooses upon observing the state. In this case, the principal is said to have delegated the choice of action to the agent. 
 We consider a setting where the decision being delegated is a choice of a utility-maximizing action from a set of several options. We assume the shared portion of the agent's and principal's utilities is drawn from a distribution known to the principal, and that utility misalignment takes the form of a known bias for or against each action. We provide tight approximation analyses for simple threshold policies under three increasingly general sets of assumptions. With independently-distributed utilities, we prove a 3-approximation. When the agent has an outside option the principal cannot rule out, the constant-approximation fails, but we prove a logρ/ log logρ-approximation, whereρis the ratio of the maximum value to the optimal utility. We also give a weaker but tight bound that holds for correlated values, and complement our upper bounds with hardness results. One special case of our model is utility-based assortment optimization, for which our results are new. 
 Full Access 
 Fast Algorithms for Directed Graph Partitioning Using Flows and Reweighted Eigenvalues 
 href="/author/Lau%2C+Lap+Chi" - Lap Chi Lau | , 
 href="/author/Tung%2C+Kam+Chuen" - Kam Chuen Tung | , 
 href="/author/Wang%2C+Robert" - Robert Wang 
 pp.591–624 
 Abstract 
 PDF 
 AbstractWe consider a new semidefinite programming relaxation for directed edge expansion, which is obtained by adding triangle inequalities to the reweighted eigenvalue formulation. Applying the matrix multiplicative weight update method on this relaxation, we derive almost linear-time algorithms to achieveO(√logn)- approximation and Cheeger-type guarantee for directed edge expansion, as well as an improved cut-matching game for directed graphs. This provides a primal-dual flow-based framework to obtain the best known algorithms for directed graph partitioning. The same approach also works for vertex expansion and for hypergraphs, providing a simple and unified approach to achieve the best known results for different expansion problems and different algorithmic techniques. 
 *The full version of the paper along with all omitted proofs can be accessed at https://doi.org/10.48550/arXiv.2306.09128 
 Full Access 
 A polynomial-time OPTɛ-approximation algorithm for maximum independent set of connected subgraphs in a planar graph 
 href="/author/Cslovjecsek%2C+Jana" - Jana Cslovjecsek | , 
 href="/author/Pilipczuk%2C+Micha%C5%82" - Michał Pilipczuk | , 
 href="/author/W%C4%99grzycki%2C+Karol" - Karol Węgrzycki 
 pp.625–638 
 Abstract 
 PDF 
 AbstractIn the Maximum Independent Set of Objects problem, we are given ann-vertex planar graphGand a familyDofN objects,where each object is a connected subgraph ofG. The task is to find a subfamilyF⊆Dof maximum cardinality that consists of pairwise disjoint objects. This problem is NP-hard and is equivalent to the problem of finding the maximum number of pairwise disjoint polygons in a given family of polygons in the plane. 
 As shown by Adamaszek et al. (J. ACM ‘19), the problem admits aquasi-polynomial time approximation scheme(QPTAS): a (1 — ɛ)-approximation algorithm with running time 2poly(log(N),1/ɛ)·nO(1).Nevertheless, to the best of our knowledge, in the polynomial-time regime only the trivialO(N)-approximation is known for the problem in full generality. In the restricted setting where the objects are pseudolines in the plane, Fox and Pach (SODA ‘11) gave anNɛ-approximation algorithm with running time 
 , for any ɛ > 0.In this work, we present an OPTɛ-approximation algorithm for the problem that runs in time 
 , for any ɛ > 0, thus improving upon the result of Fox and Pach both in terms of generality and in terms of the running time. Our approach combines the methodology ofVoronoi separators,introduced by Marx and Pilipczuk (TALG ‘22), with a new analysis of the approximation factor.*The full version of the paper [10] can be accessed at http://arxiv.org/abs/2310.20325 
 Full Access 
 Single-Source Unsplittable Flows in Planar Graphs 
 href="/author/Traub%2C+Vera" - Vera Traub | , 
 href="/author/Koch%2C+Laura+Vargas" - Laura Vargas Koch | , 
 href="/author/Zenklusen%2C+Rico" - Rico Zenklusen 
 pp.639–668 
 Abstract 
 PDF 
 AbstractThe single-source unsplittable flow (SSUF) problem asks to send flow from a common source to different terminals with unrelated demands, each terminal being served through a single path. One of the most heavily studied SSUF objectives is to minimize the violation of some given arc capacities. A seminal result of Dinitz, Garg, and Goemans showed that, whenever a fractional flow exists respecting the capacities, then there is an unsplittable one violating the capacities by at most the maximum demand. Goemans conjectured a very natural cost version of the same result, where the unsplittable flow is required to be no more expensive than the fractional one. This intriguing conjecture remains open. More so, there are arguably no non-trivial graph classes for which it is known to hold. 
 We show that a slight weakening of it (with at most twice as large violations) holds for planar graphs. Our result is based on a connection to a highly structured discrepancy problem, whose repeated resolution allows us to successively reduce the number of paths used for each terminal, until we obtain an unsplittable flow. Moreover, our techniques also extend to simultaneous upper and lower bounds on the flow values. This also affirmatively answers a conjecture of Morell and Skutella for planar SSUF. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2308.02651. This project received funding from Swiss National Science Foundation grant 200021_184622 and the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No 817750). 
 Full Access 
 2-Approximation for Prize-Collecting Steiner Forest 
 href="/author/Ahmadi%2C+Ali" - Ali Ahmadi | , 
 href="/author/Gholami%2C+Iman" - Iman Gholami | , 
 href="/author/Hajiaghayi%2C+MohammadTaghi" - MohammadTaghi Hajiaghayi | , 
 href="/author/Jabbarzade%2C+Peyman" - Peyman Jabbarzade | , 
 href="/author/Mahdavi%2C+Mohammad" - Mohammad Mahdavi 
 pp.669–693 
 Abstract 
 PDF 
 AbstractApproximation algorithms for the prize-collecting Steiner forest problem (PCSF) have been a subject of research for over three decades, starting with the seminal works of Agrawal, Klein, and Ravi [1, 2] and Goemans and Williamson [14, 15] on Steiner forest and prize-collecting problems. In this paper, we propose and analyze a natural deterministic algorithm for PCSF that achieves a 2-approximate solution in polynomial time. This represents a significant improvement compared to the previously best known algorithm with a 2.54-approximation factor developed by Hajiaghayi and Jain [19] in 2006. Furthermore, Könemann, Olver, Pashkovich, Ravi, Swamy, and Vygen [24] have established an integrality gap of at least 9/4 for the natural LP relaxation for PCSF. However, we surpass this gap through the utilization of a combinatorial algorithm and a novel analysis technique. Since 2 is the best known approximation guarantee for Steiner forest problem [2] (see also [15]), which is a special case of PCSF, our result matches this factor and closes the gap between the Steiner forest problem and its generalized version, PCSF. 
 Full Access 
 AnLower Bound for Steiner Point Removal 
 href="/author/Chen%2C+Yu" - Yu Chen | , 
 href="/author/Tan%2C+Zihan" - Zihan Tan 
 pp.694–698 
 Abstract 
 PDF 
 AbstractIn the Steiner point removal (SPR) problem, we are given a (weighted) graphGand a subsetTof its vertices called terminals, and the goal is to compute a (weighted) graphHonTthat is a minor ofG, such that the distance between every pair of terminals is preserved to within some small multiplicative factor, that is called thestretchofH. 
 It has been shown that on general graphs we can achieve stretchO(log |T|) [Filtser, 2018]. On the other hand, the best-known stretch lower bound is 8 [Chan-Xia-Konjevod-Richa, 2006], which holds even for trees. In this work, we show an improved lower bound of Ω(√log|T|). 
 Full Access 
 Euclidean Bottleneck Steiner Tree is Fixed-Parameter Tractable 
 href="/author/Bandyapadhyay%2C+Sayan" - Sayan Bandyapadhyay | , 
 href="/author/Lochet%2C+William" - William Lochet | , 
 href="/author/Lokshtanov%2C+Daniel" - Daniel Lokshtanov | , 
 href="/author/Saurabh%2C+Saket" - Saket Saurabh | , 
 href="/author/Xue%2C+Jie" - Jie Xue 
 pp.699–711 
 Abstract 
 PDF 
 AbstractIn the Euclidean Bottleneck Steiner Tree problem, the input consists of a set ofnpoints in ℝ2called terminals and a parameterk, and the goal is to compute a Steiner tree that spans all the terminals and contains at mostkpoints of ℝ2as Steiner points such that the maximum edge-length of the Steiner tree is minimized, where the length of a tree edge is the Euclidean distance between its two endpoints. The problem is well-studied and is known to be NP-hard. In this paper, we give akO(k)nO(1)-time algorithm for Euclidean Bottleneck Steiner Tree, which implies that the problem is fixed-parameter tractable (FPT). This settles an open question explicitly asked by Bae et al. [Algorithmica, 2011], who showed that the ℓ1and ℓ∞variants of the problem are FPT. Our approach can be generalized to the problem with ℓpmetric for any rational 1 ≤ρ≤ ∞, or even other metrics on ℝ2. 
 Full Access 
 Meta-theorems for Parameterized Streaming Algorithms‡ 
 href="/author/Lokshtanov%2C+Daniel" - Daniel Lokshtanov | , 
 href="/author/Misra%2C+Pranabendu" - Pranabendu Misra | , 
 href="/author/Panolan%2C+Fahad" - Fahad Panolan | , 
 href="/author/Ramanujan%2C+M+S" - M. S. Ramanujan | , 
 href="/author/Saurabh%2C+Saket" - Saket Saurabh | , 
 href="/author/Zehavi%2C+Meirav" - Meirav Zehavi 
 pp.712–739 
 Abstract 
 PDF 
 AbstractThe streaming model was introduced to parameterized complexity independently by Fafianie and Kratsch [MFCS14] and by Chitnis, Cormode, Hajiaghayi and Monemizadeh [SODA15]. Subsequently, it was broadened by Chitnis, Cormode, Esfandiari, Hajiaghayi and Monemizadeh [SPAA15] and by Chitnis, Cormode, Esfandiari, Hajiaghayi, McGregor, Monemizadeh and Vorotnikova [SODA16]. Despite its strong motivation, the applicability of the streaming model to central problems in parameterized complexity has remained, for almost a decade, quite limited. Indeed, due to simple Ω(n)-space lower bounds for many of these problems, thekO(1)· polylog(n)-space requirement in the model is too strict. 
 Thus, we exploresemi-streamingalgorithms for parameterized graph problems, and present the first systematic study of this topic. Crucially, we aim to construct succinct representations of the input on which optimal post-processing time complexity can be achieved. 
 • We devise meta-theorems specifically designed for parameterized streaming and demonstrate their applicability by obtaining the first 
 -space streaming algorithms for well-studied problems such as Feedback Vertex Set on Tournaments, Cluster Vertex Deletion, Proper Interval Vertex Deletion and Block Vertex Deletion. In the process, we demonstrate a fundamental connection between semi-streaming algorithms for recognizing graphs in a graph classHand semi-streaming algorithms for the problem of vertex deletion intoH.• We present an algorithmic machinery for obtaining streaming algorithms for cut problems and exemplify this by giving the first 
 -space streaming algorithms for Graph Bipartitization, Multiway Cut and Subset Feedback Vertex Set.*The full version of the paper can be accessed at https://arxiv.org/abs/2308.01598 Lokshtanov is supported by NSF award CCF2008838. Misra is supported by Google India Research Award 2022, and by Start-Up Grant 2022 (SRG/2022/001927) of Science and Engineering Research Board (SERB), India. Ramanujan is supported by Engineering and Physical Sciences Research Council Grants (EP/V007793/1, EP/V044621/1). Saurabh is supported by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 819416); and he also acknowledges the support of Swarnajayanti Fellowship grant DST/SJF/MSA-01/2017-18. Zehavi is supported by European Research Council (ERC) grant titled PARAPATH. 
 Full Access 
 Parameterized algorithms for block-structured integer programs with large entries 
 href="/author/Cslovjecsek%2C+Jana" - Jana Cslovjecsek | , 
 href="/author/Kouteck%C3%BD%2C+Martin" - Martin Koutecký | , 
 href="/author/Lassota%2C+Alexandra" - Alexandra Lassota | , 
 href="/author/Pilipczuk%2C+Micha%C5%82" - Michał Pilipczuk | , 
 href="/author/Polak%2C+Adam" - Adam Polak 
 pp.740–751 
 Abstract 
 PDF 
 AbstractWe study two classic variants of block-structured integer programming.Two-stage stochastic programsare integer programs of the form {Aix +Diyi= bifor alli= 1,…,n}, whereAiandDiare bounded-size matrices. Intuitively, this form corresponds to the setting when after setting a small set of global variables x, the program can be decomposed into a possibly large number of bounded-size subprograms. On the other hand,n-fold programsare integer programs of the form 
 andDiyi=bifor alli= 1,…,n}, where againCiandDiare bounded-size matrices. This form is natural for knapsack-like problems, where we have a large number of variables partitioned into small-size groups, each group needs to obey some set of local constraints, and there are only a few global constraints that link together all the variables.A line of recent work established that the optimization problem for both two-stage stochastic programs andn-fold programs is fixed-parameter tractable when parameterized by the dimensions of relevant matricesAi,Ci, Di,and by the maximum absolute value of any entry appearing in the constraint matrix. A fundamental tool used in these advances is the notion of theGraver basisof a matrix, and this tool heavily relies on the assumption that all the entries of the constraint matrix are bounded. 
 In this work, we prove that the parameterized tractability results for two-stage stochastic andn-fold programs persist even when one allows large entries in the global part of the program. More precisely, we prove the following: In this work, we prove that the parameterized tractability results for two-stage stochastic andn-fold programs persist even when one allows large entries in the global part of the program. More precisely, we prove the following: 
 • The feasibility problem for two-stage stochastic programs is fixed-parameter tractable when parameterized by the dimensions of matricesAi,Diand by the maximum absolute value of the entries of matricesDi. That is, we allow matricesAito have arbitrarily large entries. 
 • The linear optimization problem forn-fold integer programs that are uniform - all matricesCiare equal - is fixed-parameter tractable when parameterized by the dimensions of matricesCiandDiand by the maximum absolute value of the entries of matricesDi. That is, we require thatCi=Cfor all i =1,…,n, but we allowCto have arbitrarily large entries. 
 In the second result, the uniformity assumption is necessary; otherwise the problem is NP-hard already when the parameters take constant values. Both our algorithms are weakly polynomial: the running time is measured in the total bitsize of the input. 
 In both results, we depart from the approach that relies purely on Graver bases. Instead, for two-stage stochastic programs, we devise a reduction to integer programming with a bounded number of variables using new insights about the combinatorics of integer cones. Forn-fold programs, we reduce a givenn-fold program to an exponential-size program with bounded right-hand sides, which we consequently solve using a reduction to mixed integer programming with a bounded number of integral variables. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2311.01890. Martin Koutecky was partially supported by Charles University project UNCE/SCI/004 and by the project 22-22997S of GA ČR. The work of Michał Pilipczuk on this manuscript is a part of a project that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme, Grant Agreement No 948057 — BOBR. Part of this work was done when Adam Polak and Alexandra Lassota were at École Polytechnique Fédérale de Lausanne, supported by the Swiss National Science Foundation projectsLattice Algorithms and Integer Programming(185030) andComplexity of Integer Programming(CRFS-2_207365). Part of this work was carried out while Alexandra Lassota was affiliated with ... 
 Full Access 
 Factoring Pattern-Free Permutations into Separable ones 
 href="/author/Bonnet%2C+Edouard" - Edouard Bonnet | , 
 href="/author/Bourneuf%2C+Romain" - Romain Bourneuf | , 
 href="/author/Geniet%2C+Colin" - Colin Geniet | , 
 href="/author/Thomass%C3%A9%2C+St%C3%A9phan" - Stéphan Thomassé 
 pp.752–779 
 Abstract 
 PDF 
 AbstractWe show that for any permutation π there exists an integerkπsuch that every permutation avoiding π as a pattern factorises as the composition of at mostkπseparable permutations. In other words, every strict class C of permutations is contained in a bounded power of the class of separable permutations. This factorisation can be computed in linear time, for any fixed π. 
 The central tool is a notion of width of permutations, introduced by Guillemot and Marx [SODA ‘14] to efficiently detect patterns, and later generalised to graphs and matrices under the name of twin-width. Specifically, our factorisation is inspired by the decomposition used in the recent result that graphs with bounded twin-width are polynomially χ-bounded. 
 As an application, we show that there is a fixed classCof graphs of bounded twin-width such that every class of bounded twin-width is a first-order transduction ofC. 
 *This work was supported by the ANR projects TWIN-WIDTH (ANR-21-CE48-0014) and DIGRAPHS (ANR-19-CE48-0013). 
 Full Access 
 Representative set statements for delta-matroids and the Mader delta-matroid 
 href="/author/Wahlstr%C3%B6m%2C+Magnus" - Magnus Wahlström 
 pp.780–810 
 Abstract 
 PDF 
 AbstractThe representative sets lemma for linear matroids has many powerful surprising applications in parameterized complexity, including improved FPT dynamic programming algorithms (Fomin et al., JACM 2016) and polynomial kernelization and sparsification results for graph separation problems (Kratsch and Wahlström, JACM 2020). However, its application can be sporadic, as it presupposes the existence of a linear matroid encoding a property relevant to the problem at hand. Correspondingly, although its application led to several new kernelizations (e.g., Almost 2-SAT and restricted variants of MuLTIWAY Cut), there are also several problems left open (e.g., the general case of MuLTIWAY Cut). 
 We present representative sets-style statements for lineardelta-matroids,which are set systems that generalize matroids, with important connections to matching theory and graph embeddings. Furthermore, our proof uses a new approach ofsieving polynomial families,which generalizes the linear algebra approach of the representative sets lemma to a setting of bounded-degree polynomials. The representative sets statements for linear delta-matroids then follow by analyzing the Pfaffian of the skew-symmetric matrix representing the delta-matroid. Applying the same framework to the determinant instead of the Pfaffian recovers the representative sets lemma for linear matroids. Altogether, this significantly extends the toolbox available for kernelization. 
 As an application, we show an exact sparsification result forMader networks: LetG= (V,E) be a graph andTa partition of a set of terminalsT⊆V(G), |T| =k. A T-pathin G is a path with endpoints in distinct parts ofTand internal vertices disjoint fromT. In polynomial time, we can derive a graphG‘ = (V‘,E’) withT⊆V(G‘), such that for every subsetS ⊆ Tthere is a packing ofT-paths with endpointsSinGif and only if there is one inG‘, and |V(G‘)| =O(k3). This generalizes the (undirected version of the)cut-covering lemma,which corresponds to the case thatTcontains only two blocks. 
 To prove the Mader network sparsification result, we furthermore define the class ofMader delta-matroids, and show that they have linear representations. This should be of independent interest. 
 Full Access 
 On the Unreasonable Effectiveness of Single Vector Krylov Methods for Low-Rank Approximation 
 href="/author/Meyer%2C+Raphael" - Raphael Meyer | , 
 href="/author/Musco%2C+Cameron" - Cameron Musco | , 
 href="/author/Musco%2C+Christopher" - Christopher Musco 
 pp.811–845 
 Abstract 
 PDF 
 AbstractKrylov subspace methods are a ubiquitous tool for computing near-optimal rankkapproximations of large matrices. While “large block” Krylov methods with block sizeat least kgive the best known theoretical guarantees, block size one (a single vector) or a small constant is often preferred in practice. Despite their popularity, we lack theoretical bounds on the performance of such “small block” Krylov methods for low-rank approximation. 
 We address this gap between theory and practice by proving that small block Krylov methods essentially match all known low-rank approximation guarantees for large block methods. Via a black-box reduction we show, for example, that the standard single vector Krylov method run fortiterations obtains the same spectral norm and Frobenius norm error bounds as a Krylov method with block sizeℓ ≥ krun forO(t/ℓ)iterations, up to a logarithmic dependence on the smallest gap between sequential singular values. That is, for a given number of matrix-vector products, single vector methods are essentially as effective asany choice of large block size. 
 By combining our result with tail-bounds on eigenvalue gaps in random matrices, we prove that the dependence on the smallest singular value gap can be eliminated if the input matrix is perturbed by a small random matrix. Further, we show that single vector methods match the more complex algorithm of [Bakshi et al. ‘22], which combines the results of multiple block sizes to achieve an improved algorithm for Schattenp-norm low-rank approximation. 
 Full Access 
 Detecting Hidden Communities by Power Iterations with Connections to Vanilla Spectral Algorithms 
 href="/author/Mukherjee%2C+Chandra+Sekhar" - Chandra Sekhar Mukherjee | , 
 href="/author/Zhang%2C+Jiapeng" - Jiapeng Zhang 
 pp.846–879 
 Abstract 
 PDF 
 AbstractCommunity detection in the stochastic block model is one of the central problems of graph clustering. Since its introduction by Holland, Laskey, and Leinhardt (Social Networks, 1983), many subsequent papers have made great strides in solving and understanding this model. However, despite the long history of study, there are still unsolved challenges. 
 In this direction, two primary open problems are: how to recover large clusters in the presence of small clusters (we call it small cluster barrier), and how to analyze simple and practical spectral algorithms (we call them vanilla spectral algorithms), especially when the number of communities is large. In this paper, we use a power iteration approach to make progress in both these directions. 
 To this end, we design the first parameter-free community recovery algorithm that recovers large clusters in the presence of small clusters. Our algorithm only compares the rows of the powered adjacency matrix and has a recovery guarantee poly-logarithmically close to that of the state-of-the-art algorithms in this problem that require knowledge of model parameters. 
 Then based on a connection between the powered adjacency matrix and eigenvectors, we provide a “vanilla” spectral algorithm in the balanced case when the number of communities is large. This answers an open question by Van Vu (Combinatorics Probability and Computing, 2018) in the balanced case. Our methods also partially solve technical barriers discussed by Abbe, Fan, Wang, and Zhong (Annals of Statistics, 2020). 
 On the technical side, we introduce a random partition method to analyze each entry of a powered random matrix. This method can be viewed as an eigenvector version of Wigner's trace method. Recall that Wigner's trace method links the trace of the powered matrix to the matrix's eigenvalues. Our method links the whole powered matrix to the span of eigenvectors. We expect our method to have more applications in random matrix theory. 
 Full Access 
 Matrix Perturbation: Davis-Kahan in the Infinity Norm 
 href="/author/Bhardwaj%2C+Abhinav" - Abhinav Bhardwaj | , 
 href="/author/Vu%2C+van" - Van Vu 
 pp.880–934 
 Abstract 
 PDF 
 AbstractPerturbation theory is developed to analyze the impact of noise on data and has been an essential part of numerical analysis. Recently, it has played an important role in designing and analyzing matrix algorithms. One of the most useful tools in this subject, the Davis-Kahan sine theorem, provides anℓ2error bound on the perturbation of the leading singular vectors (and spaces). 
 We focus on the case when the signal matrix has low rank and the perturbation is random, which occurs often in practice. In an earlier paper, O'Rourke, Wang, and the second author showed that in this case, the Davis-Kahan bound can be improved significantly. In particular, the noise-to-gap ratio condition in the original setting can be weakened considerably. 
 In the current paper, we develop an infinity norm version of the O'Rourke-Vu-Wang result. The key ideas in the proof are a new bootstrapping argument and the so-called iterative leave-one-out method, which may be of independent interest. 
 Applying the new bounds, we develop new and very simple algorithms for several well-known problems, such as finding hidden partitions and matrix completion. The core of these new algorithms is the fact that one is now able to quickly approximate certain key objects in the infinity norm, which has critical advantages over approximations in theℓ2norm, Frobenius norm, or spectral norm. 
 Full Access 
 A PTAS forℓ0-Low Rank Approximation: Solving Dense CSPs over Reals 
 href="/author/Cohen-Addad%2C+Vincent" - Vincent Cohen-Addad | , 
 href="/author/Fan%2C+Chenglin" - Chenglin Fan | , 
 href="/author/Ghoshal%2C+Suprovat" - Suprovat Ghoshal | , 
 href="/author/Lee%2C+Euiwoong" - Euiwoong Lee | , 
 href="/author/de+Mesmay%2C+Arnaud" - Arnaud de Mesmay | , 
 href="/author/Newman%2C+Alantha" - Alantha Newman | , 
 href="/author/Wang%2C+Tony+Chang" - Tony Chang Wang 
 pp.935–961 
 Abstract 
 PDF 
 AbstractWe consider the ℓ0-Low Rank Approximation problem, where the input consists of a matrixA∈ ℝnR×ncand an integerk, and the goal is to find a matrixBof rank at mostkthat minimizes ‖A—B‖0, which is the number of entries whereAandBdiffer. For any constantkand ɛ > 0, we present a polynomial time (1 + ɛ)- approximation time for this problem, which significantly improves the previous best poly(k)-approximation. 
 Our algorithm is obtained by viewing the problem as a Constraint Satisfaction Problem (CSP) where each row and column becomes a variable that can have a value from ℝk. In this view, we have a constraint between each row and column, which results in adenseCSP, a well-studied topic in approximation algorithms. While most of previous algorithms focus on finite-size (or constant-size) domains and involve an exhaustive enumeration over the entire domain, we present a new framework that bypasses such an enumeration in ℝk. We also use tools from the rich literature of Low Rank Approximation in different objectives (e.g., ℓpwithp ∈(0, ∞)) or domains (e.g., finite fields/generalized Boolean). We believe that our techniques might be useful to study other real-valued CSPs and matrix optimization problems. 
 On the hardness side, whenkis part of the input, we prove that ℓ0-Low Rank Approximation is NP-hard to approximate within a factor of Ω(logn). This is the first superconstant NP-hardness of approximation for anyp∈[0, ∞] that does not rely on stronger conjectures (e.g., the Small Set Expansion Hypothesis). 
 Full Access 
 Strongly Polynomial Frame Scaling to High Precision 
 href="/author/Dadush%2C+Daniel" - Daniel Dadush | , 
 href="/author/Ramachandran%2C+Akshay" - Akshay Ramachandran 
 pp.962–981 
 Abstract 
 PDF 
 AbstractThe frame scaling problem is: given vectors 
 , marginals, and precision ɛ > 0, find left and right scalingssuch that(v1,…,vn):=(Lu1r1,…, Lunrn)simultaneously satisfiesand, up to error ɛ. This problem has appeared in a variety of fields throughout linear algebra and computer science. In this work, we give a strongly polynomial algorithm for frame scaling with log(1/ɛ) convergence. This answers a question of Diakonikolas, Tzamos and Kane (STOC 2023), who gave the first strongly polynomial randomized algorithm with poly(1/ɛ) convergence for Forster transformation, the special case. Our algorithm is deterministic, applies for general marginals, and requiresO(n3log(n/ɛ)) iterations as compared to theO(n5d11/ɛ5) iterations of DTK. By lifting the framework of Linial, Samorodnitsky and Wigderson (Combinatorica 2000) for matrix scaling to the frame setting, we are able to simplify both the algorithm and analysis. Our main technical contribution is to generalize the potential analysis of LSW to the frame setting and compute an update step in strongly polynomial time that achieves geometric progress in each iteration. In fact, we can adapt our results to give an improved analysis of strongly polynomial matrix scaling, reducing theO(n5log(n/ɛ)) iteration bound of LSW toO(n3log(n/ɛ)). Additionally, we give a bound on the size of approximate scaling solutions, which involves condition measurestudied in the linear programming literature, and may be of independent interest.*The full version of the paper can be accessed at https://arxiv.org/abs/XXX.XXXX (will have link in a few days!) 
 Full Access 
 Positivity Certificates for Linear Recurrences 
 href="/author/Ibrahim%2C+Alaa" - Alaa Ibrahim | , 
 href="/author/Salvy%2C+Bruno" - Bruno Salvy 
 pp.982–994 
 Abstract 
 PDF 
 AbstractWe consider linear recurrences with polynomial coefficients of Poincaré type and with a unique simple dominant eigenvalue. We give an algorithm that proves or disproves positivity of solutions provided the initial conditions satisfy a precisely defined genericity condition. For positive sequences, the algorithm produces a certificate of positivity that is a data-structure for a proof by induction. This induction works by showing that an explicitly computed cone is contracted by the iteration of the recurrence. 
 Full Access 
 A Unifying Framework for Differentially Private Sums under Continual Observation 
 href="/author/Henzinger%2C+Monika" - Monika Henzinger | , 
 href="/author/Upadhyay%2C+Jalaj" - Jalaj Upadhyay | , 
 href="/author/Upadhyay%2C+Sarvagya" - Sarvagya Upadhyay 
 pp.995–1018 
 Abstract 
 PDF 
 AbstractWe study the problem of maintaining a differentially private decaying sum under continual observation. We give a unifying framework and an efficient algorithm for this problem forany sufficiently smoothfunction. Our algorithm is the first differentially private algorithm that does not have a multiplicative error for polynomially decaying weights. Our algorithm improves on all prior works on differentially private decaying sums under continual observation and recovers exactly the additive error for the special case of continual counting from Henzinger et al. (SODA 2023) as a corollary. 
 Our algorithm is a variant of the matrix mechanism whose error depends on the γ2and γFnorm of the underlying matrix. We give a constructive proof for an almost exact upper bound on the γ2and γFnorm and an almost tight lower bound on the γ2norm for a large class of lower-triangular matrices. This is the first non-trivial lower bound for lower-triangular matrices whose non-zero entries are not all the same. It includes matrices for all continual decaying sums problems, resulting in an upper bound on the additive error of any differentially private decaying sums algorithm under continual observation. 
 We also explore some implications of our result in discrepancy theory and operator algebra. Given the importance of the γ2 norm in computer science and the extensive work in mathematics, we believe our result will have further applications. 
 Full Access 
 Optimal Bounds on Private Graph Approximation 
 href="/author/Liu%2C+Jingcheng" - Jingcheng Liu | , 
 href="/author/Upadhyay%2C+Jalaj" - Jalaj Upadhyay | , 
 href="/author/Zou%2C+Zongrui" - Zongrui Zou 
 pp.1019–1049 
 Abstract 
 PDF 
 AbstractWe propose an efficient ɛ-differentially private algorithm, that given a simpleweightedn-vertex,m-edge graph G with amaximum unweighteddegree Δ(G) ≤n- 1, outputs a synthetic graph which approximates the spectrum withÕ(min{Δ(G), √n}) bound on the purely additive error. To the best of our knowledge, this is the first ɛ-differentially private algorithm with a non-trivial additive error for approximating the spectrum of the graph. One of our subroutines also precisely simulates the exponential mechanism over a non-convex set, which could be of independent interest given the recent interest in sampling from alog-concave distributiondefined over a convex set. As a direct application of our result, we give the first non-trivial bound on approximating all-pairseffective resistancesby a synthetic graph, which also implies approximatinghitting/commute timeandcover timeof random walks on the graph. Given the significance of effective resistance in understanding the statistical properties of a graph, we believe our result would have further implications. 
 Spectral approximation also allows us to approximate all possible(S, T)-cuts, but it incurs an error that depends on the maximum degree, Δ(G). We further show that using our sampler, we can also output a synthetic graph that approximates the sizes of all (S,T)-cuts onn-vertex weighted graphGwithm-edge while preserving (ɛ, δ-differential privacy and an additive error ofÕ(√mn/ɛ). We also give a matching lower bound (with respect to all the parameters) on the private cut approximation for weighted graphs. This removes the gap of √Wavgin the upper and lower bound in Elias, Kapralov, Kulkarni, and Lee (SODA 2020), whereWavgis the average edge weight. 
 Full Access 
 Shannon meets Gray: Noise-robust, Low-sensitivity Codes with Applications in Differential Privacy 
 href="/author/Lolck%2C+David+Rasmussen" - David Rasmussen Lolck | , 
 href="/author/Pagh%2C+Rasmus" - Rasmus Pagh 
 pp.1050–1066 
 Abstract 
 PDF 
 AbstractInteger data is typically made differentially private by adding noise from a Discrete Laplace (or Discrete Gaussian) distribution. We study the setting where differential privacy of a counting query is achieved using bit-wise randomized response, i.e., independent, random bit flips on the encoding of the query answer. 
 Binaryerror-correcting codestransmitted through noisy channels with independent bit flips are well-studied in information theory. However, such codes are unsuitable for differential privacy since they have (by design) high sensitivity, i.e., neighbouring integers have encodings with a large Hamming distance.Gray codesshow that it is possible to create an efficient sensitivity 1 encoding, but are also not suitable for differential privacy due to lack of noise-robustness. 
 Our main result is that it is possible, with a constant rate code, tosimultaneouslyachieve the sensitivity of Gray codesandthe noise-robustness of error-correcting codes (down to the noise level required for differential privacy). An application of this new encoding of the integers is an asymptotically faster, space-optimal differentially private data structure for histograms. 
 Full Access 
 Adjacency Sketches in Adversarial Environments 
 href="/author/Naor%2C+Moni" - Moni Naor | , 
 href="/author/Pekel%2C+Eugene" - Eugene Pekel 
 pp.1067–1098 
 Abstract 
 PDF 
 AbstractAn adjacency sketching or implicit labeling scheme for a familyFof graphs is a method that defines for anynvertexG∈Fan assignment of labels to each vertex inG,so that the labels of two vertices tell you whether or not they are adjacent. The goal is to come up with labeling schemes that use as few bits as possible to represent the labels. By using randomness when assigning labels, it is sometimes possible to produce adjacency sketches with much smaller label sizes, but this comes at the cost of introducing some probability of error. Both deterministic and randomized labeling schemes have been extensively studied, as they have applications for distributed data structures and deeper connections to universal graphs and communication complexity. The main question of interest is which graph families have schemes using short labels, usuallyO(logn) in the deterministic case or constant for randomized sketches. 
 In this work we consider the resilience of probabilistic adjacency sketches against anadversary making adaptive queries to the labels.This differs from the previously analyzed probabilistic setting which is “one shot”. We show that in the adaptive adversarial case the size of the labels is tightly related to the maximal degree of the graphs inF. This results in a stronger characterization compared to what is known in the non-adversarial setting. In more detail, we construct sketches that fail with probability ɛ for graphs with maximal degreedusing 2dlog(1/ɛ) bit labels and show that this is roughly the best that can be done for any specific graph of maximal degree d, e.g. ad-ary tree. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2309.03728 
 Full Access 
 Sorting and Selection in Rounds with Adversarial Comparisons 
 href="/author/Trevisan%2C+Christopher" - Christopher Trevisan 
 pp.1099–1119 
 Abstract 
 PDF 
 AbstractWe continue the study of selection and sorting ofnnumbers under the adversarial comparator model, where comparisons can be adversarially tampered with if the arguments are sufficiently close. 
 We derive a randomized sorting algorithm that doesO(nlog2n) comparisons and gives a correct answer with high probability, addressing an open problem of Ajtai, Feldman, Hassadim, and Nelson [AFHN15]. Our algorithm also implies a selection algorithm that doesO(nlogn) comparisons and gives a correct answer with high probability. Both of these results are a log factor away from the naive lower bound. [AFHN15] shows an Ω(n1+ɛ) lower bound for both sorting and selection in the deterministic case, so our results also prove a discrepancy between what is possible with deterministic and randomized algorithms in this setting. 
 We also consider both sorting and selection in rounds, exploring the tradeoff between accuracy, number of comparisons, and number of rounds. Using results from sorting networks, we give general algorithms for sorting indrounds where the number of comparisons increases withdand the accuracy decreases withd.Using these algorithms, we derive selection algorithms ind+O(logd) rounds that use the same number of comparisons as the corresponding sorting algorithm, but have a constant accuracy. Notably, this gives selection algorithms indrounds that usen1+o(1)comparisons and have constant accuracy for alld= ω(1), which still beats the deterministic lower bound of Ω(n1+ɛ). 
 Full Access 
 Deterministic Byzantine Agreement with AdaptiveO(n·f) Communication 
 href="/author/Elsheimy%2C+Fatima" - Fatima Elsheimy | , 
 href="/author/Tsimos%2C+Giorgos" - Giorgos Tsimos | , 
 href="/author/Papamanthou%2C+Charalampos" - Charalampos Papamanthou 
 pp.1120–1146 
 Abstract 
 PDF 
 AbstractWe present a deterministic synchronous protocol for binary Byzantine Agreement against a corrupt minority with adaptiveO(n · f) communication complexity, wherefis the exact number of corruptions. Our protocol improves the previous best-known deterministic Byzantine Agreement protocol developed by Momose and Ren (DISC 2021), whose communication complexity is quadratic, independent of the exact number of corruptions. Our approach combines two distinct primitives that we introduce and implement withO(n·f) communication,Reliable VotingandWeak Byzantine Agreement.In Reliable Voting, all honest parties agree on the same value only if all honest parties start with that value, but there is no agreement guarantee in the general case. In Weak Byzantine Agreement we achieve agreement, but validity requires that the inputs to the protocol satisfy certain properties. Our Weak Byzantine Agreement protocol is an adaptation of the recent Cohen et al. protocol (OPODIS 2022), in which we identify and address various issues. 
 Full Access 
 Small But Unwieldy: A Lower Bound on Adjacency Labels for Small Classes 
 href="/author/Bonnet%2C+Edouard" - Edouard Bonnet | , 
 href="/author/Duron%2C+Julien" - Julien Duron | , 
 href="/author/Sylvester%2C+John" - John Sylvester | , 
 href="/author/Zamaraev%2C+Viktor" - Viktor Zamaraev | , 
 href="/author/Zhukovskii%2C+Maksim" - Maksim Zhukovskii 
 pp.1147–1165 
 Abstract 
 PDF 
 AbstractWe show that for any natural numbers,there is a constant γ and a subgraph-closed class having, for any naturaln, at most γngraphs onnvertices up to isomorphism, but no adjacency labeling scheme with labels of size at mostslogn. In other words, for everys, there is a small -eventiny- monotone class without universal graphs of sizens.Prior to this result, it was not excluded that every small class has an almost linear universal graph, or equivalently a labeling scheme with labels of size (1 +o(1))logn. The existence of such a labeling scheme, a scaled-down version of the recently disproved Implicit Graph Conjecture, was repeatedly raised [Gavoille and Labourel, ESA ‘07; Dujmović et al., JACM ‘21; Bonamy et al., SIDMA ‘22; Bonnet et al., Comb. Theory ‘22]. Furthermore, our small monotone classes have unbounded twin-width, thus simultaneously disprove the already-refuted Small conjecture; but this time with a self-contained proof, not relying on elaborate group-theoretic constructions. 
 As our main ingredient, we show that with high probability an Erdős-Rényi random graphG(n,p) withp = O(1/n) has, for everyk≤n, at most 2O(k)subgraphs onkvertices, up to isomorphism. As a barrier to our general method of producing even more complex tiny classes, we show that whenp=ω(1/n),the latter no longer holds. More concretely, we provide an explicit lower bound on the number of unlabeledk-vertex induced subgraphs ofG(n,p) when 1/n≤p≤ 1 — 1/n. We thereby obtain a threshold for the property of having exponentially many unlabeled induced subgraphs: if min{p, 1—p}< δ/nwithδ <1, then with high probability even the number of all unlabeled (not necessarily induced) subgraphs is for sufficiently largeC, then with high probability the number of unlabeled induced subgraphs is 2Θ(n). This result supplements the study of counting unlabeled induced subgraphs that was initiated by Erdős and Rényi with a question on the number of unlabeled induced subgraphs of Ramsey graphs, eventually answered by Shelah. 
 Full Access 
 On the Extremal Functions of Acyclic Forbidden 0-1 Matrices 
 href="/author/Pettie%2C+Seth" - Seth Pettie | , 
 href="/author/Tardos%2C+G%C3%A1bor" - Gábor Tardos 
 pp.1166–1176 
 Abstract 
 PDF 
 AbstractThe extremal theory of forbidden 0-1 matrices studies the asymptotic growth of the functionEx(P,n), which is the maximum weight of a matrixA∈ {0,1}n×nwhose submatrices avoid a fixed patternP∈ {0, 1}k×1. This theory has been wildly successful at resolving problems in combinatorics [Kla00, MT04, CK12], discrete and computational geometry [Für90, Agg15, ES96, PS91, Mit92, BG91], structural graph theory [GM14, BGK+21, BKTW22] and the analysis of data structures [Pet10, KS20], particularly corollaries of the dynamic optimality conjecture [CGK+15b, CGK+15a, CGJ+23, CPY24]. 
 All these applications useacyclicpatterns, meaning that whenPis regarded as the adjacency matrix of a bipartite graph, the graph is acyclic. The biggest open problem in this area is to boundEx(P,n) for acyclicP. Prior results [Pet11a, PS13] have only ruled out the strictO(nlogn) bound conjectured by Füredi and Hajnal [FH92]. At the two extremes, it isconsistentwith prior results that 
 , and also consistent that.In this paper we establish a stronger lower bound on the extremal functions of acyclicP. Specifically, for anyt≥ 1 we give a new construction of relatively dense 0-1 matrices with Θ(n(log n/ log logn)t) 1s that avoid a certain acyclic patternXt. Pach and Tardos [PT06] have conjectured that this type of result is the best possible, i.e., no acyclicPexists for whichEx(P, n) ≥n(logn)ω(1). 
 *S. Pettie is supported by NSF Grant CCF-2221980. G. Tardos is supported by the National Research, Development and Innovation Office projects K-132696 and SNN-135643 and by the ERC Advanced Grants “ERMiD” and “GeoScape.” This research was performed while S. Pettie was visiting Renyi Institute, Budapest. 
 Full Access 
 Random Embeddings of Graphs: The Expected Number of Faces in Most Graphs is Logarithmic 
 href="/author/Loth%2C+Jesse+Campion" - Jesse Campion Loth | , 
 href="/author/Halasz%2C+Kevin" - Kevin Halasz | , 
 href="/author/Masa%C5%99%C3%ADk%2C+Tom%C3%A1s" - Tomás Masařík | , 
 href="/author/Mohar%2C+Bojan" - Bojan Mohar | , 
 href="/author/%C5%A0%C3%A1mal%2C+Robert" - Robert Šámal 
 pp.1177–1193 
 Abstract 
 PDF 
 AbstractA random 2-cell embedding of a connected graphGin some orientable surface is obtained by choosing a random local rotation around each vertex. Under this setup, the number of faces or the genus of the corresponding 2-cell embedding becomes a random variable. Random embeddings of two particular graph classes - those of a bouquet ofnloops and those ofnparallel edges connecting two vertices - have been extensively studied and are well-understood. However, little is known about more general graphs despite their important connections with central problems in mainstream mathematics and in theoretical physics (see [Lando & Zvonkin, Graphs on surfaces and their applications, Springer 2004]). There are also tight connections with problems in computing (random generation, approximation algorithms). The results of this paper, in particular, explain why Monte Carlo methods (see, e.g., [Gross & Tucker, Local maxima in graded graphs of imbeddings, Ann. NY Acad. Sci 1979] and [Gross & Rieper, Local extrema in genus stratified graphs, JGT 1991]) cannot work for approximating the minimum genus of graphs. 
 In his breakthrough work ([Stahl, Permutation-partition pairs, JCTB 1991] and a series of other papers), Stahl developed the foundation of “random topological graph theory”. Most of his results have been unsurpassed until today. In our work, we analyze the expected number of faces of random embeddings (equivalently, the average genus) of a graph G. It was very recently shown [Campion Loth & Mohar, Expected number of faces in a random embedding of any graph is at most linear, CPC 2023] that for any graph G, the expected number of faces is at most linear. We show that the actual expected number of facesF(G)is almost always much smaller. In particular, we prove the following results: 
 (1) ½ lnn -2 < 𝔼 [F(Kn)]≤ 3.65 lnn+o(1). This substantially improves Stahl'sn +lnnupper bound for this case. 
 (2) For random graphsG(n,p) (p = p(n)),we have 
 .(3) For random modelsB(n, Δ)containing only graphs, whose maximum degree is at most Δ, we obtain stronger bounds by showing that the expected number of faces is Θ(lnn). 
 *The full version of our paper available on arXiv https://arxiv.org/abs/2211.01032. 
 Full Access 
 Triangulations Admit Dominating Sets of Size 2n/7. 
 href="/author/Christiansen%2C+Aleksander+B+G" - Aleksander B. G. Christiansen | , 
 href="/author/Rotenberg%2C+Eva" - Eva Rotenberg | , 
 href="/author/Rutschmann%2C+Daniel" - Daniel Rutschmann 
 pp.1194–1240 
 Abstract 
 PDF 
 AbstractWe show that every planar triangulation onn> 10 vertices has a dominating set of size 2n/7 =n/3.5. This approaches then/4 bound conjectured by Matheson and Tarjan [12], and improves significantly on the previous best bound of 17n/53 ≈n/3.117 by Spacapan [18]. 
 From our proof it follows that every 3-connectedn-vertex near-triangulation (except for 3 sporadic examples) has a dominating set of sizen/3.5. On the other hand, for 3-connected near-triangulations, we show a lower bound of 3(n— 1)/11 ≈n/3.666, demonstrating that the conjecture by Matheson and Tarjan [12] cannot be strengthened to 3-connected near-triangulations. 
 Our proof uses a penalty function that, aside from the number of vertices, penalises vertices of degree 2 and specific constellations of neighbours of degree 3 along the boundary of the outer face. To facilitate induction, we not only consider near-triangulations, but a wider class of graphs(skeletaltriangulations), allowing us to delete vertices more freely. Our main technical contribution is a set ofattachments,that are small graphs we inductively attach to our graph, in order both to remember whether existing vertices are already dominated, and that serve as a tool in a divide and conquer approach. Along with a well-chosen potential function, we thus both remove and add vertices during the induction proof. 
 We complement our proof with a constructive algorithm that returns a dominating set of size < 2n/7. Our algorithm has a quadratic running time. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.11254 
 Full Access 
 The Grid-Minor Theorem Revisited 
 href="/author/Dujmovi%C4%87%2C+Vida" - Vida Dujmović | , 
 href="/author/Hickingbotham%2C+Robert" - Robert Hickingbotham | , 
 href="/author/Hodor%2C+J%C4%99drzej" - Jędrzej Hodor | , 
 href="/author/Joret%2C+Gwena%C3%ABl" - Gwenaël Joret | , 
 href="/author/la%2C+Hoang" - Hoang La | , 
 href="/author/Micek%2C+Piotr" - Piotr Micek | , 
 href="/author/Morin%2C+Pat" - Pat Morin | , 
 href="/author/Rambaud%2C+Cl%C3%A9ment" - Clément Rambaud | , 
 href="/author/Wood%2C+David+R" - David R. Wood 
 pp.1241–1245 
 Abstract 
 PDF 
 AbstractWe prove that for every planar graphXof treedepthh,there exists a positive integercsuch that for everyX-minor-free graphG, there exists a graphHof treewidth at mostf(h) such thatGis isomorphic to a subgraph ofH⊠Kc. This is a qualitative strengthening of the Grid-Minor Theorem of Robertson and Seymour (JCTB, 1986), and treedepth is the optimal parameter in such a result. As an example application, we use this result to improve the upper bound for weak coloring numbers of graphs excluding a given graph as a minor. 
 *The full version of the paper is available at https://arxiv.org/abs/2307.02816. 
 Full Access 
 Partial Coloring Complex, Vertex Decomposability and Tverberg's Theorem with Constraints 
 href="/author/Alipour%2C+Sharareh" - Sharareh Alipour | , 
 href="/author/Jafari%2C+Amir" - Amir Jafari | , 
 href="/author/Mazidi%2C+Mohammad+Hassan" - Mohammad Hassan Mazidi | , 
 href="/author/Najafian%2C+Seyed+Abolfazl" - Seyed Abolfazl Najafian 
 pp.1246–1259 
 Abstract 
 PDF 
 AbstractWe present a novel family of simplicial complexes associated with the graph coloring problem. They include many well-known simplicial complexes such as chessboard complexes and crosspolytopes. We then study conditions under which these complexes become vertex decomposable and hence shellable. The connectivity of these complexes is also investigated. We apply these results to Tverberg's theorem with constraints and also to the chromatic number of certain Kneser-type hypergraphs and improve upon existing facts. Notably, we prove a conjecture of Engström and Norén on Tverberg graphs. 
 Full Access 
 Approximating Subset Sum Ratio faster than Subset Sum 
 href="/author/Bringmann%2C+Karl" - Karl Bringmann 
 pp.1260–1277 
 Abstract 
 PDF 
 AbstractSubset Sum Ratio is the following optimization problem: Given a set of n positive numbersI, find disjoint subsetsX, Y ⊆ Iminimizing the ratio max{Σ(X)/Σ(Y), Σ(Y)/Σ(X)}, where Σ(Z) denotes the sum of all elements ofZ. Subset Sum Ratio is an optimization variant of the Equal Subset Sum problem. It was introduced by Woeginger and Yu in ‘92 and is known to admit an FPTAS [Bazgan, Santha, Tuza ‘98]. The best approximation schemes before this work had running timeO(n4/ɛ) [Melissinos, Pagourtzis '18],Õ(n2,3/ɛ2,6)andÕ(n2/ɛ3) [Alonistiotis et al. '22]. 
 In this work, we present an improved approximation scheme for Subset Sum Ratio running in timeO(n/ɛ0.9386). Here we assume that the items are given in sorted order, otherwise we need an additional running time ofO(nlogn) for sorting. Our improved running time simultaneously improves the dependence on n to linear and the dependence on 1/ɛ to sublinear. 
 For comparison, an approximation scheme achieving the same running time for Subset Sum would falsify the Strong Exponential Time Hypothesis [Abboud, Bringmann, Hermelin, Shabtay '19] as well as the Min-Plus-Convolution Hypothesis [Bringmann, Nakos '21]. We thus establish that Subset Sum Ratio admits faster approximation schemes than Subset Sum. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.07595 
 Full Access 
 A Parameterized Family of Meta-Submodular Functions 
 href="/author/Ghadiri%2C+Mehrdad" - Mehrdad Ghadiri | , 
 href="/author/Santiago%2C+Richard" - Richard Santiago | , 
 href="/author/Shepherd%2C+Bruce" - Bruce Shepherd 
 pp.1278–1306 
 Abstract 
 PDF 
 AbstractSubmodular function maximization has found a wealth of new applications in recent years. The related supermodular maximization models also offer an abundance of applications, but they appeared to be highly intractable even under simple cardinality constraints. Hence, while there are well-developed tools for maximizing a submodular function subject to a matroid constraint, there is much less work on the corresponding supermodular maximization problems. 
 We introduce a parameterized family of monotone functions which contains submodular functions and a broad spectrum of supermodular functions including the well-studied diversity functions. Functions in this parameterized family are calledγ-meta-submodular.We develop approximation algorithms for maximization of these functions under a general matroid constraint. The approximation factors we establish only depend on the parameterγ.We show that the y-meta-submodular families model previously studied applications arising from classes of functions such as meta-submodular functions(γ =0), metric diversity functions and proportionally submodular functions (both withγ =1), diversity functions based on negativetype distances or Jensen-Shannon divergence (both withγ =2), and σ-semi metric diversity functions(γ = σ).An important property of meta-submodular functions is that they are not restricted to pairwise structures as opposed to diversity functions. In addition, the meta-submodular family is closed under composition with non-negative concave functions. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2006.13754 
 Full Access 
 Approximation Algorithms for the Weighted Nash Social Welfare via Convex and Non-Convex Programs 
 href="/author/Brown%2C+Adam" - Adam Brown | , 
 href="/author/Laddha%2C+Aditi" - Aditi Laddha | , 
 href="/author/Pittu%2C+Madhusudhan+Reddy" - Madhusudhan Reddy Pittu | , 
 href="/author/Singh%2C+Mohit" - Mohit Singh 
 pp.1307–1327 
 Abstract 
 PDF 
 AbstractIn an instance of the weighted Nash Social Welfare problem, we are given a set ofmindivisible items,G, andnagents,A, where each agenti∈Ahas a valuationvij≥ 0 for each itemj∈G. In addition, every agentihas a non-negative weightwisuch that the weights collectively sum up to 1. The goal is to find an assignment σ :G→Athat maximizes 
 . When all the weights equal to, the problem reduces to the classical Nash Social Welfare problem, which has recently received much attention. In this work, we present a-approximation algorithm for the weighted Nash Social Welfare problem, wheredenotes the KL-divergence between the distributionwand the uniform distribution on [n].We generalize the convex programming relaxations for the symmetric variant of Nash Social Welfare presented in [CDG+17, AGSS17] to two different mathematical programs. The first program is convex and is necessary for computational efficiency, while the second program is a non-convex relaxation that can be rounded efficiently. The approximation factor derives from the difference in the objective values of the convex and non-convex relaxation. 
 Full Access 
 Tight approximability of MAX 2-SAT and relatives, under UGC 
 href="/author/Brakensiek%2C+Joshua" - Joshua Brakensiek | , 
 href="/author/Huang%2C+Neng" - Neng Huang | , 
 href="/author/Zwick%2C+Uri" - Uri Zwick 
 pp.1328–1344 
 Abstract 
 PDF 
 AbstractAustrin showed that the approximation ratio β ≈ 0.94016567 obtained by the MAX 2-SAT approximation algorithm of Lewin, Livnat and Zwick (LLZ) is optimal modulo theUnique Games Conjecture(UGC) and modulo aSimplicity Conjecturethat states that the worst performance of the algorithm is obtained on so calledsimpleconfigurations. We prove Austrin's conjecture, thereby showing the optimality of the LLZ approximation algorithm, relying only on the Unique Games Conjecture. Our proof uses a combination of analytic and computational tools. 
 We also present new approximation algorithms for two restrictions of the MAX 2-SAT problem. For MAX HORN-{1, 2}-SAT, i.e., MAX CSP 
 , in which clauses are not allowed to contain two negated literals, we obtain an approximation ratio of 0.94615981. For MAX CSP, i.e., when 2-clauses are not allowed to contain negated literals, we obtain an approximation ratio of 0.95397990. By adapting Austrin's and our arguments for the MAX 2-SAT problem we show that these two approximation ratios are also tight, modulo only the UGC conjecture. This completes a full characterization of the approximability of the MAX 2-SAT problem and its restrictions.*The full version of the paper can be accessed at https://arxiv.org/abs/2310.12911 
 Full Access 
 Gap Amplification for Reconfiguration Problems 
 href="/author/Ohsaka%2C+Naoto" - Naoto Ohsaka 
 pp.1345–1366 
 Abstract 
 PDF 
 AbstractCombinatorial reconfigurationis an emerging field of theoretical computer science that studies the reachability between a pair of feasible solutions for a particular combinatorial problem. We study the hardness of accomplishing “approximate” reconfigurability, which affords to relax the feasibility of solutions. For example, in Minmax Set Cover Reconfiguration, given a pair of coversCsandCtfor a set systemF, we aim to transformCsintoCtby repeatedly adding or removing a single set ofFso as to minimize themaximum sizeof covers during transformation. The recent study by Ohsaka (STACS 2023) [Ohs23b] gives evidence that a host of reconfiguration problems are PSPACE-hard to approximate assuming theReconfiguration Inapproximability Hypothesis(RIH), which postulates that a gap version of Maxmin CSP Reconfiguration is PSPACE-hard. One limitation of this approach is that inapproximability factors are not explicitly shown, so that even a 1.00 · · · 001-approximation algorithm for Minmax Set Cover Reconfiguration may not be ruled out, whereas it admits 2-approximation as per Ito, Demaine, Harvey, Papadimitriou, Sideri, Uehara, and Uno (Theor. Comput. Sci., 2011) [IDHPSU+11]. 
 In this paper, we demonstrategap amplificationfor reconfiguration problems. In particular, we prove an explicit factor of PSPACE-hardness of approximation for three popular reconfiguration problems only assuming RIH. Our main result is that under RIH, Maxmin Binary CSP Reconfiguration is PSPACE-hard to approximate within a factor of 0.9942. Moreover, the same result holds even if the constraint graph is restricted to (d, λ)-expander for arbitrarily small 
 . The crux of its proof is an alteration of the gap amplification technique due to Dinur (J. ACM, 2007) [Din07], which amplifies the 1 vs. 1 — ɛ gap for arbitrarily small ɛ > 0 up to the 1 vs. 1 — 0.0058 gap. As an application of the main result, we demonstrate that Minmax Set Cover Reconfiguration and Minmax Dominating Set Reconfiguration are PSPACE-hard to approximate within a factor of 1.0029 under RIH. Our proof is based on a gap-preserving reduction from Label Cover to Set Cover due to Lund and Yannakakis (J. ACM, 1994) [LY94]. However, unlike Lund-Yannakakis’ reduction, the expander mixing lemma is essential to use. We highlight that all results hold unconditionally as long as “PSPACE- hard” is replaced by “NP-hard,” and are the first explicit inapproximability results for reconfiguration problems without resorting to the parallel repetition theorem. We finally complement the main result by showing that it is NP-hard to approximate Maxmin Binary CSP Reconfiguration within a factor better than ¾.*The full version of the paper can be accessed at https://arxiv.org/abs/2310.14160 [Ohs23a] 
 Full Access 
 AG codes have no list-decoding friends: Approaching the generalized Singleton bound requires exponential alphabets 
 href="/author/Alrabiah%2C+Omar" - Omar Alrabiah | , 
 href="/author/Guruswami%2C+Venkatesan" - Venkatesan Guruswami | , 
 href="/author/Li%2C+Ray" - Ray Li 
 pp.1367–1378 
 Abstract 
 PDF 
 AbstractA simple, recently observed generalization of the classical Singleton bound to list-decoding asserts that rateRcodes are not list-decodable using list-sizeLbeyond an error fraction 
 (the Singleton bound being the case ofL= 1, i.e., unique decoding). We prove that in order to approach this bound for any fixed L > 1, one needs exponential alphabets. Specifically, for everyL> 1 andR∈ (0,1), if a rateRcode can be list-of-Ldecoded up to error fraction, then its alphabet must have size at least exp(ΩL,R(1/ɛ)). This is in sharp contrast to the situation for unique decoding where certain families of rateRalgebraic-geometry (AG) codes over an alphabet of sizeO(1/ɛ2) are unique-decodable up to error fraction (1 —R— ɛ)/2.Our lower bound is tight up to constant factors in the exponent—with high probability random codes (or, as shown recently, even random linear codes) over exp(OL(1/ɛ))-sized alphabets, can be list-of-Ldecoded up to error fraction 
 .*The full version of the paper can be accessed at https://arxiv.org/abs/2308.13424 
 Full Access 
 Conflict Checkable and Decodable Codes and Their Applications 
 href="/author/Applebaum%2C+Benny" - Benny Applebaum | , 
 href="/author/Kachlon%2C+Eliran" - Eliran Kachlon 
 pp.1379–1424 
 Abstract 
 PDF 
 AbstractLetCbe an error-correcting code over a large alphabetqof block lengthn, and assume that, a possibly corrupted, codewordcis distributively stored among n servers where theith entry is being held by theith server. Suppose that every pair of servers publicly announce whether the corresponding coordinates are “consistent” with some legal codeword or “conflicted”. What type of information about c can be inferred from this consistency graph? Can wecheckwhether errors occurred and if so, can we find the error locations and effectivelydecode?We initiate the study ofconflict-checkableandconflict-decodablecodes and prove the following main results: 
 (1) (Almost-MDS conflict-checkable codes:) For every distanced ≤ n,there exists a code that supports conflict-based error-detection whose dimensionkalmost achieves the singleton bound, i.e.,k ≥ n — d+ 0.99. Interestingly, the code is non-linear, and we give some evidence that suggests that this is inherent. Combinatorially, this yields ann-partite graph over [q]nthat containsqkcliques of size n whose pair-wise intersection is at mostn—d ≤ k —0.99 vertices, generalizing a construction of Alon (Random Struct. Algorithms, ‘02) that achieves a similar result for the special case of triangles (n= 3). 
 (2) (Conflict Decodable Codes below half-distance:) For every distanced ≤ nthere exists a linear code that supports conflict-based error-decoding up to half of the distance. The code's dimensionk“half-meets” the singleton bound, i.e.,k= (n—d+ 2)/2, and we prove that this bound is tight for a natural class of such codes. The construction is based on symmetric bivariate polynomials and is rooted in the literature on verifiable secret sharing (Ben-Or, Goldwasser and Wigderson, STOC ‘88; Cramer, Damgard, and Maurer, EUROCRYPT ‘00). 
 (3) (Robust Conflict Decodable Codes:) We show that the above construction also satisfies a non-trivial notion of robust decoding/detection even when the number of errors is unbounded and up tod/2of the servers are Byzantine and may lie about their conflicts. The resulting conflict-decoder runs in exponential time in this case, and we present an alternative construction that achieves quasipolynomial complexity at the expense of degrading the dimension tok= (n—d+ 3)/3. Our construction is based on trivariate polynomials, and the algorithmic result follows by showing that the induced conflict graph is structured enough to allow efficient recovery of a minimum vertex cover. 
 As an application of the last result, we present the first polynomial-time statistical two-round Verifiable Secret Sharing (resp., three-round general MPC protocol) that remains secure in the presence of an active adversary that corrupts up tot < n/3.001 of the parties. We can upgrade the resiliency threshold to n/3, which is known to be optimal in this setting, at the expense of increasing the computational complexity to be quasipolynomial. Previous solutions (Applebaum, Kachlon, and Patra, TCC’20) suffered from an exponential-time complexity even when the adversary corrupts onlyn/4 of the parties. 
 *The full version of the paper can be accessed at https://eprint.iacr.org/2023/627 
 Full Access 
 Optimal thresholds for Latin squares, Steiner Triple Systems, and edge colorings 
 href="/author/Jain%2C+Vishesh" - Vishesh Jain | , 
 href="/author/Pham%2C+Huy+Tuan" - Huy Tuan Pham 
 pp.1425–1436 
 Abstract 
 PDF 
 AbstractGiven a graphG,a random (k, n)-list assignmentLfor edges ofGis an assignment of an independent, uniformly random set 
 of colors to each edge e and a properL-list coloring ofGis a proper edge-coloring where the color of an edgeebelongs toL(e). We show that for a random (O(logn),n)-list assignmentLfor edges of the complete bipartite graphKn,n, there is a anL-list coloring ofKn,nwith high probability. We also prove analogous results for the thresholds of Steiner triple systems and Latin squares in random (binomial) hypergraphs. All of our results are optimal up to absolute constants, and resolve several related conjectures of Johansson, Luria-Simkin, Casselgren-Häggkvist, Simkin, and Kang-Kelly-Kühn-Methuku-Osthus.A key contribution of our work is to show that in natural settings, the Lovász Local Lemma - a central tool in probabilistic combinatorics to establish the existence of objects with desired properties - can also be used to design optimally “spread” distributions on such objects. This is made possible by carefully exploiting the local uniformity property of the so-called Lovász Local Lemma distribution, an important observation that has recently been utilized in finding efficient algorithms for sampling approximately uniformly random solutions to constraint satisfaction problems. In conjunction with the recently proved Kahn-Kalai conjecture, this opens the door to obtaining optimal threshold results for the appearance of many interesting objects. 
 Full Access 
 Cliquewidth and Dimension 
 href="/author/Joret%2C+Gwena%C3%ABl" - Gwenaël Joret | , 
 href="/author/Micek%2C+Piotr" - Piotr Micek | , 
 href="/author/Pilipczuk%2C+Micha%C5%82" - Michał Pilipczuk | , 
 href="/author/Walczak%2C+Bartosz" - Bartosz Walczak 
 pp.1437–1446 
 Abstract 
 PDF 
 AbstractWe prove that every poset with bounded cliquewidth and with sufficiently large dimension contains the standard example of dimensionkas a subposet. This applies in particular to posets whose cover graphs have bounded treewidth, as the cliquewidth of a poset is bounded in terms of the treewidth of the cover graph. For the latter posets, we prove a stronger statement: every such poset with sufficiently large dimension contains the Kelly example of dimensionkas a subposet. Using this result, we obtain a full characterization of the minor-closed graph classesCsuch that posets with cover graphs inChave bounded dimension: they are exactly the classes excluding the cover graph of some Kelly example. Finally, we consider a variant of poset dimension called Boolean dimension, and we prove that posets with bounded cliquewidth have bounded Boolean dimension. 
 The proofs rely on Colcombet's deterministic version of Simon's factorization theorem, which is a fundamental tool in formal language and automata theory, and which we believe deserves a wider recognition in structural and algorithmic graph theory. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2308.11950. 
 Full Access 
 The Hierarchy of Hereditary Sorting Operators 
 href="/author/Jel%C3%ADnek%2C+V%C3%ADt" - Vít Jelínek | , 
 href="/author/Opler%2C+Michal" - Michal Opler | , 
 href="/author/Pek%C3%A1rek%2C+Jakub" - Jakub Pekárek 
 pp.1447–1464 
 Abstract 
 PDF 
 AbstractWe consider the following general model of a sorting procedure: we fix a hereditary permutation classC, which corresponds to the operations that the procedure is allowed to perform in a single step. The input of sorting is a permutation π of the set [n] = {1, 2,…,n}, i.e., a sequence where each element of [n] appears once. In every step, the sorting procedure picks a permutation σ of length n from C, and rearranges the current permutation of numbers by composing it with σ. The goal is to transform the input π into the sorted sequence 1, 2,…,nin as few steps as possible. 
 Formally, for a hereditary permutation classCand a permutation π of [n], we say that Ccan sort π in k steps,if the inverse of π can be obtained by composingk(not necessarily distinct) permutations fromC. TheC-sorting time of π,denoted st(C; π), is the smallestksuch thatCcan sort π inksteps; if no suchkexists, we put st(C; π) = +∞. For an integer n, theworst-case C-sorting time,denoted wst(C;n), is the maximum of st(C; π) over all permutations π of [n]. 
 This model of sorting captures not only classical sorting algorithms, like insertion sort or bubble sort, but also sorting by series of devices, like stacks or parallel queues, as well as sorting by block operations commonly considered, e.g., in the context of genome rearrangement. 
 Our goal is to describe the possible asymptotic behavior of the function wst(C;n), and relate it to structural properties ofC. As the main result, we show that any hereditary permutation classCfalls into one of the following five categories: 
 • wst(C;n) = +∞ for n large enough, 
 • wst(C;n) = Θ(n2), 
 • Ω(√n) ≤ wst(C;n) ≤O(n), 
 • Ω(logn) ≤ wst(C;n) ≤O(log2n), or 
 • wst(C;n) = 1 for alln≥ 2. 
 In addition, we characterize the permutation classes in each of the five categories. 
 Full Access 
 Cactus Representations in Polylogarithmic Max-flow via Maximal Isolating Mincuts 
 href="/author/He%2C+Zhongtian" - Zhongtian He | , 
 href="/author/Huang%2C+Shang-En" - Shang-En Huang | , 
 href="/author/Saranurak%2C+Thatchaphol" - Thatchaphol Saranurak 
 pp.1465–1502 
 Abstract 
 PDF 
 AbstractAcactusrepresentation of a graph, introduced by Dinitzet al.in 1976, is an edge sparsifier ofO(n) size that exactly capturesallglobal minimum cuts of the graph. It is a central combinatorial object that has been a key ingredient in almost all algorithms for the connectivity augmentation problems and for maintaining minimum cuts under edge insertions (e.g. [Naor etal.SICOMP’97], [Cen etal.SODA’22], [Henzinger ICALP’95]). This sparsifier was generalized toSteiner cactusfor a vertex setT, which can be seen as a vertex sparsifier ofO(|T|) size that captures all partitions ofTcorresponding to aT-Steiner minimum cut, and alsohypercactus,an analogous concept in hypergraphs. These generalizations further extend the applications of cactus to the Steiner and hypergraph settings. 
 In a long line of work on fast constructions of cactus and its generalizations, a near-linear time construction of cactus was shown by Karger and Panigrahi [SODA’09]. Unfortunately, their technique based on tree packing inherently does not generalize. The state-of-the-art algorithms for Steiner cactus and hypercactus are still slower than linear time by a factor ofΩ(|T|) [Dinitz and Vainshtein STOC’94] and Ω(n) [Chekuri and Xu SODA’17], respectively. 
 We show how to construct both Steiner cactus and hypercactus using polylogarithmic calls to max flow, which gives the first almost-linear time algorithms of both problems. The constructions immediately imply almost-linear-time connectivity augmentation algorithms in the Steiner and hypergraph settings, as well as speed up the incremental algorithm for maintaining minimum cuts in hypergraphs by a factor ofn. 
 The key technique behind our result is a novel variant of the influentialisolating mincut technique[Li and Panigrahi FOCS’20, Abboudet al.STOC’21] which we calledmaximal isolating mincuts.This technique makes the isolating mincuts to be “more balanced” which, we believe, will likely be useful in future applications. 
 Full Access 
 Cactus Representation of Minimum Cuts: Derandomize and Speed up 
 href="/author/He%2C+Zhongtian" - Zhongtian He | , 
 href="/author/Huang%2C+Shang-En" - Shang-En Huang | , 
 href="/author/Saranurak%2C+Thatchaphol" - Thatchaphol Saranurak 
 pp.1503–1541 
 Abstract 
 PDF 
 AbstractGiven an undirected weighted graph withnvertices andmedges, we give the first deterministicm1+o(1)-time algorithm for constructing the cactus representation ofallglobal minimum cuts. This improves the currentn2+o(1)-time state-of-the-art deterministic algorithm, which can be obtained by combining ideas implicitly from three papers [22, 27, 12]. The known explicitly stated deterministic algorithm has a runtime ofÕ(mn)[9, 34]. Using our technique, we can even speed up the fastest randomized algorithm of [23] whose running time is at least Ω(mlog4n) toO(mlog3n). 
 Full Access 
 Beyond the Quadratic Time Barrier for Network Unreliability 
 href="/author/Cen%2C+Ruoxu" - Ruoxu Cen | , 
 href="/author/He%2C+William" - William He | , 
 href="/author/Li%2C+Jason" - Jason Li | , 
 href="/author/Panigrahi%2C+Debmalya" - Debmalya Panigrahi 
 pp.1542–1567 
 Abstract 
 PDF 
 AbstractKarger (STOC 1995) gave the first FPTAS for the network (un)reliability problem, setting in motion research over the next three decades that obtained increasingly faster running times, eventually leading to aÕ(n2)-time algorithm (Karger, STOC 2020). This represented a natural culmination of this line of work because the algorithmic techniques used can enumerate Θ(n2) (near)-minimum cuts. In this paper, we go beyond this quadratic barrier and obtain a faster FPTAS for the network unreliability problem. Our algorithm runs inm1+o(1)+Õ)(n1.5)time. 
 Our main contribution is a new estimator for network unreliability inveryreliable graphs. These graphs are usually the bottleneck for network unreliability since the disconnection event is elusive. Our estimator is obtained by defining an appropriate importance sampling subroutine on a dual spanning tree packing of the graph. To complement this estimator for very reliable graphs, we use recursive contraction formoderatelyreliable graphs. We show that an interleaving of sparsification and contraction can be used to obtain a better parametrization of the recursive contraction algorithm that yields a faster running time matching the one obtained for the very reliable case. 
 Full Access 
 On (1 + ɛ)-Approximate Flow Sparsifiers 
 href="/author/Chen%2C+Yu" - Yu Chen | , 
 href="/author/Tan%2C+Zihan" - Zihan Tan 
 pp.1568–1605 
 Abstract 
 PDF 
 AbstractGiven a large graphGwith a subset |T| =kof its vertices called terminals, aquality-q flow sparsifieris a small graphG’that containsTand preserves all multicommodity flows that can be routed between terminals inT, to within factorq. The problem of constructing flow sparsifiers with good (small) quality and (small) size has been a central problem in graph compression for decades. 
 A natural approach of constructingO(1)-quality flow sparsifiers, which was adopted in most previous constructions, is contraction. Andoni, Krauthgamer, and Gupta constructed a sketch of sizef (k, ɛ)that stores all feasible multicommodity flows up to a factor of (1 + ɛ), raised the question of constructing quality- (1 + ɛ) flow sparsifiers whose size only depends onk, ɛ (but not the number of vertices in the input graphG), and proposed a contraction-based framework towards it using their sketch result. 
 In this paper, we settle their question for contraction-based flow sparsifiers, by showing that quality-(1 + ɛ) contraction-based flow sparsifiers with sizef(ɛ) exist for all 5-terminal graphs, but not for all 6-terminal graphs. Our hardness result on 6-terminal graphs improves upon a recent hardness result by Krauthgamer and Mosenzon on exact (quality-1) flow sparsifiers, for contraction-based constructions. Our construction and proof utilize the notion oftight spansin metric geometry, which we believe is a powerful tool for future work. 
 Full Access 
 Maxs,t-Flow Oracles and Negative Cycle Detection in Planar Digraphs 
 href="/author/Karczmarz%2C+Adam" - Adam Karczmarz 
 pp.1606–1620 
 Abstract 
 PDF 
 AbstractWe study the maximums,t-flow oracle problem on planardirectedgraphs where the goal is to design a data structure answering maxs,t-flow value (or equivalently, mins,t-cut value) queries for arbitrary source- target pairs (s,t). For the case of polynomially bounded integer edge capacities, we describe anexactmaxs,t-flow oracle with truly subquadratic space and preprocessing, and sublinear query time. Moreover, if (1 — ɛ)-approximate answers are acceptable, we obtain a static oracle with near-linear preprocessing andÕ(n3/4) query time and a dynamic oracle supporting edge capacity updates and queries inÕ(n6/7)worst-case time. 
 To the best of our knowledge, fordirectedplanar graphs, no (approximate) maxs, t-flow oracles have been described even in the unweighted case, and only trivial tradeoffs involving either no preprocessing or precomputing all then2possible answers have been known. 
 One key technical tool we develop on the way is a sublinear (in the number of edges) algorithm for finding a negative cycle in so-called dense distance graphs. By plugging it in earlier frameworks, we obtain improved bounds for other fundamental problems on planar digraphs. In particular, we show: 
 (1) a deterministicO(nlog(nC)) time algorithm for negatively-weighted SSSP in planar digraphs with integer edge weights at least —C. This improves upon the previously known bounds in the important case of weights polynomial inn. 
 (2) an improvedO(nlogn) bound on finding a perfect matching in a bipartite planar graph. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2311.01094. 
 Full Access 
 Breaking the Metric Voting Distortion Barrier 
 href="/author/Charikar%2C+Moses" - Moses Charikar | , 
 href="/author/Ramakrishnan%2C+Prasanna" - Prasanna Ramakrishnan | , 
 href="/author/Wang%2C+Kangning" - Kangning Wang | , 
 href="/author/Wu%2C+Hongxun" - Hongxun Wu 
 pp.1621–1640 
 Abstract 
 PDF 
 AbstractWe consider the following well studied problem of metric distortion in social choice. Suppose we have an election with n voters and m candidates who lie in a shared metric space. We would like to design a voting rule that chooses a candidate whose average distance to the voters is small. However, instead of having direct access to the distances in the metric space, each voter gives us a ranked list of the candidates in order of distance. Can we design a rule that regardless of the election instance and underlying metric space, chooses a candidate whose cost differs from the true optimum by only a small factor (known as thedistortion)? 
 A long line of work culminated in finding deterministic voting rules with metric distortion 3, which is the best possible for deterministic rules and many other classes of voting rules. However, without any restrictions, there is still a significant gap in our understanding: Even though the best lower bound is substantially lower at 2.112, the best upper bound is still 3, which is attained even by simple rules such as Random Dictatorship. Finding a rule that guarantees distortion 3 — ɛ for some constant ɛ has been a major challenge in computational social choice. 
 In this work, we give a rule that guarantees distortion less than 2.753. To do so we study a handful of voting rules that are new to the problem. One isMaximal Lotteries,a rule based on the Nash equilibrium of a natural zero-sum game which dates back to the 60’s. The others are novel rules that can be thought of as hybrids of Random Dictatorship and the Copeland rule. Though none of these rules can beat distortion 3 alone, a careful randomization between Maximal Lotteries and any of the novel rules can. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2306.17838 
 Full Access 
 Composition of nested embeddings with an application to outlier removal 
 href="/author/Chawla%2C+Shuchi" - Shuchi Chawla | , 
 href="/author/Sheridan%2C+Kristin" - Kristin Sheridan 
 pp.1641–1668 
 Abstract 
 PDF 
 AbstractWe study the design of embeddings into Euclidean space with outliers. Given a metric space (X, d)and an integerk, the goal is to embed all butkpoints inX(called the “outliers”) intoℓ2with the smallest possible distortionc. Finding the optimal distortioncfor a given outlier set sizek, or alternately the smallestkfor a given target distortioncare both NP-hard problems. In fact, it is UGC-hard to approximate k to within a factor smaller than 2 even when the metric sans outliers is isometrically embeddable into ℓ2. We consider bi-criteria approximations. Our main result is a polynomial time algorithm that approximates the outlier set size to within anO(log2k) factor and the distortion to within a constant factor. 
 The main technical component in our result is an approach for constructing Lipschitz extensions of embeddings into Banach spaces (such as ℓpspaces). We consider a stronger version of Lipschitz extension that we call anested composition of embeddings: given a low distortion embedding of a subset S of the metric spaceX, our goal is to extend this embedding to all ofXsuch that the distortion overSis preserved, whereas the distortion over the remaining pairs of points inXis bounded by a function of the size ofX\S. Prior work on Lipschitz extension considers settings where the size of X is potentially much larger than that of S and the expansion bounds depend on |S|. In our setting, the setSis nearly all ofXand the remaining setX\S, a.k.a. the outliers, is small. We achieve an expansion bound that is polylogarithmic in |X\S|. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2306.11604 
 Full Access 
 On Approximability of Steiner Tree inℓp-metrics 
 href="/author/Fleischmann%2C+Henry" - Henry Fleischmann | , 
 href="/author/Gavva%2C+Surya+Teja" - Surya Teja Gavva | , 
 href="/author/C.+S.%2C+Karthik" - Karthik C. S. 
 pp.1669–1703 
 Abstract 
 PDF 
 AbstractIn the Continuous Steiner Tree problem (CST), we are given as input a set of points (calledterminals) in a metric space and ask for the minimum-cost tree connecting them. Additional points (calledSteiner points) from the metric space can be introduced as nodes in the solution. In the Discrete Steiner Tree problem (DST), we are given in addition to the terminals, a set of facilities, and any solution tree connecting the terminals can only contain the Steiner points from this set of facilities. 
 Trevisan [SICOMP’00] showed that CST and DST are APX-hard when the input lies in the ℓ1-metric (and Hamming metric). Chlebik and Chlebíková [TCS’08] showed that DST is NP-hard to approximate to factor of 96/95 ≈ 1.01 in the graph metric (and consequentlyℓ∞-metric). Prior to this work, it was unclear if CST and DST are APX-hard in essentially every other popular metric! 
 In this work, we prove that DST is APX-hard in every ℓp-metric. We also prove that CST is APX-hard in theℓ∞-metric. Finally, we relate CST and DST, by observing a gap preserving reduction from CST to DST inℓp-metrics. 
 It is known that the APX-hardness of DST inℓ0,ℓ1,and ℓ∞-metrics can be obtained from the APX-hardness of covering problems (with additional structure). Our main conceptual insight is that for certain ranges ofp(such asp= 2), the soundness guarantees of covering problems might be insufficient to show that DST in theℓp-metric is APX-hard, but the soundness guarantees of a packing problem (with requisite additional structure) is enough. Equipped with this insight, we are then able to embed set systems into everyℓp-metric, and, depending on the value ofp, our soundness analysis of the corresponding DST instance in theℓp-metric will use either the packing property or the covering property (or both) of the set system in the soundness case. 
 Due to the discrete structure of the Hamming space, the APX-hardness of CST in theℓ0and ℓ1metrics follow from similar methods. However, these techniques do not extend to CST in otherℓp-metrics. To show APX-hardness of CST in theℓ∞-metric, we instead rely on the robust hardness guarantees of graph coloring problems. Concretely, we present a reduction from a graphGonnvertices to a point-setPin theℓ∞-metric space, where the cost of the optimal Steiner tree ofPis exactly 
 , wherex(G)is the chromatic number ofG. 
 Full Access 
 Improved Approximations for Ultrametric Violation Distance 
 href="/author/Charikar%2C+Moses" - Moses Charikar | , 
 href="/author/Gao%2C+Ruiquan" - Ruiquan Gao 
 pp.1704–1737 
 Abstract 
 PDF 
 AbstractWe study the ultrametric violation distance problem introduced by Cohen-Addad, Fan, Lee, and Mesmay [FOCS, 2022]. Given pairwise distances 
 as input, the goal is to modify the minimum number of distances so as to make it a valid ultrametric. In other words, this is the problem of fitting an ultrametric to given data, where the quality of the fit is measured by the norm of the error; variants of the problem for the ℓ∞andℓ1norms are well-studied in the literature.Our main result is a 5-approximation algorithm for ultrametric violation distance, improving the previous best large constant factor (≥ 1000) approximation algorithm. We give anO(min{L, logn})- approximation for weighted ultrametric violation distance where the weights satisfy triangle inequality and L is the number of distinct values in the input. We also give a 16-approximation algorithm for the problem onk-partite graphs, where the input is specified on pairs of vertices that form a completek-partite graph. All our results use a unified algorithmic framework with small modifications for the three cases. 
 Full Access 
 A (3 + ɛ)-approximation algorithm for the minimum sum of radii problem with outliers and extensions for generalized lower bounds 
 href="/author/Buchem%2C+Moritz" - Moritz Buchem | , 
 href="/author/Ettmayr%2C+Katja" - Katja Ettmayr | , 
 href="/author/Rosado%2C+Hugo+K+K" - Hugo K. K. Rosado | , 
 href="/author/Wiese%2C+Andreas" - Andreas Wiese 
 pp.1738–1765 
 Abstract 
 PDF 
 AbstractClustering is a fundamental problem setting with applications in many different areas. For a given set of points in a metric space and an integerk, we seek to partition the given points intokclusters. For each computed cluster, one typically defines one point as the center of the cluster. A natural objective is to minimize the sum of the cluster center's radii, where we assign the smallest radiusrto each center such that each point in the cluster is at a distance of at mostrfrom the center. The best-known polynomial time approximation ratio for this problem is 3.389. In the setting with outliers, i.e., we are given an integermand allow up tompoints that are not in any cluster, the best-known approximation factor is 12.365. 
 In this paper, we improve both approximation ratios to 3 + ɛ. Our algorithms are primal-dual algorithms that use fundamentally new ideas to compute solutions and to guarantee the claimed approximation ratios. 
 For example, we replace the classical binary search to find the best value of a Lagrangian multiplier λ by a primal-dual routine in which λ is a variable that is raised. Also, we show that for each connected component due to almost tight dual constraints, we can find one single cluster that covers all its points and we bound its cost via a new primal-dual analysis. We remark that our approximation factor of 3 + ɛ is a natural limit for the known approaches in the literature. 
 Then, we extend our results to the setting of lower bounds. There are algorithms known for the case that for each pointithere is a lower boundLi,stating that we need to assign at leastLiclients toiifiis a cluster center. For this setting, there is a 3.83 approximation if outliers are not allowed and a 12.365- approximation with outliers. We improve both ratios to 3.5 + ɛ and, at the same time, generalize the type of allowed lower bounds. 
 Full Access 
 href="/doi/10.1137/1.9781611977912.70" - On Deterministically Approximating Total Variation Distance
href="/author/Feng%2C+Weiming" - Weiming Feng | , 
 href="/author/Liu%2C+Liqiang" - Liqiang Liu | , 
 href="/author/Liu%2C+Tianren" - Tianren Liu 
 pp.1766–1791 
 Abstract 
 PDF 
 AbstractTotal variation distance (TV distance) is an important measure for the difference between two distributions. 
 Recently, there has been progress in approximating the TV distance between product distributions: a deterministic algorithm for a restricted class of product distributions (Bhattacharyya, Gayen, Meel, Myrisiotis, Pavan and Vinodchandran 2023) and a randomized algorithm for general product distributions (Feng, Guo, Jerrum and Wang 2023). We give adeterministicfully polynomial-time approximation algorithm (FPTAS) for the TV distance between product distributions. Given two product distributions ℙ and ℚ over[q]n, our algorithm approximates their TV distance with relative error ɛ in time 
 .Our algorithm is built around two key concepts: 1) Thelikelihood ratioas a distribution, which captures sufficient information to compute the TV distance. 2) We introduce a metric between likelihood ratio distributions, called theminimum total variation distance.Our algorithm computes a sparsified likelihood ratio distribution that is close to the original one w.r.t. the new metric. The approximated TV distance can be computed from the sparsified likelihood ratio. 
 Our technique also implies deterministic FPTAS for the TV distance between Markov chains. 
 Full Access 
 The Sharp Power Law of Local Search on Expanders 
 href="/author/Br%C3%A2nzei%2C+Simina" - Simina Brânzei | , 
 href="/author/Choo%2C+Davin" - Davin Choo | , 
 href="/author/Recker%2C+Nicholas" - Nicholas Recker 
 pp.1792–1809 
 Abstract 
 PDF 
 AbstractLocal search is a powerful heuristic in optimization and computer science, the complexity of which has been studied in the white box and black box models. In the black box model, we are given a graphG= (V,E) and oracle access to a functionf:V →ℝ. The local search problem is to find a vertexvthat is a local minimum, i.e. withf(v) ≤f(u) for all(u, v) ∈ E, using as few queries to the oracle as possible. The query complexity is well understood on the grid and the hypercube, but much less is known beyond. 
 We show that the query complexity of local search ond-regular expanders with constant degree is 
 , wherenis the number of vertices of the graph. This matches within a logarithmic factor the upper bound ofO(√n) for constant degree graphs due to Aldous [2], implying that steepest descent with a warm start is essentially an optimal algorithm for expanders. The best lower bound known from prior literature was, shown by Santha and Szegedy [34] for quantum and randomized algorithms.We obtain this result by considering a broader framework of graph features such as vertex congestion and separation number. We show that for each graph, the randomized query complexity of local search is 
 , wheregis the vertex congestion of the graph; and, where s is the separation number and Δ is the maximum degree. For separation number the previous best bound was, given by Santha and Szegedy [34] for quantum and randomized algorithms.We also show a variant of the relational adversary method of Aaronson [1]. Our variant is asymptotically at least as strong as the version in [1] for all randomized algorithms, as well as strictly stronger on some problems and easier to apply in our setting. 
 *The full version of the paper can be found at https://arxiv.org/abs/2305.08269. The authors are listed in alphabetical order. This work was done in part while the authors were visiting the Simons Institute for the Theory of Computing. This research/project is supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG-PhD/2021-08-013). This research is supported by the US National Science Foundation under grant CCF-2238372. 
 Full Access 
 Randomized Communication and Implicit Representations for Matrices and Graphs of Small Sign-Rank 
 href="/author/Harms%2C+Nathaniel" - Nathaniel Harms | , 
 href="/author/Zamaraev%2C+Viktor" - Viktor Zamaraev 
 pp.1810–1833 
 Abstract 
 PDF 
 AbstractWe prove a characterization of the structural conditions on matrices of sign-rank 3 and unit disk graphs (UDGs) which permitconstant-costpublic-coin randomized communication protocols. Therefore, under these conditions, these graphs also admit implicit representations. 
 Thesign-rankof a matrixM ∈{±1}N×Nis the smallest rank of a matrixRsuch thatMi,j= sign(Ri,j) for alli, j∈ [N]; equivalently, it is the smallest dimensiondin whichMcan be represented as a pointhalfspace incidence matrix with halfspaces through the origin, and it is essentially equivalent to theunbounded- error communication complexity.Matrices of sign-rank 3 can achieve the maximum possiblebounded-errorrandomized communication complexity Θ(logN), and meanwhile the existence of implicit representations for graphs of bounded sign-rank (including UDGs, which have sign-rank 4) has been open since at least 2003. We prove that matrices of sign-rank 3, and UDGs, haveconstantrandomized communication complexity if and only if they do not encode arbitrarily large instances of the Greater-Than communication problem, or, equivalently, if they do not contain large half-graphs as semi-induced subgraphs. This also establishes the existence of implicit representations for these graphs under the same conditions. 
 *The paper is also available at https://arxiv.org/abs/2307.04441. 
 Full Access 
 Computations with polynomial evaluation oracle: ruling out superlinear SETH-based lower bounds 
 href="/author/Belova%2C+Tatiana" - Tatiana Belova | , 
 href="/author/Kulikov%2C+Alexander+S" - Alexander S. Kulikov | , 
 href="/author/Mihajlin%2C+Ivan" - Ivan Mihajlin | , 
 href="/author/Ratseeva%2C+Olga" - Olga Ratseeva | , 
 href="/author/Reznikov%2C+Grigory" - Grigory Reznikov | , 
 href="/author/Sharipov%2C+Denil" - Denil Sharipov 
 pp.1834–1853 
 Abstract 
 PDF 
 AbstractThe field of fine-grained complexity aims at proving conditional lower bounds on the time complexity of computational problems. One of the most popular and successfully used assumptions, Strong Exponential Time Hypothesis (SETH), implies that SAT cannot be solved in 2(1-ɛ)ntime. In recent years, it has been proved that known algorithms for many problems are optimal under SETH. Despite the wide applicability of SETH, for many problems, there are no known SETH-based lower bounds, so the quest for new reductions continues. 
 Two barriers for proving SETH-based lower bounds are known. Carmosino et al. (ITCS 2016) introduced the Nondeterministic Strong Exponential Time Hypothesis (NSETH) stating that TAUT cannot be solved in time 
 even if one allows nondeterminism. They used this hypothesis to show that some natural fine-grained reductions would be difficult to obtain: proving that, say, 3-SUM requires timen1.5+ɛunder SETH, breaks NSETH and this, in turn, implies strong circuit lower bounds. Recently, Belova et al. (SODA 2023) introduced the so-called polynomial formulations to show that for many NP-hard problems, proving any explicit exponential lower bound under SETH also implies strong circuit lower bounds. 
 In this paper, we combine the two barriers above. We prove that for a range of problems from P, includingk-SUM and triangle detection, proving superlinear lower bounds under SETH is challenging as it implies new circuit lower bounds. To this end, we show that these problems can be solved in nearly linear time with oracle calls to evaluating a polynomial of constant degree. Then, we introduce a strengthening of SETH stating that solving SAT in time is difficult even if one has constant degree polynomial evaluation oracle calls. This hypothesis is stronger and less believable than SETH, but refuting it is still challenging: we show that this implies circuit lower bounds. 
 Finally, by considering computations that make oracle calls to evaluating constant degree polynomials depending on a small number of variables, we show connections between nondeterministic time lower bounds and arithmetic circuit lower bounds. Namely, we prove that if any of MAX-k-SAT, Binary Permanent, or a variant of Set Cover problems cannot be solved in co-nondeterministic time 2(1-ɛ)n, for anyɛ> 0, then one gets arbitrary large polynomial arithmetic circuit lower bounds. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2307.11444 
 Full Access 
 Count on CFI graphs for #P-hardness 
 href="/author/Curticapean%2C+Radu" - Radu Curticapean 
 pp.1854–1871 
 Abstract 
 PDF 
 AbstractAhomomorphismbetween graphsHandG,possibly with vertex-colors, is a functionf : V(ℋ) →V(G) that preserves colors and edges. Many interesting graph parameters are finite linear combinationsp(·) =ΣηαHhom(ℋ, ·) of homomorphism counts from fixed pattern graphsH; this includes (induced) subgraph counts for fixed patterns. Interpreting graph parameters as linear combinations of homomorphism counts has proven to be useful in understanding their computational complexity, as it is known that such linear combinations are as hard to evaluate as their hardest terms, whose complexity in turn is governed by the treewidth of the pattern graph. More formally, given oracle access to a linear combination of homomorphism countspas above and a graphSwith coefficientαs≠ 0, it is possible to compute hom(S,G) for anyn-vertex input graphGin 2|E(S)|poly(s,n) time, wheresis the maximum size of graphs in the defining linear combination ofp.This reduction runs in polynomial time whenpandSare fixed or small in comparison toG;this is the relevant setting in several results based on this reduction. 
 In this paper, we show that a similar reduction can be performed in poly(n, s)time even ifSis part of the input, provided thatShas constant maximum degree. Our polynomial-time reduction is based on graph products with Cai-Fürer-Immerman graphs, a novel technique that is likely of independent interest in algorithms and complexity. The new reduction yields #P-hardness results for problems that could previously only be studied under parameterized complexity assumptions such as FPT ≠ #W[1], which are a priori stronger than classical assumptions. This includes the problems #Hom(ℋ), #Sub(ℋ) and #Ind(ℋ) for fixed graph classesHsatisfying natural polynomial-time enumerability conditions, which ask to count homomorphisms fromHtoGor (induced) subgraph copies ofHinG, given as input a graphH∈Hand a general graphG. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2305.04767 
 Full Access 
 On the Hardness of PosSLP 
 href="/author/B%C3%BCrgisser%2C+Peter" - Peter Bürgisser | , 
 href="/author/Jindal%2C+Gorav" - Gorav Jindal 
 pp.1872–1886 
 Abstract 
 PDF 
 AbstractThe problem PosSLP involves determining whether an integer computed by a given straight-line program is positive. This problem has attracted considerable attention within the field of computational complexity as it provides a complete characterization of the complexity associated with numerical computation. However, non-trivial lower bounds for PosSLP remain unknown. In this paper, we demonstrate that PosSLP ∈ BPP would imply that NP ⊆ BPP, under the assumption of a conjecture concerning the complexity of the radical of a polynomial proposed by Dutta, Saxena, and Sinhababu (STOC’2018). Our proof builds upon the established NP-hardness of determining if a univariate polynomial computed by an SLP has a real root, as demonstrated by Perrucci and Sabia (JDA’2005). 
 Full Access 
 Computing the 5-Edge-Connected Components in Linear Time 
 href="/author/Kosinas%2C+Evangelos" - Evangelos Kosinas 
 pp.1887–2119 
 Abstract 
 PDF 
 AbstractWe provide a deterministic algorithm for computing the 5-edge-connected components of an undirected multigraph in linear time. There were probably good indications that this computation can be performed in linear time, but no such algorithm was actually known prior to this work. Thus, our paper answers a theoretical question, and sheds light on the possibility that a solution may exist for generalk. Furthermore, although the algorithm that we provide is quite extensive and broken up into several pieces, it can have an almost-linear time implementation with the use of elementary data structures. A key component in our algorithm is an oracle for answering connectivity queries for pairs of vertices in the presence of at most four edge-failures. Specifically, the oracle has sizeO(n), it can be constructed in linear time, and it answers connectivity queries in the presence of at most four edge-failures inO(1) time, where n denotes the number of vertices of the graph. We note that this is a result of independent interest. 
 Our paper can be considered as a follow-up of recent work on computing the 4-edge-connected components in linear time. Specifically, we follow a DFS-based approach in order to compute a collection of 4-edge cuts, that is rich enough in properties for our purposes. Furthermore, we expand the toolkit of DFS-based concepts, and demonstrate its general usefulness. In particular, our oracle for connectivity queries is also based on them. However, in dealing with the computation of the 5-edge-connected components, we are faced with unique challenges that do not appear when dealing with lower connectivity. The problem is that the 4-edge cuts in 3-edge-connected graphs are entangled in various complicated ways, that make it difficult to organize them in a compact way. Here we provide a novel analysis of those cuts, that reveals the existence of various interesting structures. These can be exploited so that we can disentangle and collect only those cuts that are essential in computing the 5-edge-connected components. This analysis may provide a clue for a general solution for thek-edge-connected components, or other related graph connectivity problems. 
 Full Access 
 Edge-Coloring Algorithms for Bounded Degree Multigraphs 
 href="/author/Dhawan%2C+Abhishek" - Abhishek Dhawan 
 pp.2120–2157 
 Abstract 
 PDF 
 AbstractIn this paper, we consider algorithms for edge-coloring multigraphsGof bounded maximum degree, i.e., Δ(G)=O(1). Shannon's theorem states that any multigraph of maximum degree Δ can be properly edge- colored with ⌊3Δ/2⌋ colors. Our main results include algorithms for computing such colorings. We design deterministic and randomized sequential algorithms with running timeO(nlogn) andO(n),respectively. This is the first improvement since theO(n2) algorithm in Shannon's original paper, and our randomized algorithm is optimal up to constant factors. We also develop distributed algorithms in the LOCAL model of computation. Namely, we design deterministic and randomized LOCAL algorithms with running timeÕ(log5n) andO(log2n), respectively. The deterministic sequential algorithm is a simplified extension of earlier work of Gabow et al. in edge-coloring simple graphs. The other algorithms apply the entropy compression method in a similar way to recent work by the author and Bernshteyn, where the authors design algorithms for Vizing's theorem for simple graphs. We also extend those results to Vizing's theorem for multigraphs. 
 Full Access 
 Exact Community Recovery in the Geometric SBM 
 href="/author/Gaudio%2C+Julia" - Julia Gaudio | , 
 href="/author/Niu%2C+Xiaochun" - Xiaochun Niu | , 
 href="/author/Wei%2C+Ermin" - Ermin Wei 
 pp.2158–2184 
 Abstract 
 PDF 
 AbstractWe study the problem of exact community recovery in the Geometric Stochastic Block Model (GSBM), where each vertex has an unknown community label as well as a known position, generated according to a Poisson point process in ℝd. Edges are formed independently conditioned on the community labels and positions, where vertices may only be connected by an edge if they are within a prescribed distance of each other. The GSBM thus favors the formation of dense local subgraphs, which commonly occur in real-world networks, a property that makes the GSBM qualitatively very different from the standard Stochastic Block Model (SBM). We propose a linear-time algorithm for exact community recovery, which succeeds down to the information-theoretic threshold, confirming a conjecture of Abbe, Baccelli, and Sankararaman. The algorithm involves two phases. The first phase exploits the density of local subgraphs to propagate estimated community labels among sufficiently occupied subregions, and produces an almost-exact vertex labeling. The second phase then refines the initial labels using a Poisson testing procedure. Thus, the GSBM enjoyslocal to global amplificationjust as the SBM, with the advantage of admitting an information-theoretically optimal, linear-time algorithm. 
 Full Access 
 A Faster Combinatorial Algorithm for Maximum Bipartite Matching 
 href="/author/Chuzhoy%2C+Julia" - Julia Chuzhoy | , 
 href="/author/Khanna%2C+Sanjeev" - Sanjeev Khanna 
 pp.2185–2235 
 Abstract 
 PDF 
 AbstractThe maximum bipartite matching problem is among the most fundamental and well-studied problems in combinatorial optimization. A beautiful and celebrated combinatorial algorithm of Hopcroft and Karp [26] shows that maximum bipartite matching can be solved inO(m√n)time on a graph withnvertices andmedges. For the case of very dense graphs, a different approach based on fast matrix multiplication was subsequently developed [27, 39], that achieves a running time ofO(n2.371). For the next several decades, these results represented the fastest known algorithms for the problem until in 2013, a ground-breaking work of Madry [36] gave a significantly faster algorithm for sparse graphs. Subsequently, a sequence of works developed increasingly faster algorithms for solving maximum bipartite matching, and more generally directed maximum flow, culminating in a spectacular recent breakthrough [9] that gives anm1+o(1)time algorithm for maximum bipartite matching (and more generally, for min cost flows). These more recent developments collectively represented a departure from earlier combinatorial approaches: they all utilized continuous techniques based on interior-point methods for solving linear programs. 
 This raises a natural question: are continuous techniques essential to obtaining fast algorithms for the bipartite matching problem? Our work makes progress on this question by presenting a new, purely combinatorial algorithm for bipartite matching, that, on moderately dense graphs outperforms both Hopcroft- Karp and the fast matrix multiplication based algorithms. Similar to the classical algorithms for bipartite matching, our approach is based on iteratively augmenting a current matching using augmenting paths in the (directed) residual flow network. A common method for designing fast algorithms for directed flow problems is via the multiplicative weights update (MWU) framework, that effectively reduces the flow problem to decremental single-source shortest paths (SSSP) in directed graphs. Our main observation is that a slight modification of this reduction results in aspecial caseof SSSP that appears significantly easier than general decremental directed SSSP. Our main technical contribution is an efficient algorithm for thisspecial caseof SSSP, that outperforms the current state of the art algorithms for general decremental SSSP with adaptive adversary, leading to a deterministic algorithm for bipartite matching, whose running time isÕ(m1/3n5/3). This new algorithm thus starts to outperform the Hopcroft-Karp algorithm in graphs withm= ω(n7/4), and it also outperforms the fast matrix multiplication based algorithms on dense graphs. We believe that this framework for obtaining faster combinatorial algorithms for bipartite matching by exploiting the special properties of the resulting decremental SSSP instances is one of the main conceptual contributions of our work that we hope paves the way for even faster combinatorial algorithms for bipartite matching. 
 Finally, using a standard reduction from the maximum vertex-capacitateds-tflow problem in directed graphs to maximum bipartite matching, we also obtain anO(m1/3n5/3) time deterministic algorithm for maximum vertex-capacitateds-tflow when all vertex capacities are identical. 
 Full Access 
 Higher-Order Cheeger Inequality for Partitioning with Buffers 
 href="/author/Makarychev%2C+Konstantin" - Konstantin Makarychev | , 
 href="/author/Makarychev%2C+Yury" - Yury Makarychev | , 
 href="/author/Shan%2C+Liren" - Liren Shan | , 
 href="/author/Vijayaraghavan%2C+Aravindan" - Aravindan Vijayaraghavan 
 pp.2236–2274 
 Abstract 
 PDF 
 AbstractWe prove a new generalization of the higher-order Cheeger inequality for partitioning with buffers. Consider a graphG= (V,E). The buffered expansion of a setS ⊆ Vwith a bufferB ⊆ V \ Sis the edge expansion ofSafter removing all the edges from setSto its bufferB. Anɛ-bufferedk-partitioning is a partitioning of a graph into disjoint componentsPiand buffersBi, in which the size of bufferBiforPiis small relative to the size ofPi:|Bi| ≤ ɛ|Pi|. The buffered expansion of a buffered partition is the maximum of buffered expansions of theksetsPiwith buffersBi. Let 
 be the buffered expansion of the optimalɛ-bufferedk-partitioning, then for every δ > 0,where λ[(1 + δ)kis the [(1 + δ)k-th smallest eigenvalue of the normalized Laplacian ofG. 
 Our inequality is constructive and avoids the “square-root loss” that is present in the standard Cheeger inequalities (even fork= 2). We also provide a complementary lower bound, and a novel generalization to the setting with arbitrary vertex weights and edge costs. Moreover our result implies and generalizes the standard higher-order Cheeger inequalities and another recent Cheeger-type inequality by Kwok, Lau, and Lee (2017) involving robust vertex expansion. 
 Full Access 
 Dependent rounding with strong negative-correlation, and scheduling on unrelated machines to minimize completion time 
 href="/author/Harris%2C+David+G" - David G. Harris 
 pp.2275–2304 
 Abstract 
 PDF 
 AbstractWe describe a new dependent-rounding algorithmic framework for bipartite graphs. Given a fractional assignmentyof values to edges of graphG= (U∪V,E) the algorithms return an integral solutionYsuch that each right-nodev∈Vhas at most one neighboring edgefwithYf= 1, and where the variablesYealso satisfy broad nonpositive-correlation properties. In particular, for any edgese1,e2sharing a left-nodeu∈U, the variablesYe1,Ye2have strong negative-correlation properties, i.e. the expectation ofYe1Ye2is significantly belowye1ye2. 
 This algorithm is based on generating negatively-correlated Exponential random variables and using them in a contention-resolution scheme inspired by an algorithm Im & Shadloo (2020). Our algorithm gives stronger and much more flexible negative correlation properties. 
 Dependent rounding schemes with negative correlation properties have been used for approximation algorithms for job-scheduling on unrelated machines to minimize weighted completion times (Bansal, Srinivasan, & Svensson (2021), Im & Shadloo (2020), Im & Li (2023)). Using our new dependent-rounding algorithm, among other improvements, we obtain a 1.4-approximation for this problem. This significantly improves over the prior 1.45- approximation ratio of Im & Li (2023). 
 Full Access 
 Faster exact and approximation algorithms for packing and covering matroids via push-relabel 
 href="/author/Quanrud%2C+Kent" - Kent Quanrud 
 pp.2305–2336 
 Abstract 
 PDF 
 AbstractMatroids are a fundamental object of study in combinatorial optimization. Three closely related and important problems involving matroids are maximizing the size of the union ofkindependent sets (that is,k-fold matroid union),computingkdisjoint bases (a.k.a.matroid base packing),and covering the elements bykbases (a.k.a.matroid base covering).These problems generalize naturally to integral and real-valued capacities on the elements. This work develops faster exact and/or approximation problems for these and some other closely related problems such as optimal reinforcement and matroid membership. We obtain improved running times both for general matroids in the independence oracle model and for the graphic matroid. The main thrust of our improvements comes from developing a faster and unifyingpush-relabelalgorithm for the integer-capacitated versions of these problems, building on previous work by Frank and Miklós [24]. We then build on this algorithm in two directions. First we develop a faster augmenting path subroutine fork-fold matroid union that, when appended to an approximation version of the push-relabel algorithm, gives a faster exact algorithm for some parameters ofk.In particular we obtain a subquadratic-query running time in the uncapacitated setting for the three basic problems listed above. We also obtain faster approximation algorithms for these problems with real-valued capacities by reducing to small integral capacities via randomized rounding. To this end, we develop a new randomized rounding technique for base covering problems in matroids that may also be of independent interest. 
 Full Access 
 New SDP Roundings and Certifiable Approximation for Cubic Optimization 
 href="/author/Hsieh%2C+Jun-Ting" - Jun-Ting Hsieh | , 
 href="/author/Kothari%2C+Pravesh+K" - Pravesh K. Kothari | , 
 href="/author/Pesenti%2C+Lucas" - Lucas Pesenti | , 
 href="/author/Trevisan%2C+Luca" - Luca Trevisan 
 pp.2337–2362 
 Abstract 
 PDF 
 AbstractWe give new rounding schemes for SDP relaxations for the problems of maximizing cubic polynomials over the unit sphere and then-dimensional hypercube. In both cases, the resulting algorithms yield a 
 multiplicative approximation in2O(k)poly(n) time. In particular, we obtain aapproximation in polynomial time. For the unit sphere, this improves on the rounding algorithms of [5] that need quasi-polynomial time to obtain a similar approximation guarantee. Over then-dimensional hypercube, our results match the guarantee of a search algorithm of Khot and Naor [19] that obtains a similar approximation ratio via techniques from convex geometry. Unlike their method, our algorithm obtains an upper bound on the integrality gap of SDP relaxations for the problem and as a result, also yields acertificateon the optimum value of the input instance. Our results naturally generalize to homogeneous polynomials of higher degree and imply improved algorithms for approximating satisfiable instances of Max-3SAT.Our main motivation is the stark lack of rounding techniques for SDP relaxations of higher degree polynomial optimization in sharp contrast to a rich theory of SDP roundings for the quadratic case. Our rounding algorithms introduce two new ideas: 1) a new polynomial reweighting based method to round sum-of-squares relaxations of higher degree polynomial maximization problems, and 2) a general technique tocompresssuch relaxations down to substantially smaller SDPs by relying on an explicit construction of certain hitting sets. We hope that our work will inspire improved rounding algorithms for polynomial optimization and related problems. 
 *The arXiv version of the paper can be accessed at https://arxiv.org/abs/2310.00393 
 Full Access 
 New Approximation Bounds for Small-Set Vertex Expansion 
 href="/author/Ghoshal%2C+Suprovat" - Suprovat Ghoshal | , 
 href="/author/Louis%2C+Anand" - Anand Louis 
 pp.2363–2375 
 Abstract 
 PDF 
 AbstractThe vertex expansion of graph is a fundamental graph parameter. Given a graphG =(V, E)and a parameter δ ∈ (0, 1/2], its δ-SSVE is defined as 
 where∂V(S) is the vertex boundary of a setS. The SSVE problem, in addition to being of independent interest as a natural graph partitioning problem, is also of interest due to its connections to the StrongU-niqueGames problem [16]. We give a randomized algorithm running in time 
 , which outputs a setSof size Θ(δn), having vertex expansion at mostwheredis the largest vertex degree of the graph, andφ* is the optimal δ-SSVE. The previous best known guarantees for this were the bi-criteria bounds of 
 anddue to Louis-Makarychev [TOC’16].Our algorithm uses the basic SDP relaxation of the problem augmented with poly(1/δ) rounds of the Lasserre/SoS hierarchy. Our rounding algorithm is a combination of rounding algorithms of [37, 7]. A key component of our analysis is novel Gaussian rounding lemma for hyperedges which might be of independent interest. 
 Full Access 
 On the hardness of finding balanced independent sets in random bipartite graphs 
 href="/author/Perkins%2C+Will" - Will Perkins | , 
 href="/author/Wang%2C+Yuzhou" - Yuzhou Wang 
 pp.2376–2397 
 Abstract 
 PDF 
 AbstractWe consider the algorithmic problem of finding largebalancedindependent sets in sparse random bipartite graphs, and more generally the problem of finding independent sets with specified proportions of vertices on each side of the bipartition. In a bipartite graph it is trivial to find an independent set of density at least half (take one of the partition classes). In contrast, in a random bipartite graph of average degreed, the largest balanced independent sets (containing equal number of vertices from each class) are typically of density 
 . Can we find such large balanced independent sets in these graphs efficiently? By utilizing the overlap gap property and the low-degree algorithmic framework, we prove that local and low- degree algorithms (even those that know the bipartition) cannot find balanced independent sets of density greater thanfor anyɛ> 0 fixed anddlarge but constant. This factor 2statistical-computational gapbetween what exists and what local algorithms can achieve is analogous to the gap for finding large independent sets in (non-bipartite) random graphs. Our results therefor suggest that this gap is pervasive in many models, and that hard computational problems can lurk inside otherwise tractable ones. A particularly striking aspect of the gap in bipartite graphs is that the algorithm achieving the lower bound is extremely simple and can be implemented as a 1-local algorithm and a degree-1 polynomial (a linear function).More generally, we provide a tight characterization of the power of local and low-degree algorithms to find γ-balanced independent sets in randomd-regular bipartite graphs (with γ ≤ 1/2 proportion of vertices on one side of the partition): for larged, local algorithms can find γ-balanced independent sets a factor (1 — γ) smaller than those that exist whp in random bipartite graphs, and no larger. 
 Full Access 
 An Improved Classical Singular Value Transformation for Quantum Machine Learning 
 href="/author/Bakshi%2C+Ainesh" - Ainesh Bakshi | , 
 href="/author/Tang%2C+Ewin" - Ewin Tang 
 pp.2398–2453 
 Abstract 
 PDF 
 AbstractThe field of quantum machine learning (QML) produces many proposals for attaining quantum speedups for tasks in machine learning and data analysis. Such speedups can only manifest if classical algorithms for these tasks perform significantly slower than quantum ones. We study quantum-classical gaps in QML through the quantum singular value transformation (QSVT) framework. QSVT, introduced by Gilyén, Su, Low and Wiebe [GSLW19], unifies all major types of quantum speedup [MRTC21]; in particular, a wide variety of QML proposals are applications of QSVT on low-rank classical data. We challenge these proposals by providing a classical algorithm that matches the performance of QSVT in this regime up to a small polynomial overhead. 
 We show that, given a matrixA∈ Cm×n, a vectorb∈Cn, a bounded degree-dpolynomialp, and linear-time pre-processing, we can output a description of a vectorvsuch that 
 time. This improves upon the best known classical algorithm [CGLLTW22], which requirestime, and narrows the gap with QSVT, which, after linear-time pre-processing to load input into a quantum-accessible memory, can estimate the magnitude of an entryp(A)btoɛ‖b‖ error inÕ(d‖A‖F/(ɛ‖A‖)) time. Instantiating our algorithm with different polynomials, we improve on prior classical algorithms for quantum-inspired regression [CGLLTW22; GST22], recommendation systems [Tan19; CGLLTW22], and Hamiltonian simulation [CGLLTW22].Our key insight is to combine theClenshaw recurrence,an iterative method for computing matrix polynomials, with sketching techniques to simulate QSVT classically. We introduce several new classical techniques in this work, including (a) anon-obliviousmatrix sketch for approximately preserving bi-linear forms, (b) a new stability analysis for the Clenshaw recurrence, and (c) a new technique to bound arithmetic progressions of the coefficients appearing in the Chebyshev series expansion of bounded functions, each of which may be of independent interest. 
 Full Access 
 Recovering the original simplicity: succinct and deterministic quantum algorithm for the welded tree problem 
 href="/author/Li%2C+Guanzhong" - Guanzhong Li | , 
 href="/author/Li%2C+Lvzhou" - Lvzhou Li | , 
 href="/author/Luo%2C+Jingquan" - Jingquan Luo 
 pp.2454–2480 
 Abstract 
 PDF 
 AbstractThis work revisits quantum algorithms for the well-known welded tree problem, proposing a very succinct quantum algorithm based on the simplest coined quantum walks. It simply iterates the naturally defined coined quantum walk operator for a predetermined time and finally measure, where the predetermined time can be efficiently computed on classical computers. Then, the algorithm returns the correct answer deterministically, and achieves exponential speedups over any classical algorithm. The significance of the results may be seen as follows. (i) Our algorithm is rather simple compared with the one in (Jeffery and Zur, STOC’2023), which not only breaks the stereotype that coined quantum walks can only achieve quadratic speedups over classical algorithms, but also demonstrates the power of the simplest quantum walk model. (ii) Our algorithm theoretically achieves certainty of success, which is not possible with existing methods. Thus, it becomes one of the few examples that exhibit exponential separation between deterministic (exact) quantum and randomized query complexities, which may also change people's perception that since quantum mechanics is inherently probabilistic, it impossible to have a deterministic quantum algorithm with exponential speedups for the welded tree problem. 
 Full Access 
 Viderman's algorithm for quantum LDPC codes 
 href="/author/Krishna%2C+Anirudh" - Anirudh Krishna | , 
 href="/author/Livni+Navon%2C+Inbal" - Inbal Livni Navon | , 
 href="/author/Wootters%2C+Mary" - Mary Wootters 
 pp.2481–2507 
 Abstract 
 PDF 
 AbstractQuantum low-density parity-check (LDPC) codes, a class of quantum error correcting codes, are considered a blueprint for scalable quantum circuits. To use these codes, one needs efficient decoding algorithms. In the classical setting, there are multiple efficient decoding algorithms available, includingViderman's algorithm(Viderman, TOCT 2013). Viderman's algorithm for classical LDPC codes essentially reduces the error- correction problem to that oferasure-correction, by identifying a small envelopeLthat is guaranteed to contain the error set. 
 Our main result is a generalization of Viderman's algorithm to quantum LDPC codes, namelyhypergraph product codes(Tillich, Zémor, IEEE T-IT, 2013). This is the first erasure-conversion algorithm that can correct up to Ω(D) errors for constant-rate quantum LDPC codes, whereDis the distance of the code. In that sense, it is also fundamentally different from existing decoding algorithms, in particular from the small-set-flip algorithm (Leverrier, Tillich, Zémor, FOCS, 2015). Moreover, in some parameter regimes, our decoding algorithm improves on the decoding radius of existing algorithms. We note that we do not yet have linear-time erasure-decoding algorithms for quantum LDPC codes, and thus the final running time of the whole decoding algorithm is not linear; however, we view our linear-time envelope-finding algorithm as an important first step. 
 Full Access 
 Efficient Quantum State Synthesis with One Query 
 href="/author/Rosenthal%2C+Gregory" - Gregory Rosenthal 
 pp.2508–2534 
 Abstract 
 PDF 
 AbstractWe present a polynomial-time quantum algorithm making a single query (in superposition) to a classical oracle, such that for every state |ψ〉 there exists a choice of oracle that makes the algorithm construct an exponentially close approximation of |ψ〉. Previous algorithms for this problem either used a linear number of queries and polynomial time, or a constant number of queries and polynomially many ancillae but no nontrivial bound on the runtime. As corollaries we do the following: 
 • We simplify the proof that statePSPACE ⊆ stateQIP (a quantum state analogue of PSPACE ⊆ IP) and show that a constant number of rounds of interaction suffices. 
 • We show that QACf0lower bounds for constructing explicit states would imply breakthrough circuit lower bounds for computing explicit boolean functions. 
 • We prove that everyn-qubit state can be constructed to within 0.01 error by anO(2n/n)-size circuit over an appropriate finite gate set. More generally we give a size-error tradeoff which, by a counting argument, is optimal foranyfinite gate set. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2306.01723. 
 Full Access 
 Quantum Worst-Case to Average-Case Reductions for All Linear Problems 
 href="/author/Asadi%2C+Vahid+R" - Vahid R. Asadi | , 
 href="/author/Golovnev%2C+Alexander" - Alexander Golovnev | , 
 href="/author/Gur%2C+Tom" - Tom Gur | , 
 href="/author/Shinkar%2C+Igor" - Igor Shinkar | , 
 href="/author/Subramanian%2C+Sathyawageeswar" - Sathyawageeswar Subramanian 
 pp.2535–2567 
 Abstract 
 PDF 
 AbstractWe study the problem of constructing worst-case algorithms from average-case algorithms. Prior to this work, such reductions were only known for a small number of specific problems or restricted computational models. In contrast, we show that for quantum computation,all linear problemsadmit worst-case to average-case reductions. Specifically, we provide an explicit and efficient transformation of quantum algorithms that are only correct on a small (even sub-constant) fraction of their inputs into ones that are correct on all inputs. En route, we obtain a tight Ω(n2) lower bound on the average-case quantum query complexity of the Matrix-Vector Multiplication problem. 
 Our techniques strengthen and generalise the recently introducedadditive combinatoricsframework for classical worst-case to average-case reductions (STOC 2022). We rely on quantum singular value transformations to construct quantum algorithms for linear verification in superposition and learning Bogolyubov subspaces from noisy quantum oracles, which could be of independent interest. We use these tools to prove a quantum local correction lemma, which lies at the heart of our reductions, based on a noise- robust probabilistic generalisation of Bogolyubov's lemma from additive combinatorics. 
 Full Access 
 Nearly Optimal Approximate Dual-Failure Replacement Paths 
 href="/author/Chechik%2C+Shiri" - Shiri Chechik | , 
 href="/author/Zhang%2C+Tianyi" - Tianyi Zhang 
 pp.2568–2596 
 Abstract 
 PDF 
 AbstractGiven a directed graphG = (V, E, ω)onnvertices with positive edge weights as well as two designated terminalss,t∈V, our goal is to compute the shortest path fromstotavoiding any pair of presumably failed edgesf1,f2∈E, which is a natural generalization of the classical replacement path problem which considers single edge failures only. 
 This dual failure replacement paths problem was recently studied by [Vassilevska Williams, Woldeghebriela and Xu, 2022] who designed a Õ(n3) time algorithm for general weighted digraphs which is conditionally optimal. In the same paper, they also showed that the cubic time barrier can be bypassed by aÕ(M2/3n2.9146) time algorithm for input graphs with small integer edge weights from {—M,—M+1, ···, M — 1, M}. 
 In this paper, we study the natural question whether sub-cubic time algorithms exist for general weighted digraphs when approximation is allowed. As our main result, we show that (1 + ɛ)-approximations of all dual-failure replacement paths can be computed in Õɛ(n2) time which is nearly optimal. 
 Full Access 
 Exact Shortest Paths with Rational Weights on the Word RAM 
 href="/author/Karczmarz%2C+Adam" - Adam Karczmarz | , 
 href="/author/Nadara%2C+Wojciech" - Wojciech Nadara | , 
 href="/author/Soko%C5%82owski%2C+Marek" - Marek Sokołowski 
 pp.2597–2608 
 Abstract 
 PDF 
 AbstractExact computation of shortest paths in weighted graphs has been traditionally studied in one of two settings. First, one can assume that the edge weights are real numbers and all the performed operations on reals (typically comparisons and additions) take constant time. Classical Dijkstra's and Bellman-Ford algorithms have been described in this setting. 
 More efficient exact shortest paths algorithms have been obtained for integer-weighted graphs. Integrality assumption not only enables faster algorithms but also allows implementing the aforementioned algorithms in a much more realistic word RAM model where only arithmetic operations onO(logn)-bit integers are performed in constant time. 
 On the word RAM one can as efficiently exactly encode evenrational-weightedinstances withO(logn)-bit numerators and denominators. However, the known exact real-weighted shortest paths algorithms, run on such a rational input, can easily encounter intermediate values ofΘ(n)bits if represented exactly. This leads to a factor-Ω(n) slowdown on the word RAM. At the same time, the scaling algorithms suited for integer weights do not produce exact solutions for rational inputs without dramatically increasing their accuracy. 
 In this paper, we design randomized exact single-source shortest paths algorithms for rational-weighted graphs on the word RAM. Most importantly, in the non-negative case, we obtain a near-linear time algorithm matching Dijkstra's algorithm running time up to polylogarithmic factors. In presence of negative weights, we give anÕ(n2.5)-time algorithm breaking through the best known strongly polynomial bound attained by Bellman-Ford for sufficiently dense graphs. 
 *This work is a part of project BOBR (WN, MS) that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 948057). Adam Karczmarz was partially supported by the ERC CoG grant TUgbOAT no 772346 and the National Science Centre (NCN) grant no. 2022/47/D/ST6/02184. The full version of the paper can be accessed at https://arxiv.org/abs/2311.03321. 
 Full Access 
 Fault-Tolerant Spanners against Bounded-Degree Edge Failures: Linearly More Faults, Almost For Free 
 href="/author/Bodwin%2C+Greg" - Greg Bodwin | , 
 href="/author/Haeupler%2C+Bernhard" - Bernhard Haeupler | , 
 href="/author/Parter%2C+Merav" - Merav Parter 
 pp.2609–2642 
 Abstract 
 PDF 
 AbstractWe study a new and stronger notion of fault-tolerant graph structures whose size bounds depend on the degree of the failing edge set, rather than the total number of faults. For a subset of faulty edgesF⊆G, thefaulty-degreedeg(F) is the largest number of faults inFincident to any given vertex. For example, a matchingFhas deg(F) = 1 while |F| might be as large asn/2. 
 We design new fault-tolerant structures with size comparable to previous constructions, but which tolerate every fault set of small faulty-degree deg(F), rather than only fault sets of small size |F|. Thus, for example, our structures can tolerate alinearnumber of edge faults with almost the same size bounds currently known for handling asingleedge failure, provided that the edge faults are arranged in a matching. Our main results are: 
 • New FT-Certificates: For everyn-vertex graphGand degree thresholdf, one can compute a connectivity certificateH⊆Gwith |E(H)| =Õ(fn)edges that has the following guarantee: for any edge setFwith faulty-degree deg(F) ≤fand every vertex pairu,v, it holds thatuandvare connected inH\Fiff they are connected inG\F. This bound on |E(H)| is nearly tight. Since our certificates handle some fault sets of size up to |F| =O(fn), prior work did not imply any nontrivial upper bound for this problem, even whenf= 1. 
 • New FT-Spanners: We show that everyn-vertex graphGadmits a(2k —1)-spannerHwith |E(H)| =Ok(f1-1/kn1+1/k) edges, which tolerates any fault setFof faulty-degree at mostf. This bound on |E(H)| optimal up to its hidden dependence onk, and it is close to the bound ofOk(|F|1/2n1+1/k+ |F|n) that is known for the case where thetotalnumber of faults is |F| [Bodwin, Dinitz, Robelle SODA ‘22]. Our proof of this theorem is non-constructive, but by following a proof strategy of Dinitz and Robelle [PODC ‘20], we show that the runtime can be made polynomial by paying an additional polylognfactor in spanner size. 
 Our techniques are based on an adaptation of the blocking set method used in previous work on fault tolerant spanners, as well as a new expander-based toolkit which translates the quality guarantees for expander routing into fault tolerance guarantees. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2309.06696 
 Full Access 
 Simpler and Higher Lower Bounds for Shortcut Sets 
 href="/author/Williams%2C+Virginia+Vassilevska" - Virginia Vassilevska Williams | , 
 href="/author/Xu%2C+Yinzhan" - Yinzhan Xu | , 
 href="/author/Xu%2C+Zixuan" - Zixuan Xu 
 pp.2643–2656 
 Abstract 
 PDF 
 AbstractWe study the well-known shortcut set problem: how much can one decrease the diameter of a directed graph by adding a small set of shortcuts from the transitive closure of the graph. 
 We provide a variety of lower bounds. First, we vastly simplify the recent construction of Bodwin and Hoppenworth [FOCS 2023] which showed an 
 lower bound for the diameter of a directed unweightedn-node graph after addingO(n)shortcut edges. We highlight that our simplification completely removes the use of the convex sets by Bárány and Larman [Math. Ann. 1998] used in all previous lower bound constructions. Our simplification also removes the need for randomness and further removes some log factors. It allows us to generalize the construction to higher dimensions, which in turn can be used to show the following results:• There is an Ω(n1/5) lower bound for the diameter of the graph after addingO(m)shortcuts, wheremdenotes the number of edges in the input graph. 
 • For allɛ> 0, there exists aδ> 0 such that there aren-vertexO(n)-edge graphsGwhere adding any shortcut set of sizeO(n2-ɛ)keeps the diameter ofGat Ω(nδ). This improves the sparsity of the constructed graph compared to a known similar result by Hesse [SODA 2003]. 
 • For any integerd≥ 2, there exists a graphG= (V,E) onnvertices andS⊆Vwith 
 , such that when addingO(n) orO(m) shortcuts, the sourcewise diameter (the largest distance from some vertex inSto some reachable vertex in the graph) is. This initiates the study of sourcewise diameter in the setting of the shortcut set problem; previously, the study of the sourcewise variant is popular in a wide variety of related problems such as spanners and distance preservers. Complementing this lower bound result, we also provide an upper bound: we show that, we can reduce the sourcewise diameter toby addingO(n) shortcut edges.*Massachusetts Institute of Technology. Supported by NSF Grants CCF-2129139 and CCF-2330048 and BSF Grant 2020356. 
 Full Access 
 Distances and shortest paths on graphs of bounded highway dimension: simple, fast, dynamic 
 href="/author/Collette%2C+S%C3%A9bastien" - Sébastien Collette | , 
 href="/author/Iacono%2C+John" - John Iacono 
 pp.2657–2678 
 Abstract 
 PDF 
 AbstractDijkstra's algorithm is the standard method for computing shortest paths on arbitrary graphs. However, it is slow for large graphs, taking at least linear time. It has been long known that for real world road networks, creating a hierarchy of well-chosen shortcuts allows fast distance and path computation, with exact distance queries seemingly being answered in logarithmic time. However, these methods were but heuristics until the work of Abraham et al. [JACM 2016], where they defined a graph parameter called highway dimension which is constant for real-world road networks, and showed that in graphs of constant highway dimension, a shortcut hierarchy exists that guarantees shortest distance computation takesO(log(U+|V|)) time andO(Vlog(U+|V|)) space, whereUis the ratio of the smallest to largest edge, and |V| is the number of vertices. The problem is that they were unable to efficiently compute the hierarchy of shortcuts. Here we present a simple and efficient algorithm to compute the needed hierarchy of shortcuts in time and spaceO(Vlog(U+ |V|)), as well as supporting updates in timeO(log(U+ |V|)). 
 Full Access 
 Fair Price Discrimination 
 href="/author/Banerjee%2C+Siddhartha" - Siddhartha Banerjee | , 
 href="/author/Munagala%2C+Kamesh" - Kamesh Munagala | , 
 href="/author/Shen%2C+Yiheng" - Yiheng Shen | , 
 href="/author/Wang%2C+Kangning" - Kangning Wang 
 pp.2679–2703 
 Abstract 
 PDF 
 AbstractA seller is pricing identical copies of a good to a stream of unit-demand buyers. Each buyer has a value on the good as his private information. The seller only knows the empirical value distribution of the buyer population and chooses the revenue-optimal price. We consider a widely studied third-degree price discrimination model where an information intermediary with perfect knowledge of the arriving buyer's value sends a signal to the seller, hence changing the seller's posterior and inducing the seller to set a personalized posted price. Prior work of Bergemann, Brooks, and Morris (American Economic Review, 2015) has shown the existence of a signaling scheme that preserves seller revenue, while always selling the item, hence maximizing consumer surplus. In a departure from prior work, we ask whether the consumer surplus generated is fairly distributed among buyers with different values. To this end, we aim to maximize functions of buyers’ welfare that reward more balanced surplus allocations. 
 Our main result is the surprising existence of a novel signaling scheme thatsimultaneously8-approximatesallwelfare functions that are non-negative, monotonically increasing, symmetric, and concave, compared with any other signaling scheme. Classical examples of such welfare functions include the utilitarian social welfare, the Nash welfare, and the max-min welfare. Such a guarantee cannot be given by consumer-surplus-maximizing schemes — which are the ones typically studied in the literature. In addition, our scheme is socially efficient, and has the fairness property that buyers with higher values enjoy higher expected surplus, which is not always the case for existing schemes. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2305.07006. 
 Full Access 
 School Redistricting: Wiping Unfairness Off the Map 
 href="/author/Procaccia%2C+Ariel" - Ariel Procaccia | , 
 href="/author/Robinson%2C+Isaac" - Isaac Robinson | , 
 href="/author/Tucker-Foltz%2C+Jamie" - Jamie Tucker-Foltz 
 pp.2704–2724 
 Abstract 
 PDF 
 AbstractWe introduce and study the problem of designing an equitable school redistricting map, which we formalize as that of assigningnstudents to school attendance zones in a way that is fair to various demographic groups. Drawing on methodology from fair division, we consider the demographic groups as players and seats in schools as homogeneous goods. Due to geographic constraints, not every school can be assigned to every student. This raises new obstacles, rendering some classic fairness criteria infeasible. Nevertheless, we show that it is always possible to find an almost proportional allocation amonggdemographic groups if we are allowed to addO(glogg) extra seats. For any fixedg, we show that such an allocation can be found in polynomial time, obtaining a runtime ofO(n2logn) in the special (but practical) case whereg≤ 3. 
 Full Access 
 Oracle Efficient Online Multicalibration and Omniprediction 
 href="/author/Garg%2C+Sumegha" - Sumegha Garg | , 
 href="/author/Jung%2C+Christopher" - Christopher Jung | , 
 href="/author/Reingold%2C+Omer" - Omer Reingold | , 
 href="/author/Roth%2C+Aaron" - Aaron Roth 
 pp.2725–2792 
 Abstract 
 PDF 
 AbstractA recent line of work has shown a surprising connection between multicalibration, a multi- group fairness notion, and omniprediction, a learning paradigm that provides simultaneous loss minimization guarantees for a large family of loss functions [20, 19, 21, 18]. Prior work studies omniprediction in the batch setting. We initiate the study of omniprediction in the online adversarial setting. Although there exist algorithms for obtaining notions of multicalibration in the online adversarial setting [23], unlike batch algorithms, they work only for small finite classes of benchmark functionsF, because they require enumerating every functionf∈Fat every round. In contrast, omniprediction is most interesting for learning theoretichypothesis classes F, which are generally continuously (or at least exponentially) large. 
 We develop a new online multicalibration algorithm that is well defined for infinite benchmark classesF(e.g. the set of all linear functions), and is oracle efficient — i.e. for any classF, the algorithm has the form of an efficient reduction to a no-regret learning algorithm forF. The result is the first efficient online omnipredictor — an oracle efficient prediction algorithm that can be used to simultaneously obtain no regret guarantees to all Lipschitz convex loss functions. For the classFof linear functions, we show how to make our algorithm efficient in the worst case (i.e. the “oracle” that we need is itself efficient even in the worst case). We show how our results extend beyond mean multicalibration to quantile multicalibration, with applications to oracle efficient multivalid conformal prediction. Finally, we show upper and lower bounds on the extent to which our rates can be improved: our oracle efficient algorithm actually promises a stronger guarantee called “swap-omniprediction”, and we prove a lower bound showing that obtainingO(√T) bounds for swap-omniprediction is impossible in the online setting. On the other hand, we give a (non-oracle efficient) algorithm which can obtain the optimalO(√T) omniprediction bounds without going through multicalibration, giving an information theoretic separation between these two solution concepts. We leave the problem of obtainingO(√T) omniprediction bounds in an oracle efficient manner as our main open problem. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2307.08999 
 Full Access 
 Improved Approximation Algorithms for the Joint Replenishment Problem with Outliers, and with Fairness Constraints 
 href="/author/Suriyanarayana%2C+Varun" - Varun Suriyanarayana | , 
 href="/author/Sivashankar%2C+Varun" - Varun Sivashankar | , 
 href="/author/Gollapudi%2C+Siddharth" - Siddharth Gollapudi | , 
 href="/author/Shmoys%2C+David+B" - David B. Shmoys 
 pp.2793–2828 
 Abstract 
 PDF 
 AbstractThejoint replenishment problem(JRP) is a classical inventory management problem. We consider a natural generalizationwith outliers,where we are allowed to reject (that is, not service) a subset of demand points. In this paper, we are motivated by issues offairness- if we do not serve all of the demands, we wish to “spread out the pain” in a balanced way among customers, communities, or any specified market segmentation. One approach is to constrain the rejections allowed, and to have separate bounds for each given customer. In our most general setting, we consider a set ofCfeatures, where each demand point has an associated rejection cost for each feature, and we have a given bound on the allowed rejection cost incurred in total for each feature. This generalizes an extensively studied model of fairness introduced in earlier work on the Colorfulk—Center problem in which (analogously) each demand point has a given color, and we bound the number of rejections of each color class. In the JRP, we seek to balance the cost incurred by a fixed ordering overhead with the cost of maintaining on-hand inventory over a longer period in advance of when it is needed. More precisely, there is a given set of item types, for which there is specified demand over a finite, discrete-time horizon, and placing any order at a given time incurs a general ordering cost and item-specific ordering costs (independent of the total demand serviced); in addition, for each unit of demand held in inventory for an interval of time, there is a corresponding item-specific holding cost incurred; the aim is to minimize the total cost. 
 We give the first constant approximation algorithms for the fairness-constrained JRP with a constant number of features; specifically, we give a 2.86-approximation algorithm in this case. Even for the special case in which we bound the total (weighted) number of outliers, this performance guarantee improves upon bounds previously known for this case. Our approach is an LP-based algorithm that splits the instance into two subinstances. One is solved by a novel iterative rounding approach and the other by a significant extension of pipage-based rounding. The standard LP relaxation has an unbounded integrality gap, and hence another key element of our algorithm is to strengthen the relaxation by correctly guessing key attributes of the optimal solution, which are sufficiently concise, so that we can enumerate over all possible guesses in polynomial time - albeit exponential inC, the number of features. 
 Full Access 
 Santa Claus meets Makespan and Matroids: Algorithms and Reductions 
 href="/author/Bamas%2C+%C3%89tienne" - Étienne Bamas | , 
 href="/author/Lindermayr%2C+Alexander" - Alexander Lindermayr | , 
 href="/author/Megow%2C+Nicole" - Nicole Megow | , 
 href="/author/Rohwedder%2C+Lars" - Lars Rohwedder | , 
 href="/author/Schl%C3%B6ter%2C+Jens" - Jens Schlöter 
 pp.2829–2860 
 Abstract 
 PDF 
 AbstractIn this paper we study the relation of two fundamental problems in scheduling and fair allocation: makespan minimization on unrelated parallel machines and max-min fair allocation, also known as the Santa Claus problem. For both of these problems the best approximation factor is a notorious open question; more precisely, whether there is a better-than-2 approximation for the former problem and whether there is a constant approximation for the latter. 
 While the two problems are intuitively related and history has shown that techniques can often be transferred between them, no formal reductions are known. We first show that an affirmative answer to the open question for makespan minimization implies the same for the Santa Claus problem by reducing the latter problem to the former. We also prove that for problem instances with only two input values both questions are equivalent. 
 We then move to a special case called “restricted assignment”, which is well studied in both problems. Although our reductions do not maintain the characteristics of this special case, we give a reduction in a slight generalization, where the jobs or resources are assigned to multiple machines or players subject to a matroid constraint and in addition we have only two values. Since for the Santa Claus problem with matroids the two value case is up to constants equivalent to the general case, this draws a similar picture as before: equivalence for two values and the general case of Santa Claus can only be easier than makespan minimization. To complete the picture, we give an algorithm for our new matroid variant of the Santa Claus problem using a non-trivial extension of the local search method from restricted assignment. Thereby we unify, generalize, and improve several previous results. We believe that this matroid generalization may be of independent interest and provide several sample applications. 
 As corollaries, we obtain a polynomial-time (2 — 1/nɛ)-approximation for two-value makespan minimization for every ɛ > 0, improving on the previous (2 — 1/m)-approximation, and a polynomial-time (1.75 + ɛ)- approximation for makespan minimization in the restricted assignment case with two values, improving the previous best rate of 
 .*We thank Schloss Dagstuhl for hosting the Seminar 23061 on Scheduling in February 2023 where we had fruitful discussions on this topic. 
 Full Access 
 A (3 + ɛ)-Approximate Correlation Clustering Algorithm in Dynamic Streams 
 href="/author/Cambus%2C+Melanie" - Melanie Cambus | , 
 href="/author/Kuhn%2C+Fabian" - Fabian Kuhn | , 
 href="/author/Lindy%2C+Etna" - Etna Lindy | , 
 href="/author/Pai%2C+Shreyas" - Shreyas Pai | , 
 href="/author/Uitto%2C+Jara" - Jara Uitto 
 pp.2861–2880 
 Abstract 
 PDF 
 AbstractGrouping together similar elements in datasets is a common task in data mining and machine learning. In this paper, we study streaming and parallel algorithms for correlation clustering, where each pair of elements is labeled either similar or dissimilar. The task is to partition the elements and the objective is to minimize disagreements, that is, the number of dissimilar elements grouped together and similar elements that get separated. 
 Our main contribution is a semi-streaming algorithm that achieves a (3 + ɛ)-approximation to the minimum number of disagreements using a single pass over the stream. In addition, the algorithm also works for dynamic streams. Our approach builds on the analysis of the PIVOT algorithm by Ailon, Charikar, and Newman [JACM’08] that obtains a 3-approximation in the centralized setting. Our design allows us to sparsify the input graph by ignoring a large portion of the nodes and edges without a large extra cost as compared to the analysis of PIVOT. This sparsification makes our technique applicable in several models of massive graph processing, such as semi-streaming and Massively Parallel Computing (MPC), where sparse graphs can typically be handled much more efficiently. 
 Our work improves on the approximation ratio of the recent single-pass 5-approximation algorithm and on the number of passes of the recentO(1/ɛ)-pass (3 + ɛ)-approximation algorithm [Behnezhad, Charikar, Ma, Tan FOCS’22, SODA’23]. Our algorithm is also more robust and can be applied in dynamic streams. Furthermore, it is the first single pass (3 + ɛ)-approximation algorithm that uses polynomial post-processing time. 
 Full Access 
 An Unconditional Lower Bound for Two-Pass Streaming Algorithms for Maximum Matching Approximation 
 href="/author/Konrad%2C+Christian" - Christian Konrad | , 
 href="/author/Naidu%2C+Kheeran+K" - Kheeran K. Naidu 
 pp.2881–2899 
 Abstract 
 PDF 
 AbstractIn this paper, we give the first unconditional space lower bound for two-pass streaming algorithms for Maximum Bipartite Matching approximation. We show that every randomized two-pass streaming algorithm that computes a 
 -approximation to Maximum Bipartite Matching, for any constant ɛ > 0, requires space, where n is the number of vertices of the input graph.Previously, only a conditional lower bound by Assadi [SODA’22] was known that relates the quality of their lower bound to the maximum density of Ruzsa-Szemeredi graphs (RS-graphs) with matchings of linear sizes. In the best case, i.e., if very dense RS-graphs with linear-sized matchings exist, their lower bound rules out approximation ratios above 0.98, however, with current knowledge, only approximation factors of 1 —o(1) are ruled out. 
 Our lower bound makes use of the information cost trade-off of the Index problem in the two-party communication setting established by Jain et al. [JACM’09]. To the best of our knowledge, our work is the first that exploits this trade-off result in the context of lower bounds for multi-pass graph streaming algorithms. 
 Full Access 
 Time-Space Lower Bounds for Bounded-Error Computation in the Random-Query Model 
 href="/author/Dinur%2C+Itai" - Itai Dinur 
 pp.2900–2915 
 Abstract 
 PDF 
 AbstractThe random-query model was introduced by Raz and Zhan at ITCS 2020 as a new model of space-bounded computation. In this model, a branching program of length T and width 2Sattempts to compute a functionf: {0, 1}n→ {0, 1}. However, instead of receiving direct access to the input bits(x1,…,xn), the input is given in pairs of the form (ij, xij) ∈ {1, …,n} × {0, 1} forj= 1, 2,…,T, where the indicesi1,…,iTare chosen at random from a pre-fixed distribution. 
 Raz and Zhan proved that any branching program in the random-query model with the independent distribution (where {ij}j=1,…,t are uniform and independent) that computes a functionfwith sensitivityksatisfies T · (S+ logn) ≥ Ω(n·k). This gives a quadratic time-space lower bound for many natural functions which have sensitivity Ω(n), such as XOR and Majority. The bound was proved in the zero-error regime, where for each input, the branching program is required to output a value with high probability, and given that a value is output, it must be correct with probability 1. 
 Furthermore, Raz and Zhan conjectured that (up to logarithmic factors inn) a quadratic time-space lower bound still holds for the XOR function in the more conventional bounded-error regime, where for each input, the output must be correct with high probability. 
 In this paper, we prove this conjecture. More generally, letf: {0, 1}n→ {0, 1} haveaverage sensitivity(or total influence) I[f]. We prove that any branching program in the random-query model with the independent distribution that computesfin the bounded-error regime satisfies 
 (where Ω hides logarithmic factors inn). Moreover, we prove a quadratic time-space lower bound for the Majority function, even though its total influence is.Our proof is based on a reduction from a communication complexity problem. 
 *The full version of the paper can be accessed at https://eccc .weizmann.ac.il/report/2023/084/ 
 Full Access 
 Robust Sparsification for Matroid Intersection with Applications 
 href="/author/Huang%2C+Chien-Chung" - Chien-Chung Huang | , 
 href="/author/Sellier%2C+Fran%C3%A7ois" - François Sellier 
 pp.2916–2940 
 Abstract 
 PDF 
 AbstractMatroid intersection is a classical optimization problem where, given two matroids over the same ground set, the goal is to find the largest common independent set. In this paper, we show that there exists a certain “sparsifer”: a subset of elements, of sizeO(|Sopt| · 1/ɛ), whereSoptdenotes the optimal solution, that is guaranteed to contain a 3/2 + ɛ approximation, while guaranteeing certain robustness properties. We call such a small subset aDensity Constrained Subset(DCS), which is inspired by theEdge-Degree Constrained, Subgraph,(EDCS) [Bernstein and Stein, 2015], originally designed for the maximum cardinality matching problem in a graph. Our proof is constructive and hinges on a greedy decomposition of matroids, which we call thedensity-based decomposition.We show that this sparsifier has certain robustness properties that can be used in one-way communication and random-order streaming models. 
 Specifically, we use the DCS to design a one-way communication protocol for matroid intersection and obtain a 3/2 + ɛ approximation, using a message of sizeO(|Sopt| · 1/ɛ). This matches the best achievable ratio for the one-way communication bipartite matching [Goel, Kapralov, and Khanna, 2012]. 
 Moreover, the DCS can be used to design a streaming algorithm in the random-order streaming model requiring the space ofO(|Sopt| ·poly(log(n),1/ɛ)), where n is the size of the stream (the ground set of the matroids). Our algorithm guarantees a 3/2 + ɛ approximationin expectationand, when the size ofSoptis not too small,with high probability.Prior to our work, the best approximation ratio of a streaming algorithm in the random-order streaming model was an expected 2 — δ for some small constantδ >0 [Guruganesh and Singla, 2017]. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.16827 
 Full Access 
 Robust 1-bit Compressed Sensing with Iterative Hard Thresholding 
 href="/author/Matsumoto%2C+Namiko" - Namiko Matsumoto | , 
 href="/author/Mazumdar%2C+Arya" - Arya Mazumdar 
 pp.2941–2979 
 Abstract 
 PDF 
 AbstractIn 1-bit compressed sensing, the aim is to estimate ak-sparse unit vectorx∈Sn-1within an e error (in ℓ2) from minimal number of linear measurements that are quantized to just their signs, i.e., from measurements of the formy= sign((a, x}). In this paper, we study a noisy version where a fraction of the measurements can be flipped, potentially by an adversary. In particular, we analyze the Binary Iterative Hard Thresholding (BIHT) algorithm, a proximal gradient descent on a properly defined loss function used for 1-bit compressed sensing, in this noisy setting. It is known from recent results that, with 
 noiseless measurements, BIHT provides an estimate within ɛ error. This result is optimal and universal, meaning one set of measurements work for all sparse vectors. In this paper, we show that BIHT also provides better results than all known methods for the noisy setting. We show that when up to τ-fraction of the sign measurements are incorrect (adversarial error), with the same number of measurements as before, BIHT agnostically provides an estimate ofxwithin anÕ(ɛ + τ) error, maintaining the universality of measurements. This establishes stability of iterative hard thresholding in the presence of measurement error. To obtain the result, we use the restricted approximate invertibility of Gaussian matrices, as well as a tight analysis of the high-dimensional geometry of the adversarially corrupted measurements. 
 Full Access 
 Incremental Approximate Maximum Flow on Undirected Graphs in Subpolynomial Update Time 
 href="/author/van+den+Brand%2C+Jan" - Jan van den Brand | , 
 href="/author/Chen%2C+Li" - Li Chen | , 
 href="/author/Kyng%2C+Rasmus" - Rasmus Kyng | , 
 href="/author/Liu%2C+Yang+P" - Yang P. Liu | , 
 href="/author/Peng%2C+Richard" - Richard Peng | , 
 href="/author/Gutenberg%2C+Maximilian+Probst" - Maximilian Probst Gutenberg | , 
 href="/author/Sachdeva%2C+Sushant" - Sushant Sachdeva | , 
 href="/author/Sidford%2C+Aaron" - Aaron Sidford 
 pp.2980–2998 
 Abstract 
 PDF 
 AbstractWe provide an algorithm which, with high probability, maintains a (1 — ɛ)-approximate maximum flow on an undirected graph undergoingm-edge additions in amortizedmo(1)ɛ-3time per update. To obtain this result, we provide a more general algorithm that solves what we call theincremental, thresholded, p-norm flow problemthat asks to determine the first edge-insertion in an undirected graph that causes the minimumℓp-norm flow to decrease below a given threshold in value. Since we solve this thresholded problem, our data structure succeeds against an adaptive adversary that can only see the data structure's output. Furthermore, since our algorithm holds forp= 2, we obtain improved algorithms for dynamically maintaining the effective resistance between a pair of vertices in an undirected graph undergoing edge insertions. 
 Our algorithm builds upon previous dynamic algorithms for approximately solving the minimum-ratio cycle problem that underlie previous advances on the maximum flow problem [Chen-Kyng-Liu-Peng-Probst Gutenberg-Sachdeva, FOCS ‘22] as well as recent dynamic maximum flow algorithms [v.d.Brand-Liu-Sidford, STOC ‘23]. Instead of using interior point methods, which were a key component of these recent advances, our algorithm uses an optimization method based onℓp-norm iterative refinement and the multiplicative weight update method. This ensures a monotonicity property in the minimum-ratio cycle subproblems that allows us to apply known data structures and bypass issues arising from adaptive queries. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2311.03174 
 Full Access 
 Fully Dynamic Min-Cut of Superconstant Size in Subpolynomial Time 
 href="/author/Jin%2C+Wenyu" - Wenyu Jin | , 
 href="/author/Sun%2C+Xiaorui" - Xiaorui Sun | , 
 href="/author/Thorup%2C+Mikkel" - Mikkel Thorup 
 pp.2999–3026 
 Abstract 
 PDF 
 AbstractWe present a deterministic fully dynamic algorithm with subpolynomial worst-case time per graph update such that after processing each update of the graph, the algorithm outputs a minimum cut of the graph if the graph has a cut of size at mostcfor somec= (logn)o(1). Previously, the best update time was 
 for anyc> 2 andc=O(logn) [28]. 
 Full Access 
 Fully Dynamic Shortest Path Reporting Against an Adaptive Adversary 
 href="/author/Alokhina%2C+Anastasiia" - Anastasiia Alokhina | , 
 href="/author/van+den+Brand%2C+Jan" - Jan van den Brand 
 pp.3027–3039 
 Abstract 
 PDF 
 AbstractAlgebraic data structures are the main subroutine for maintaining distances in fully dynamic graphs in subquadratic time. However, these dynamic algebraic algorithms generally cannot maintain the shortest paths, especially against adaptive adversaries. We present the first fully dynamic algorithm that maintains the shortest paths against an adaptive adversary in subquadratic update time. This is obtained via a combinatorial reduction that allows reconstructing the shortest paths with only a few distance estimates. Using this reduction, we obtain the following: 
 On weighted directed graphs with real edge weights in [1,W], we can maintain (1 +ε)-approximate shortest paths in 
 update andquery time. This improves upon the approximate distance data structures from [v.d.Brand, Nanongkai; FOCS’19], which only returned a distance estimate, by matching their complexity and returning an approximate shortest path.On unweighted directed graphs, we can maintain exact shortest paths in 
 update andquery time. This improves upon [Bergamaschi, Henzinger, P.Gutenberg, V.Williams, Wein; SODA’21] who could report the path only against oblivious adversaries. We improve both their update and query time while also handling adaptive adversaries.On unweighted undirected graphs, our reduction holds not just against adaptive adversaries but is also deterministic. We maintain a (1 + ɛ)-approximatest-shortest path inO(n1.529/ɛ2) time per update, and (1 + ɛ)- approximate single source shortest paths inO(n1.764/ɛ2) time per update. Previous deterministic results by [v.d.Brand, Nazari, Forster; FOCS’22] could only maintain distance estimates but no paths. 
 *The full version [9] can be accessed at https://arxiv.org/abs/2304.07403 
 Full Access 
 Fully Dynamic Matching:-Approximation in Polylog Update Time 
 href="/author/Azarmehr%2C+Amir" - Amir Azarmehr | , 
 href="/author/Behnezhad%2C+Soheil" - Soheil Behnezhad | , 
 href="/author/Roghani%2C+Mohammad" - Mohammad Roghani 
 pp.3040–3061 
 Abstract 
 PDF 
 AbstractWe study maximum matchings in fully dynamic graphs, which are graphs that undergo both edge insertions and deletions. Our focus is on algorithms that estimate the size of maximum matching after each update while spending a small time. 
 An important question studied extensively is the best approximation achievable via algorithms that only spend poly(logn) time per update, where n is the number of vertices. The current best bound is a (1/2 + ɛ0)- approximation for a small constant ɛ0> 0, due to recent works of Behnezhad [SODA’23] (ɛ0~ 0.001) and Bhattacharya, Kiss, Saranurak, Wajc [SODA’23] (ɛ0~ 0.006) who broke the long-standing 1/2-approximation barrier. These works also showed that for any fixed ɛ > 0, the approximation can be further improved to (2 — 
 — ɛ) ~ .585 for bipartite graphs, leaving a huge gap between general and bipartite graphs.In this work, we close this gap. We show that for any fixed ɛ > 0, a (2 — 
 — ɛ) approximation can be maintained in poly(logn) time per update evenin general graphs.Our techniques also lead to the same approximation for general graphs in two passes of the semi-streaming setting, removing a similar gap in that setting. 
 Full Access 
 Adaptive Out-Orientations with Applications 
 href="/author/Chekuri%2C+Chandra" - Chandra Chekuri | , 
 href="/author/Christiansen%2C+Aleksander+Bj%C3%B8rn" - Aleksander Bjørn Christiansen | , 
 href="/author/Holm%2C+Jacob" - Jacob Holm | , 
 href="/author/van+der+Hoog%2C+Ivor" - Ivor van der Hoog | , 
 href="/author/Quanrud%2C+Kent" - Kent Quanrud | , 
 href="/author/Rotenberg%2C+Eva" - Eva Rotenberg | , 
 href="/author/Schwiegelshohn%2C+Chris" - Chris Schwiegelshohn 
 pp.3062–3088 
 Abstract 
 PDF 
 AbstractWe give improved algorithms for maintaining edge-orientations of a fully-dynamic graph, such that the maximum out-degree is bounded. On one hand, we show how to orient the edges such that maximum out- degree is proportional to the arboricity α of the graph, in, either, an amortised update time of𝒪(log2nlog α), or a worst-case update time of𝒪(log3nlog α). On the other hand, motivated by applications including dynamic maximal matching, we obtain a different trade-off. Namely, the improved update time of either𝒪(lognlog α), amortised, or𝒪(log2nlog α), worst-case, for the problem of maintaining an edge-orientation with at most𝒪(α + logn) out-edges per vertex. Finally, all of our algorithms naturally limit the recourse to be polylogarithmic in n and α. Our algorithms adapt to the current arboricity of the graph, and yield improvements over previous work: 
 Firstly, we obtain deterministic algorithms for maintaining a (1 + ɛ) approximation of the maximum subgraph density, ρ, of the dynamic graph. Our algorithms have update times of𝒪(ɛ-6log3nlog ρ) worst- case, and𝒪(ɛ-4log2nlog ρ) amortised, respectively. We may output a subgraph H of the input graph where its density is a (1 + ɛ) approximation of the maximum subgraph density in time linear in the size of the subgraph. These algorithms have improved update time compared to the𝒪(ɛ-6log4n) algorithm by Sawlani and Wang from STOC 2020. 
 Secondly, we obtain an𝒪(ɛ-6log3nlog α) worst-case update time algorithm for maintaining a (1 + ɛ)OPT + 2 approximation of the optimal out-orientation of a graph with adaptive arboricity α, improving the𝒪(ɛ-6α2log3n) algorithm by Christiansen and Rotenberg from ICALP 2022. This yields the first worst-case polylogarithmic dynamic algorithm for decomposing into𝒪(α) forests. 
 Thirdly, we obtain arboricity-adaptive fully-dynamic deterministic algorithms for a variety of problems including maximal matching, Δ + 1 colouring, and matrix vector multiplication. All update times are worst- case𝒪(α + log2nlog α), where α is the current arboricity of the graph. For the maximal matching problem, the state-of-the-art deterministic algorithms by Kopelowitz, Krauthgamer, Porat, and Solomon from ICALP 2014 runs in time𝒪(α2+ log2n), and by Neiman and Solomon from STOC 2013 runs in time 
 . We give improved running times whenever the arboricity.*The full version of the paper can be accessed at https://arxiv.org/abs/2310.18146 
 Full Access 
 Deterministic Near-Linear Time Minimum Cut in Weighted Graphs 
 href="/author/Henzinger%2C+Monika" - Monika Henzinger | , 
 href="/author/Li%2C+Jason" - Jason Li | , 
 href="/author/Rao%2C+Satish" - Satish Rao | , 
 href="/author/Wang%2C+Di" - Di Wang 
 pp.3089–3139 
 Abstract 
 PDF 
 AbstractIn 1996, Karger [Kar96] gave a startling randomized algorithm that finds a minimum-cut in a (weighted) graph in timeO(mlog3n) which he termed near-linear time meaning linear (in the size of the input) times a polylogarthmic factor. In this paper, we give the first deterministic algorithm which runs in near-linear time for weighted graphs. 
 Previously, the breakthrough results of Kawarabayashi and Thorup [KT19] gave a near-linear time algorithm for simple graphs (which was improved to have running timeO(mlog2nlog logn) in [HRW20].) The main technique here is a clustering procedure that perfectly preserves minimum cuts. Recently, Li [Li21] gave anm1+o(1)deterministic minimum-cut algorithm for weighted graphs; this form of running time has been termed “almost-linear”. Li uses almost-linear time deterministic expander decompositions which do not perfectly preserve minimum cuts, but he can use these clusterings to, in a sense, “derandomize” the methods of Karger. 
 In terms of techniques, we provide a structural theorem that says there exists a sparse clustering that preserves minimum cuts in a weighted graph witho(1) error. In addition, we construct it deterministically in near linear time. This was done exactly for simple graphs in [KT19, HRW20] and with polylogarithmic error for weighted graphs in [Li21]. Extending the techniques in [KT19, HRW20] to weighted graphs presents significant challenges, and moreover, the algorithm can only polylogarithmically approximately preserve minimum cuts. A remaining challenge is to reduce the polylogarithmic-approximate clusterings to 1 +o(1/ logn)-approximate so that they can be applied recursively as in [Li21] overO(logn) many levels. This is an additional challenge that requires building on properties of tree-packings in the presence of a wide range of edge weights to, for example, find sources for local flow computations which identify minimum cuts that cross clusters. 
 Full Access 
 The Cost of Parallelizing Boosting 
 href="/author/Lyu%2C+Xin" - Xin Lyu | , 
 href="/author/Wu%2C+Hongxun" - Hongxun Wu | , 
 href="/author/Yang%2C+Junzhao" - Junzhao Yang 
 pp.3140–3155 
 Abstract 
 PDF 
 AbstractWe study the cost of parallelizing weak-to-strong boosting algorithms for learning, following the recent work of Karbasi and Larsen. Our main results are two-fold: First, we prove a tight lower bound, showing that even “slight” parallelization of boosting requires an exponential blow-up in the complexity of training. Specifically, let γ be the weak learner's advantage over random guessing. The famous AdaBoost algorithm produces an accurate hypothesis by interacting with the weak learner forÕ(1/γ2)1rounds where each round runs in polynomial time. Karbasi and Larsen showed that “significant” parallelization must incur exponential blow-up: Any boosting algorithm either interacts with the weak learner for Ω(1/γ) rounds or incurs an exp(d/γ) blow-up in the complexity of training, wheredis the VC dimension of the hypothesis class. We close the gap by showing that any boosting algorithm either has Ω(1/γ2) rounds of interaction or incurs a smaller exponential blow-up of exp(d). Complementing our lower bound, we show that there exists a boosting algorithm usingÕ(1/(tγ2)) rounds, and only suffer a blow-up of exp(d ·t2).Plugging int= ω(1), this shows that the smaller blow-up in our lower bound is tight. More interestingly, this provides the first trade-off between the parallelism and the total work required for boosting. 
 Our lower bound follows from a novel interpretation of parallel boosting as a variant of “coin game”. The upper bound is inspired by the “bagging” technique in machine learning and draws a connection to differential privacy. 
 Full Access 
 How Many Neurons Does it Take to Approximate the Maximum? 
 href="/author/Safran%2C+Itay" - Itay Safran | , 
 href="/author/Reichman%2C+Daniel" - Daniel Reichman | , 
 href="/author/Valiant%2C+Paul" - Paul Valiant 
 pp.3156–3183 
 Abstract 
 PDF 
 AbstractWe study the size of a neural network needed to approximate the maximum function overdinputs, in the most basic setting of approximating with respect to theL2norm, for continuous distributions, for a network that uses ReLU activations. We provide new lower and upper bounds on the width required for approximation across various depths. Our results establish new depth separations between depth 2 and 3, and depth 3 and 5 networks, as well as providing a depth𝒪(log(log(d))) and width𝒪(d)construction which approximates the maximum function. Our depth separation results are facilitated by a new lower bound for depth 2 networks approximating the maximum function over the uniform distribution, assuming an exponential upper bound on the size of the weights. Furthermore, we are able to use this depth 2 lower bound to provide tight bounds on the number of neurons needed to approximate the maximum by a depth 3 network. Our lower bounds are of potentially broad interest as they apply to the widely studied and usedmaxfunction, in contrast to many previous results that base their bounds on specially constructed or pathological functions and distributions. 
 Full Access 
 Learning Hard-Constrained Models with One Sample 
 href="/author/Galanis%2C+Andreas" - Andreas Galanis | , 
 href="/author/Kalavasis%2C+Alkis" - Alkis Kalavasis | , 
 href="/author/Kandiros%2C+Anthimos+Vardis" - Anthimos Vardis Kandiros 
 pp.3184–3196 
 Abstract 
 PDF 
 AbstractWe consider the problem of estimating the parameters of a Markov Random Field withhard-constraints using a single sample. As our main running examples, we use thek-SAT and the proper coloring models, as well as generalH-coloring models; for all of these we obtain both positive and negative results. In contrast to the soft-constrained case, we show in particular that single-sample estimation is not always possible, and that the existence of an estimator is related to the existence of non-satisfiable instances. 
 Our algorithms are based on the pseudo-likelihood estimator. We show variance bounds for this estimator using coupling techniques inspired, in the case ofk-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results for colorings build on this new coupling approach. Forq-colorings on graphs with maximum degreed,we give a linear-time estimator exists whenq < d+ 1, whereas the problem is non-identifiable whenq ≤ d+ 1. For generalH-colorings, we show that standard conditions that guarantee sampling, such as Dobrushin's condition, are insufficient for one-sample learning; on the positive side, we provide a general condition that is sufficient to guarantee linear-time learning and obtain applications for proper colorings and permissive models. For thek-SAT model on formulas with maximum degreed, we provide a linear-time estimator whenk≳ 6.45 logd, whereas the problem becomes non-identifiable whenk≲ logd. 
 *The full version of the paper appears with the same title at ArXiv. For the purpose of Open Access, the authors have applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission. All data is provided in full in the results section of this paper. 
 Full Access 
 Online Robust Mean Estimation 
 href="/author/Kane%2C+Daniel+M" - Daniel M. Kane | , 
 href="/author/Diakonikolas%2C+Ilias" - Ilias Diakonikolas | , 
 href="/author/Xiao%2C+Hanshen" - Hanshen Xiao | , 
 href="/author/Liu%2C+Sihan" - Sihan Liu 
 pp.3197–3235 
 Abstract 
 PDF 
 AbstractThis We study the problem of high-dimensional robust mean estimation in an online setting. Specifically, we consider a scenario wherensensors are measuring some common, ongoing phenomenon. At each time stept= 1, 2,. .,T, theithsensor reports its readings for that time step. The algorithm must then commit to its estimate μtfor the true mean value of the process at timet. We assume that most of the sensors observe independent samples from some common distributionX, but an ɛ-fraction of them may instead behave maliciously. The algorithm wishes to compute a good approximation μ to the true meanμ*:= E[X]. We note that if the algorithm is allowed to wait until timeTto report its estimate, this reduces to the well-studied problem of robust mean estimation. However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation. 
 We prove two main results about online robust mean estimation in this model. First, if the uncorrupted samples satisfy the standard condition of (ɛ, δ)-stability, we give an efficient online algorithm that outputs estimatesμt,t∈ [T], such that with high probability it holds that ‖μ — μ*‖2=O (δlog (T)), where μ = (μt)t∈[T]. We note that this error bound is nearly competitive with the best offline algorithms, which would achieve ℓ2-error ofO(δ).Our second main result shows that with additional assumptions on the input (most notably thatXis a product distribution) there are inefficient algorithms whose error does not depend onTat all. 
 Full Access 
 Optimal rates for ranking a permuted isotonic matrix in polynomial time 
 href="/author/Pilliat%2C+Emmanuel" - Emmanuel Pilliat | , 
 href="/author/Carpentier%2C+Alexandra" - Alexandra Carpentier | , 
 href="/author/Verzelen%2C+Nicolas" - Nicolas Verzelen 
 pp.3236–3273 
 Abstract 
 PDF 
 AbstractWe consider a ranking problem where we have noisy observations from a matrix with isotonic columns whose rows have been permuted by some permutation π*. This encompasses many models, including crowd-labeling and ranking in tournaments by pair-wise comparisons. In this work, we provide an optimal and polynomial-time procedure for recovering π*, settling an open problem in [8]. As a byproduct, our procedure is used to improve the state-of-the art for ranking problems in the stochastically transitive model (SST). Our approach is based on iterative pairwise comparisons by suitable data-driven weighted means of the columns. These weights are built using a combination of spectral methods with new dimension-reduction techniques. In order to deal with the important case of missing data, we establish a new concentration inequality for sparse and centered rectangular Wishart-type matrices. 
 *The full version of the paper can also be accessed at https://arxiv.org/abs/2310.01133 
 Full Access 
 Faster Sublinear-Time Edit Distance 
 href="/author/Bringmann%2C+Karl" - Karl Bringmann | , 
 href="/author/Cassis%2C+Alejandro" - Alejandro Cassis | , 
 href="/author/Fischer%2C+Nick" - Nick Fischer | , 
 href="/author/Kociumaka%2C+Tomasz" - Tomasz Kociumaka 
 pp.3274–3301 
 Abstract 
 PDF 
 AbstractWe study the fundamental problem of approximating the edit distance of two strings. After an extensive line of research led to the development of a constant-factor approximation algorithm in almost-linear time, recent years have witnessed a notable shift in focus towardssublinear-timealgorithms. Here, the task is typically formalized as the (k,K)-gap edit distanceproblem: Distinguish whether the edit distance of two strings is at mostkor more thanK. 
 Surprisingly, it is still possible to compute meaningful approximations in this challenging regime. Nevertheless, in almost all previous work, truly sublinear running time ofO(n1-ɛ)(for a constant ɛ > 0) comes at the price of at leastpolynomialgapK≥k·nΩ(ɛ). Only recently, [Bringmann, Cassis, Fischer, and Nakos; STOC ‘22] broke through this barrier and solved thesub-polynomial (k, k1+o(1))-gap edit distance problem in timeO(n/k+k4+o(1)), which is truly sublinear if 
 . Then/kterm is inevitable (already for Hamming distance), but it remains an important task to optimize the poly(k) term and, in general, solve the (k,k1+o(1))-gap edit distance problem in sublinear-time for larger values ofk.In this work, we design an improved algorithm for the (k,k1+o(1))-gap edit distance problem in sublinear timeO(n/k+k2+o(1)), yielding a significant quadratic speed-up over the previousO(n/k+k4+o(1))-time algorithm. Notably, our algorithm is unconditionally almost-optimal (up to subpolynomial factors) in the regime where 
 and improves upon the state of the art for. Similarly to previous results, our algorithm is based on the framework of [Andoni, Krauthgamer, and Onak; FOCS ‘10], and thus we can further reduce the gap to polylogarithmic (K=k· (logk)O(1/ɛ)) at the cost of increasing our running time by a factorkɛ. 
 Full Access 
 Near-Optimal Quantum Algorithms for Bounded Edit Distance and Lempel-Ziv Factorization 
 href="/author/Gibney%2C+Daniel" - Daniel Gibney | , 
 href="/author/Jin%2C+Ce" - Ce Jin | , 
 href="/author/Kociumaka%2C+Tomasz" - Tomasz Kociumaka | , 
 href="/author/Thankachan%2C+Sharma+V" - Sharma V. Thankachan 
 pp.3302–3332 
 Abstract 
 PDF 
 AbstractMeasuring sequence similarity and compressing texts are among the most fundamental tasks in string algorithms. In this work, we develop near-optimalquantumalgorithms for the central problems in these two areas: computing the edit distance of two strings [Levenshtein, 1965] and building the Lempel-Ziv factorization of a string [Ziv & Lempel, 1977], respectively. 
 Classically, the edit distance of two length-nstrings can be computed in𝒪(n2) time and there is little hope for a significantly faster algorithm: an𝒪(n2-ɛ)-time procedure would falsify the Strong Exponential Time Hypothesis. Quantum computers might circumvent this lower bound, but even 3-approximation of edit distance is not known to admit an𝒪(n2-ɛ)-time quantum algorithm. In theboundedsetting, where the complexity is parameterized by the valuekof the edit distance, there is an𝒪(n+k2)-time classical algorithm [Myers, 1986; Landau & Vishkin, 1988], which is optimal (up to sub-polynomial factors and conditioned on SETH) as a function ofnandk. Our first main contribution is a quantum 
 - time algorithm that usesqueries, where theÕ(·) notation hides polylogarithmic factors. This query complexity is unconditionally optimal, and any significant improvement in the time complexity would break the quadratic barrier for the unbounded setting. Interestingly, our divide-and-conquer quantum algorithm reduces the bounded edit distance problem to the special case where the two input strings have small Lempel-Ziv factorizations. Then, it combines our quantum LZ compression algorithm with a classical subroutine computing edit distance between compressed strings. The LZ factorization problem can be classically solved in𝒪(n) time, which is unconditionally optimal in the quantum setting (even for computing just the sizezof the factorization). We can, however, hope for a quantum speedup if we parameterize the complexity in terms ofz. Already a generic oracle identification algorithm [Kothari 2014] yields the optimal query complexity ofat the price of exponential running time. Our second main contribution is a quantum algorithm that also achieves the optimal time complexity of𝒪(zlog2n). The key insight is the introduction of a novel LZ-like factorization of size𝒪(zlog2n), which allows us to efficiently compute each new factor through a combination of classical and quantum algorithmic techniques. From this, we obtain the desired LZ factorization. Using existing results [Kempa & Kociumaka, 2020], we can then obtain the string's run-length encoded Burrows-Wheeler Transform (BWT)—another classical compressor [Burrows & Wheeler, 1994], and a structure for longest common extensions (LCE) queries inÕ(z) extra time [I, 2017; Nishimoto et al., 2016].Lastly, we obtain efficient indexes of size𝒪(z) for counting and reporting the occurrences of a given pattern and for supporting more general suffix array and inverse suffix array queries, based on the recentr-index[Gagie, Navarro, and Prezza, 2020]. These indexes can be constructed in 
 quantum time, which allows us to solve many fundamental problems, like longest common substring, maximal unique matches, and Lyndon factorization, in time.*The full version of the paper can be accessed at https://arxiv.org/abs/2311.01793 
 Full Access 
 Deterministic Sparse Pattern Matching via the Baur-Strassen Theorem 
 href="/author/Fischer%2C+Nick" - Nick Fischer 
 pp.3333–3353 
 Abstract 
 PDF 
 AbstractHow fast can you test whether a constellation of stars appears in the night sky? This question can be modeled as the computational problem of testing whether a set of pointsPcan be moved into (or close to) another setQunder some prescribed group of transformations. Problems of this kind are subject to intensive study in computational geometry and enjoy countless theoretical and practical applications. 
 Consider, as a simple representative, the following problem: Given two sets of at mostnintegersP, Q⊆ [N], determine whether there is some shiftssuch thatPshifted by s is a subset ofQ, i.e.,P+s= {p+s:p∈P} ⊆Q. This problem, to which we refer as theConstellationproblem, can be solved in near-linear timeO(nlogn) by a Monte Carlo randomized algorithm [Cardoze, Schulman; FOCS ‘98] and timeO(nlog2N) by a Las Vegas randomized algorithm [Cole, Hariharan; STOC ‘02]. Moreover, there is a deterministic algorithm running in time 
 [Chan, Lewenstein; STOC ‘15]. An interesting question left open by these previous works is whether Constellation is indeterministic near-lineartime (i.e., with only polylogarithmic overhead).We answer this question positively by giving anO(npolylog(N))-time deterministic algorithm for the Constellation problem. Our algorithm extends to various more complex Point Pattern Matching problems in higher dimensions, under translations and rigid motions, and possibly with mismatches, and also to a near-linear-time derandomization of the Sparse Wildcard Matching problem on strings. 
 We find it particularly interestinghowwe obtain our deterministic algorithm. All previous algorithms are based on the same baseline idea, using additive hashing and the Fast Fourier Transform. In contrast, our algorithms are based on new ideas, involving a surprising blend of combinatorial andalgebraictechniques. At the heart lies an innovative application of the Baur-Strassen theorem from algebraic complexity theory. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.11913. 
 Full Access 
 Sparse Regular Expression Matching 
 href="/author/Bille%2C+Philip" - Philip Bille | , 
 href="/author/G%C3%B8rtz%2C+Inge+Li" - Inge Li Gørtz 
 pp.3354–3375 
 Abstract 
 PDF 
 AbstractA regular expression specifies a set of strings formed by single characters combined with concatenation, union, and Kleene star operators. Given a regular expressionRand a stringQ, the regular expression matching problem is to decide ifQmatches any of the strings specified byR. Regular expressions are a fundamental concept in formal languages and regular expression matching is a basic primitive for searching and processing data. A standard textbook solution [Thompson, CACM 1968] constructs and simulates a nondeterministic finite automaton, leading to anO(nm)time algorithm, wherenis the length ofQandmis the length ofR. Despite considerable research efforts only polylogarithmic improvements of this bound are known. Recently, conditional lower bounds provided evidence for this lack of progress when Backurs and Indyk [FOCS 2016] proved that, assuming the strong exponential time hypothesis (SETH), regular expression matching cannot be solved inO((nm)1-ɛ), for any constant ɛ > 0. Hence, the complexity of regular expression matching is essentially settled in terms ofnandm. 
 In this paper, we take a new approach and introduce adensityparameter, Δ, that captures the amount of nondeterminism in the NFA simulation onQ. The density is at mostnm+ 1 but can be significantly smaller. Our main result is a new algorithm that solves regular expression matching in time. 
 This essentially replacesnmwith Δ in the complexity of regular expression matching. We complement our upper bound by a matching conditional lower bound that proves that we cannot solve regular expression matching in timeO(Δ1-ɛ) for any constant ɛ > 0 assuming SETH. 
 The key technical contribution in the result is a new linear space representation of the classic position automaton that supports fast state-set transition computation in near-linear time in the size of the input and output state sets. To achieve this we develop several new insights and techniques of independent interest, including new structural properties of the parse trees of regular expression, a decomposition of state-set transitions based on parse trees, and a fast batched predecessor data structure. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/1907.04752 
 Full Access 
 Grammar Boosting: A New Technique for Proving Lower Bounds for Computation over Compressed Data 
 href="/author/de%2C+Rajat" - Rajat De | , 
 href="/author/Kempa%2C+Dominik" - Dominik Kempa 
 pp.3376–3392 
 Abstract 
 PDF 
 AbstractComputation over compressed data is a new paradigm in the design of algorithms and data structures that can reduce space usage and speed up computation by orders of magnitude. One of the most frequently employed compression frameworks, capturing many practical compression methods (such as the Lempel-Ziv family, dictionary methods, and others), is grammar compression. In this framework, a stringTof lengthNis represented as a context-free grammar of sizenwhose language contains only the stringT. In this paper, we focus on studying the limitations of these techniques. Previous work focused on proving lower bounds for algorithms and data structures operating over grammars constructed using algorithms that achieve the approximation ratio ρ =O(polylogN) (since finding the smallest grammar representation is NP-hard, every polynomial-time grammar compressor can be viewed as an approximation algorithm). Unfortunately, for many grammar compressors we either haveρ = ω(polylogN) or it is not known whether ρ =O(polylogN) holds. In their seminal paper, Charikar, Lehman, Liu, Panigrahy, Prabhakaran, Sahai, and Shelat [IEEE Trans. Inf. Theory 2005] studied seven popular grammar compression algorithms: RePair, Greedy, LongestMatch, Sequential, Bisection, LZ78, and α-Balanced. Only one of them (α-Balanced) is known to achieve ρ =O(polylogN). 
 In this paper, we develop the first technique for proving lower bounds for data structures and algorithms on grammars that is fully general and does not depend on the approximation ratio ρ of the used grammar compressor. Our first set of results concernscompressed data structures.In 2013, Verbin and Yu proved that implementing random access toTusing a grammar constructed by an algorithm with ρ =O(polylogN) requires Ω(logN/ log logN) time in the worst case. This lower bound applies to any structure usingO(npolylogN) space and matches the existing upper bounds. We prove that this lower bound holds also for RePair, Greedy, LongestMatch, Sequential, and Bisection, while Ω(log logN) time is required for random access to LZ78. Our lower bounds apply to any structure usingO(npolylogN) space and match the existing upper bounds. Moreover, we show that our technique generalizes to the class ofglobalalgorithms (that includes, e.g., the RePair algorithm), i.e., the lower bound Ω(logN/ log logN) applies to the whole class. This makes a significant step forward in a long-standing open problem of analyzing global algorithms. 
 Our second set of results concernscompressed computation,i.e., computation that runs in time that depends on the size of the input in compressed form. Recently, Abboud, Backurs, Bringmann, and Künnemann [FOCS 2017 and NeurIPS 2020] proved numerous limitations of compressed computation under popular conjectures (such as SETH,k-Clique,k-OV, andk-SUM). Similarly as above, however, their framework also displays a dependence on ρ. For example, their results imply that, assuming thek-Clique Conjecture, there is no algorithm to solve CFG Parsing (for which the best algorithm has a time complexity ofO(Nω), where ω is the exponent of matrix multiplication) on grammars constructed using Bisection (which satisfies 
 that runs inO(nc·Nω-ɛ) time for constants ɛ > 0 andc< 2ɛ. Using our new techniques, we improve these and other conditional lower bounds. For example, for CFG parsing on Bisection, we rule out algorithms with runtimeO(nc·Nω-ɛ) forallconstants ɛ > 0 andc> 0.*The full version of the paper can be accessed at https://arxiv.org/abs/2307.08833. 
 Full Access 
 Nibbling at Long Cycles: Dynamic (and Static) Edge Coloring in Optimal Time 
 href="/author/Bhattacharya%2C+Sayan" - Sayan Bhattacharya | , 
 href="/author/Costa%2C+Mart%C3%ADn" - Martín Costa | , 
 href="/author/Panski%2C+Nadav" - Nadav Panski | , 
 href="/author/Solomon%2C+Shay" - Shay Solomon 
 pp.3393–3440 
 Abstract 
 PDF 
 AbstractWe consider the problem of maintaining a (1 +ɛ)∆-edge coloring in a dynamic graphGwithnnodes and maximum degree at most Δ. The state-of-the-art update time isOɛ(polylog(n)), by Duan, He and Zhang [SODA’19] and by Christiansen [STOC’23], and more preciselyO(log7n/ɛ2), where Δ = Ω(log2n/ɛ2). 
 The following natural question arises: What is the best possible update time of an algorithm for this task? More specifically, can we bring it all the way down to some constant (for constantɛ)? This question coincides with thestatictime barrier for the problem: Even for (2Δ — 1)-coloring, there is only a naiveO(mlog Δ)-time algorithm. 
 We answer this fundamental question in the affirmative, by presenting a dynamic (1 +ɛ)Δ-edge coloring algorithm withO(log4(1/ɛ)/ɛ9) update time, provided Δ = Ωɛ(polylog(n)). As a corollary, we also get the first linear time (for constantɛ)staticalgorithm for (1 +ɛ)Δ-edge coloring; in particular, we achieve a running time ofO(mlog(1/ɛ)/ɛ2). 
 We obtain our results by carefully combining a variant of the Nibble algorithm from Bhattacharya, Grandoni and Wajc [SODA’21] with the subsampling technique of Kulkarni, Liu, Sah, Sawhney and Tarnawski [STOC’22]. 
 Full Access 
 Dynamic algorithms fork-center on graphs 
 href="/author/Cruciani%2C+Emilio" - Emilio Cruciani | , 
 href="/author/Forster%2C+Sebastian" - Sebastian Forster | , 
 href="/author/Goranci%2C+Gramoz" - Gramoz Goranci | , 
 href="/author/Nazari%2C+Yasamin" - Yasamin Nazari | , 
 href="/author/Skarlatos%2C+Antonis" - Antonis Skarlatos 
 pp.3441–3462 
 Abstract 
 PDF 
 AbstractIn this paper we give the first efficient algorithms for thek-center problem on dynamic graphs undergoing edge updates. In this problem, the goal is to partition the input intoksets by choosingkcenters such that the maximum distance from any data point to its closest center is minimized. It is known that it is NP-hard to get a better than 2 approximation for this problem. 
 While in many applications the input may naturally be modeled as a graph, all prior works onk-center problem in dynamic settings are on point sets in arbitrary metric spaces. In this paper, we give a deterministic decremental (2 +ɛ)-approximation algorithm and a randomized incremental (4 +ɛ)-approximation algorithm, both with amortized update timekno(1)for weighted graphs. Moreover, we show a reduction that leads to a fully dynamic (2 +ɛ)-approximation algorithm for thek-center problem, with worst-case update time that is within a factorkof the state-of-the-art upper bound for maintaining (1+ɛ)-approximate single-source distances in graphs. Matching this bound is a natural goalpost because the approximate distances of each vertex to its center can be used to maintain a (2 +ɛ)-approximation of the graph diameter and the fastest known algorithms for such a diameter approximation also rely on maintaining approximate single-source distances. 
 *Supported by the Austrian Science Fund (FWF): P 32863-N. This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No 947702). 
 Full Access 
 Fully Dynamic Consistentk-Center Clustering 
 href="/author/%C5%81%C4%85cki%2C+Jakub" - Jakub Łącki | , 
 href="/author/Haeupler%2C+Bernhard" - Bernhard Haeupler | , 
 href="/author/Grunau%2C+Christoph" - Christoph Grunau | , 
 href="/author/Jayaram%2C+Rajesh" - Rajesh Jayaram | , 
 href="/author/Rozho%C5%88%2C+V%C3%A1clav" - Václav Rozhoň 
 pp.3463–3484 
 Abstract 
 PDF 
 AbstractWe study theconsistent k-center clusteringproblem. In this problem, the goal is to maintain a constant factor approximatek-center solution during a sequence ofnpoint insertions and deletions while minimizing therecourse,i.e., the number of changes made to the set of centers after each point insertion or deletion. Previous works by Lattanzi and Vassilvitskii [ICML ‘12] and Fichtenberger, Lattanzi, Norouzi-Fard, and Svensson [SODA ‘21] showed that in the incremental setting, where deletions are not allowed, one can obtaink· polylog(n)/namortized recourse for bothk-center andk-median, and demonstrated a matching lower bound. However, no algorithm for the fully dynamic setting achieves less than the trivialO(k)changes per update, which can be obtained by simply reclustering the full dataset after every update. 
 In this work, we give the first algorithm for consistentk-center clustering for the fully dynamic setting, i.e., when both point insertions and deletions are allowed, and improves upon a trivialO(k) recourse bound. Specifically, our algorithm maintains a constant factor approximate solution while ensuring worst-caseconstantrecourse per update, which is optimal in the fully dynamic setting. Moreover, our algorithm is deterministic and is therefore correct even if an adaptive adversary chooses the insertions and deletions. 
 Full Access 
 Dynamic Algorithms for Matroid Submodular Maximization 
 href="/author/Banihashem%2C+Kiarash" - Kiarash Banihashem | , 
 href="/author/Biabani%2C+Leyla" - Leyla Biabani | , 
 href="/author/Goudarzi%2C+Samira" - Samira Goudarzi | , 
 href="/author/Hajiaghayi%2C+MohammadTaghi" - MohammadTaghi Hajiaghayi | , 
 href="/author/Jabbarzade%2C+Peyman" - Peyman Jabbarzade | , 
 href="/author/Monemizadeh%2C+Morteza" - Morteza Monemizadeh 
 pp.3485–3533 
 Abstract 
 PDF 
 AbstractSubmodular maximization under matroid and cardinality constraints are classical problems with a wide range of applications in machine learning, auction theory, and combinatorial optimization. In this paper, we consider these problems in the dynamic setting where (1) we have oracle access to a monotone submodular functionf: 2V→ ℝ+and (2) we are given a sequenceSof insertions and deletions of elements of an underlying ground setV. 
 We develop the first fully dynamic algorithm for the submodular maximization problem under the matroid constraint that maintains a (4 +ɛ)-approximation solution (0 <ɛ≤ 1) using an expected query complexity ofO(klog(k) log3(k/ɛ)), which is indeed parameterized by the rankkof the matroidM(V, I)as well. 
 Chen and Peng [52] at STOC’22 studied the complexity of this problem in the insertion-only dynamic model (a restricted version of the fully dynamic model where deletion is not allowed), and they raised the following important open question:“for fully dynamic streams [sequences of insertions and deletions of elements], there is no known constant-factor approximation algorithm with poly(k) amortized queries for matroid constraints.”Our dynamic algorithm answers this question as well as an open problem of Lattanzi et al. [109] (NeurIPS’20) affirmatively. 
 As a byproduct, for the submodular maximization under the cardinality constraintk,we propose a parameterized (by the cardinality constraintk)dynamic algorithm that maintains a (2 +ɛ)-approximate solution of the sequenceSat any timetusing an expected query complexity ofO(kɛ-1log2(k)), which is an improvement upon the dynamic algorithm that Monemizadeh [125] (NeurIPS’20) developed for this problem using an expected query complexityO(k2ɛ-3log5(n)). In particular, this dynamic algorithm is the first one for this problem whose query complexity is independent of the size of ground setV(i.e.,n =|V|). 
 We develop our dynamic algorithm for the submodular maximization problem under the matroid or cardinality constraint by designing a randomized leveled data structure that supports insertion and deletion operations, maintaining an approximate solution for the given problem. In addition, we develop a fast construction algorithm for our data structure that uses a one-pass over a random permutation of the elements and utilizes monotonicity property of our problems which has a subtle proof in the matroid case. We believe these techniques could also be useful for other optimization problems in the area of dynamic algorithms. 
 Full Access 
 On Dynamic Graph Algorithms with Predictions 
 href="/author/Brand%2C+Jan+van+den" - Jan van den Brand | , 
 href="/author/Forster%2C+Sebastian" - Sebastian Forster | , 
 href="/author/Nazari%2C+Yasamin" - Yasamin Nazari | , 
 href="/author/Polak%2C+Adam" - Adam Polak 
 pp.3534–3557 
 Abstract 
 PDF 
 AbstractDynamic algorithms operate on inputs undergoing updates, e.g., insertions or deletions of edges or vertices. After processing each update, the algorithm has to answer queries regarding the current state of the input data. We study dynamic algorithms in the model of algorithms with predictions (also known as learning-augmented algorithms). We assume the algorithm is given imperfect predictions regarding future updates, and we ask how such predictions can be used to improve the running time. In other words, we study the complexity of dynamic problems parameterized by the prediction accuracy. This can be seen as a model interpolating between classic online dynamic algorithms - which know nothing about future updates - and offline dynamic algorithms with the whole update sequence known upfront, which is similar to having perfect predictions. Our results give smooth tradeoffs between these two extreme settings. 
 Our first group of results is about partially dynamic problems with edge updates. We give algorithms for incremental and decremental transitive closure and approximate APSP that take as an additional input a predicted sequence of updates (edge insertions, or edge deletions, respectively). They preprocess it inÕ(n(3+ω)/2)time, and then handle updates in Õ(1) worst-case time and queries inÕ(n2)worst-case time. Herenis an error measure that can be bounded by the maximum difference between the predicted and actual insertion (deletion) time of an edge, i.e., by theℓ∞-error of the predictions. 
 The second group of results concerns fully dynamic problems with vertex updates, where the algorithm has access to a predicted sequence of the nextnupdates. We show how to solve fully dynamic triangle detection, maximum matching, single-source reachability, and more, inO(nω-1+nηi) worst-case update time. Hereηidenotes how much earlier thei-th update occurs than predicted. 
 Our last result is a reduction that transforms a worst-case incremental algorithm without predictions into a fully dynamic algorithm which is given a predicted deletion time for each element at the time of its insertion. As a consequence we can, e.g., maintain fully dynamic exact APSP with such predictions inÕ(n2)worst-case vertex insertion time andÕ(n2(1 +ηi)) worst-case vertex deletion time (for the prediction errorηidefined as above). 
 Our algorithms from the first two groups, given sufficiently accurate predictions, achieve running times that go below known lower bounds for classic (without predictions) dynamic algorithms under the OMv Hypothesis. Moreover, our dependence on the prediction errors (so-called smoothness) is conditionally optimal, under plausible fine-grained complexity assumptions, at least in certain parameter regimes. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2307.09961. This work is supported by the Austrian Science Fund (FWF): P 32863-N. This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No 947702). Part of this work was done when Yasamin Nazari was affiliated with University of Salzburg. Part of this work was done when Adam Polak was affiliated with Max-Planck Institute of Informatics. This work was initiated at the AlgPiE 2022 workshop, organized by IGAFIT. The authors would like to thank Nicole Megow and Danupon Nanongkai for inspiring discussions on algorithms with predictions. 
 Full Access 
 Fast Algorithms for Separable Linear Programs 
 href="/author/Dong%2C+Sally" - Sally Dong | , 
 href="/author/Goranci%2C+Gramoz" - Gramoz Goranci | , 
 href="/author/Li%2C+Lawrence" - Lawrence Li | , 
 href="/author/Sachdeva%2C+Sushant" - Sushant Sachdeva | , 
 href="/author/Ye%2C+Guanghao" - Guanghao Ye 
 pp.3558–3604 
 Abstract 
 PDF 
 AbstractIn numerical linear algebra, considerable effort has been devoted to obtaining faster algorithms for linear systems whose underlying matrices exhibit structural properties. A prominent success story is the method of generalized nested dissection [Lipton-Rose-Tarjan’79] for separable matrices. On the other hand, the majority of recent developments in the design of efficient linear program (LP) solvers have not leveraged the ideas underlying these faster linear system solvers nor exploited the separable structure of the constraint matrix. 
 In this work, we consider LPs of the form minAx=b,l≤x≤uCTx, where the graphical support of the constraint matrix A ∈ ℝn×misnα-separable. We present anÕ((m+m1/2+2α) log(1/ɛ))-time algorithm for solving these LPs to e relative accuracy. 
 Our new solver has two important implications: for thek-multicommodity flow problem on planar graphs, we obtain anÕ(k5/2m3/2log(1/ɛ))-time algorithm; and when the support of A isnα-separable with α ≤ 1/4, our runtime ofÕ(mlog(1/ɛ)) is nearly optimal. The latter significantly improves upon the natural approach of combining interior point methods and nested dissection, whose time complexity is lower bounded by 
 where ω ≈ 2.373 is the matrix multiplication exponent. Lastly, our solver can be applied to low-treewidth LPs to recover the results of [DLY21,GS22] while using significantly simpler data structure machinery. 
 Full Access 
 Integer Programming with GCD Constraints 
 href="/author/D%C3%A9fossez%2C+R%C3%A9my" - Rémy Défossez | , 
 href="/author/Haase%2C+Christoph" - Christoph Haase | , 
 href="/author/Mansutti%2C+Alessio" - Alessio Mansutti | , 
 href="/author/P%C3%A9rez%2C+Guillermo+A" - Guillermo A. Pérez 
 pp.3605–3658 
 Abstract 
 PDF 
 AbstractWe study the non-linear extension of integer programming with greatest common divisor constraints of the form gcd(f,g)~d,wherefandgare linear polynomials,dis a positive integer, and ~ is a relation among ≤, = ≠, = and ≥. We show that the feasibility problem for these systems is in NP, and that an optimal solution minimizing a linear objective function, if it exists, has polynomial bit length. To show these results, we identify an expressive fragment of the existential theory of the integers with addition and divisibility that admits solutions of polynomial bit length. It was shown by Lipshitz[Trans. Am. Math. Soc.,235, pp. 271-283, 1978] that this theory adheres to a local-to-global principle in the following sense: a formula Φ is equi-satisfiable with a formula Ψ in this theory such that Ψ has a solution if and only if Ψ has a solution modulo every primep.We show that in our fragment, only a polynomial number of primes of polynomial bit length need to be considered, and that the solutions modulo prime numbers can be combined to yield a solution to Φ of polynomial bit length. As a technical by-product, we establish a Chinese-remainder-type theorem for systems of congruences and non-congruences showing that solution sizes do not depend on the magnitude of the moduli of non-congruences. 
 Full Access 
 Convex Minimization with Integer Minima inÕ(n4) Time 
 href="/author/Jiang%2C+Haotian" - Haotian Jiang | , 
 href="/author/Lee%2C+Yin+Tat" - Yin Tat Lee | , 
 href="/author/Song%2C+Zhao" - Zhao Song | , 
 href="/author/Zhang%2C+Lichen" - Lichen Zhang 
 pp.3659–3684 
 Abstract 
 PDF 
 AbstractGiven a convex functionfon ℝnwith an integer minimizer, we show how to find an exact minimizer offusingO(n2logn) calls to a separation oracle andO(n4logn) time. The previous best polynomial time algorithm for this problem given in [Jiang, SODA 2021, JACM 2022] achievesO(n2log logn/ logn) oracle complexity. However, the overall runtime of Jiang's algorithm is at least 
 , due to expensive sub-routines such as the Lenstra-Lenstra-Lovász (LLL) algorithm [Lenstra, Lenstra, Lovász, Math. Ann. 1982] and random walk based cutting plane method [Bertsimas, Vempala, JACM 2004]. Our significant speedup is obtained by a nontrivial combination of a faster version of the LLL algorithm due to [Neumaier, Stehle, ISSAC 2016] that gives similar guarantees, the volumetric center cutting plane method (CPM) by [Vaidya, FOCS 1989] and its fast implementation given in [Jiang, Lee, Song, Wong, STOC 2020].For the special case of submodular function minimization (SFM), our result implies a strongly polynomial time algorithm for this problem usingO(n3logn) calls to an evaluation oracle andO(n4logn) additional arithmetic operations. Both the oracle complexity and the number of arithmetic operations of our more general algorithm are better than the previous best-known runtime algorithms for this specific problem given in [Lee, Sidford, Wong, FOCS 2015] and [Dadush, Végh, Zambelli, SODA 2018, MOR 2021]. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2304.03426 
 Full Access 
 A Whole New Ball Game: A Primal Accelerated Method for Matrix Games and Minimizing the Maximum of Smooth Functions 
 href="/author/Carmon%2C+Yair" - Yair Carmon | , 
 href="/author/Jambulapati%2C+Arun" - Arun Jambulapati | , 
 href="/author/Jin%2C+Yujia" - Yujia Jin | , 
 href="/author/Sidford%2C+Aaron" - Aaron Sidford 
 pp.3685–3723 
 Abstract 
 PDF 
 AbstractWe design algorithms for minimizing maxi∈[n]fi(x) over ad-dimensional Euclidean or simplex domain. When eachfiis 1-Lipschitz and 1-smooth, our method computes anɛ-approximate solution usingÕ(nɛ-1/3+ɛ-2) gradient and function evaluations, andÕ(nɛ-4/3) additional runtime. For large n, our evaluation complexity is optimal up to polylogarithmic factors. In the special case where eachfiis linear—which corresponds to finding a near-optimal primal strategy in a matrix game—our method finds anɛ-approximate solution in runtimeÕ(n(d/ɛ)2/3+nd+dɛ-2). Forn>dand 
 this improves over all existing first-order methods. When additionallyd=ω(n8/11) our runtime also improves over all known interior point methods.Our algorithm combines three novel primitives: (1) A dynamic data structure which enables efficient stochastic gradient estimation in smallℓ2orℓ1balls. (2) A mirror descent algorithm tailored to our data structure implementing an oracle which minimizes the objective over these balls. (3) A simple ball oracle acceleration framework suitable for non-Euclidean geometry. 
 Full Access 
 Arborescences, Colorful Forests, and Popularity 
 href="/author/Kavitha%2C+Telikepalli" - Telikepalli Kavitha | , 
 href="/author/Makino%2C+Kazuhisa" - Kazuhisa Makino | , 
 href="/author/Schlotter%2C+Ildik%C3%B3" - Ildikó Schlotter | , 
 href="/author/Yokoi%2C+Yu" - Yu Yokoi 
 pp.3724–3746 
 Abstract 
 PDF 
 AbstractOur input is a directed, rooted graphG =(V∪ {r},E)where each vertex inVhas a partial order preference over its incoming edges. The preferences of a vertex extend naturally to preferences over arborescences rooted atr. We seek apopulararborescence inG, i.e., one for which there is no “more popular” arborescence. Popular arborescences have applications in liquid democracy or collective decision making; however, they need not exist in every input instance. The popular arborescence problem is to decide if a given input instance admits a popular arborescence or not. We show a polynomial-time algorithm for this problem, whose computational complexity was not known previously. 
 Our algorithm is combinatorial, and can be regarded as a primal-dual algorithm. It searches for an arborescence along with its dual certificate, a chain of subsets ofE, witnessing its popularity. In fact, our algorithm solves the more general popular common base problem in the intersection of two matroids, where one matroid is the partition matroid defined by any partition 
 and the other is an arbitrary matroidM= (E, I) of rank |V|, with eachv ∈ Vhaving a partial order over elements in δ(ν). We extend our algorithm to the case with forced or forbidden edges.We also study the related popular colorful forest (or more generally, the popular common independent set) problem where edges are partitioned into color classes, and the task is to find a colorful forest that is popular within the set of all colorful forests. For the case with weak rankings, we formulate the popular colorful forest polytope, and thus show that a minimum-cost popular colorful forest can be computed efficiently. By contrast, we prove that it is NP-hard to compute a minimum-cost popular arborescence, even when rankings are strict. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.19455 
 Full Access 
 Sub-Exponential Lower Bounds for Branch-and-Bound with General Disjunctions via Interpolation 
 href="/author/Gl%C3%A4ser%2C+Max" - Max Gläser | , 
 href="/author/Pfetsch%2C+Marc+E" - Marc E. Pfetsch 
 pp.3747–3764 
 Abstract 
 PDF 
 AbstractThis paper investigates linear programming based branch-and-bound using general disjunctions, also known as stabbing planes, for solving integer programs. We derive the first sub-exponential lower bound (in the encoding lengthLof the integer program) for the size of a general branch-and-bound tree for a particular class of (compact) integer programs, namely 2Ω(L1/12-ɛ)for every ɛ > 0. This is achieved by showing that general branch-and-bound admits quasi-feasible monotone real interpolation, which allows us to utilize sub-exponential lower-bounds for monotone real circuits separating the so-called clique-coloring pair. The same ideas also prove that refuting Θ(log(n))-CNFs requires size 2nΩ(1)branch-and-bound trees with high probability by considering the closely related notion of infeasibility certificates introduced by Hrubeš and Pudlák [18]. One important ingredient of the proof of our interpolation result is that for every general branch-and-bound tree proving integer-freeness of a productP × Qof two polytopesPandQ, there exists a closely related branch-and-bound tree for showing integer-freeness ofPor one showing integer-freeness ofQ. Moreover, we prove that monotone real circuits can perform binary search efficiently. 
 Full Access 
 Faster Rectangular Matrix Multiplication by Combination Loss Analysis 
 href="/author/Gall%2C+Fran%C3%A7ois+le" - François Le Gall 
 pp.3765–3791 
 Abstract 
 PDF 
 AbstractDuan, Wu and Zhou (FOCS 2023) recently obtained the improved upper bound on the exponent of square matrix multiplication ω < 2.3719 by introducing a new approach to quantify and compensate the “combination loss” in prior analyses of powers of the Coppersmith-Winograd tensor. In this paper we show how to use this new approach to improve the exponent of rectangular matrix multiplication as well. Our main technical contribution is showing how to combine this analysis of the combination loss and the analysis of the fourth power of the Coppersmith-Winograd tensor in the context of rectangular matrix multiplication developed by Le Gall and Urrutia (SODA 2018). 
 Full Access 
 New Bounds for Matrix Multiplication: from Alpha to Omega 
 href="/author/Williams%2C+Virginia+Vassilevska" - Virginia Vassilevska Williams | , 
 href="/author/Xu%2C+Yinzhan" - Yinzhan Xu | , 
 href="/author/Xu%2C+Zixuan" - Zixuan Xu | , 
 href="/author/Zhou%2C+Renfei" - Renfei Zhou 
 pp.3792–3835 
 Abstract 
 PDF 
 AbstractThe main contribution of this paper is a new improved variant of the laser method for designing matrix multiplication algorithms. Building upon the recent techniques of [Duan, Wu, Zhou, FOCS 2023], the new method introduces several new ingredients that not only yield an improved bound on the matrix multiplication exponent ω, but also improve the known bounds on rectangular matrix multiplication by [Le Gall and Urrutia, SODA 2018]. 
 In particular, the new bound on ω is 
 ω ≤ 2.371552 (improved from ω ≤ 2.371866). 
 For the dual matrix multiplication exponent α defined as the largest α for which ω(1, α, 1) = 2, we obtain the improvement 
 α ≥ 0.321334 (improved from α ≥ 0.31389). 
 Similar improvements are obtained for various other exponents for multiplying rectangular matrices. 
 Full Access 
 Fast Fourier transform via automorphism groups of rational function fields 
 href="/author/Li%2C+Songsong" - Songsong Li | , 
 href="/author/Xing%2C+Chaoping" - Chaoping Xing 
 pp.3836–3859 
 Abstract 
 PDF 
 AbstractThe Fast Fourier Transform (FFT) over a finite field 𝔽qcomputes evaluations of a given polynomial of degree less thannat a specifically chosen set ofndistinct evaluation points in 𝔽q. Ifqorq —1 is a smooth number, then the divide-and-conquer approach leads to the fastest known FFT algorithms. Depending on the type of group that the set of evaluation points forms, these algorithms are classified as multiplicative (Math of Comp. 1965) and additive (FOCS 2014) FFT algorithms. In this work, we provide a unified framework for FFT algorithms that include both multiplicative and additive FFT algorithms as special cases, and beyond: our framework also works whenq+ 1 is smooth, while all known results requireqorq— 1 to be smooth. For the new case whereq+ 1 is smooth (this new case was not considered before in literature as far as we know), we show that ifnis a divisor ofq+ 1 that isB-smooth for a realB> 0, then our FFT needsO(Bnlogn) arithmetic operations in 𝔽q. Our unified framework is a natural consequence of introducing the algebraic function fields into the study of FFT. 
 Full Access 
 Nearly Optimal Black Box Polynomial Root-finders 
 href="/author/Pan%2C+Victor+Y" - Victor Y. Pan 
 pp.3860–3900 
 Abstract 
 PDF 
 AbstractUnivariate polynomial root-finding has been studied for four millennia and very intensively in the last decades. Our novelnearly optimalLas Vegas randomized root-finders approximate all zeros of a polynomial almost as fast as one accesses its coefficients with the precision required for the solution within a prescribed error bound.1Moreover, our root-finders can be applied to ablack box polynomial,defined by an oracle (that is, black box subroutine) for its evaluation rather than by its coefficients. Such root-finders are particularly fast for polynomials that can be evaluated fast, e.g., the sum of a few shifted monomials, but the only other known black box root-finder is the pioneering one by Louis and Vempala at FOCS 2016, and it only approximates the absolutely largest root of a real-rooted polynomial. Our deterministic divide and conquer algorithm of ACM STOC 1995 is the only other known nearly optimal polynomial root-finder, and it extensively uses the coefficients, is quite involved, and has never been implemented, while according to extensive numerical experiments with standard test polynomials, already initial implementations of our new root-finders compete with user's choice package of root-finding subroutine MPSolve and supersede it more and more significantly where the degree of a polynomial grows large. Our root-finders are readily extended to support approximation of the eigenvalues of a matrix within a record Las Vegas expected bit operation time bound. Our auxiliary algorithms and techniques for computations with black box polynomials can be of independent interest. 
 Keywords: polynomial computations, matrix eigenvalues, complexity, polynomial zeros, black box polynomials, root-squaring, symbolic-numeric computing. 
 Full Access 
 Deterministic Algorithms for Low Degree Factors of Constant Depth Circuits 
 href="/author/Kumar%2C+Mrinal" - Mrinal Kumar | , 
 href="/author/Ramanathan%2C+Varun" - Varun Ramanathan | , 
 href="/author/Saptharishi%2C+Ramprasad" - Ramprasad Saptharishi 
 pp.3901–3918 
 Abstract 
 PDF 
 AbstractFor every constantd,we design a subexponential time deterministic algorithm that takes as input a multivariate polynomialfgiven as a constant depth algebraic circuit over the field of rational numbers, and outputsallirreducible factors offof degree at mostdtogether with their respective multiplicities. Moreover, iffis a sparse polynomial, then the algorithm runs in quasipolynomial time. 
 Our results are based on a more fine-grained connection between polynomial identity testing (PIT) and polynomial factorization in the context of constant degree factors and rely on a clean connection between divisibility testing of polynomials and PIT due to Forbes [For15] and on subexponential time deterministic PIT algorithms for constant depth algebraic circuits from the recent work of Limaye, Srinivasan and Tavenas [LST21]. 
 Full Access 
 The Identity Problem in nilpotent groups of bounded class 
 href="/author/Dong%2C+Ruiwen" - Ruiwen Dong 
 pp.3919–3959 
 Abstract 
 PDF 
 AbstractLetGbe a unitriangular matrix group of nilpotency class at most ten. We show that the Identity Problem (does a semigroup contain the identity matrix?) and the Group Problem (is a semigroup a group?) are decidable in polynomial time for finitely generated subsemigroups ofG. Our decidability results also hold whenGis an arbitrary finitely generated nilpotent group of class at most ten. This extends earlier work of Babai et al. on commutative matrix groups (SODA’96) and work of Bell et al. on SL(2, ℤ) (SODA’17). Furthermore, we formulate a sufficient condition for the generalization of our results to nilpotent groups of classd> 10. For every suchd,we exhibit an effective procedure that verifies this condition in case it is true. 
 Full Access 
 Massively Parallel Algorithms for High-Dimensional Euclidean Minimum Spanning Tree 
 href="/author/Jayaram%2C+Rajesh" - Rajesh Jayaram | , 
 href="/author/Mirrokni%2C+Vahab" - Vahab Mirrokni | , 
 href="/author/Narayanan%2C+Shyam" - Shyam Narayanan | , 
 href="/author/Zhong%2C+Peilin" - Peilin Zhong 
 pp.3960–3996 
 Abstract 
 PDF 
 AbstractWe study the classic Euclidean Minimum Spanning Tree (MST) problem in the Massively Parallel Computation (MPC) model. Given a setX⊂ ℝdofnpoints, the goal is to produce a spanning tree forXwith weight within a small factor of optimal. Euclidean MST is one of the most fundamental hierarchical geometric clustering algorithms, and with the proliferation of enormous high-dimensional data sets, such as massive transformer-based embeddings, there is now a critical demand for efficient distributed algorithms to cluster such data sets. 
 In low-dimensional space, whered=O(1), Andoni, Nikolov, Onak, and Yaroslavtsev [STOC ‘14] gave a constant round MPC algorithm that obtains a high accuracy (1 + ɛ)-approximate solution. However, the situation is much more challenging for high-dimensional spaces: the best-known algorithm to obtain a constant approximation requiresO(logn) rounds. Recently Chen, Jayaram, Levi, and Waingarten [STOC ‘22] gave aO(logn) approximation algorithm in a constant number of rounds based on embeddings into tree metrics. However, to date, no known algorithm achieves both a constant number of rounds and approximation. 
 In this paper, we make strong progress on this front by giving a constant factor approximation inÕ(log logn) rounds of the MPC model. In contrast to tree-embedding-based approaches, which necessarily must pay Ω(logn)-distortion, our algorithm is based on a new combination of graph-based distributed MST algorithms and geometric space partitions. Additionally, although the approximate MST we return can have a large depth, we show that it can be modified to obtain aO(log logn)-round constant factor approximation to the Euclidean Traveling Salesman Problem (TSP) in the MPC model. Previously, only aO(logn) round was known for the problem. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2308.00503. 
 Full Access 
 Parallel Approximate Maximum Flows in Near-Linear Work and Polylogarithmic Depth 
 href="/author/Agarwal%2C+Arpit" - Arpit Agarwal | , 
 href="/author/Khanna%2C+Sanjeev" - Sanjeev Khanna | , 
 href="/author/Li%2C+Huan" - Huan Li | , 
 href="/author/Patil%2C+Prathamesh" - Prathamesh Patil | , 
 href="/author/Wang%2C+Chen" - Chen Wang | , 
 href="/author/White%2C+Nathan" - Nathan White | , 
 href="/author/Zhong%2C+Peilin" - Peilin Zhong 
 pp.3997–4061 
 Abstract 
 PDF 
 AbstractWe present a parallel algorithm for the (1 — ɛ) -approximate maximum flow problem in capacitated, undirected graphs withnvertices andmedges, achievingO(ɛ-3polylogn) depth andO(mɛ-3polylogn) work in the PRAM model. Although near-linear time sequential algorithms for this problem have been known for almost a decade, no parallel algorithms that simultaneously achieved polylogarithmic depth and near-linear work were known. 
 At the heart of our result is a polylogarithmic depth, near-linear work recursive algorithm for computing congestion approximators. Our algorithm involves a recursive step to obtain a low-quality congestion approximator followed by a “boosting” step to improve its quality which prevents a multiplicative blow-up in error. Similar to Peng [SODA’16], our boosting step builds upon the hierarchical decomposition scheme of Räcke, Shah, and Taubig [SODA’14]. A direct implementation of this approach, however, leads only to an algorithm withno(1)depth andm1+o(1)work. To get around this, we introduce a new hierarchical decomposition scheme, in which we only need to solve maximum flows on subgraphs obtained bycontractingvertices, as opposed to vertex-induced subgraphs used in Räcke, Shah, and Taubig [SODA’14]. This in particular enables us to directly extract congestion approximators for the subgraphs from a congestion approximator for the entire graph, thereby avoiding additional recursion on those subgraphs. Along the way, we also develop a parallel flow-decomposition algorithm that is crucial to achieving polylogarithmic depth and may be of independent interest. 
 We extend our results to related graph problems such as sparsest and balanced sparsest cuts, fair and isolating cuts, approximate Gomory-Hu trees, and hierarchical clustering. All algorithms achieve polylogarithmic depth and near-linear work. 
 Finally, our PRAM results also imply the first polylogarithmic round, near-linear total space MPC algorithms for approximate undirected maximum flows, as well as all its aforementioned applications in the fully scalable regime where the local machine memory isO(nδ) for any constant δ > 0. 
 Full Access 
 A Nearly Linear-Time Distributed Algorithm for Exact Maximum Matching 
 href="/author/Izumi%2C+Taisuke" - Taisuke Izumi | , 
 href="/author/Kitamura%2C+Naoki" - Naoki Kitamura | , 
 href="/author/Yamaguchi%2C+Yutaro" - Yutaro Yamaguchi 
 pp.4062–4082 
 Abstract 
 PDF 
 AbstractIn this paper, we propose a randomizedÕ(µ(G))-round algorithm for the maximum cardinality matching problem in the CONGEST model, whereµ(G)means the maximum size of a matching of the input graphG.The proposed algorithm substantially improves the current best worst-case running time. The key technical ingredient is a new randomized algorithm of finding an augmenting path of lengthℓwith high probability withinÕ(ℓ) rounds, which positively settles an open problem left in the prior work by Ahmadi and Kuhn [DISC’20]. 
 The idea of our augmenting path algorithm is based on a recent result by Kitamura and Izumi [IEICE Trans.’22], which efficiently identifies a sparse substructure of the input graph containing an augmenting path, following a new concept calledalternating base trees.Their algorithm, however, resorts to a centralized approach of collecting the entire information of the substructure into a single vertex for constructing an augmenting path. The technical highlight of this paper is to provide a fully-decentralized counterpart of such a centralized method. To develop the algorithm, we prove several new structural properties of alternating base trees, which are of independent interest. 
 Full Access 
 A Distributed Palette Sparsification Theorem 
 href="/author/Flin%2C+Maxime" - Maxime Flin | , 
 href="/author/Ghaffari%2C+Mohsen" - Mohsen Ghaffari | , 
 href="/author/Halld%C3%B3rsson%2C+Magn%C3%BAs+M" - Magnús M. Halldórsson | , 
 href="/author/Kuhn%2C+Fabian" - Fabian Kuhn | , 
 href="/author/Nolin%2C+Alexandre" - Alexandre Nolin 
 pp.4083–4123 
 Abstract 
 PDF 
 AbstractThe celebrated palette sparsification result of [Assadi, Chen, and Khanna SODA’19] shows that to compute a Δ + 1 coloring of the graph, where Δ denotes the maximum degree, it suffices if each node limits its color choice toO(logn) independently sampled colors in {1, 2,…, Δ + 1}. They showed that it is possible to color the resulting sparsified graph—the spanning subgraph with edges between neighbors that sampled a common color, which are onlyÕ(n) edges—and obtain a Δ + 1 coloring for the original graph. However, to compute the actual coloring, that information must be gathered at a single location for centralized processing. We seek instead a local algorithm to compute such a coloring in the sparsified graph. The question is if this can be achieved in poly (logn) distributed rounds with small messages. 
 Our main result is an algorithm that computes a Δ + 1-coloring after palette sparsification withO(log2n) random colors per node and runs inO(log2Δ + log3logn) rounds on the sparsified graph, usingO(logn)-bit messages. We show that this is close to the best possible: any distributed Δ + 1-coloring algorithm that runs in the LOCAL model on the sparsified graph, given by palette sparsification, for any poly (logn) colors per node, requires Ω(log Δ/ log logn) rounds. This distributed palette sparsification result leads to the first poly (logn)- round algorithms for Δ + 1-coloring in two previously studied distributed models: the Node Capacitated Clique, and the cluster graph model. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2301.06457 
 Full Access 
 Breaking 3-Factor Approximation for Correlation Clustering in Polylogarithmic Rounds 
 href="/author/Cao%2C+Nairen" - Nairen Cao | , 
 href="/author/Huang%2C+Shang-En" - Shang-En Huang | , 
 href="/author/SU%2C+Hsin-Hao" - Hsin-Hao SU 
 pp.4124–4154 
 Abstract 
 PDF 
 AbstractIn this paper, we study parallel algorithms for the correlation clustering problem, where every pair of two different entities is labeled with similar or dissimilar. The goal is to partition the entities into clusters to minimize the number of disagreements with the labels. Currently, all efficient parallel algorithms have an approximation ratio of at least 3. In comparison with the 1.994 + ɛ ratio achieved by polynomial-time sequential algorithms [25], a significant gap exists. 
 We propose the first poly-logarithmic round parallel algorithm that achieves a better approximation ratio than 3. Specifically, our algorithm computes a (2.4 + ɛ)-approximate solution and usesÕ(m1.5) work. Additionally, it can be translated into aÕ(m1.5)-time sequential algorithm and a poly-logarithmic rounds sublinear-memory MPC algorithm with Õ(m1.5) total memory. 
 Our approach is inspired by Awerbuch, Khandekar, and Rao's [6] length-constrained multi-commodity flow algorithm, where we develop an efficient parallel algorithm to solve a truncated correlation clustering linear program of Charikar, Guruswami, and Wirth [16]. Then we show the solution of the truncated linear program can be rounded with a factor of at most 2.4 loss by using the framework of [17]. Such a rounding framework can then be implemented using parallel pivot-based approaches (e.g. [10, 29]). 
 *This work is supported by NSF CCF-2008422. 
 Full Access 
 The Minority Dynamics and the Power of Synchronicity 
 href="/author/Becchetti%2C+Luca" - Luca Becchetti | , 
 href="/author/Clementi%2C+Andrea" - Andrea Clementi | , 
 href="/author/Pasquale%2C+Francesco" - Francesco Pasquale | , 
 href="/author/Trevisan%2C+Luca" - Luca Trevisan | , 
 href="/author/Vacus%2C+Robin" - Robin Vacus | , 
 href="/author/Ziccardi%2C+Isabella" - Isabella Ziccardi 
 pp.4155–4176 
 Abstract 
 PDF 
 AbstractWe study the minority-opinion dynamics over a fully-connected network ofnnodes with binary opinions. Upon activation, a node receives a sample of opinions from a limited number of neighbors chosen uniformly at random. Each activated node then adopts the opinion that is least common within the received sample. 
 Unlike all other known consensus dynamics, we prove that this elementary protocol behaves in dramatically different ways, depending on whether activations occur sequentially or in parallel. Specifically, we show that its expected consensus time is exponential innunder asynchronous models, such as asynchronous GOSSIP. On the other hand, despite its chaotic nature, we show that it converges withinO(log2n) rounds with high probability under synchronous models, such as synchronous GOSSIP. 
 Finally, our results shed light on the bit-dissemination problem, that was previously introduced to model the spread of information in biological scenarios. Specifically, our analysis implies that the minority-opinion dynamics is the firststatelesssolution to this problem, in the parallel passive-communication setting, achieving convergence within a polylogarithmic number of rounds. This, together with a known lower bound for sequential stateless dynamics, implies a parallel-vs-sequential gap for this problem that is nearly quadratic in the numbernof nodes. This is in contrast to all known results for problems in this area, which exhibit a linear gap between the parallel and the sequential setting. 
 Full Access 
 Bin Packing under Random-Order: Breaking the Barrier of 3/2 
 href="/author/Hebbar%2C+Anish" - Anish Hebbar | , 
 href="/author/Khan%2C+Arindam" - Arindam Khan | , 
 href="/author/Sreenivas%2C+K+V+N" - K. V. N. Sreenivas 
 pp.4177–4219 
 Abstract 
 PDF 
 AbstractBest-Fit is one of the most prominent and practically used algorithms for the bin packing problem, where a set of items with associated sizes needs to be packed in the minimum number of unit-capacity bins. Kenyon [SODA ‘96] studied online bin packing under random-order arrival, where the adversary chooses the list of items, but the items arrive one by one according to an arrival order drawn uniformly at random from the set of all permutations of the items. Kenyon's seminal result established an upper bound of 1.5 and a lower bound of 1.08 on therandom-order ratioof Best-Fit, and it was conjectured that the true ratio is ≍ 1.15. The conjecture, if true, will also imply that Best-Fit (on randomly permuted input) has the best performance guarantee among all the widely-used simple algorithms for (offline) bin packing. This conjecture has remained one of the major open problems in the area, as highlighted in the recent survey on random-order models by Gupta and Singla [Beyond the Worst-Case Analysis of Algorithms ‘20]. Recently, Albers et al. [Algorithmica ‘21] improved the upper bound to 1.25 for the special case when all the item sizes are greater than 1/3, and they improve the lower bound to 1.1. Ayyadevara et al. [ICALP ‘22] obtained an improved result for the special case when all the item sizes lie in (1/4,1/2], which corresponds to the3-partitionproblem. The upper bound of 3/2 for the general case, however, has remained unimproved. This also has remained the best random-order ratio among all polynomial-time algorithms for online bin packing. 
 In this paper, we make the first progress towards the conjecture, by showing that Best-Fit achieves a random-order ratio of at most 1.5 — ɛ, for a small constant ɛ > 0. Furthermore, we establish an improved lower bound of 1.144 on the random-order ratio of Best-Fit, nearly reaching the conjectured ratio. 
 Full Access 
 Poly-logarithmic Competitiveness for thek-Taxi Problem 
 href="/author/Gupta%2C+Anupam" - Anupam Gupta | , 
 href="/author/Kumar%2C+Amit" - Amit Kumar | , 
 href="/author/Panigrahi%2C+Debmalya" - Debmalya Panigrahi 
 pp.4220–4246 
 Abstract 
 PDF 
 AbstractThe onlinek-taxi problem generalizes thek-server problem, requiring servers to move between source-sink pairs in ann-point metric space, and the cost is the overhead incurred. In the deterministic setting, the problem has a lower bound on the competitiveness of Ω(2k), showing that it is significantly harder thank-server. Randomized algorithms are known with competitivenessO(2klogn)(by Coester and Koutsoupias), 
 (by Buchbinder, Coester and Naor), where Δ is the aspect ratio of then-point metric space), andO((nlogk)2logn) (by Bubeck, Buchbinder, Coester, and Sellke). The best lower bound known is Ω(log2k) which is inherited from thek-server problem, obtained in a recent breakthrough by Bubeck, Coester, and Rabani, showing a large gap in our understanding of problems that go slightly beyond the metrical task system framework.An open question left by these works was whether there is a randomized algorithm for the thek-taxi problem with a competitive ratio that is poly-logarithmic in all the parameters. We answer this question in the affirmative in this paper. For our work, we give a covering relaxation fork-taxi on HSTs, which is obtained from the (non-covering) min-cost flow formulation of the problem. The constraints of our LP have compositionality properties that we use to develop a hierarchical primal-dual algorithm defined on the subtrees of the HST. 
 Full Access 
 Controlling Tail Risk in Online Ski-Rental 
 href="/author/Dinitz%2C+Michael" - Michael Dinitz | , 
 href="/author/Im%2C+Sungjin" - Sungjin Im | , 
 href="/author/Lavastida%2C+Thomas" - Thomas Lavastida | , 
 href="/author/Moseley%2C+Benjamin" - Benjamin Moseley | , 
 href="/author/Vassilvitskii%2C+Sergei" - Sergei Vassilvitskii 
 pp.4247–4263 
 Abstract 
 PDF 
 AbstractThe classical ski-rental problem admits a textbook 2-competitive deterministic algorithm, and a simple randomized algorithm that ise/e-1-competitive in expectation. The randomized algorithm, while optimal in expectation, has a large variance in its performance: it has more than a 37% chance of competitive ratio exceeding 2, and the change of the competitive ratio exceeding n is Θ(1/n)! 
 We ask what happens to the optimal solution if we insist that thetail risk,i.e., the chance of the competitive ratio exceeding a specific value, is bounded by some constant δ. We find that this additional modification significantly changes the structure of the optimal solution. The probability of purchasing skis on a given day becomes non-monotone, discontinuous, and arbitrarily large (for sufficiently small tail risk δ and large purchase costn). 
 *A full version of the paper can be accessed at https://arxiv.org/abs/2308.05067 
 Full Access 
 Breaking thek/ logkBarrier in Collective Tree Exploration via Tree-Mining 
 href="/author/Cosson%2C+Romain" - Romain Cosson 
 pp.4264–4282 
 Abstract 
 PDF 
 AbstractIn collective tree exploration, a team ofkmobile agents is assigned to go through all edges of an unknown tree as fast as possible. An edge of the tree is revealed to the team when one agent becomes adjacent to that edge. The agents start from the root and all move synchronously along one adjacent edge in each round. Communication between the agents is unrestricted, and they are, therefore, centrally controlled by a single exploration algorithm. The algorithm's guarantee is typically compared to the number of rounds required by the agents to go through all edges if they had known the tree in advance. This quantity is at least max{2n/k, 2D} wherenis the number of nodes andDis the tree depth. Since the introduction of the problem by [11, 12], two types of guarantees have emerged: the first takes the formr(k)(n/k+D), wherer(k) is called the competitive ratio, and the other takes the form2n/k+f (k, D), wheref (k, D)is called the competitive overhead. In this paper, we present the first algorithm with linear-in-Dcompetitive overhead, thereby reconciling both approaches. Specifically, our bound is in2n/k+O(klog2(k)-1D)and leads to a competitive ratio in 
 . This is the first improvement overO(k/Ink) since the introduction of the problem, twenty years ago. Our algorithm is developed for an asynchronous generalization of collective tree exploration (ACTE). It belongs to a broad class oflocally-greedyexploration algorithms that we define. We show that the analysis of locally-greedy algorithms can be seen through the lens of a 2-player game that we call thetree-mininggame and which could be of independent interest. 
 Full Access 
 Maintaining Matroid Intersections Online 
 href="/author/Buchbinder%2C+Niv" - Niv Buchbinder | , 
 href="/author/Gupta%2C+Anupam" - Anupam Gupta | , 
 href="/author/Hathcock%2C+Daniel" - Daniel Hathcock | , 
 href="/author/Karlin%2C+Anna+R" - Anna R. Karlin | , 
 href="/author/Sarkar%2C+Sherry" - Sherry Sarkar 
 pp.4283–4304 
 Abstract 
 PDF 
 AbstractMaintaining a maximum bipartite matching online while minimizing augmentations is a well studied problem, motivated by content delivery, job scheduling, and hashing. A breakthrough result of Bernstein, Holm, and Rotenberg (SODA 2018) resolved this problem up to a logarithmic factors. However, to model other problems in scheduling and resource allocation, we may need a richer class of combinatorial constraints (e.g., matroid constraints). 
 We consider the problem of maintaining a maximum independent set of an arbitrary matroidMand a partition matroidP. Specifically, at each timesteptone partPtof the partition matroid is revealed: we must now select at most one newly-revealed element, but may exchange some previously selected elements, to maintain a maximum independent set on the elements seen thus far. The goal is to minimize the number of augmentations. IfMis also a partition matroid, we recover the problem of maintaining a maximum bipartite matching online with recourse as a special case. 
 Our main result is anO(nlog2n)-competitive algorithm, where n is the rank of the largest common base; this matches the current best quantitative bound for the bipartite matching special case. Our result builds substantively on the result of Bernstein, Holm, and Rotenberg: a key contribution of our work is to make use of market equilibria and prices in submodular utility allocation markets. 
 Full Access 
 A Tight Bound for Testing Partition Properties 
 href="/author/Shapira%2C+Asaf" - Asaf Shapira | , 
 href="/author/Stagni%2C+Henrique" - Henrique Stagni 
 pp.4305–4320 
 Abstract 
 PDF 
 AbstractApartition propertyof orderkasks if a graph can be partitioned intokvertex sets of prescribed sizes so that the densities between any pair of sets falls within a prescribed range. This family of properties has been extensively studied in various areas of research ranging from theoretical computer science to statistical physics. Our main result is that every partition property of orderkis testable with query complexity poly(k/ɛ). We thus obtain an exponential improvement (ink) over the (1/ɛ)O(k)bound obtained by Goldreich, Goldwasser and Ron in their seminal FOCS 1996 paper. We further prove that our bound is tight in the sense that it cannot be made sub-polynomial ineither kor ɛ. 
 Besides the intrinsic interest in obtaining a tight bound for the above well studied family of properties, our improved bound has several combinatorial and algorithmic implications, stemming from the fact that it remains polynomial even when testing partition properties of orderk= poly(1/ɛ). 
 Full Access 
 Mildly Exponential Lower Bounds on Tolerant Testers for Monotonicity, Unateness, and Juntas 
 href="/author/Chen%2C+Xi" - Xi Chen | , 
 href="/author/de%2C+Anindya" - Anindya De | , 
 href="/author/Li%2C+Yuhao" - Yuhao Li | , 
 href="/author/Nadimpalli%2C+Shivam" - Shivam Nadimpalli | , 
 href="/author/Servedio%2C+Rocco+A" - Rocco A. Servedio 
 pp.4321–4337 
 Abstract 
 PDF 
 AbstractWe give the first super-polynomial (in fact, mildly exponential) lower bounds for tolerant testing (equivalently, distance estimation) of monotonicity, unateness, and juntas with aconstantseparation between the “yes” and “no” cases. Specifically, we give 
 • A 
 -query lower bound for non-adaptive, two-sided tolerant monotonicity testers and unateness testers when the “gap” parameter ɛ2— ɛ1is equal to ɛ, for any;• A 2Ω(k1/2)-query lower bound for non-adaptive, two-sided tolerant junta testers when the gap parameter is an absolute constant. 
 In the constant-gap regime no non-trivial prior lower bound was known for monotonicity, the best prior lower bound known for unateness was 
 queries, and the best prior lower bound known for juntas was poly(k) queries. 
 Full Access 
 Uniformity Testing over Hypergrids with Subcube Conditioning 
 href="/author/Chen%2C+Xi" - Xi Chen | , 
 href="/author/Marcussen%2C+Cassandra" - Cassandra Marcussen 
 pp.4338–4370 
 Abstract 
 PDF 
 AbstractWe give an algorithm for testing uniformity of distributions supported on hypergrids [m1] × · · · × [mn], which makes 
 many queries to a subcube conditional sampling oracle withm= maximi. Whenmis a constant, our algorithm is nearly optimal and strengthens the algorithm of Canonne et al. (SODA 2021) which has the same query complexity but works for hypercubes {±1}nonly.A key technical contribution behind the analysis of our algorithm is a proof of a robust version of Pisier's inequality for functions over hypergrids using Fourier analysis. 
 Full Access 
 Tight Lower Bound on Equivalence Testing in Conditional Sampling Model 
 href="/author/Chakraborty%2C+Diptarka" - Diptarka Chakraborty | , 
 href="/author/Chakraborty%2C+Sourav" - Sourav Chakraborty | , 
 href="/author/Kumar%2C+Gunjan" - Gunjan Kumar 
 pp.4371–4394 
 Abstract 
 PDF 
 AbstractWe study the equivalence testing problem where the goal is to determine if the given two unknown distributions on [n] are equal or ɛ-far in the total variation distance in the conditional sampling model (CFGM, SICOMP16; CRS, SICOMP15) wherein a tester can get a sample from the distribution conditioned on any subset. Equivalence testing is a central problem in distribution testing, and there has been a plethora of work on this topic in various sampling models. 
 Despite significant efforts over the years, there remains a gap in the current best-known upper bound ofÕ(log logn) [FJOPS, COLT 2015] and lower bound of 
 [ACK, RANDOM 2015, Theory of Computing 2018]. Closing this gap has been repeatedly posed as an open problem (listed as problems 66 and 87 at sublinear.info). In this paper, we completely resolve the query complexity of this problem by showing a lower bound of. For that purpose, we develop a novel and generic proof technique that enables us to break thebarrier, not only for the equivalence testing problem but also for other distribution testing problems, such as uniblock property. 
 Full Access 
 Adversarial Low Degree Testing 
 href="/author/Minzer%2C+Dor" - Dor Minzer | , 
 href="/author/Zheng%2C+Kai+Zhe" - Kai Zhe Zheng 
 pp.4395–4409 
 Abstract 
 PDF 
 AbstractIn thet-online-erasure model in property testing, an adversary is allowed to erasetvalues of a queried function for each query the tester makes. This model was recently formulated by Kalemaj, Raskhodnikova and Varma, who showed that the properties of linearity of functions as well as quadraticity can be tested inOt(1) many queries:O(log(t)) for linearity and 22O(t)for quadraticity. They asked whether the more general property of low-degreeness can be tested in the online erasure model, whether better testers exist for quadraticity, and if similar results hold when “erasures” are replaced with “corruptions”. 
 We show that, in thet-online-erasure model, for a prime powerq, given query access to a functionf: 𝔽qn→ 𝔽q, one can distinguish in poly(logd+q(t) /δ) queries between the case thatfis degree at mostd, and the case thatfis δ-far from any degreedfunction (with respect to the fractional hamming distance). This answers the aforementioned questions and brings the query complexity to nearly match the query complexity of low-degree testing in the classical property testing model. 
 Our results are based on the observation that the property of low-degreeness admits a large and versatile family of query efficient testers. Our testers operates by querying a uniformly random, sufficiently large set of points in a large enough affine subspace, and finding a tester for low-degreeness that only utilizes queries from that set of points. We believe that this tester may find other applications to algorithms in the online-erasure model or other related models, and may be of independent interest. 
 *The full version of the paper can be accessed at https://arxiv.org/pdf/2308.15441 
 Full Access 
 Fully Scalable Massively Parallel Algorithms for Embedded Planar Graphs 
 href="/author/Chang%2C+Yi-Jun" - Yi-Jun Chang | , 
 href="/author/Zheng%2C+da+Wei" - Da Wei Zheng 
 pp.4410–4450 
 Abstract 
 PDF 
 AbstractWe consider themassively parallel computation(MPC) model, which is a theoretical abstraction of large- scale parallel processing models such as MapReduce. In this model, assuming the widely believed 1-vs-2-cycles conjecture, solving many basic graph problems inO(1) rounds with a strongly sublinear memory size per machine is impossible. We improve on the recent work of Holm and Tětek [SODA 2023] that bypass this barrier for problems when a planar embedding of the graph is given. In the previous work, on graphs of sizenwithO(n/S)machines, the memory size per machine needs to be at leastS = n2/3+Ω(1),whereas we extend their work to thefully scalableregime, where the memory size per machine can beS=nδfor any constant 0 < δ < 1. We thus give the first constant round fully scalable algorithms for embedded planar graphs for the problems of (i) connectivity and (ii) minimum spanning tree (MST). 
 Moreover, we show that the ɛ-emulator of Chang, Krauthgamer, and Tan [STOC 2022] can be incorporated into our recursive framework to obtain constant-round (1 + ɛ)-approximation algorithms for the problems of computing (iii) single source shortest path (SSSP), (iv) global min-cut, and (v)st-max flow. All previous results on cuts and flows required linear memory in the MPC model. Furthermore, our results give new algorithms for problems that implicitly involve embedded planar graphs. We give as corollaries of our result the constant round fully scalable algorithms for (vi) 2D Euclidean MST usingO(n) total memory and (vii) (1 + ɛ)-approximate weighted edit distance usingÕ(n2-δ) memory. 
 Our main technique is a recursive framework combined with novel graph drawing algorithms that allow us to compute smaller embedded planar graphs in constant rounds in the fully scalable setting. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2304.07441 
 Full Access 
 An Optimal Algorithm for Higher-Order Voronoi Diagrams in the Plane: The Usefulness of Nondeterminism 
 href="/author/Chan%2C+Timothy+M" - Timothy M. Chan | , 
 href="/author/Cheng%2C+Pingan" - Pingan Cheng | , 
 href="/author/Zheng%2C+da+Wei" - Da Wei Zheng 
 pp.4451–4463 
 Abstract 
 PDF 
 AbstractWe present the first optimal randomized algorithm for constructing the order-kVoronoi diagram ofnpoints in two dimensions. The expected running time isO(nlogn+nk),which improves the previous, two-decades- old result of Ramos (SoCG’99) by a 2O(log*k)factor. To obtain our result, we (i) use a recent decision-tree technique of Chan and Zheng (SODA’22) in combination with Ramos's cutting construction, to reduce the problem toverifyingan order-kVoronoi diagram, and (ii) solve the verification problem by a new divide-and-conquer algorithm using planar-graph separators. 
 We also describe a deterministic algorithm for constructing thek-level ofnlines in two dimensions inO(nlogn+nk1/3) time, and constructing thek-level ofnplanes in three dimensions inO(nlogn+nk3/2) time. These time bounds (ignoring thenlognterm) match the current best upper bounds on the combinatorial complexity of thek-level. Previously, the same time bound in two dimensions was obtained by Chan (1999) but with randomization. 
 Full Access 
 Improved Bounds for Point Selections and Halving Hyperplanes in Higher Dimensions 
 href="/author/Rubin%2C+Natan" - Natan Rubin 
 pp.4464–4501 
 Abstract 
 PDF 
 AbstractLet (P,E)be a (d+ 1)-uniform geometric hypergraph, wherePis ann-point set in general position in ℝdand 
 is a collection ofd-dimensional simplices with vertices inP, for 0 <ɛ≤ 1. We show that there is a pointx∈ ℝdthat pierces simplices inE, for any fixed δ > 0. This is a dramatic improvement in all dimensionsd≥ 3, over the previous lower bounds of the general form ɛ(cd)d+1nd+1, which date back to the seminal 1991 work of Alon, Bárány, Füredi and Kleitman.As a result, anyn-point set in general position in ℝdadmits only halving hyperplanes, for any δ > 0, which is a significant improvement over the previously best known bound 
 in all dimensionsd≥ 5.An essential ingredient of our proof is the following semi-algebraic Turán-type result of independent interest, which holds for any fixed δ > 0: Let (V1,…,Vk, E)be a hypergraph of bounded semi-algebraic description complexity, whose vertices are in sufficiently general position in ℝd. Suppose that |E| ≥ ɛ|V1| ·… · |Vk| holds for some ɛ > 0, then there exist subsetsWi ⊆ Viso that |Wi| = Ω (ɛd+1+δ|Vi|) for 1≤ i ≤ k -1, |Wk| = Ω (ɛ|Vi|), andWi× … ×Wk⊆ E. 
 Full Access 
 Solving Fréchet Distance Problems by Algebraic Geometric Methods 
 href="/author/Cheng%2C+Siu-Wing" - Siu-Wing Cheng | , 
 href="/author/Huang%2C+Haoqiang" - Haoqiang Huang 
 pp.4502–4513 
 Abstract 
 PDF 
 AbstractWe study several polygonal curve problems under the Fréchet distance via algebraic geometric methods. Let 𝕏dmand 𝕏dkbe the spaces of all polygonal curves ofmandkvertices in ℝd, respectively. We assume thatk≤m. Let 
 be the set of ranges in 𝕏dmfor all possible metric balls of polygonal curves in 𝕏dkunder the Fréchet distance. We prove a nearly optimal bound ofO(dklog(km)) on the VC dimension of the range space (𝕏dm,), improving on the previousO(d2k2log(dkm)) upper bound and approaching the current Ω(dklogk) lower bound. Our upper bound also holds for the weak Fréchet distance. We also obtain exact solutions that are hitherto unknown for the curve simplification, range searching, nearest neighbor search, and distance oracle problems.*Research supported by the Research Grants Council, Hong Kong, China (project no. 16208923). 
 Full Access 
 Fast and Accurate Approximations of the Optimal Transport in Semi-Discrete and Discrete Settings 
 href="/author/Agarwal%2C+Pankaj+K" - Pankaj K. Agarwal | , 
 href="/author/Raghvendra%2C+Sharath" - Sharath Raghvendra | , 
 href="/author/Shirzadian%2C+Pouyan" - Pouyan Shirzadian | , 
 href="/author/Yao%2C+Keegan" - Keegan Yao 
 pp.4514–4529 
 Abstract 
 PDF 
 AbstractGiven ad-dimensional continuous (resp. discrete) probability distribution μ and a discrete distributionν, the semi-discrete (resp. discrete) optimal transport (OT) problem asks for computing a minimum-cost plan to transport mass from μ toν; we assumento be the number of points in the support of the discrete distributions. In this paper, we present three approximation algorithms for the OT problem with strong provable guarantees. 
 (i)Additive approximation for semi-discrete OT:For any parameter ɛ > 0, we present an algorithm that computes a semi-discrete transport plan 
 with costintime; here, τ* is the optimal transport plan,Dis the diameter of the supports of μ and ν, and we assume we have access to an oracle that outputs the mass of μ inside a constant-complexity region inO(1) time. Our algorithm works for several ground distances including theLp-norm and the squared-Euclidean distance.(ii)Relative approximation for semi-discrete OT:For any parameter ɛ > 0, we present an algorithm that computes a semi-discrete transport plan 
 with costinnlog(n) · (ɛ-1log logn)O(d)expected time; here, τ* is the optimal transport plan, and we assume we have access to an oracle that outputs the mass of μ inside an orthogonal box inO(1) time, and the ground distance is anyLpnorm.(iii)Relative approximation for discrete OT:For any parameter ɛ > 0, we present a Monte-Carlo algorithm that computes a transport plan τ with an expected cost 
 under anyLpnorm innlog(n) · (ɛ-1log logn)O(d)time; here, τ* is an optimal transport plan and we assume that the spread of the supports of μ andνis polynomially bounded.*The full version of the paper can be accessed at https://arxiv.org/abs/2311.02172 
 Full Access 
 Set Covering with Our Eyes Wide Shut 
 href="/author/Gupta%2C+Anupam" - Anupam Gupta | , 
 href="/author/Kehne%2C+Gregory" - Gregory Kehne | , 
 href="/author/Levin%2C+Roie" - Roie Levin 
 pp.4530–4553 
 Abstract 
 PDF 
 AbstractIn thestochastic set cover problem(Grandoni et al., FOCS ‘08), we are given a collectionSofmsets over a universeUof sizeN, and a distributionDover elements ofU. The algorithm drawsnelements one-by-one fromDand must buy a set to cover each element on arrival; the goal is to minimize the total cost of sets bought during this process. Auniversalalgorithm a priori maps each elementu∈Uto a setS(u) such that ifU ⊆ Uis formed by drawingntimes from distributionD, then the algorithm commits to outputtingS(U). Grandoni et al. gave anO(log mN)-competitive universal algorithm for this stochastic set cover problem. 
 We improve unilaterally upon this result by giving a simple, polynomial timeO(logmn)-competitive universal algorithm for the more generalprophetversion, in whichUis formed by drawing fromndifferent distributionsD1,…,Dn. Furthermore, we show that we do not need full foreknowledge of the distributions: in fact, a single sample from each distribution suffices. We show similar results for the2-stage prophetsetting and for theonline-with-a-samplesetting. 
 We obtain our results via a generic reduction from the single-sample prophet setting to the random-order setting (for which Gupta et al., FOCS 2021 provides an algorithm); this reduction holds for a broad class of minimization problems that includes all covering problems. We take advantage of this framework by giving random-order algorithms for non-metric facility location and set multicover; using our framework, these automatically translate to universal prophet algorithms. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2304.02063. 
 Full Access 
 Edge-disjoint paths in expanders: online with removals 
 href="/author/Dragani%C4%87%2C+Nemanja" - Nemanja Draganić | , 
 href="/author/Nenadov%2C+Rajko" - Rajko Nenadov 
 pp.4554–4563 
 Abstract 
 PDF 
 AbstractWe consider the problem of finding edge-disjoint paths between given pairs of vertices in a sufficiently strongd-regular expander graphGwithnvertices. In particular, we describe a deterministic, polynomial time algorithm which maintains an initially empty collection of edge-disjoint pathsPinGand fulfills any series of two types of requests: 
 1. Given two verticesaandbsuch that each appears as an endpoint inO(d) paths inPand, additionally, |P| =O(nd/logn), the algorithm finds a path of length at most lognconnectingaandbwhich is edge-disjoint from all other paths inP, and adds it toP. 
 2. Remove a given pathP∈PfromP. 
 Importantly, each request is processed before seeing the next one. The upper bound on the length of found paths and the constraints are the best possible up to a constant factor. This establishes the first online algorithm for finding edge-disjoint paths in expanders which also allows removals, significantly strengthening a long list of previous results on the topic. 
 Full Access 
 Online Duet between Metric Embeddings and Minimum-Weight Perfect Matchings 
 href="/author/Bhore%2C+Sujoy" - Sujoy Bhore | , 
 href="/author/Filtser%2C+Arnold" - Arnold Filtser | , 
 href="/author/Toth%2C+Csaba+D" - Csaba D. Toth 
 pp.4564–4579 
 Abstract 
 PDF 
 AbstractLow-distortional metric embeddings are a crucial component in the modern algorithmic toolkit. In an online metric embedding, points arrive sequentially and the goal is to embed them into a simple space irrevocably, while minimizing the distortion. Our first result is a deterministic online embedding of a general metric into Euclidean space with distortion 
 if the metric has doubling dimensiond), solving affirmatively a conjecture by Newman and Rabinovich (2020), and quadratically improving the dependence on the aspect ratio Φ from Indyk et al. (2010). Our second result is a stochastic embedding of a metric space into trees with expected distortionO(d·log Φ), generalizing previous results (Indyk et al. (2010), Bartal et al. (2020)).Next, we study the problem ofonline minimum-weight perfect matching (MWPM).Here a sequence of 2npointss1,…s2nin a metric space arrive in pairs, and one has to maintain a perfect matching on the first2ipointsSi={s1,…s2i}. We allow recourse (as otherwise the order of arrival determines the matching). The goal is to return a perfect matching that approximates theminimum-weightperfect matching onSi, while minimizing the recourse. Online matchings are among the most studied online problems, however, there is no previous work on online MWPM. One potential reason for this is that online MWPM is drastically non-monotone, which makes online optimization highly challenging. Our third result is a randomized algorithm with competitive ratioO(d ·log Φ) and recourseO(logΦ) against an oblivious adversary, this result is obtained via our new stochastic online embedding. Our fourth result is a deterministic algorithm that works against an adaptive adversary, usingO(log2n) recourse, and maintains a matching of total weight at mostO(logn) times the weight of the MST, i.e., a matching of lightnessO(logn). We complement our upper bounds with a strategy for an oblivious adversary that, with recourser, establishes a lower bound of 
 for both competitive ratio as well as lightness.*The full version of the paper can be accessed at http://arxiv.org/abs/2310.14078 
 Full Access 
 Power of Posted-price Mechanisms for Prophet Inequalities 
 href="/author/Banihashem%2C+Kiarash" - Kiarash Banihashem | , 
 href="/author/Hajiaghayi%2C+MohammadTaghi" - MohammadTaghi Hajiaghayi | , 
 href="/author/Kowalski%2C+Dariusz+R" - Dariusz R. Kowalski | , 
 href="/author/Krysta%2C+Piotr" - Piotr Krysta | , 
 href="/author/Olkowski%2C+Jan" - Jan Olkowski 
 pp.4580–4604 
 Abstract 
 PDF 
 AbstractWe study the power of posted pricing mechanisms for Bayesian online optimization problems subject to combinatorial feasibility constraints. When the objective is to maximize social welfare, the problem is widely studied in the literature on prophet inequalities. While most (though not all) existing algorithms for prophet inequalities are implemented using a pricing mechanism, whether or not this can be done in general is unknown, and was formally left as an open question by Dutting, Feldman, Kesselheim, and Lucier (FOCS 2017, SICOMP 2020). Understanding the power and limitations of posted prices is important from a mechanism design perspective because any posted price mechanism is truthful, and is also interesting in its own right as it can guide future research on prophet inequalities. 
 We show that any prophet inequality has an implementation using a posted price mechanism, thereby resolving the open question of Dutting et al. Given an algorithm for Bayesian online optimization, we show that it can be transformed, in a black-box manner, to a posted price algorithm that has the same or higher expected social welfare and preserves the distribution over the assigned outcomes. We further show how to implement our reduction efficiently under standard assumptions using access to a sampling oracle. As an immediate consequence, we obtain improved pricing-based prophet inequalities for maximum weight matching, resolving an open problem of Ezra, Feldman, Gravin and Tang (EC 2020, MOR 2022). Correa and Cristi (STOC 2023) proved recently an existence of prophet inequality with constant approximation ratio for online social welfare maximizing combinatorial auctions with subadditive valuations. They left as an open problem to provide a posted pricing based implementation of their algorithm. Our technique resolves this question in affirmative as well. 
 Full Access 
 Combinatorial Stationary Prophet Inequalities 
 href="/author/Patel%2C+Neel" - Neel Patel | , 
 href="/author/Wajc%2C+David" - David Wajc 
 pp.4605–4630 
 Abstract 
 PDF 
 AbstractNumerous recent papers have studied the tension between thickening and clearing a market in (uncertain, online) long-time horizon Markovian settings. In particular, (Aouad and Saritaç EC’20, Collina et al. WINE’20, Kessel et al. EC’22) studied what the latter referred to as the Stationary Prophet Inequality Problem, due to its similarity to the classic finite-time horizon prophet inequality problem. These works all consider unit-demand buyers. Mirroring the long line of work on the classic prophet inequality problem subject tocombinatorial constraints,we initiate the study of the stationary prophet inequality problem subject tocombinatorially-constrained buyers. 
 Our results can be summarized succinctly as unearthing an algorithmic connection between contention resolution schemes (CRS) and stationary prophet inequalities. While the classic prophet inequality problem has a tight connection to online CRS (Feldman et al. SODA’16, Lee and Singla ESA’18), we show that for the stationary prophet inequality problem,offlineCRS play a similarly central role. We show that, up to small constant factors, the best (ex-ante) competitive ratio achievable for the combinatorial prophet inequality equals the best possible balancedness achievable by offline CRS for the same combinatorial constraints. 
 Full Access 
 Edge-weighted Online Stochastic Matching: Beatinghref="/author/Yan%2C+Shuyi" - Shuyi Yan 
 pp.4631–4640 
 Abstract 
 PDF 
 AbstractWe study the edge-weighted online stochastic matching problem. Since [6] introduced the online stochastic matching problem and proposed the ( 
 )-competitive Suggested Matching algorithm, there has been no improvement in the edge-weighted setting. In this paper, we introduce the first algorithm beating thebarrier in this setting, achieving a competitive ratio of 0.645. Under the LP proposed by [13], we design an algorithmic preprocessing, dividing all edges into two classes. Then we use different matching strategies to improve the performance on edges in one class in the early stage and on edges in another class in the late stage, while keeping the matching events of different edges highly independent. By balancing them, we finally guarantee the matched probability of every single edge. 
 Full Access 
 Improved Roundtrip Spanners, Emulators, and Directed Girth Approximation 
 href="/author/Harbuzova%2C+Alina" - Alina Harbuzova | , 
 href="/author/Jin%2C+Ce" - Ce Jin | , 
 href="/author/Williams%2C+Virginia+Vassilevska" - Virginia Vassilevska Williams | , 
 href="/author/Xu%2C+Zixuan" - Zixuan Xu 
 pp.4641–4669 
 Abstract 
 PDF 
 AbstractRoundtrip spanners are the analog of spanners in directed graphs, where the roundtrip metric is used as a notion of distance. Recent works have shown existential results of roundtrip spanners nearly matching the undirected case, but the time complexity for constructing roundtrip spanners is still widely open. 
 This paper focuses on developing fast algorithms for roundtrip spanners and related problems. For anyn-vertex directed graphGwithmedges (with non-negative edge weights), our results are as follows: 
 • 3-roundtrip spanner faster than APSP: We give an 
 -time algorithm that constructs a roundtrip spanner of stretch 3 and optimal sizeO(n3/2). Previous constructions of roundtrip spanners of the same size either required Ω(nm) time [Roditty, Thorup, Zwick SODA’02; Cen, Duan, Gu ICALP’20], or had worse stretch 4 [Chechik and Lifshitz SODA’21].• Optimal roundtrip emulator in dense graphs: For integerk≥ 3, we give anO(kn2logn)-time algorithm that constructs a roundtripemulatorof stretch (2k— 1) and sizeO(kn1+1/k), which is optimal for constantkunder Erdős’ girth conjecture. Previous work of [Thorup and Zwick STOC’01] implied a roundtrip emulator of the same size and stretch, but it required Ω(nm) construction time. Our improved running time is near-optimal for dense graphs. 
 • Faster girth approximation in sparse graphs: We give anÕ(mn1/3)-time algorithm that 4-approximates the girth of a directed graph. This can be compared with the previous 2-approximation algorithm inÕ( 
 ) time by [Chechik and Lifshitz SODA’21]. In sparse graphs, our algorithm achieves better running time at the cost of a larger approximation ratio.*The full version of the paper can be accessed at https://arxiv.org/abs/2310.20473 
 Full Access 
 The Time Complexity of Fully Sparse Matrix Multiplication 
 href="/author/Abboud%2C+Amir" - Amir Abboud | , 
 href="/author/Bringmann%2C+Karl" - Karl Bringmann | , 
 href="/author/Fischer%2C+Nick" - Nick Fischer | , 
 href="/author/K%C3%BCnnemann%2C+Marvin" - Marvin Künnemann 
 pp.4670–4703 
 Abstract 
 PDF 
 AbstractWhat is the time complexity of matrix multiplication of sparse integer matrices withminnonzeros in the input andmoutnonzeros in the output? This paper provides improved upper bounds for this question for almost any choice ofminvs.mout,and provides evidence that these new bounds might be optimal up to further progress on fast matrix multiplication. 
 Our main contribution is a new algorithm that reduces sparse matrix multiplication to dense (but smaller) rectangular matrix multiplication. Our running time thus depends on the optimal exponentω(a,b,c) of multiplyingdense na× nbbynb×ncmatrices. We discover that when 
 the time complexity of sparse matrix multiplication is, for allɛ >0, whereσis the solution to the equationω(σ — 1, 2 — σ, 1+r— σ) = σ. No matter whatω(·, ·, ·) turns out to be, and for allr∈ (0, 2), the new bound beats the state of the art, and we provide evidence that it is optimal based on the complexity of the all-edge triangle problem.In particular, in terms of the input plus output sizem=min+moutour algorithm runs in timeO(m1.3459). 
 Even for Boolean matrices, this improves over the previous 
 bound [Amossen, Pagh; 2009], which was a natural barrier since it coincides with the longstanding bound of all-edge triangle in sparse graphs [Alon, Yuster, Zwick; 1994]. We find it interesting that matrix multiplication can be solved faster than triangle detection in this natural setting. In fact, we establish an equivalence to aspecial caseof the all-edge triangle problem.*The full version of the paper can be accessed at https://arxiv.org/abs/2309.06317. 
 Full Access 
 The Effect of Sparsity onk-Dominating Set and Related First-Order Graph Properties 
 href="/author/Fischer%2C+Nick" - Nick Fischer | , 
 href="/author/K%C3%BCnnemann%2C+Marvin" - Marvin Künnemann | , 
 href="/author/Redzic%2C+Mirza" - Mirza Redzic 
 pp.4704–4727 
 Abstract 
 PDF 
 AbstractWe revisit the classick-Dominating Set problem. Besides its importance as perhaps the most naturalW[2]-complete problem, it is among the first problems for which a tightnk-o(1)conditional lower bound (for all sufficiently largek), based on the Strong Exponential Time Hypothesis (SETH), was shown (Patrascu and Williams, SODA 2007). Notably, however, the underlying reduction creates dense graphs, raising the question: how much does the sparsity of the graph affect its fine-grained complexity? 
 As our first result, we settle the fine-grained complexity ofk-Dominating Set in terms of both the number of nodesnand number of edgesm, up to resolving the matrix multiplication exponent ω. Specifically, on the hardness side, we show anmnk-2-o(1)lower bound based on SETH, for any dependence ofmonn. On the algorithmic side, this is complemented by anmnk-2+o(1)-time algorithm for all sufficiently largek. For the smallest non-trivial case ofk= 2, i.e., 2-Dominating Set, we give a randomized algorithm that employs a Bloom-filter inspired hashing to improve the state of the art ofnω+o(1)tomω/2+o(1)=O(m1.187). Ifω= 2, this yields a conditionally tight bound for allk≥ 2. 
 To study whetherk-Dominating Set is special in its sensitivity to sparsity, we study the effect of sparsity on very related problems: 
 • Thek-Dominating Set problem belongs to a type of first-order definable graph properties that we callmonochromatic basic problems.These problems are the canonical monochromatic variants of the basic problems that were proven complete for the class FOP of first-order definable properties (Gao, Impagliazzo, Kolokolova, and Williams, TALG 2019). We show that among the monochromatic basic problems, thek-Dominating Set property is theonlyproperty whose fine-grained complexity decreases in sparse graphs. Only for the special case of reflexive properties is there an additional basic problem that can be solved faster thannk±o(1)on sparse graphs. 
 • For the natural variant of distance-r k-dominating set, we obtain a hardness ofnk-o(1)under SETH for everyr≥ 2 already on sparse graphs, which is tight for sufficiently largek. 
 • 
 Full Access 
 Fast 2-Approximate All-Pairs Shortest Paths 
 href="/author/Dory%2C+Michal" - Michal Dory | , 
 href="/author/Forster%2C+Sebastian" - Sebastian Forster | , 
 href="/author/Kirkpatrick%2C+Yael" - Yael Kirkpatrick | , 
 href="/author/Nazari%2C+Yasamin" - Yasamin Nazari | , 
 href="/author/Williams%2C+Virginia+Vassilevska" - Virginia Vassilevska Williams | , 
 href="/author/Vos%2C+Tijn+de" - Tijn de Vos 
 pp.4728–4757 
 Abstract 
 PDF 
 AbstractIn this paper, we revisit the classic approximate All-Pairs Shortest Paths (APSP) problem in undirected graphs. For unweighted graphs, we provide an algorithm for 2-approximate APSP in Õ(n2.5-r+nω(r)) time, for anyr ∈[0,1]. This isO(n2.032) time, using known bounds for rectangular matrix multiplicationnω(r)[Le Gall, Urrutia, SODA 2018]. Our result improves on theÕ(n2·25)bound of [Roditty, STOC 2023], and on the 
 bound of [Baswana, Kavitha, SICOMP 2010] for graphs withm≥n1·532edges.For weighted graphs, we obtain (2 +ɛ)-approximate APSP in 
 time, for anyr ∈[0,1]. This isO(n2.214) time using known bounds forω(r). It improves on the state of the art bound ofO(n2.25) by [Kavitha, Algorithmica 2012]. Our techniques further lead to improved bounds in a wide range of density for weighted graphs. In particular, for the sparse regime we construct a distance oracle inÕ(mn2/3)time that supports 2-approximate queries in constant time. For sparse graphs, the preprocessing time of the algorithm matches conditional lower bounds [Patrascu, Roditty, Thorup, FOCS 2012; Abboud, Bringmann, Fischer, STOC 2023]. To the best of our knowledge, this is the first 2-approximate distance oracle that has subquadratic preprocessing time in sparse graphs.We also obtain new bounds in the near additive regime for unweighted graphs. We give faster algorithms for (1 +ɛ, k)- approximate APSP, fork= 2, 4, 6, 8. 
 We obtain these results by incorporating fast rectangular matrix multiplications into various combinatorial algorithms that carefully balance out distance computation on layers of sparse graphs preserving certain distance information. 
 Full Access 
 Faster Approximate All Pairs Shortest Paths 
 href="/author/Saha%2C+Barna" - Barna Saha | , 
 href="/author/Ye%2C+Christopher" - Christopher Ye 
 pp.4758–4827 
 Abstract 
 PDF 
 AbstractThe all pairs shortest path problem (APSP) is one of the foundational problems in computer science. For weighted dense graphs onnvertices, no truly sub-cubic algorithms exist to compute APSP exactly even for undirected graphs. This is popularly known as the APSP conjecture and has played a prominent role in developing the field of fine-grained complexity. The seminal results of Seidel and Zwick show that using fast matrix multiplication (FMM) it is possible to compute APSP on unweighted undirected graphs exactly inÕ(nω) time, and can be approximated within (1 +ɛ) factor in weighted undirected graphs in time Õ(nω) respectively. Here ω is the exponent of FMM, which currently stands atω =2.37188. Moreover even for unweighted undirected graphs, it is not possible to obtain a (2 —ɛ)-multiplicative approximation of APSP for anyɛ> 0 ino(nω) time. Since 2000, a result by Dor, Halperin, and Zwick gave the best 2 approximation algorithm for APSP in unweighted undirected graphs in time Õ(n7/3). This result was recently improved by Deng, Kirkpatrick, Rong, Williams and Zhong to Õ(n2.2593) using fast min-plus product for bounded-difference matrices which uses FMM as a subroutine (the stated bound here uses new results for computing such min-plus products by Durr). In fact both these results obtain a +2-additive approximation. Recently, Roditty (STOC, 2023) improved the previous bounds for multiplicative 2-approximation of APSP in unweighted undirected graphs giving the best known bound ofÕ(n2.25). All these algorithms are deterministic. Roditty also considers estimating shortest paths for all paths of length ≥kfork≥ 4, and gives improved bounds when the underlying graph is sparse using randomization. Though for dense graphs, the best known bounds still remained at those provided by Dor et al. more than two decades back. 
 In this paper, we provide a multitude of new results for multiplicative and additive approximations of APSP in undirected graphs for both unweighted and weighted cases. We provide new algorithms for multiplicative 2-approximation of unweighted graphs: a deterministic one that runs inÕ(n2.072) time and a randomized one that runs inÕ(n2.0318) on expectation improving upon the best known bound ofÕ(n2.25). The algorithm uses FMM as well as new combinatorial insights. For 2-approximating paths of length ≥k,k≥ 4, we provide the first improvement after Dor et al. for dense graphs even just using combinatorial methods, and then improve it further using FMM. We next consider additive approximations, and provide improved bounds for all additiveβ-approximations,β≥ 4. For example, we achieve a running time ofÕ(n2.155) for +4 additive approximation improving over the previously known bound ofÕ(n2.2), and for a +6 additive approximation, our algorithm has a running time ofÕ(n2.103) as opposed to theÕ(n2.125) time that was previously known. For weighted graphs, we show that by allowing small additive errors along with an (1 +ɛ)-multiplicative approximation, it is possible to improve upon Zwick'sÕ(nω) algorithm. For example, it is possible to obtain a bi-criteria (1 +ɛ, 2wu,v) approximation inÕ(n2.152) time for the shortest path distance between all vertex pairsu,vwherewu,vis the highest weight edge on theu-vshortest path. Additionally, we provide a landscape of such bi-criteria approximations for weighted and unweighted graphs. Our results point out the crucial role that FMM can play even on approximating APSP on unweighted undirected graphs, and reveal new bottlenecks towards achieving a quadratic running time to approximate APSP. 
 Full Access 
 Faster Algorithms for Bounded Knapsack and Bounded Subset Sum Via Fine-Grained Proximity Results 
 href="/author/Chen%2C+Lin" - Lin Chen | , 
 href="/author/Lian%2C+Jiayi" - Jiayi Lian | , 
 href="/author/Mao%2C+Yuchen" - Yuchen Mao | , 
 href="/author/Zhang%2C+Guochuan" - Guochuan Zhang 
 pp.4828–4848 
 Abstract 
 PDF 
 AbstractWe investigate pseudopolynomial-time algorithms for Bounded Knapsack and Bounded Subset Sum. Recent years have seen a growing interest in settling their fine-grained complexity with respect to various parameters. For Bounded Knapsack, the number of itemsnand the maximum item weightwmaxare two of the most natural parameters that have been studied extensively in the literature. The previous best running time in terms ofnandwmaxis 
 [Polak, Rohwedder, Węgrzycki ‘21]. There is a conditional lower bound of (n+wmax)2-o(1)based on (min, +)-convolution hypothesis [Cygan, Mucha, Węgrzycki, Włodarczyk ‘17]. We narrow the gap significantly by proposing an-time algorithm. Our algorithm works for both 0-1 Knapsack and Bounded Knapsack. Note that in the regime wherewmax≈n, our algorithm runs inÕ(n12/5) time, while all the previous algorithms require Ω(n3) time in the worst case.For Bounded Subset Sum, we give two algorithms running in Õ(nwmax) and 
 time, respectively. These results match the currently best running time for 0-1 Subset Sum. Prior to our work, the best running times (in terms ofnandwmax) for Bounded Subset Sum are[Polak, Rohwedder, Węgrzycki ‘21] and[implied by Bringmann ‘19 and Bringmann, Wellnitz ‘21], whereµmaxrefers to the maximum multiplicity of item weights. 
 Full Access 
 Flip Graph Connectivity for Arrangements of Pseudolines and Pseudocircles 
 href="/author/Radtke%2C+Yan+Alves" - Yan Alves Radtke | , 
 href="/author/Felsner%2C+Stefan" - Stefan Felsner | , 
 href="/author/Obenaus%2C+Johannes" - Johannes Obenaus | , 
 href="/author/Roch%2C+Sandro" - Sandro Roch | , 
 href="/author/Scheucher%2C+Manfred" - Manfred Scheucher | , 
 href="/author/Vogtenhuber%2C+Birgit" - Birgit Vogtenhuber 
 pp.4849–4871 
 Abstract 
 PDF 
 AbstractFlip graphs of combinatorial and geometric objects are at the heart of many deep structural insights and connections between different branches of discrete mathematics and computer science. They also provide a natural framework for the study of reconfiguration problems. We study flip graphs of arrangements of pseudolines and of arrangements of pseudocircles, which are combinatorial generalizations of lines and circles, respectively. In both cases we consider triangle flips as local transformation and prove conjectures regarding their connectivity. 
 In the case ofnpseudolines we show that the connectivity of the flip graph equals its minimum degree, which is exactlyn—2. For the proof we introduce the class ofshellableline arrangements, which serve as reference objects for the construction of disjoint paths. In fact, shellable arrangements are elements of a flip graph of line arrangements which are vertices of a polytope (Felsner and Ziegler; DM 241 (2001), 301-312). This polytope forms a cluster of good connectivity in the flip graph of pseudolines. In the case of pseudocircles we show that triangle flips induce a connected flip graph onintersectingarrangements and also oncylindricalintersecting arrangements. The result for cylindrical arrangements is used in the proof for intersecting arrangements. We also show that in both settings the diameter of the flip graph is in Θ(n3). Our constructions make essential use of variants of the sweeping lemma for pseudocircle arrangements (Snoeyink and Hershberger; Proc. SoCG 1989: 354-363). We finally study cylindrical arrangements in their own right and provide new combinatorial characterizations of this class. 
 *This work was initiated at a workshop of the collaborative DACH projectArrangements and Drawingsin Lutherstadt Wittenberg in April 2022 and parts appeared in the Bachelor's thesis of the first author [4]. We thank all the participants for the inspiring atmosphere. S.F. was supported by DFG Grant FE 340/13-1. J.O. was supported by ERC StG 757609. S.R. was supported by DFG-Research Training Group ‘Facets of Complexity’ (DFG-GRK 2434). M.S. was supported by DFG Grant SCHE 2214/1-1. 
 Full Access 
 Delaunay Bifiltrations of Functions on Point Clouds 
 href="/author/Alonso%2C+%C3%81ngel+Javier" - Ángel Javier Alonso | , 
 href="/author/Kerber%2C+Michael" - Michael Kerber | , 
 href="/author/Lam%2C+Tung" - Tung Lam | , 
 href="/author/Lesnick%2C+Michael" - Michael Lesnick 
 pp.4872–4891 
 Abstract 
 PDF 
 AbstractThe Delaunay filtrationD.(X)of a point cloudX ⊂ ℝdis a central tool of computational topology. Its use is justified by the topological equivalence ofD. (X) and the offset (i.e., union-of-balls) filtration ofX. Given a function γ :X→ ℝ, we introduce a Delaunay bifiltrationDC.(γ) that satisfies an analogous topological equivalence, ensuring thatDC. (γ) topologically encodes the offset filtrations of all sublevel sets of γ, as well as the topological relations between them.DC.(γ) is of size 
 , which fordodd matches the worst-case size ofD. (X). Adapting the Bowyer-Watson algorithm for computing Delaunay triangulations, we give a simple, practical algorithm to computeDC.(γ) in timeOur implementation, based on CGAL, computesDC. (γ) with modest overhead compared to computingD. (X), and handles tens of thousands of points in ℝ3within seconds. 
 Full Access 
 Fast Approximation Algorithms for Piercing Boxes by Points 
 href="/author/Agarwal%2C+Pankaj+K" - Pankaj K. Agarwal | , 
 href="/author/Har-Peled%2C+Sariel" - Sariel Har-Peled | , 
 href="/author/Raychaudhury%2C+Rahul" - Rahul Raychaudhury | , 
 href="/author/Sintos%2C+Stavros" - Stavros Sintos 
 pp.4892–4908 
 Abstract 
 PDF 
 AbstractLetB= (b1,…, bn} be a set of n axis-aligned boxes in ℝdwhered≥ 2 is a constant. Thepiercing problemis to compute a smallest set of pointsN∪ ℝdthat hits every box inB, i.e.,N∩ bi≠ ϕ, fori= 1,…,n. The problem is known to be NP-Hard. Letp:=p(B), thepiercing numberbe the minimum size of a piercing set ofB. We first present a randomizedO(log logp)-approximation algorithm with expected running timeO(nd/2polylog(n)). Next, we show that the expected running time can be improved to near-linear using a sampling-based technique, ifp=O(n1/(d-1)). Specifically, in the plane, the improved running time isO(nlogp), assumingp<n/ logΩ(1)n. Finally, we study the dynamic version of the piercing problem where boxes can be inserted or deleted. For boxes in ℝ2, we obtain a randomizedO(log logp)-approximation algorithm withO(n1/2polylog(n)) amortized expected update time for insertion or deletion of boxes. For squares in ℝ2, the update time can be improved toO(n1/3polylog(n)). 
 Our algorithms are based on the multiplicative weight-update (MWU) method and require the construction of a weakɛ-net for a point set with respect to boxes. A key idea of our work is to exploit the duality between the piercing set and independent set (for boxes) to speed up our MWU. We also present a simpler and slightly more efficient algorithm for constructing a weakɛ-net than in [Ezr10], which is of independent interest. Our approach also yields a simpler algorithm for constructing (regular)ɛ-nets with respect to boxes ford=2, 3. 
 *A full version of this paper is available on the arXiv [AHRS23]. 
 Full Access 
 Untangling Graphs on Surfaces 
 href="/author/de+Verdi%C3%A8re%2C+%C3%89ric+Colin" - Éric Colin de Verdière | , 
 href="/author/Despr%C3%A9%2C+Vincent" - Vincent Despré | , 
 href="/author/Dubois%2C+Lo%C3%AFc" - Loïc Dubois 
 pp.4909–4941 
 Abstract 
 PDF 
 AbstractConsider a graph drawn on a surface (for example, the plane minus a finite set of obstacle points), possibly with crossings. We provide an algorithm to decide whether such a drawing can beuntangled,namely, if one can slide the vertices and edges of the graph on the surface (avoiding the obstacles) to remove all crossings; in other words, whether the drawing is homotopic to an embedding. While the problem boils down to planarity testing when the surface is the sphere or the disk (or equivalently the plane without any obstacle), the other cases have never been studied before, except when the input graph is a cycle, in an abundant literature in topology and more recently by Despré and Lazarus [SoCG 2017, J. ACM 2019], who gave a near-linear algorithm for this problem. 
 Our algorithm runs inO(m+ poly(g+b)nlogn) time, whereg≥ 0 andb≥ 0 are the genus and the number of boundary components of the input orientable surfaceS, andnis the size of the input graph drawing, lying on some fixed graph of sizemcellularly embedded onS. 
 We use various techniques from two-dimensional computational topology and from the theory of hyperbolic surfaces. Most notably, we introducereducing triangulations,a novel discrete analog of hyperbolic surfaces in the spirit ofsystems of quadsby Lazarus and Rivaud [FOCS 2012] and Erickson and Whittlesey [SODA 2013], which have the additional benefit that reduced paths are unique and stable upon reversal; they are likely of independent interest. Tailored data structures are needed to achieve certain homotopy tests efficiently on these triangulations. As a key subroutine, we rely on an algorithm to test theweak simplicityof a graph drawn on a surface by Akitaya, Fulek, and Tóth [SODA 2018, TALG 2019]. 
 Full Access 
 Near-Optimal Min-Sum Motion Planning for Two Square Robots in a Polygonal Environment 
 href="/author/Agarwal%2C+Pankaj+K" - Pankaj K. Agarwal | , 
 href="/author/Halperin%2C+Dan" - Dan Halperin | , 
 href="/author/Sharir%2C+Micha" - Micha Sharir | , 
 href="/author/Steiger%2C+Alex" - Alex Steiger 
 pp.4942–4962 
 Abstract 
 PDF 
 AbstractLetW⊂ ℝ2be a planar polygonal environment (i.e., a polygon potentially with holes) with a total ofnvertices, and letA, Bbe two robots, each modeled as an axis-aligned unit square, that can translate insideW. Given source and target placementssA,tA,sB,tB∈WofAandB, respectively, the goal is to compute acollision-free-motion planπ*, i.e., a motion plan that continuously movesAfromsAtotAandBfromsBtotBso thatAandBremain insideWand do not collide with each other during the motion. Furthermore, if such a plan exists, then we wish to return a plan that minimizes the sum of the lengths of the paths traversed by the robots. GivenW,sA,tA,sB,tBand a parameterɛ> 0, we present ann2ɛ-°(1)logn-time (1 +ɛ)-approximation algorithm for this problem. We are not aware of any polynomial-time algorithm for this problem, nor do we know whether the problem is NP-Hard. Our result is the first polynomial-time (1 +ɛ)-approximation algorithm for an optimal motion-planning problem involving two robots moving in a polygonal environment. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2310.20615. Work by P.A. and A.S. has been partially supported by IIS-1814493, CCF-2007556, and CCF-2223870. Work by D.H. has been supported in part by the Israel Science Foundation (grant nos. 1736/19 and 2261/23), by NSF/US-Israel-BSF (grant no. 2019754), by the Israel Ministry of Science and Technology (grant no. 103129), by the Blavatnik Computer Science Research Fund, and by the Yandex Machine Learning Initiative for Machine Learning at Tel Aviv University. Work by M.S. has been supported by Israel Science Foundation Grants 260/18 and 495/23. 
 Full Access 
 New Explicit Constant-Degree Lossless Expanders 
 href="/author/Golowich%2C+Louis" - Louis Golowich 
 pp.4963–4971 
 Abstract 
 PDF 
 AbstractWe present a new explicit construction of onesided bipartite lossless expanders of constant degree, with arbitrary constant ratio between the sizes of the two vertex sets. Our construction is simpler to state and analyze than the only prior construction of Capalbo, Reingold, Vadhan, and Wigderson (2002), and achieves improved parameters. 
 We construct our lossless expanders by imposing the structure of a constant-sized lossless expander “gadget” within the neighborhoods of a large bipartite spectral expander; similar constructions were previously used to obtain the weaker notion of unique-neighbor expansion. Our analysis simply consists of elementary counting arguments and an application of the expander mixing lemma. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2306.07551 
 Full Access 
 Fast Sampling ofb-Matchings andb-Edge Covers 
 href="/author/Chen%2C+Zongchen" - Zongchen Chen | , 
 href="/author/Gu%2C+Yuzhou" - Yuzhou Gu 
 pp.4972–4987 
 Abstract 
 PDF 
 AbstractFor an integerb≥ 1, ab-matching (resp.b-edge cover) of a graphG =(V, E) is a subsetS ⊆ Eof edges such that every vertex is incident with at most (resp. at least)bedges fromS. We prove that for anyb≥ 1 the simple Glauber dynamics for sampling (weighted)b-matchings andb-edge covers mixes inO(nlogn) time on alln-vertex bounded-degree graphs. This significantly improves upon previous results which have worse running time and only work forb-matchings withb≤ 7 and forb-edge covers withb≤ 2. 
 More generally, we provespectral independencefor a broad class of binary symmetric Holant problems withlog-concavesignatures, includingb-matchings,b-edge covers, and antiferromagnetic 2-spin edge models. We hence deduce optimal mixing time of the Glauber dynamics from spectral independence. 
 The core of our proof is a recursive coupling inspired by [CZ23] which upper bounds the WassersteinW1distance between distributions under different pinnings. Using a similar method, we also obtain the optimalO(nlogn) mixing time of the Glauber dynamics for the hardcore model on n-vertex bounded-degree claw-free graphs, foranyfugacity λ. This improves over previous works which have at least cubic dependence onn. 
 Full Access 
 Combinatorial Approach for Factorization of Variance and Entropy in Spin Systems 
 href="/author/Chen%2C+Zongchen" - Zongchen Chen 
 pp.4988–5012 
 Abstract 
 PDF 
 AbstractWe present a simple combinatorial framework for establishing approximate tensorization of variance and entropy in the setting of spin systems (a.k.a. undirected graphical models) based on balanced separators of the underlying graph. Such approximate tensorization results immediately imply as corollaries many important structural properties of the associated Gibbs distribution, in particular rapid mixing of the Glauber dynamics for sampling. We prove approximate tensorization by recursively establishing block factorization of variance and entropy with a small balanced separator of the graph. Our approach goes beyond the classical canonical path method for variance and the recent spectral independence approach, and allows us to obtain new rapid mixing results. As applications of our approach, we show that: 
 1. On graphs of treewidtht, the mixing time of the Glauber dynamics isnO(t), which recovers the recent results of Eppstein and Frishberg [EF21] with improved exponents and simpler proofs; 
 2. On bounded-degree planar graphs, strong spatial mixing impliesÕ(n) mixing time of the Glauber dynamics, which gives a faster algorithm than the previous deterministic counting algorithm by Yin and Zhang [YZ13]. 
 Full Access 
 Optimality of Glauber dynamics for general-purpose Ising model sampling and free energy approximation 
 href="/author/Kunisky%2C+Dmitriy" - Dmitriy Kunisky 
 pp.5013–5028 
 Abstract 
 PDF 
 AbstractRecently, Eldan, Koehler, and Zeitouni (2020) showed that Glauber dynamics mixes rapidly for general Ising models so long as the difference between the largest and smallest eigenvalues of the coupling matrix is at most 1 —ɛfor any fixedɛ> 0. We give evidence that Glauber dynamics is in fact optimal for this “generalpurpose sampling” task. Namely, we give an average-case reduction from hypothesis testing in a Wishart negatively-spiked matrix model to approximately sampling from the Gibbs measure of a general Ising model for which the difference between the largest and smallest eigenvalues of the coupling matrix is at most 1 +ɛfor any fixedɛ> 0. Combined with results of Bandeira, Kunisky, and Wein (2019) that analyze low-degree polynomial algorithms to give evidence for the hardness of the former spiked matrix problem, our results in turn give evidence for the hardness of general-purpose sampling improving on Glauber dynamics. We also give a similar reduction to approximating the free energy of general Ising models, and again infer evidence that simulated annealing algorithms based on Glauber dynamics are optimal in the general-purpose setting. 
 Full Access 
 Universality of Spectral Independence with Applications to Fast Mixing in Spin Glasses 
 href="/author/Anari%2C+Nima" - Nima Anari | , 
 href="/author/Jain%2C+Vishesh" - Vishesh Jain | , 
 href="/author/Koehler%2C+Frederic" - Frederic Koehler | , 
 href="/author/Pham%2C+Huy+Tuan" - Huy Tuan Pham | , 
 href="/author/Vuong%2C+Thuy-Duong" - Thuy-Duong Vuong 
 pp.5029–5056 
 Abstract 
 PDF 
 AbstractWe study Glauber dynamics for sampling from discrete distributionsμon the hypercube {±1}n. Recently, techniques based on spectral independence have successfully yielded optimalO(n)relaxation times for a host of different distributionsμ. We show that spectral independence is universal: a relaxation time ofO(n)implies spectral independence. 
 We then study a notion of tractability forμ, defined in terms of smoothness of the multilinear extension of its Hamiltonian - logμ- over[—1, +1]n. We show that Glauber dynamics has relaxation timeO(n)for suchμ,and using the universality of spectral independence, we conclude that these distributions are also fractionally log-concave and consequently satisfy modified log-Sobolev inequalities. We sharpen our estimates and obtain approximate tensorization of entropy and the optimalÕ(n)mixing time for random Hamiltonians, i.e. the classically studied mixedp-spin model at sufficiently high temperature. These results have significant downstream consequences for concentration of measure, statistical testing, and learning. 
 Full Access 
 Smoothed Complexity of SWAP in Local Graph Partitioning 
 href="/author/Chen%2C+Xi" - Xi Chen | , 
 href="/author/Guo%2C+Chenghao" - Chenghao Guo | , 
 href="/author/Vlatakis-Gkaragkounis%2C+Emmanouil+V" - Emmanouil V. Vlatakis-Gkaragkounis | , 
 href="/author/Yannakakis%2C+Mihalis" - Mihalis Yannakakis 
 pp.5057–5083 
 Abstract 
 PDF 
 AbstractWe give the first quasipolynomial upper boundφnpolylog(n)for the smoothed complexity of the SWAP algorithm for local Graph Partitioning (also known as Bisection Width) under the full perturbation model, wherenis the number of nodes in the graph andφis a parameter that measures the magnitude of perturbations applied on its edge weights. More generally, we show that the same quasipolynomial upper bound holds for the smoothed complexity of the 2-FLIP algorithm for any binary Maximum Constraint Satisfaction Problem, including local Max-Cut, for which similar bounds were only known for 1-FLIP. Our results are based on an analysis of a new notion of useful cycles in the multigraph formed by long sequences of double flips, showing that it is unlikely for every double flip in a long sequence to incur a positive but small improvement in the cut weight. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2305.15804 
 Full Access 
 Sublinear Time Low-Rank Approximation of Toeplitz Matrices 
 href="/author/Musco%2C+Cameron" - Cameron Musco | , 
 href="/author/Sheth%2C+Kshiteej" - Kshiteej Sheth 
 pp.5084–5117 
 Abstract 
 PDF 
 AbstractWe present a sublinear time algorithm for computing a near optimal low-rank approximation to any positive semidefinite (PSD) Toeplitz matrixT∈ ℝd×d, given noisy access to its entries. In particular, given entrywise query access toT+Efor an arbitrary noise matrixE∈ ℝd×d, integer rankk≤d,and error parameterδ >0, our algorithm runs in time poly(k, log(d/δ)) and outputs (in factored form) a Toeplitz matrix 
 with rank poly(k, log(d/δ)) satisfying, for some fixed constantC,Here ‖ · ‖Fis the Frobenius norm andTkis the best (not necessarily Toeplitz) rank-kapproximation toTin the Frobenius norm, given by projectingTonto its topkeigenvectors. 
 Our robust low-rank approximation primitive can be applied in several settings. WhenE= 0, we obtain the first sublinear time near-relative-error low-rank approximation algorithm for PSD Toeplitz matrices, resolving the main open problem of Kapralov et al. SODA ‘23, which gave an algorithm with sublinear query complexity but exponential runtime. Our algorithm can also be applied to approximate the unknown Toeplitz covariance matrix of a multivariate Gaussian distribution, given sample access to this distribution. By doing so, we resolve an open question of Eldar et al. SODA ‘20, improving the state-of-the-art error bounds and achieving a polynomial rather than exponential (in the sample size) runtime. 
 Our algorithm is based on applying sparse Fourier transform techniques to recover a low-rank Toeplitz matrix using its Fourier structure. Our key technical contribution is the first polynomial time algorithm fordiscrete time off-gridsparse Fourier recovery, which may be of independent interest. We also contribute a structural heavy-light decomposition result for PSD Toeplitz matrices, which allows us to apply this primitive to low-rank Toeplitz matrix recovery. 
 Full Access 
 A Quasi-Monte Carlo Data Structure for Smooth Kernel Evaluations 
 href="/author/Charikar%2C+Moses" - Moses Charikar | , 
 href="/author/Kapralov%2C+Michael" - Michael Kapralov | , 
 href="/author/Waingarten%2C+Erik" - Erik Waingarten 
 pp.5118–5144 
 Abstract 
 PDF 
 AbstractIn the kernel density estimation (KDE) problem one is given a kernelK(x, y)and a datasetPof points in a high dimensional Euclidean space, and must prepare a small space data structure that can quickly answer density queries: given a pointq, output a (1 +ɛ)-approximation to 
 . The classical approach to KDE (and the more general problem of matrix vector multiplication for kernel matrices) is the celebrated fast multipole method of Greengard and Rokhlin [1983]. The fast multipole method combines a basic space partitioning approach with a multidimensional Taylor expansion, which yields a ≈ logd(n/ɛ) query time (exponential in the dimensiond). A recent line of work initiated by Charikar and Siminelakis [2017] achieved polynomial dependence ondvia a combination of random sampling and randomized space partitioning, with Backurs et al. [2018] giving an efficient data structure with query time ≈ polylog(1/µ)/ɛ2for smooth kernels.Quadratic dependence onɛ, inherent to the sampling (i.e., Monte Carlo) methods above, is prohibitively expensive for smallɛ. This is a classical issue addressed by quasi-Monte Carlo methods in numerical analysis. The high level idea in quasi-Monte Carlo methods is to replace random sampling with a discrepancy based approach - an idea recently applied to coresets for KDE by Phillips and Tai [2020]. The work of Phillips and Tai gives a space efficient data structure with query complexity ≈ 1/(ɛμ). This is polynomially better in 1/ɛ, but exponentially worse in 1/μ. In this work we show how to get the best of both worlds: we give a data structure with ≈ polylog(1 /μ)/ɛquery time for smooth kernel KDE. Our main insight is a new way to combine discrepancy theory with randomized space partitioning inspired by, but significantly more efficient than, that of the fast multipole methods. We hope that our techniques will find further applications to linear algebra for kernel matrices. 
 Full Access 
 Code Sparsification and its Applications 
 href="/author/Khanna%2C+Sanjeev" - Sanjeev Khanna | , 
 href="/author/Putterman%2C+Aaron+Louie" - Aaron (Louie) Putterman | , 
 href="/author/Sudan%2C+Madhu" - Madhu Sudan 
 pp.5145–5168 
 Abstract 
 PDF 
 AbstractWe introduce a notion ofcodesparsification that generalizes the notion of cut sparsification in graphs. For a (linear) codeC⊆ 𝔽nqof dimensionka (1 ± ɛ)-sparsificationof sizesis given by a weighted setS ⊆[n] with |S| ≤ssuch that for every codewordc∈Cthe projectionc|sofcto the setShas (weighted) hamming weight which is a (1 ± ɛ) approximation of the hamming weight ofc. We show that for every code there exists a (1 ± ɛ)-sparsification of sizes= Õ(klog(q)/ɛ2). This immediately implies known results on graph and hypergraph cut sparsification up to polylogarithmic factors (with a simple unified proof) — the former follows from the well-known fact that cuts in a graph form a linear code over 𝔽2, while the latter is obtained by a simple encoding of hypergraph cuts. Further, by connections between the eigenvalues of the Laplacians of Cayley graphs over 
 to the weights of codewords, we also give the first proof of the existence of spectral Cayley graph sparsifiers overby Cayley graphs, i.e., where we sparsify the set of generators to nearly-optimal size. Additionally, this work can be viewed as a continuation of a line of works on building sparsifiers for constraint satisfaction problems (CSPs); this result shows that there exist near-linear size sparsifiers for CSPs over 𝔽p-valued variables whose unsatisfying assignments can be expressed as the zeros of a linear equation modulo a primep.As an application we give a full characterization of ternary Boolean CSPs (CSPs where the underlying predicate acts on three Boolean variables) that allow for near-linear size sparsification. This makes progress on a question posed by Kogan and Krauthgamer (ITCS 2015) asking which CSPs allow for near-linear size sparsifiers (in the number of variables).At the heart of our result is a codeword counting bound that we believe is of independent interest. Indeed, extending Karger's cut-counting bound (SODA 1993), we show a novel decomposition theorem of linear codes: we show that every linear code has a (relatively) small subset of coordinates such that after deleting those coordinates, the code on the remaining coordinates has a smooth upper bound on the number of codewords of small weight. Using the deleted coordinates in addition to a (weighted) random sample of the remaining coordinates now allows us to sparsify the whole code. The proof of this decomposition theorem extends Karger's proof (and the contraction method) in a clean way, while enabling the extensions listed above without any additional complexity in the proofs. 
 *The full version of the paper can be accessed at https://arxiv.org/pdf/2311.00788.pdf 
 Full Access 
 Linear-Sized Sparsifiers via Near-Linear Time Discrepancy Theory 
 href="/author/Jambulapati%2C+Arun" - Arun Jambulapati | , 
 href="/author/Reis%2C+Victor" - Victor Reis | , 
 href="/author/Tian%2C+Kevin" - Kevin Tian 
 pp.5169–5208 
 Abstract 
 PDF 
 AbstractDiscrepancy theory has provided powerful tools for producing higher-quality objects which “beat the union bound” in fundamental settings throughout combinatorics and computer science. However, this quality has often come at the price of more computationally-expensive algorithms. We introduce a new framework for bridging this gap, by allowing for the efficient implementation of discrepancy-theoretic primitives. Our framework repeatedly solves regularized optimization problems to low accuracy to approximate the partial coloring method of [Rot17], and simplifies and generalizes recent work of [JSS23] on fast algorithms for Spencer's theorem. In particular, our framework only requires that the discrepancy body of interest has exponentially large Gaussian measure and is expressible as a sublevel set of a symmetric, convex function. We combine this framework with new tools for proving Gaussian measure lower bounds to give improved algorithms for a variety of sparsification and coloring problems. 
 As a first application, we use our framework to obtain anÕ(m·ɛ-3.5) time algorithm for constructing anɛ-approximate spectral sparsifier of anm-edge graph, matching the sparsity of [BSS14] up to constant factors and improving upon theÕ(m·ɛ-6.5) runtime of [LS17]. We further give a state-of-the-art algorithm for constructing graph ultrasparsifiers and an almost-linear time algorithm for constructing linear-sized degree- preserving sparsifiers via discrepancy theory; in the latter case, such sparsifiers were not known to exist previously. We generalize these results to their analogs in sparsifying isotropic sums of positive semidefinite matrices. Finally, to demonstrate the versatility of our technique, we obtain a nearly-input-sparsity time constructive algorithm for Spencer's theorem (where we recover a recent result of [JSS23]). 
 Full Access 
 Quotient sparsification for submodular functions 
 href="/author/Quanrud%2C+Kent" - Kent Quanrud 
 pp.5209–5248 
 Abstract 
 PDF 
 AbstractGraph sparsification has been an important topic with many structural and algorithmic consequences. Recently hypergraph sparsification has come to the fore and has seen exciting progress. In this paper we take a fresh perspective and show that they can be both be derived as corollaries of a general theorem on sparsifying matroids and monotone submodular functions. 
 Quotients of matroids and monotone submodular functions generalizek-cuts in graphs and hypergraphs. We show that a weighted ground set of a monotone submodular functionfcan be sparsified while approximately preserving the weight of every quotient offwith high probability in randomized polynomial time. 
 This theorem conceptually unifies cut sparsifiers for undirected graphs [7] with other interesting applications. One basic application is to reduce the number of elements in a matroid while preserving the weight of every quotient of the matroid. For hypergraphs, the theorem gives an alternative approach to the hypergraph cut sparsifiers obtained recently in [12], that also preserves allk-cuts. Another application is to reduce the number of points in a set system while preserving the weight of the union of every collection of sets. We also present algorithms that sparsify hypergraphs and set systems in nearly linear time, and sparsify matroids in nearly linear time and queries in the rank oracle model. 
 *Dept. of Computer Science, Purdue University, West Lafayette, IN 47907. Supported in part by NSF grant CCF-2129816. 
 Full Access 
 Induced-Minor-Free Graphs: Separator Theorem, Subexponential Algorithms, and Improved Hardness of Recognition 
 href="/author/Korhonen%2C+Tuukka" - Tuukka Korhonen | , 
 href="/author/Lokshtanov%2C+Daniel" - Daniel Lokshtanov 
 pp.5249–5275 
 Abstract 
 PDF 
 AbstractA graphGcontains a graphHas an induced minor ifHcan be obtained fromGby vertex deletions and edge contractions. The class ofH-induced-minor-free graphs generalizes the class ofH-minor-free graphs, but unlikeH-minor-free graphs, it can contain dense graphs. We show that if ann-vertexm-edge graphGdoes not contain a graphHas an induced minor, then it has a balanced vertex separator of size 
 , where theOH(·)-notation hides factors depending onH. More precisely, our upper bound for the size of the balanced separator is. We give an algorithm for finding either an induced minor model ofHinGor such a separator in randomized polynomial-time. We apply this to obtain subexponentialtime algorithms onH-induced-minor-free graphs for a large class of problems including maximum independent set, minimum feedback vertex set, 3-coloring, and planarization.For graphsHwhere every edge is incident to a vertex of degree at most 2, our results imply a 
 time algorithm for testing ifGcontainsHas an induced minor. Our second main result is that there exists a fixed treeT, so that there is notime algorithm for testing if a givenn-vertex graph containsTas an induced minor unless the Exponential Time Hypothesis (ETH) fails. Our reduction also gives NP-hardness, which solves an open problem asked by Fellows, Kratochvíl, Middendorf, and Pfeiffer [Algorithmica, 1995], who asked if there exists a fixed planar graphHso that testing forHas an induced minor is NP-hard.*The research leading to these results has received funding from the Research Council of Norway via the project BWCA (grant no. 314528) and NSF award CCF-2008838. 
 Full Access 
 Odd Cycle Transversal onP5-free Graphs in Quasi-polynomial Time 
 href="/author/Agrawal%2C+Akanksha" - Akanksha Agrawal | , 
 href="/author/Lima%2C+Paloma+T" - Paloma T. Lima | , 
 href="/author/Lokshtanov%2C+Daniel" - Daniel Lokshtanov | , 
 href="/author/Saurabh%2C+Saket" - Saket Saurabh | , 
 href="/author/Sharma%2C+Roohani" - Roohani Sharma 
 pp.5276–5290 
 Abstract 
 PDF 
 AbstractAnindependent setin a graphGis a set of pairwise non-adjacent vertices. A graphGisbipartiteif its vertex set can be partitioned into two independent sets. In the Odd Cycle Transversal problem, the input is a graphGalong with a weight function w associating a rational weight with each vertex, and the task is to find a smallest weight vertex subsetSinGsuch thatG—Sis bipartite; the weight of 
 . We show that Odd Cycle Transversal admits an algorithm with running timeon graphs excludingP5(a path on five vertices) as an induced subgraph. The problem was previously known to be polynomial time solvable onP4-free graphs and NP-hard onP6-free graphs [Dabrowski, Feghali, Johnson, Paesani, Paulusma and Rzążewski, Algorithmica 2020]. Bonamy, Dabrowski, Feghali, Johnson and Paulusma [Algorithmica 2019] posed the existence of a polynomial time algorithm onP5-free graphs as an open problem, this was later re-stated by Rzążewski [Dagstuhl Reports, 9(6): 2019] and by Chudnovsky, King, Pilipczuk, Rzążewski, and Spirkl [SIDMA 2021], who gave an algorithm with running time. While ourtime algorithm falls short of completely resolving the complexity status of Odd Cycle Transversal onP5-free graphs it shows that the problem is not NP-hard unless every problem in NP is solvable in quasi-polynomial time.*Funding acknowledgements: Agrawal is supported by SERB Startup Research Grant, no. SRG/2022/000962; Lima is supported by the Independent Research Fund Denmark grant agreement number 2098-00012B; Lokshtanov is supported by NSF grant CCF-2008838; Saurabh is supported by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme grant agreement number 819416, and by a Swarnajayanti Fellowship (No. DST/SJF/MSA01/2017-18). 
 Full Access 
 Sparse induced subgraphs inP6-free graphs 
 href="/author/Chudnovsky%2C+Maria" - Maria Chudnovsky | , 
 href="/author/McCarty%2C+Rose" - Rose McCarty | , 
 href="/author/Pilipczuk%2C+Marcin" - Marcin Pilipczuk | , 
 href="/author/Pilipczuk%2C+Micha%C5%82" - Michał Pilipczuk | , 
 href="/author/Rz%C4%85%C5%BCewski%2C+Pawe%C5%82" - Paweł Rzążewski 
 pp.5291–5299 
 Abstract 
 PDF 
 AbstractWe prove that a number of computational problems that ask for the largest sparse induced subgraph satisfying some property definable in CMSO2logic, most notably Feedback Vertex Set, are polynomial-time solvable in the class ofP6-free graphs. This generalizes the work of Grzesik, Klimošová, Pilipczuk, and Pilipczuk on the Maximum Weight Independent Set problem inP6-free graphs [SODA 2019, TALG 2022], and of Abrishami, Chudnovsky, Pilipczuk, Rzążewski, and Seymour on problems inP5-free graphs [SODA 2021]. 
 The key step is a new generalization of the framework ofpotential maximal cliques.We show that instead of listing a large family of potential maximal cliques, it is sufficient to only list theircarvers: vertex sets that contain the same vertices from the sought solution and have similar separation properties. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2307.07330. This research is a part of a project that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme Grant Agreement 714704 (Rose, Marcin) and 948057 (Michał, Paweł). Maria is supported by NSF- EPSRC Grant DMS-2120644 and by AFOSR grant FA9550-22-1-008. Rose is also supported by NSF Grant DMS-2202961. Marcin is also partially funded by BARC, supported by the VILLUM Foundation grant 16582, and by Polish National Science Centre SONATA BIS-12 grant number 2022/46/E/ST6/00143. 
 Full Access 
 Shortcut Partitions in Minor-Free Graphs: Steiner Point Removal, Distance Oracles, Tree Covers, and More 
 href="/author/Chang%2C+Hsien-Chih" - Hsien-Chih Chang | , 
 href="/author/Conroy%2C+Jonathan" - Jonathan Conroy | , 
 href="/author/le%2C+Hung" - Hung Le | , 
 href="/author/Milenkovi%C4%87%2C+Lazar" - Lazar Milenković | , 
 href="/author/Solomon%2C+Shay" - Shay Solomon | , 
 href="/author/Than%2C+Cuong" - Cuong Than 
 pp.5300–5331 
 Abstract 
 PDF 
 AbstractThe notion ofshortcut partition,introduced recently by Chang, Conroy, Le, Milenković, Solomon, and Than [CCL+23], is a new type of graph partition into low-diameter clusters. Roughly speaking, the shortcut partition guarantees that for every two verticesuandvin the graph, there exists a path betweenuandvthat intersects only a few clusters. They proved that any planar graph admits a shortcut partition and gave several applications, including a construction of tree cover for arbitrary planar graphs with stretch 1 +ɛandO(1) many trees for any fixedɛ∈ (0,1). However, the construction heavily exploits planarity in multiple steps, and is thus inherently limited to planar graphs. 
 In this work, we breach the “planarity barrier” to construct a shortcut partition forKr-minor-free graphs for anyr. To this end, we take a completely different approach — our key contribution is a novel deterministic variant of thecop decompositionin minor-free graphs [And86, AGG+14]. Our shortcut partition forKr-minor-free graphs yields several direct applications. Most notably, we construct the firstoptimaldistance oracle forKr-minor-free graphs, with 1 +ɛstretch, linear space, and constant query time for any fixedɛ∈ (0,1). The previous best distance oracle [AG06] usesO(nlogn) space andO(logn) query time, and its construction relies on Robertson-Seymour structural theorem and other sophisticated tools. We also obtain the first tree cover ofO(1) size for minor-free graphs with stretch 1 +ɛ, while the previous best (1 +ɛ)-tree cover has sizeO(log2n) [BFN19]. 
 As a highlight of our work, we employ our shortcut partition to resolve a major open problem — theSteiner point removal (SPR)problem: Given any setKofterminalsin an arbitrary edge-weighted planar graphG, is it possible to construct a minorMofGwhose vertex set isK, which preserves the shortest-path distances between all pairs of terminals inGup to aconstantfactor? Positive answers to the SPR problem were only known for very restricted classes of planar graphs: trees [Gup01], outerplanar graphs [BG08], and series-parallel graphs [HL22]. We resolve the SPR problem in the affirmative for any planar graph, and more generally for anyKr-minor-free graph for any fixedr. To achieve this result, we prove the following general reduction and combine it with our new shortcut partition: For any graph family closed under taking subgraphs, the existence of a shortcut partition yields a positive solution to the SPR problem. 
 Full Access 
 VC Set Systems in Minor-free (Di)Graphs and Applications 
 href="/author/le%2C+Hung" - Hung Le | , 
 href="/author/Wulff-Nilsen%2C+Christian" - Christian Wulff-Nilsen 
 pp.5332–5360 
 Abstract 
 PDF 
 AbstractA recent line of work on VC set systems in minor-free (undirected) graphs, starting from Li and Parter [LP19], who constructed a new VC set system for planar graphs, has given surprising algorithmic results [LP19, Le23, DHV20, FHMWN20]. In this work, we initialize a more systematic study of VC set systems for minor-free graphs and their applications in both undirected graphs and directed graphs (a.k.adigraphs). More precisely: 
 1. We propose a new variant of the Li-Parter set system forundirectedgraphs. Our set system settles two weaknesses of the Li-Parter set system: the terminals can be anywhere, and the graph can beKh-minor-free for any fixedh. We obtain several algorithmic applications, notably: (i) the first exact distance oracle for unweighted and undirectedKh-minor-free graphs that has truly subquadratic space and constant query time, and (ii) the first truly subquadratic time algorithm for computing Wiener index ofKh-minor-free graphs, resolving an open problem posed by Ducoffe, Habib, and Viennot [DHV20]. 
 2. We extend our set system toKh-minor-freedigraphsand show that its VC dimension isO(h2). We use this result to design the first subquadratic time algorithm for computing (unweighted) diameter and all-vertices eccentricities inKh-minor-free digraphs. 
 3. We show that the system ofdirectedballs in minor-free digraphs has VC dimension at mosth— 1. We then present a new technique to exploit the VC system of balls, giving the first exact distance oracle for unweighted minor-free digraphs that has truly subquadratic space and logarithmic query time. 
 4. On the negative side, we show that VC set system constructed from shortest path trees of planar digraphs does not have a bounded VC dimension. This leaves an intriguing open problem: determine a necessary and sufficient condition for a set system derived from a minor-free graph to have a bounded VC dimension. 
 The highlight of our work is the results for digraphs, as we are not aware of known algorithmic work on constructing and exploiting VC set systems for digraphs. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2304.01790 
 Book Details | Published:2024 
 eISBN:978-1-61197-791-2 
 https://doi.org/10.1137/1.9781611977912 
 Book Series Name:Proceedings 
 Book Code:PRDA24 
 Book Pages:xx + 5360 
 BibTex 
 Recommended Content 
 Society for Industrial and 
 Applied Mathematics 
 Society for Industrial and Applied Mathematics 
 3600 Market Street, 6th Floor 
 Philadelphia, PA 19104 
 USA 
 © 2025 Society for Industrial and Applied Mathematics 
 Browse | Browse | Journals 
 E-books 
 Bookstore 
 Proceedings 
 Alerts | Alerts | Sign up/Manage Email Alerts 
 Information | Information | href="/journal-authors" - For Journal Authors 
 href="/book-authors" - For Book Authors 
 For Librarians 
 Help 
 Terms of Use & Privacy Policy 
 About | About | SIAM 
 Join SIAM 
 Donate to SIAM 
 Request Username 
 Can't sign in? Forgot your username? 
 Enter your email address below and we will send you your username 
 EmailClose 
 If the address matches an existing account you will receive an email with instructions to retrieve your username 
 Register 
 Email*Already have an account?Change Password 
 Old PasswordNew PasswordToo ShortWeakMediumStrongVery StrongToo LongYour password must have 2 characters or more and contain 3 of the following: 
 a lower case character, 
 an upper case character, 
 a special character 
 or a digit 
 Too ShortPassword Changed Successfully 
 Your password has been changed 
 Login 
 Email*Password*Forgot your password?Create AccountKeep me logged inCreate AccountLog in via your institutionCan't sign in? Forgot your password? 
 Enter your email address below and we will send you the reset instructions 
 EmailCancelIf the address matches an existing account you will receive an email with instructions to reset your password 
 CloseVerify Phone 
 Enter the verification codeCancelCongrats! 
 Your Phone has been verified 
 closeCopy link✓ 
 Thanks for sharing! 
 Find any service 
 AddToAny 
 More…

