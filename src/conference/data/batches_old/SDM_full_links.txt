Conference full name: SIAM International Conference on Data Mining (SDM)

1. Website of SDM_2: https://www.siam.org/conferences-events/siam-conferences/sdm25/
Website information of SDM_2:

Skip to main contentJoin SIAM 
 Donate 
 Log In 
 Journals 
 Books 
 SIAM Engage 
 Join SIAM 
 Donate 
 Log In 
 SIAM News 
 Activity Groups 
 Prizes & Awards 
 Log In 
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
 Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
 SIAM Journal on Applied Algebra and Geometry 
 SIAM Journal on Applied Dynamical Systems 
 SIAM Journal on Applied Mathematics 
 SIAM Journal on Computing 
 SIAM Journal on Control and Optimization 
 SIAM Journal on Discrete Mathematics 
 SIAM Journal on Financial Mathematics 
 SIAM Journal on Imaging Sciences 
 SIAM Journal on Life Sciences 
 SIAM Journal on Mathematical Analysis 
 SIAM Journal on Mathematics of Data Science 
 SIAM Journal on Matrix Analysis and Applications 
 SIAM Journal on Numerical Analysis 
 SIAM Journal on Optimization 
 SIAM Journal on Scientific Computing 
 SIAM / ASA Journal on Uncertainty Quantification 
 Theory of Probability and Its Applications 
 href="/publications/siam-journals/siam-undergraduate-research-online-siuro/" - SIAM Undergraduate Research Online 
 SIAM Books 
 Our textbooks and monographs are indispensable to researchers, faculty, and students around the world. 
 SIAM Books 
 SIAM News 
 The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science. 
 SIAM News 
 Reports 
 Proceedings 
 Subscriptions & Ordering 
 Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
 Visiting Lecturer Program 
 MathWorks Math Modeling (M3) Challenge 
 href="/programs-initiatives/programs/siam-simons-undergraduate-summer-research-program/" - SIAM-Simons Undergraduate Summer Research Program 
 SIAM Science Policy Fellowship 
 MGB-SIAM Early Career Fellowship 
 SIAM Postdoctoral Support Program 
 Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
 See All Programs 
 Professional Development | Careers in Applied Mathematics 
 Career Resources 
 Job Board 
 Internships 
 Prizes and Awards | Deadline Calendar 
 SIAM Fellows Program 
 Policy & Procedures 
 Congratulations to the 2025 Class of SIAM Fellows! 
 These distinguished members were nominated in recognition of their outstanding research and service to the community. 
 href="/publications/siam-news/articles/siam-announces-2025-class-of-fellows/" - Congratulations to the 2025 Class of SIAM Fellows! 
 Industry 
 Equity, Diversity, & Inclusion 
 Education Resources 
 Science Policy 
 Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
 Section Meetings 
 Webinars & Seminars 
 Workshops 
 Career Fairs 
 Cooperating Conferences 
 Archive 
 See all Events 
 Conference Support | Travel & Registration Support 
 Child Care Grants 
 About SIAM Conferences & Events | For Sponsors & Exhibitors 
 Conference Guidelines 
 Featured Videos & Lectures 
 Save the Date for AN25! 
 The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada. 
 Save the Date for AN25! 
 Membership | Toggle sub-menu | Individual Membership | Join 13,000+ applied mathematicians and computational and data scientists from around the world. 
 Learn More 
 Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
 Learn More 
 Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
 Get Your Questions Answered 
 Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
 Sections 
 Student Chapters 
 SIAM Engage Online Community 
 Ways to Participate | Advocate to Support Our Community 
 href="/publications/siam-journals/" - Become an Author, Editor, or Referee 
 Network and Present at a Conference 
 Nominate for Prizes 
 Serve on Committees 
 href="/publications/siam-news/about-siam-news/submission-guidelines/" - Write for SIAM News 
 Ways to Support | Become a Sponsor 
 Donate to SIAM 
 Spread the Word 
 About Us | Toggle sub-menu | Overview 
 Mission & History 
 Governance & Leadership 
 Committees 
 Staff 
 Collaborations 
 Bylaws & Reports 
 Policies & Guidelines 
 Join SIAM 
 Contact Us 
 Back to topHome 
 Conferences & Events 
 SIAM Conferences 
 SDM25 
 In Person 
 SIAM Conferences 
 SIAM International Conference on Data Mining (SDM25) 
 Online RegistrationEvent Details 
 May 1–3 , 2025 
 Alexandria Virginia, U.S. 
 The Westin Alexandria Old Town Hotel 
 Stay Connected 
 Facebook 
 href="https://twitter.com/search?q=%23SIAMSDM25&src=typed_query" - #SIAMSDM25 
 In This Section 
 href="/conferences-events/siam-conferences/sdm25/registration/" - Registration 
 href="/conferences-events/siam-conferences/sdm25/lodging-support/" - Lodging & Support 
 href="/conferences-events/siam-conferences/sdm25/program/" - Program 
 href="/conferences-events/siam-conferences/sdm25/submissions/" - Submissions 
 More 
 Deadlines 
 href="/conferences-events/siam-conferences/sdm25/submissions/" - Deadline Passed: Abstract Submissions | September 27, 2024 
 href="/conferences-events/siam-conferences/sdm25/submissions/" - Deadline Passed: Full Paper Submissions | October 4, 2024 
 href="/conferences-events/siam-conferences/sdm25/submissions/" - Deadline Passed: Workshop and Tutorial Proposals | October 11, 2024 
 href="/conferences-events/siam-conferences/sdm25/submissions/" - Deadline Passed: Blue Sky Idea Submissions Deadline | October 25, 2024 
 Deadline Passed: Travel Support Application Deadline | February 3, 2025 
 href="/conferences-events/siam-conferences/sdm25/registration/" - Register Now: Early Registration Deadline | April 3, 2025 
 href="/conferences-events/siam-conferences/sdm25/lodging-support/hotel-transportation/" - Reserve Now: Hotel Reservation Deadline Extended | April 7, 2025 
 href="/conferences-events/siam-conferences/sdm25/program/special-events/" - Nominate Now: IBM Early Data Mining Research Award | March 21, 2025 
 About the Conference 
 This meeting is sponsored by theSIAM Activity Group on Data Science. 
 The SIAM International Conference on Data Mining (SDM25) invites submissions of high-quality research papers that present original results on data mining algorithms and their applications. Data mining is a core process within computing and statistics, aimed at discovering valuable knowledge from data. This field has significant applications across various domains including science, engineering, healthcare, business, and medicine. Datasets in these fields are typically large, complex, and noisy, necessitating sophisticated, high-performance analysis techniques grounded in sound theoretical and statistical principles. SDM25 provides a venue for researchers who are addressing these problems to present their work in a peer-reviewed forum. It also provides an ideal setting for graduate students to network and get feedback for their work (as part of the doctoral forum) and everyone new to the field to learn about cutting-edge research by hearing outstanding invited speakers and attending presentations, tutorials and a number of focused workshops. The proceedings of the conference are published in archival form and are also made available on the SIAM website. 
 Topics of Interest: 
 We welcome contributions addressing all aspects of data mining, including but not limited to: 
 Methods and Algorithms 
 Anomaly & outlier detection 
 Big data & large-scale systems 
 Causal inference 
 Classification & semi-supervised learning 
 Clustering & unsupervised learning 
 Data cleaning & integration 
 Deep learning & representation learning 
 Feature extraction, selection and dimensionality reduction 
 Mining data streams 
 Mining graphs & complex data 
 Mining on emerging architectures & data clouds 
 Mining semi structured data 
 Mining spatial & temporal data 
 Mining text, web & social media 
 Optimization methods 
 Parallel and distributed methods 
 Pattern mining 
 Probabilistic & statistical methods 
 Scalable & high-performance mining 
 Show moreApplications of Data Mining 
 Business and marketing 
 Healthcare 
 Scientific data 
 Scientific data 
 Human Factors and Social Issues 
 Ethics of data mining 
 Intellectual ownership 
 Intellectual ownership 
 Privacy and fairness models 
 Privacy preserving data mining 
 Risk analysis and risk management 
 Transparency and algorithmic bias 
 User interfaces and visual analytics 
 General Co-Chairs 
 Vagelis Papalexakis 
 University of California, Riverside U.S. 
 Matteo Riondato 
 Amherst College, U.S. 
 Program Co-Chairs 
 Tim Weninger 
 University of Notre Dame, U.S. 
 Elena Zheleva 
 University of Illinois at Chicago, U.S. 
 Local Chair 
 Carlotta Domeniconi 
 George Mason University, U.S. 
 Workshops Co-Chairs 
 Qi Li 
 Iowa State University, U.S. 
 Hua Wei 
 Arizona State University, U.S. 
 Tutorials Chair 
 Stefan Neumann 
 TU Wien, Austria 
 Doctoral Forum Co-Chairs 
 Tyler Derr 
 Vanderbilt University, U.S. 
 Li Zhang 
 University of Texas Rio Grande Valley, U.S. 
 Panel Chair 
 Petko Bogdanov 
 University at Albany SUNY, U.S. 
 Publicity Co-Chairs 
 Jumanah S. Alshehri 
 Imam Abdulrahman bin Faisal University, Saudi Arabia 
 Matthew Facciani 
 University of Notre Dame, U.S. 
 Willaim H. Hsu 
 Kansas State University, U.S. 
 Awards Chair - TBA 
 Aris Gionis 
 KTH Royal Institute of Technology, Sweden 
 Proceedings Co-Chairs 
 Michael Yankoski 
 University of William and Mary, U.S. 
 Sourav Medya 
 University of Illinois Chicago, U.S 
 Blue Sky Idea Track Chair 
 Wei Ding 
 University of Massachusetts, U.S. 
 Sponsorship Co-Chairs 
 Sanmitra Bhattacharya 
 Deloitte, U.S. 
 Neil Shah 
 Snap, U.S. 
 Steering Committee Chair 
 Zoran Obradovic 
 Temple University, U.S. 
 Get Involved 
 Sponsor, exhibit, or check out past content in our video and presentation archive. 
 Ways to Sponsor 
 SIAM invites you to show support of this conference through sponsorship opportunities ranging from support of receptions, audio-video needs, to awards for student travel, and more. 
 Ways to Exhibit 
 Learn about opportunities to become an exhibitor at a SIAM conference. 
 Featured Lectures & Videos 
 View slides, recordings, and video from past SIAM conferences. 
 Become a Member 
 SIAM members get 20-30% off registration for our conferences, plus deep discounts on SIAM books, journals, activity group membership, and more. Start reaping the benefits! 
 Thank You to Our Sponsors 
 Funding Agency Support 
 SIAM and the Organizing Committee wish to extend their thanks and appreciation to theU.S. National Science Foundationfor supporting this conference. 
 Make the Most of Your Experience 
 About SIAM Conferences 
 Find all of the information you'll need to prepare for and navigate SIAM conferences, including conference guidelines and how to propose a new conference. 
 Explore Conferences 
 Statement on Equity, Diversity, and Inclusion 
 As a professional society, SIAM is committed to empowering equitable, diverse, and inclusive participation in all aspects of our community. SIAM will provide a climate that encourages the open expression and exchange of ideas, that is free from all forms of discrimination, harassment, and retaliation, and that is welcoming and comfortable to all members and to those who participate in its activities. 
 In pursuit of this commitment, SIAM is dedicated to the philosophy of equality of opportunity and treatment for all participants regardless of gender, gender identity or expression, sexual orientation, race, color, national or ethnic origin, religion or religious belief, age, marital status, disabilities, veteran status, and field of expertise. 
 This philosophy extends from SIAM’s governing structures and bodies to its conferences, publications, awards, and to all its organized activities. 
 We expect all members of SIAM and participants in SIAM activities to work towards this commitment to equity, diversity, and inclusion. 
 If you have experienced or observed behavior that is not consistent with the principles expressed above, you are encouraged to report any violation using the SIAM hotline, hosted by the third-party hotline provider, EthicsPoint. The information you provide will be sent to us by EthicsPoint on a totally confidential and anonymous basis if you should choose. You have our guarantee that your comments will be heard.Please submit reports. 
 Read all ofSIAM's conference guidelines and policies, including the Statement on Potentially Offensive Material 
 Contact Us 
 Questions about SIAM conferences? Get in touch with our staff. 
 Contact SIAM Conference Staff 
 3600 Market Street6th FloorPhiladelphia, PA 19104 USAFacebook 
 Twitter 
 Youtube 
 LinkedIn 
 About SIAM | Mission & History 
 Governance & Leadership 
 Committees 
 Staff 
 Collaborations 
 Code of Conduct 
 Policies & Guidelines 
 Jobs at SIAM 
 Contact Us 
 Membership | Member Benefits 
 Become a Member 
 Renew Your Membership 
 Connect with a Community 
 Ways to Participate 
 Jobs in STEM 
 Share & Support | Newsroom 
 Advertise with Us 
 Become a Sponsor 
 Post a Job 
 Information for Librarians 
 Subscribe to Our Emails 
 © 2025 Society for Industrial and Applied Mathematics 
 Terms & Conditions 
 Privacy

2. Website of SDM_2: https://epubs.siam.org/doi/book/10.1137/1.9781611978032
Website information of SDM_2:

Skip to main content 
 SearchSearch 
 This BookThis Book 
 Anywhere 
 Books 
 Journals 
 Proceedings 
 Quick Search in BooksEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Quick Search anywhereEnter Search TermsSearch 
 Advanced Search 
 0Register / Sign In 
 Access via your Institution 
 Skip main navigationClose Drawer MenuOpen Drawer MenuMenuJournals | SIAM Review 
 Multiscale Modeling & Simulation 
 SIAM Journal on Applied Algebra and Geometry 
 SIAM Journal on Applied Dynamical Systems 
 SIAM Journal on Applied Mathematics 
 SIAM Journal on Computing 
 SIAM Journal on Control and Optimization 
 SIAM Journal on Discrete Mathematics 
 SIAM Journal on Financial Mathematics 
 SIAM Journal on Imaging Sciences 
 SIAM Journal on Mathematical Analysis 
 SIAM Journal on Mathematics of Data Science 
 SIAM Journal on Matrix Analysis and Applications 
 SIAM Journal on Numerical Analysis 
 SIAM Journal on Optimization 
 SIAM Journal on Scientific Computing 
 SIAM/ASA Journal on Uncertainty Quantification 
 Theory of Probability & Its Applications 
 Locus 
 E-books 
 Bookstore 
 Proceedings 
 href="#" - For Authors | href="/journal-authors" - Journal Authors 
 href="/book-authors" - Book Authors 
 For Librarians 
 Collections | href="/topic/topics/topic-epidemiology" - Epidemiology Collection 
 href="/topic/topics/topic-highimpact" - High Impact Article Collection 
 JOIN SIAM 
 HELP/CONTACT US 
 Proceedings 
 Proceedings of the 2024 SIAM International Conference on Data Mining (SDM) 
 Editor(s):href="/author/Shekhar%2C+Shashi" - Shashi Shekhar | , 
 href="/author/Papalexakis%2C+Vagelis" - Vagelis Papalexakis | , 
 href="/author/Gao%2C+Jing" - Jing Gao | , 
 href="/author/Jiang%2C+Zhe" - Zhe Jiang | , and 
 href="/author/Riondato%2C+Matteo" - Matteo Riondato 
 Proceedings Series | Algorithm Engineering & Experiments (ALENEX) 
 Algorithmic Principles of Computer Systems-APOCS 
 Analytic Algorithmics and Combinatorics (ANALCO) 
 Applied and Computational Discrete Algorithms (ACDA) 
 Combinatorial Scientific Computing (CSC) 
 Control and its Applications 
 Data Mining 
 Discrete Algorithms (SODA) 
 International Congress of Industrial and Applied Mathematics (ICIAM) 
 International Meshing Roundtable (IMR) 
 Mathematics for Industry 
 Parallel Processing for Scientific Computing (PP) 
 Simplicity in Algorithms-SOSA 
 ShareShare onFacebook 
 Twitter 
 LinkedIn 
 Email 
 HomeProceedingshref="/doi/book/10.1137/1.9781611978032" - Proceedings of the 2024 SIAM International Conference on Data Mining (SDM)
Description | Data mining is an important tool in science, engineering, industrial processes, healthcare, business, and medicine. The datasets in these fields are large, complex, and often noisy. Extracting knowledge requires the use of sophisticated, high performance and principled analysis techniques and algorithms, based on sound theoretical and statistical foundations. These techniques in turn require implementations that are carefully tuned for performance; powerful visualization technologies; interface systems that are usable by scientists, engineers, and physicians as well as researchers; and infrastructures that support them. 
 This conference provides a venue for researchers who are addressing these problems to present their work in a peer-reviewed forum. It also provides an ideal setting for graduate students and others new to the field to learn about cutting-edge research by hearing outstanding invited speakers and attending presentations and tutorials (included with conference registration). A set of focused workshops are also held on the last day of the conference. The proceedings of the conference are published in archival form, and are also made available on the SIAM web site. 
 CHAPTERS 
 CHAPTERS 
 Select AllFor selected items: 
 Full Access 
 Front Matter 
 pp.i–xii 
 Abstract 
 PDF 
 AbstractFrontmatter includes preface/ acknowledgments and table of contents 
 Full Access 
 Local Differential Privacy in Graph Neural Networks: a Reconstruction Approach 
 href="/author/Bhaila%2C+Karuna" - Karuna Bhaila | , 
 href="/author/Huang%2C+Wen" - Wen Huang | , 
 href="/author/Wu%2C+Yongkai" - Yongkai Wu | , 
 href="/author/Wu%2C+Xintao" - Xintao Wu 
 pp.1–9 
 Abstract 
 PDF 
 AbstractGraph Neural Networks have achieved tremendous success in modeling complex graph data in a variety of applications. However, there are limited studies investigating privacy protection in GNNs. In this work, we propose a learning framework that can provide local node privacy for users, while incurring low utility loss. We focus on a decentralized notion of Differential Privacy, namely Local Differential Privacy, and apply randomization mechanisms to perturb both feature and label data at the node level before they are collected by a server for model training. Specifically, we investigate the application of randomization mechanisms in high-dimensional feature settings and propose an LDP protocol with strict privacy guarantees. Based on frequency estimation in statistical analysis of randomized data, we develop reconstruction methods to approximate features and labels from perturbed data. We also formulate this learning framework to utilize frequency estimates of graph clusters to supervise the training procedure at a sub-graph level. Extensive experiments on real-world and semi-synthetic datasets demonstrate the validity of our proposed model. 
 Full Access 
 Genius: Subteam Replacement with Clustering-based Graph Neural Networks 
 href="/author/Hu%2C+Chuxuan" - Chuxuan Hu | , 
 href="/author/Zhou%2C+Qinghai" - Qinghai Zhou | , 
 href="/author/Tong%2C+Hanghang" - Hanghang Tong 
 pp.10–18 
 Abstract 
 PDF 
 AbstractThe state of the art forsubteam replacement, based on random walk graph kernels, encounter the following limitations: (1) ineffective in capturing fine-grained node feature correlations, (2) inefficient without proper pruning mechanisms, and (3) limited applicability to single-member or equal-sized subteam replacements. In this paper, we address these limitations by proposing Genius, a clustering-based graph neural network (GNN) framework that (1) captures team social network knowledge forsubteam replacementby deploying team-level attention GNNs (TAGs) and self-supervisedpositive team contrastingtraining scheme, (2) generates unsu-pervised team social network member clusters to prune candidates for fast computation, and (3) incorporates asubteam recommenderthat selects new subteams of flexible sizes. We demonstrate the efficacy of the proposed method in terms of (1)effectiveness: being able to select better subteam members that significantly increase the similarity between the new and original teams, and (2)efficiency: achieving more than 600× speed-up in average running time. 
 Full Access 
 Laplacian Score Benefit Adaptive Filter Selection for Graph Neural Networks 
 href="/author/Wang%2C+Yewen" - Yewen Wang | , 
 href="/author/Zhang%2C+Shichang" - Shichang Zhang | , 
 href="/author/Cho%2C+John+Junghoo" - John (Junghoo) Cho | , 
 href="/author/Sun%2C+Yizhou" - Yizhou Sun 
 pp.19–27 
 Abstract 
 PDF 
 AbstractGraph Neural Networks (GNNs) have emerged as powerful tools for representation learning on structured data. The graph convolutional filter (GCF) for aggregating neighbor information is shown to be the key factor that leads to GNNs' success. Various GCFs are designed buthow to select the proper filterthat can best benefit the data and the task remains an open problem. In this paper, we introduce the Adaptive Filter Selection (AdaFS) framework that addresses two critical issues: (1) defining a criterion to establish a strong base filter set; and (2) adaptively selecting filters for a specific task, even when labeled data is limited, by employing Laplacian score regularization. We further connect this multiple GCF learning process and the well-developed multiple kernel learning problem to provide a solid rationale for filter selection. With experiments on 9 datasets, AdaFS gets the best average performance. 
 Full Access 
 Self-Similar Graph Neural Network for Hierarchical Graph Learning 
 href="/author/Zhang%2C+Zheng" - Zheng Zhang | , 
 href="/author/Zhao%2C+Liang" - Liang Zhao 
 pp.28–36 
 Abstract 
 PDF 
 AbstractMany real-world networks, such as graph-structured molecules or social networks, exhibit latent hierarchical structures at many different resolutions. Existing hierarchical graph neural networks (GNNs) mainly focus on modifying graph global pooling regions into partitioned clusters, while keeping the convolutional layers unchanged. However, these approaches may suffer from a loss of expressive power in learned representations due to the uncontrolled growth of the neighborhood, leading to a failure in capturing true hierarchies. Furthermore, many real-world hierarchical graphs possess an underlying fractal structure, which is crucial to unraveling the formation mechanism of networks. Unfortunately, existing hierarchical GNNs often overlook this important aspect of graph hierarchy. To tackle these challenges, this paper proposes a generic framework for hierarchical network representation learning. We propose the Self-Similar Graph Neural Network (SS-GNN), which leverages localized representations by excluding redundant nodes and edges. At each resolution of the coarsened map, SS-GNN extracts both intra- and inter-cluster embeddings to preserve the discriminative power of the model with a theoretical guarantee. To exploit the graph fractal structure, we introduce a novel module for measuring self-similarity between resolutions and a characterized objective function for automatic adjustment of model parameters. We demonstrate the strength of our proposed framework through extensive experiments on 13 real-world datasets by outperforming the state-of-the-art GNN models. 
 Full Access 
 PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies 
 href="/author/der%2C+Audrey" - Audrey Der | , 
 href="/author/Yeh%2C+Chin-Chia+Michael" - Chin-Chia Michael Yeh | , 
 href="/author/Zheng%2C+Yan" - Yan Zheng | , 
 href="/author/Wang%2C+Junpeng" - Junpeng Wang | , 
 href="/author/Zhuang%2C+Zhongfang" - Zhongfang Zhuang | , 
 href="/author/Wang%2C+Liang" - Liang Wang | , 
 href="/author/Zhang%2C+Wei" - Wei Zhang | , 
 href="/author/Keogh%2C+Eamonn" - Eamonn Keogh 
 pp.37–45 
 Abstract 
 PDF 
 AbstractIn recent years there has been significant progress in time series anomaly detection. However, after detecting an (perhaps tentative) anomaly, can we explain it? Such explanations would be useful to triage anomalies. For example, in an oil refinery, should we respond to an anomaly by dispatching a hydraulic engineer, or an intern to replace the battery on a sensor? There have been some parallel efforts to explain anomalies, however many proposed techniques produce explanations that are indirect, and often seem more complex than the anomaly they seek to explain. Our review of the literature/checklists/user-manuals used by frontline practitioners in various domains reveals an interesting near-universal commonality. Most practitioners discuss, explain and report anomalies in the following format: The anomaly would be like normal data A, if not for the corruption B. The reader will appreciate that is a type of counterfactual explanation. In this work we introduce a domain agnostic counterfactual explanation technique to produce explanations for time series anomalies. As we will show, our method can produce both visual and text-based explanations that are objectively correct, intuitive and in many circumstances, directly actionable. 
 Full Access 
 An Exemplars-Based Approach for Explainable Clustering: Complexity and Efficient Approximation Algorithms 
 href="/author/Davidson%2C+Ian" - Ian Davidson | , 
 href="/author/Livanos%2C+Michael" - Michael Livanos | , 
 href="/author/Gourru%2C+Antoine" - Antoine Gourru | , 
 href="/author/Walker%2C+Peter" - Peter Walker | , 
 href="/author/Ravi%2C+Julien+Velcin+S+S" - Julien Velcin S. S. Ravi 
 pp.46–54 
 Abstract 
 PDF 
 AbstractExplainable AI (XAI) is an important area but remains relatively understudied for clustering. We propose an explainable-by-design clustering approach that not only finds clusters but also exemplars to explain each cluster. The use of exemplars for understanding is supported by the exemplar-based school of concept definition in psychology. We show that finding a small set of exemplars to explain even a single cluster is computationally intractable; hence, the overall problem is challenging. We develop an approximation algorithm that provides provable performance guarantees with respect to clustering quality as well as the number of exemplars used. This basic algorithm explains all the instances in every cluster whilst another approximation algorithm uses a bounded number of exemplars to allow simpler explanations and provably covers a large fraction of all the instances. Experimental results show that our work is useful in domains involving difficult to understand deep embeddings of images and text. 
 Full Access 
 MISS: Multiclass Interpretable Scoring Systems 
 href="/author/Grzeszczyk%2C+Michal+K" - Michal K. Grzeszczyk | , 
 href="/author/Trzci%C5%84ski%2C+Tomasz" - Tomasz Trzciński | , 
 href="/author/Sitek%2C+Arkadiusz" - Arkadiusz Sitek 
 pp.55–63 
 Abstract 
 PDF 
 AbstractIn this work, we present a novel, machine-learning approach for constructing Multiclass Interpretable Scoring Systems (MISS) - a fully data-driven methodology for generating single, sparse, and user-friendly scoring systems for multi-class classification problems. Scoring systems are commonly utilized as decision support models in healthcare, criminal justice, and other domains where interpretability of predictions and ease of use are crucial. Prior methods for data-driven scoring, such as SLIM (Supersparse Linear Integer Model), were limited to binary classification tasks and extensions to multiclass domains were primarily accomplished via one-versus-all-type techniques. The scores produced by our method can be easily transformed into class probabilities via the softmax function. We demonstrate techniques for dimensionality reduction and heuristics that enhance the training efficiency and decrease the optimality gap, a measure that can certify the optimality of the model. Our approach has been extensively evaluated on datasets from various domains, and the results indicate that it is competitive with other machine learning models in terms of classification performance metrics and provides well-calibrated class probabilities. 
 Full Access 
 XGExplainer: Robust Evaluation-based Explanation for Graph Neural Networks 
 href="/author/Kubo%2C+Ryoji" - Ryoji Kubo | , 
 href="/author/Difallah%2C+Djellel" - Djellel Difallah 
 pp.64–72 
 Abstract 
 PDF 
 AbstractGraph Neural Networks (GNNs) have emerged as a powerful tool for machine learning on graph datasets. Although GNNs can achieve high accuracy on several tasks, the explainability of the predictions remains a challenge. Existing works in GNN explainability aim to extract the key features contributing to the prediction made by a pre-trained model. For instance, perturbation-based methods focus on evaluating the potential explanatory subgraphs using the pre-trained model itself as anevaluatorto determine whether the subgraphs capture the informative features. However, we show that this approach can fail to recognize informative subgraphs that become out-of-distribution relative to the training data. To address this limitation, we propose XGExplainer, a method designed to enhance the robustness of perturbation-based explainers. It achieves this by training a specialized GNN model, i.e., a robust evaluator model that aims at estimating the true graph distribution from randomized subgraphs of the input graph. Our method is geared towards enhancing the generalizability of existing explainability techniques by decoupling the pre-trained model from the evaluator, whose primary role is to gauge the informativeness of potential explanatory subgraphs. Our experiments show that XGExplainer consistently improves the performance of local and global explainer techniques and outperforms state-of-the-art methods on all datasets for node and graph classification tasks. 
 Full Access 
 STES: A Spatiotemporal Explanation Supervision Framework 
 href="/author/Yu%2C+Dazhou" - Dazhou Yu | , 
 href="/author/Chen%2C+Binbin" - Binbin Chen | , 
 href="/author/Li%2C+Yun" - Yun Li | , 
 href="/author/Dhakal%2C+Suman" - Suman Dhakal | , 
 href="/author/Zhang%2C+Yifei" - Yifei Zhang | , 
 href="/author/Liu%2C+Zhenke" - Zhenke Liu | , 
 href="/author/Zhang%2C+Minxing" - Minxing Zhang | , 
 href="/author/Zhang%2C+Jie" - Jie Zhang | , 
 href="/author/Zhao%2C+Liang" - Liang Zhao 
 pp.73–81 
 Abstract 
 PDF 
 AbstractExplanation supervision is a technique that guides a deep learning model to have correct attention during training and thus improve both the interpretability and predictability of the model. However, the exploration of explanation supervision methods for spatiotemporal prediction has been limited. In this paper, we propose a framework for explanation-supervised spatiotemporal forecasting which aims to explicitly incorporate human-annotated spatiotemporal explanations as supervision signals, achieved by introducing a unique objective that integrates human explanations for general spa-tiotemporal predictive models. Specifically, to extend the explanation supervision technique to spatiotemporal prediction, our framework addresses several inherent challenges associated with spatiotemporal data. Firstly, it tackles the difficulty of identifying and correcting the spatiotemporal reasoning process. Secondly, it addresses the challenge of handling the absence of human explanation annotation through interpolation techniques. Lastly, it handles the varying influence of different time points. To evaluate the effectiveness of our approach, we conducted extensive experiments on two real-world spatiotemporal datasets. The results demonstrate the superiority of our methods in improving the interpretability of explanations and the performance of the backbone deep neural network models, surpassing existing state-of-the-art explanation supervision methods. 
 Full Access 
 CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic Dimensionality Guidance 
 href="/author/Zhang%2C+Dongyu" - Dongyu Zhang | , 
 href="/author/Hu%2C+Ruofan" - Ruofan Hu | , 
 href="/author/Rundensteiner%2C+Elke" - Elke Rundensteiner 
 pp.82–90 
 Abstract 
 PDF 
 AbstractDeep neural networks (DNNs) have advanced many machine learning tasks, but their performance is often harmed by noisy labels in real-world data. Addressing this, we introduce CoLafier, a novel approach that uses Local Intrinsic Dimensionality (LID) for learning with noisy labels. CoLafier consists of two subnets: LID-dis and LID-gen. LID-dis is a specialized classifier. Trained with our uniquely crafted scheme, LID-dis consumes both a sample's features and its label to predict the label - which allows it to produce an enhanced internal representation. We observe that LID scores computed from this representation that effectively distinguish between correct and incorrect labels across various noise scenarios. In contrast to LID-dis, LID-gen, functioning as a regular classifier, operates solely on the sample's features. During training, CoLafier utilizes two augmented views per instance to feed both subnets. CoLafier considers the LID scores from the two views as produced by LID-dis to assign weights in an adapted loss function for both subnets. Concurrently, LID-gen, serving as classifier, suggests pseudo-labels. LID-dis then processes these pseudo-labels along with two views to derive LID scores. Finally, these LID scores along with the differences in predictions from the two subnets guide the label update decisions. This dual-view and dual-subnet approach enhances the overall reliability of the framework. Upon completion of the training, we deploy the LID-gen subnet of CoLafier as the final classification model. CoLafier demonstrates improved prediction accuracy, surpassing existing methods, particularly under severe label noise. For more details, see the code at https://github.com/zdy93/CoLafier. 
 Full Access 
 Differences Between Hard and Noisy-labeled Samples: An Empirical Study 
 href="/author/Forouzesh%2C+Mahsa" - Mahsa Forouzesh | , 
 href="/author/Thiran%2C+Patrick" - Patrick Thiran 
 pp.91–99 
 Abstract 
 PDF 
 AbstractExtracting noisy or incorrectly labeled samples from a labeled dataset with hard/difficult samples is an important, and yet under-explored topic. Current methods focus in general either on noisy labels, or on hard samples, but not jointly on both. When the two types of data are both present, these methods often fail to distinguish them, which results in a decline in the overall performance of the model. We propose a systematic empirical study that provides insights into the similarities and more importantly the differences between hard and noisy samples. The method consists of designing synthetic datasets customized with different hardness and noisiness levels for different samples. These controlled experiments pave the way for the evaluation and development of methods that distinguish between hard and noisy samples. We evaluate how various data-partitioning methods are able to remove noisy samples while retaining hard samples. Our study highlights the advantages of using a metric in data partitioning that we propose and callstatic centroid distance.The resulting data-partitioning method outperforms others: It leads to a high test accuracy on models trained on the filtered datasets, as shown both for datasets with synthetic label noise and for datasets withreal-worldlabel noise. It also significantly outperforms other methods when employed within a semi-supervised learning framework. 
 Full Access 
 Feature-Engineered Random Forests 
 href="/author/Sathe%2C+Saket" - Saket Sathe | , 
 href="/author/Aggarwal%2C+Charu" - Charu Aggarwal | , 
 href="/author/Samulowitz%2C+Horst" - Horst Samulowitz | , 
 href="/author/Turaga%2C+Deepak" - Deepak Turaga 
 pp.100–108 
 Abstract 
 PDF 
 AbstractIn this paper, we present a method for constructing a feature-engineered random forest by transforming the features of a given data set using a set of diverse and randomized transforms. The transformed features are then used for creating splits at each node of a random forest. In particular, we use sum-product features because of their strong expressive power. This type of on-the-fly feature engineering has significant advantages over traditional random forests because it adds to the diversity of the splits. Such a diversity further helps in variance reduction; over and above the variance reduction ability offered by traditional random forests. We show the advantages of the proposed approach over traditional random forests and other well-established baselines using extensive experimental evaluation. 
 Full Access 
 Multi-polytope Machine for Classification 
 href="/author/Phan%2C+Dzung+T" - Dzung T. Phan | , 
 href="/author/Nguyen%2C+Lam" - Lam Nguyen | , 
 href="/author/Kalagnanam%2C+Jayant" - Jayant Kalagnanam | , 
 href="/author/Reddy%2C+Chandra" - Chandra Reddy 
 pp.109–117 
 Abstract 
 PDF 
 AbstractIn numerous machine learning applications, there is a preference for classifiers characterized by a polyhedral description, as they are intended for utilization within optimization frameworks or for interpretability purposes. Here, we present a structured classifier designed to cater to downstream decision-making tasks. The classification method is achieved through the process of partitioning the feature domain into clusters and encompassing each cluster within a polytope. We employ a combined approach that integrates semi-supervisedk-means with SVM. This unified optimization framework enables the simultaneous generation of multiple polytopes. The central concept involves using ak-means-based clustering method for the clustering step, followed by the utilization of SVM to construct hyperplanes between each pair of clusters. Notably, the clustering process for each class considers classification loss as well as information from other classes when allocating sample points to clusters. We propose an algorithm to solve the integer program. Our numerical experiments demonstrate the competitiveness of the proposed method across a wide spectrum of datasets, exhibiting its efficacy in comparison to existing hyperplane-based classifiers and nonlinear classifiers. 
 Full Access 
 YOLO-OCR: End-to-end Compound Figure Separation and Label Recognition of Images in Scientific Publications 
 href="/author/Meng%2C+Shuo" - Shuo Meng | , 
 href="/author/Liang%2C+Xinshuo" - Xinshuo Liang | , 
 href="/author/Zhang%2C+Shuai" - Shuai Zhang | , 
 href="/author/Lei%2C+Leqi" - Leqi Lei | , 
 href="/author/Wu%2C+Hanbai" - Hanbai Wu | , 
 href="/author/IQBAL%2C+Saira" - Saira IQBAL | , 
 href="/author/Hu%2C+Jinlian" - Jinlian Hu 
 pp.118–126 
 Abstract 
 PDF 
 AbstractScientific publications, especially biomedical publications, contain a large number of compound figures, which are composed of multiple graphs, plots, and drawings. With the growing interest in data mining, scientific image understanding, and retrieval, compound figure separation and label recognition have become vital steps for various downstream tasks. However, existing studies are difficult to apply to increasingly complex scenarios, and they usually treat these two tasks separately. In this work, we propose a new model called YOLO-OCR to do compound figure separation and label recognition simultaneously. The YOLO-OCR realizes object detection, text detection, and text recognition altogether in a unified end-to-end trainable network. Benefiting from shared convolution features, the model has fewer computation costs and higher performance. To reduce annotation costing, we train the model on a synthesized compound figure dataset and then finetune the model in actual compound figure datasets based on an active learning strategy. The results show that the proposed method achieves a new state-of-the-art performance on the ImageCLEF 2016 dataset and our dataset. In addition, we developed an online system based on the proposed model to help researchers conveniently separate compound figures. The project is publicly available at https://www.chatfigures.com/figure-separation. 
 Full Access 
 Tensorized Hypergraph Neural Networks 
 href="/author/Wang%2C+Maolin" - Maolin Wang | , 
 href="/author/Zhen%2C+Yaoming" - Yaoming Zhen | , 
 href="/author/Pan%2C+Yu" - Yu Pan | , 
 href="/author/Zhao%2C+Yao" - Yao Zhao | , 
 href="/author/Zhuang%2C+Chenyi" - Chenyi Zhuang | , 
 href="/author/Xu%2C+Zenglin" - Zenglin Xu | , 
 href="/author/Guo%2C+Ruocheng" - Ruocheng Guo | , 
 href="/author/Zhao%2C+Xiangyu" - Xiangyu Zhao 
 pp.127–135 
 Abstract 
 PDF 
 AbstractHypergraph neural networks (HGNN) have recently become attractive and received significant attention due to their excellent performance in various domains. However, most existing HGNNs rely on first-order approximations of hypergraph connectivity patterns, which ignores important high-order information. To address this issue, we propose a novel adjacency-tensor-based Tensorized Hypergraph Neural Network (THNN). THNN is a faithful hypergraph modeling framework through high-order outer product feature message passing and is a natural tensor extension of the adjacency-matrix-based graph neural networks. The proposed THNN is equivalent to a high-order polynomial regression scheme, which enables THNN with the ability to efficiently extract high-order information from uniform hypergraphs. Moreover, in consideration of the exponential complexity of directly processing high-order outer product features, we propose using a partially symmetric CP decomposition approach to reduce model complexity to a linear degree. Additionally, we propose two simple yet effective extensions of our method for non-uniform hypergraphs commonly found in real-world applications. Results from experiments on two widely used hypergraph datasets for 3-D visual object classification show the model's promising performance. 
 Full Access 
 Training Sparse Graph Neural Networks via Pruning and Sprouting 
 href="/author/Ma%2C+Xueqi" - Xueqi Ma | , 
 href="/author/Ma%2C+Xingjun" - Xingjun Ma | , 
 href="/author/Erfani%2C+Sarah" - Sarah Erfani | , 
 href="/author/Bailey%2C+James" - James Bailey 
 pp.136–144 
 Abstract 
 PDF 
 AbstractWith the emergence of large-scale graphs and deeper graph neural networks (GNNs), sparsifying GNNs including graph connections and model parameters has attracted a lot of attention. However, most existing GNN sparsification methods apply traditional neural network pruning techniques to sparsify graphs in an iterative cycle (train-then-sparsify), which not only incurs high training costs but also limits model performance. In this paper, we propose a novelPruningandSproutingframework for GNN (PSGNN) that not only enhances the efficiency of inference, but also boosts the performance of GNN trained on a core subgraph beyond the original graph. Based on during-training pruning, our framework gradually sparsifies the graph connections and model weights simultaneously. More specifically, PSGNN removes edges in the original graph according to the predicted label similarity between nodes from a global view. Additionally, with our graph sprouting strategy, PSGNN can generate new edges to include important yet missing topological and feature information in the original graph, while maintaining the sparsity of the graph. Extensive experiments on node classification task across different GNN architectures and graph datasets demonstrate that our proposed PSGNN method improves the performance over existing methods while saving training and inference costs. 
 Full Access 
 Prompt Based Tri-Channel Graph Convolution Neural Network for Aspect Sentiment Triplet Extraction 
 href="/author/Peng%2C+Kun" - Kun Peng | , 
 href="/author/Jiang%2C+Lei" - Lei Jiang | , 
 href="/author/Peng%2C+Hao" - Hao Peng | , 
 href="/author/Liu%2C+Rui" - Rui Liu | , 
 href="/author/Yu%2C+Zhengtao" - Zhengtao Yu | , 
 href="/author/Ren%2C+Jiaqian" - Jiaqian Ren | , 
 href="/author/Hao%2C+Zhifeng" - Zhifeng Hao | , 
 href="/author/Yu%2C+Philip+S" - Philip S. Yu 
 pp.145–153 
 Abstract 
 PDF 
 AbstractAspect Sentiment Triplet Extraction (ASTE) is an emerging task to extract a given sentence's triplets, which consist of aspects, opinions, and sentiments. Recent studies tend to address this task with a table-filling paradigm, wherein word relations are encoded in a two-dimensional table, and the process involves clarifying all the individual cells to extract triples. However, these studies ignore the deep interaction between neighbor cells, which we find quite helpful for accurate extraction. To this end, we propose a novel model for the ASTE task, called Prompt-based Tri-Channel Graph Convolution Neural Network (PT-GCN), which converts the relation table into a graph to explore more comprehensive relational information. Specifically, we treat the original table cells as nodes and utilize a prompt attention score computation module to determine the edges' weights. This enables us to construct a target-aware gridlike graph to enhance the overall extraction process. After that, a triple-channel convolution module is conducted to extract precise sentiment knowledge. Extensive experiments on the benchmark datasets show that our model achieves state-of-the-art performance. The code is available at https://github.com/KunPunCN/PT-GCN. 
 Full Access 
 Non-Euclidean Spatial Graph Neural Network 
 href="/author/Zhang%2C+Zheng" - Zheng Zhang | , 
 href="/author/Li%2C+Sirui" - Sirui Li | , 
 href="/author/Zhou%2C+Jingcheng" - Jingcheng Zhou | , 
 href="/author/Wang%2C+Junxiang" - Junxiang Wang | , 
 href="/author/Angirekula%2C+Abhinav" - Abhinav Angirekula | , 
 href="/author/Zhang%2C+Allen" - Allen Zhang | , 
 href="/author/Zhao%2C+Liang" - Liang Zhao 
 pp.154–162 
 Abstract 
 PDF 
 AbstractSpatial networks are networks whose graph topology is constrained by their embedded spatial space. Understanding the coupled spatial-graph properties is crucial for extracting powerful representations from spatial networks. Therefore, merely combining individual spatial and network representations cannot reveal the underlying interaction mechanism of spatial networks. Besides, existing spatial network representation learning methods can only consider networks embedded in Euclidean space, and can not well exploit the rich geometric information carried by irregular and non-uniform non-Euclidean space. In order to address this issue, in this paper we propose a novel generic framework to learn the representation of spatial networks that are embedded in non-Euclidean manifold space. Specifically, a novel message-passing-based neural network is proposed to combine graph topology and spatial geometry, where spatial geometry is extracted as messages on the edges. We theoretically guarantee that the learned representations are provably invariant to important symmetries such as rotation or translation, and simultaneously maintain sufficient ability in distinguishing different geometric structures. The strength of our proposed method is demonstrated through extensive experiments on both synthetic and real-world datasets. 
 Full Access 
 EsaCL: An Efficient Continual Learning Algorithm 
 href="/author/Ren%2C+Weijieying" - Weijieying Ren | , 
 href="/author/Honavar%2C+Vasant+G" - Vasant G Honavar 
 pp.163–171 
 Abstract 
 PDF 
 AbstractA key challenge in the continual learning setting is to efficiently learn a sequence of tasks without forgetting how to perform previously learned tasks. Many existing approaches to this problem work by either retraining the model on previous tasks or by expanding the model to accommodate new tasks. However, these approaches typically suffer from increased storage and computational requirements, a problem that is worsened in the case of sparse models due to need for expensive re-training after sparsification. To address this challenge, we propose a new method for efficient continual learning of sparse models (EsaCL) that can automatically prune redundant parameters without adversely impacting the model's predictive power, and circumvent the need of retraining. We conduct a theoretical analysis of loss landscapes with parameter pruning, and design a directional pruning (SDP) strategy that is informed by the sharpness of the loss function with respect to the model parameters. SDP ensures model with minimal loss of predictive accuracy, accelerating the learning of sparse models at each stage. To accelerate model update, we introduce an intelligent data selection (IDS) strategy that can identify critical instances for estimating loss landscape, yielding substantially improved data efficiency. The results of our experiments show that EsaCL achieves performance that is competitive with the state-of-the-art methods. 
 Full Access 
 On the number of iterations of the DBA algorithm 
 href="/author/Br%C3%BCning%2C+Frederik" - Frederik Brüning | , 
 href="/author/Driemel%2C+Anne" - Anne Driemel | , 
 href="/author/Erg%C3%BCr%2C+Alperen" - Alperen Ergür | , 
 href="/author/R%C3%B6glin%2C+Heiko" - Heiko Röglin 
 pp.172–180 
 Abstract 
 PDF 
 AbstractThe DTW Barycenter Averaging (DBA) algorithm is a widely used algorithm for estimating the mean of a given set of point sequences. In this context, the mean is defined as a point sequence that minimises the sum of dynamic time warping distances (DTW). The algorithm is similar to thek-means algorithm in the sense that it alternately repeats two steps: (1) computing an optimal assignment to the points of the current mean, and (2) computing an optimal mean under the current assignment. The popularity of DBA can be attributed to the fact that it works well in practice, despite any theoretical guarantees to be known. In our paper, we aim to initiate a theoretical study of the number of iterations that DBA performs until convergence. We assume the algorithm is givennsequences ofmpoints in ℝdand a parameterkthat specifies the length of the mean sequence to be computed. We show that, in contrast to its fast running time in practice, the number of iterations can be exponential inkin the worst case — even if the number of input sequences isn= 2. We complement these findings with experiments on real-world data that suggest this worst-case behaviour is likely degenerate. To better understand the performance of the algorithm on non-degenerate input, we study DBA in the model of smoothed analysis, upper-bounding the expected number of iterations in the worst case under random perturbations of the input. Our smoothed upper bound is polynomial ink, nandd, and for constantn, it is also polynomial inm.For our analysis, we adapt the set of techniques that were developed for analysingk-means and observe that this set of techniques is not sufficient to obtain tight bounds for generaln. 
 Full Access 
 Robust Sparse Online Learning for Data Streams with Streaming Features 
 href="/author/Chen%2C+Zhong" - Zhong Chen | , 
 href="/author/He%2C+Yi" - Yi He | , 
 href="/author/Wu%2C+Di" - Di Wu | , 
 href="/author/Zhan%2C+Huixin" - Huixin Zhan | , 
 href="/author/Sheng%2C+Victor" - Victor Sheng | , 
 href="/author/Zhang%2C+Kun" - Kun Zhang 
 pp.181–189 
 Abstract 
 PDF 
 AbstractSparse online learning has received extensive attention during the past few years. Most of existing algorithms that utilize ℓ1-norm regularization or ℓ1-ball projection assume that the feature space is fixed or changes by following explicit constraints. However, this assumption does not always hold in many real applications. Motivated by this observation, we propose a new online learning algorithm tailored for data streams described by open feature spaces, where new features can be occurred, and old features may be vanished over various time spans. Our algorithm named RSOL provides a strategy to adapt quickly to such feature dynamics by encouraging sparse model representation with an ℓ1- and ℓ2-mixed regularizer. We leverage the proximal operator of the ℓ1,2-mixed norm and show that our RSOL algorithm enjoys a closed-form solution at each iteration. A sub-linear regret bound of our proposed algorithm is guaranteed with a solid theoretical analysis. Empirical results benchmarked on nine streaming datasets validate the effectiveness of the proposed RSOL method over three state-of-the-art algorithms. 
 Full Access 
 Utility-Oriented String Mining 
 href="/author/Bernardini%2C+Giulia" - Giulia Bernardini | , 
 href="/author/Chen%2C+Huiping" - Huiping Chen | , 
 href="/author/Conte%2C+Alessio" - Alessio Conte | , 
 href="/author/Grossi%2C+Roberto" - Roberto Grossi | , 
 href="/author/Guerrini%2C+Veronica" - Veronica Guerrini | , 
 href="/author/Loukides%2C+Grigorios" - Grigorios Loukides | , 
 href="/author/Pisanti%2C+Nadia" - Nadia Pisanti | , 
 href="/author/Pissis%2C+Solon+P" - Solon P. Pissis 
 pp.190–198 
 Abstract 
 PDF 
 AbstractA string is often provided with numerical scores (utilities) which quantify the importance, interest, profit, or risk of the letters occurring at every position of the string. For example, every DNA fragment produced by modern sequencing machines comes with a confidence score per position. Motivated by the abundance of strings with utilities, we introduce Utility-oriented String Mining (USM), a natural generalization of the classic frequent substring mining problem. Given a stringSof lengthnand a threshold𝒱, USM asks for every stringRwhose utilityU(R) is at least𝒱, whereUis a function that mapsRto a utility score based on the utilities of all letters of every occurrence ofRinS.In addition, our work makes the following contributions: (1) We identify a class 𝕌 of utility functions for which USM admits an𝒪(n2)-time algorithm. (2) We prove that no listing algorithm solves the USM problem in subquadratic time for every utility function, or even for every function in 𝕌. (3) We propose an𝒪(nlogn)-time algorithm that solves USM for a class of monotone functions from 𝕌. (4) We design another𝒪(nlogn)-time algorithm for the same problem that is comparable in runtime but offers drastic space savings in practice when, in addition, a lower bound on the length of the output strings is provided as input. (5) We demonstrate experimentally using publicly available, billion-letter datasets that our algorithms are many times more efficient, in terms of runtime and/or space, compared to an Apriori-like baseline which employs advanced string processing tools. 
 Full Access 
 Early Multiple Temporal Patterns Based Event Prediction in Heterogeneous Multivariate Temporal Data 
 href="/author/Itzhak%2C+Nevo" - Nevo Itzhak | , 
 href="/author/Jaroszewicz%2C+Szymon" - Szymon Jaroszewicz | , 
 href="/author/Moskovitch%2C+Robert" - Robert Moskovitch 
 pp.199–207 
 Abstract 
 PDF 
 AbstractPredicting an event of interest based on heterogeneous multivariate temporal data is challenging but desirable as it allows the utilization of all types of temporal variables. In various domains, symbolic time intervals (STIs) can be used to represent real-life events that vary in duration, such as the period a traffic light remains green, or the time a patient undergoes treatment or is on medication. Further, heterogeneous multivariate temporal data may be composed of STIs along with event-driven or continuous temporal variables, such as traffic collisions or blood test values. Temporal abstraction can be used to uniformly represent heterogeneous multivariate temporal variables with STIs, from which frequent time intervals related patterns (TIRPs) can be discovered. We extend earlier work on continuous completion prediction of a single TIRP that ends with an event of interest, introducing a continuous prediction method based onmultipledifferent instances of multiple TIRPs that end with the event of interest, for which we propose and evaluate several weighted aggregation functions. The proposed method overall performed better on real-life, medical, and non-medical datasets, than the use of a single TIRP, and in comparison to the baseline models (XGBoost, ResNet, LSTM-FCN, and ROCKET). 
 Full Access 
 Semi-Supervised Clustering via Structural Entropy with Different Constraints 
 href="/author/Zeng%2C+Guangjie" - Guangjie Zeng | , 
 href="/author/Peng%2C+Hao" - Hao Peng | , 
 href="/author/Li%2C+Angsheng" - Angsheng Li | , 
 href="/author/Liu%2C+Zhiwei" - Zhiwei Liu | , 
 href="/author/Yang%2C+Runze" - Runze Yang | , 
 href="/author/Liu%2C+Chunyang" - Chunyang Liu | , 
 href="/author/He%2C+Lifang" - Lifang He 
 pp.208–216 
 Abstract 
 PDF 
 AbstractSemi-supervised clustering techniques have emerged as valuable tools for leveraging prior information in the form of constraints to improve the quality of clustering outcomes. Despite the proliferation of such methods, the ability to seamlessly integrate various types of constraints remains limited. While structural entropy has proven to be a powerful clustering approach with wide-ranging applications, it has lacked a variant capable of accommodating these constraints. In this work, we present Semi-supervised clustering via Structural Entropy (SSE), a novel method that can incorporate different types of constraints from diverse sources to perform both partitioning and hierarchical clustering. Specifically, we formulate a uniform view for the commonly used pairwise and label constraints for both types of clustering. Then, we design objectives that incorporate these constraints into structural entropy and develop tailored algorithms for their optimization. We evaluate SSE on nine clustering datasets and compare it with eleven semi-supervised partitioning and hierarchical clustering methods. Experimental results demonstrate the superiority of SSE on clustering accuracy with different types of constraints. Additionally, the functionality of SSE for biological data analysis is demonstrated by cell clustering experiments conducted on four single-cell RNA-seq datasets. 
 Full Access 
 Towards Tuning-Free Minimum-Volume Nonnegative Matrix Factorization 
 href="/author/Nguyen%2C+Duc+Toan" - Duc Toan Nguyen | , 
 href="/author/Chi%2C+Eric+C" - Eric C. Chi 
 pp.217–225 
 Abstract 
 PDF 
 AbstractNonnegative Matrix Factorization (NMF) is a versatile and powerful tool for discovering latent structures in data matrices, with many variations proposed in the literature. Recently, Leplat et al. (2019) introduced a minimum-volume NMF for the identifiable recovery of rank-deficient matrices in the presence of noise. The performance of their formulation, however, requires the selection of a tuning parameter whose optimal value depends on the unknown noise level. In this work, we propose an alternative formulation of minimum-volume NMF inspired by the square-root lasso and its tuning-free properties. Our formulation also requires the selection of a tuning parameter, but its optimal value does not depend on the noise level. To fit our NMF model, we propose a majorization-minimization (MM) algorithm that comes with global convergence guarantees. We show empirically that the optimal choice of our tuning parameter is insensitive to the noise level in the data. 
 Full Access 
 Decentralized Stochastic Compositional Gradient Descent for AUPRC Maximization 
 href="/author/Gao%2C+Hongchang" - Hongchang Gao | , 
 href="/author/Duan%2C+Yubin" - Yubin Duan | , 
 href="/author/Zhang%2C+Yihan" - Yihan Zhang | , 
 href="/author/Wu%2C+Jie" - Jie Wu 
 pp.226–234 
 Abstract 
 PDF 
 AbstractIn this paper, we consider the large-scale Area Under the Precision-Recall Curve (AUPRC) maximization problem for the imbalanced data classification task. Existing optimization methods for AUPRC maximization only focus on the single-machine setting, which are not applicable to the distributed data. To address this problem, we propose a novel decentralized stochastic compositional gradient descent method for large-scale AUPRC maximization. Our theoretical analysis shows that it can achieve a better sample complexity𝒪(1/ϵ4) than𝒪(1/ϵ6) of existing decentralized methods, but has the same communication complexity𝒪(1/ϵ4). To further reduce the communication cost, we developed a novel communication-efficient decentralized stochastic compositional gradient descent method, whose communication complexity is improved to𝒪(1/ϵ4–4α) (whereα∈ (0,1/4)). To the best of our knowledge, this is the first work achieving such favorable sample and communication complexities. Finally, we conduct extensive experiments for imbalanced data classification and the empirical results confirm the superior performance of our proposed methods. 
 Full Access 
 On Robust Wasserstein Barycenter: The Model and Algorithm 
 href="/author/Wang%2C+Xu" - Xu Wang | , 
 href="/author/Huang%2C+Jiawei" - Jiawei Huang | , 
 href="/author/Yang%2C+Qingyuan" - Qingyuan Yang | , 
 href="/author/Zhang%2C+Jinpeng" - Jinpeng Zhang 
 pp.235–243 
 Abstract 
 PDF 
 AbstractTheWasserstein barycenter problemis to compute the average ofmgiven probability measures, which has been widely studied in many different areas; however, real-world data sets are often noisy and huge, which impedes its application in practice. Hence, in this paper, we focus on improving the computational efficiency of two types ofrobust Wasserstein barycenter problem(RWB):fixed-supportRWB (fixed-RWB) andfree-supportRWB (free-RWB); actually, the former is a subroutine of the latter. Firstly, we improve efficiency through model reduction; we reduce RWB as anaugmented Wasserstein barycenter problem, which works for both fixed-RWB and free-RWB. Especially, fixed-RWB can be computed within 
 time by using an off-the-shelf solver, where ϵ+is the pre-specified additive error andnis the size of locations of input measures. Then, for free-RWB, we leverage a quality guaranteed data compression technique, coreset, to accelerate computation by reducing the data set sizem.It shows that running algorithms on the coreset is enough instead of on the original data set. Next, by combining the model reduction and coreset techniques above, we propose an algorithm for free-RWB by updating the weights and locations alternatively. Finally, our experiments demonstrate the efficiency of our techniques.*The full version of the paper can be accessed at https://arxiv.org/pdf/2312.15762.pdf 
 Full Access 
 Towards Optimization and Model Selection for Domain Generalization: A Mixup-guided Solution 
 href="/author/Lu%2C+Wang" - Wang Lu | , 
 href="/author/Wang%2C+Jindong" - Jindong Wang | , 
 href="/author/Wang%2C+Yidong" - Yidong Wang | , 
 href="/author/Xie%2C+Xing" - Xing Xie 
 pp.244–252 
 Abstract 
 PDF 
 AbstractThe distribution shifts between training and test data typically undermine the performance of models. In recent years, lots of work pays attention to domain generalization (DG) where distribution shifts exist and target data are unseen. Despite the progress in algorithm design, two foundational factors have long been ignored: 1) the optimization for regularization-based objectives, and 2) the model selection for DG since no knowledge about the target domain can be utilized. In this paper, we propose Mixup guided optimization and selection techniques for DG. For optimization, we utilize an adapted Mixup to generate an out-of-distribution dataset that can guide the preference direction and optimize with Pareto optimization. For model selection, we generate a validation dataset with a closer distance to the target distribution, and thereby it can better represent the target data. We also present some theoretical insights behind our proposals. Comprehensive experiments demonstrate that our model optimization and selection techniques can largely improve the performance of existing domain generalization algorithms and even achieve new state-of-the-art results. 
 Full Access 
 Helper Recommendation with seniority control in Online Health Community 
 href="/author/Gao%2C+Junruo" - Junruo Gao | , 
 href="/author/Ling%2C+Chen" - Chen Ling | , 
 href="/author/Yang%2C+Carl" - Carl Yang | , 
 href="/author/Zhao%2C+Liang" - Liang Zhao 
 pp.253–261 
 Abstract 
 PDF 
 AbstractOnline health communities (OHCs) provide an essential platform for patients with similar health conditions to share experiences and offer moral support. However, many time-sensitive questions from patients often remain unanswered due to the multitude of threads and the random nature of patient visits in OHCs. Traditional recommendation systems solely based on similarity for recommendations cannot be directly applied in OHCs. They tend to overlook the influence of patients' dynamically changing features (e.g., health stages), affecting their ability to provide meaningful responses to questions. To address this, we propose a novel recommender system scenario designed for OHCs, which differs from traditional recommender systems in several ways. Firstly, it's challenging to model the social support factors that form helper-seeker links in OHCs. Secondly, the impact of patients' historical activities is complex to quantify. Lastly, ensuring recommended helpers have the requisite expertise is crucial. To overcome these challenges, we develop a Monotonically regularIzed diseNTangled Variational Autoencoders (MINT) model. This model formulates interactions between seekers and helpers as a dynamic graph, using encoded historical activities as node features. We also introduce a graph-based disentangle VAE to capture patient features and a monotonic regularizer to ensure the logical pairing of seekers and helpers. Our extensive experiments show the effectiveness of our approach. 
 Full Access 
 Active Learning for Graphs with Noisy Structures 
 href="/author/Chi%2C+Hongliang" - Hongliang Chi | , 
 href="/author/Qi%2C+Cong" - Cong Qi | , 
 href="/author/Wang%2C+Suhang" - Suhang Wang | , 
 href="/author/Ma%2C+Yao" - Yao Ma 
 pp.262–270 
 Abstract 
 PDF 
 AbstractGraph Neural Networks (GNNs) have seen significant success in tasks such as node classification, largely contingent upon the availability of sufficient labeled nodes. Yet, the excessive cost of labeling large-scale graphs led to a focus on active learning on graphs, which aims for effective data selection to maximize downstream model performance. Notably, most existing methods assume reliable graph topology, while real-world scenarios often present noisy graphs. Given this, designing a successful active learning framework for noisy graphs is highly needed but challenging, as selecting data for labeling and obtaining a clean graph are two tasks naturally interdependent: selecting high-quality data requires clean graph structure while cleaning noisy graph structure requires sufficient labeled data. Considering the complexity mentioned above, we propose an active learning framework, GALClean, which has been specifically designed to adopt an iterative approach for conducting both data selection and graph purification simultaneously with best information learned from the prior iteration. Importantly, we summarize GALClean as an instance of the Expectation-Maximization algorithm, which provides a theoretical understanding of its design and mechanisms. This theory naturally leads to an enhanced version, GALClean+. Extensive experiments have demonstrated the effectiveness and robustness of our proposed method across various types and levels of noisy graphs. 
 Full Access 
 Graph Summarization for Preserving Spectral Characteristics 
 href="/author/Zhou%2C+Houquan" - Houquan Zhou | , 
 href="/author/Liu%2C+Shenghua" - Shenghua Liu | , 
 href="/author/Shen%2C+Huawei" - Huawei Shen | , 
 href="/author/Cheng%2C+Xueqi" - Xueqi Cheng 
 pp.271–279 
 Abstract 
 PDF 
 AbstractHow does the graph change if we summarize it by merging nodes? How can we summarize the graph while preserving its spectral characteristics? Graph summarization aims to present a graph in a compact summary graph form while keeping its important structural information. Existing methods primarily focus on preserving the adjacency matrix. In contrast, spectral graph theory provides a powerful tool to describe the characteristics of a graph. In this paper, we propose a novel graph summarization method that preserves the spectral characteristics, including spectral moments and heat traces. We analyze the change of the spectral characteristics after summarization and design a simple yet effective summarization method based on agglomerative clustering. Our approach is extensively evaluated on real-world datasets. The experimental results show that our method excels in preserving the spectral characteristics and obtains better performance on the subsequent graph classification task. 
 Full Access 
 H2ABM: Heterogeneous Agent-based Model on Hypergraphs to Capture Group Interactions 
 href="/author/Anand%2C+Vivek" - Vivek Anand | , 
 href="/author/Cui%2C+Jiaming" - Jiaming Cui | , 
 href="/author/Heavey%2C+Jack" - Jack Heavey | , 
 href="/author/Vullikanti%2C+Anil" - Anil Vullikanti | , 
 href="/author/Prakash%2C+B+Aditya" - B. Aditya Prakash 
 pp.280–288 
 Abstract 
 PDF 
 AbstractHeterogeneous agent-based models (HABMs) can simulate the dynamics of multiple types of entities and their interactions on contact networks. In recent years, they have gathered great interest and are widely applied in multiple fields, such as personalized recommendations, publication ranking, and epidemic modeling. Nevertheless, conventional HABMs on graphs can only capture pair-wise interactions between agents but fail to capture the more complex dynamics of group interactions (e.g., multiple people in the same location simultaneously), consequently leading to suboptimal performance. To address this, we propose using hypergraphs to capture such group interactions better and extend the current graph-based HABMs to hypergraphs. Specifically, we use MRSA (Methicillin-resistantStaphylococcus aureus, a kind of infectious disease acquired by patients during treatment at healthcare facilities) spread in the University of Virginia hospital as an example to showcase how we extend an existing graph-based HABM, Graph-HeterSIS, to a hypergraph-based HABM (H2ABM), Hypergraph-HeterSIS. We show how the hyper-graphs can capture the structural difference between contacts before and during the first wave of COVID-19 outbreak in Virginia better than graphs. Our experiments show that H2ABM better captures the underlying group interactions and better fits and forecasts MRSA cases. 
 Full Access 
 Treatment-Aware Hyperbolic Representation Learning for Causal Effect Estimation with Social Networks 
 href="/author/Cui%2C+Ziqiang" - Ziqiang Cui | , 
 href="/author/Tang%2C+Xing" - Xing Tang | , 
 href="/author/Qiao%2C+Yang" - Yang Qiao | , 
 href="/author/He%2C+Bowei" - Bowei He | , 
 href="/author/Chen%2C+Liang" - Liang Chen | , 
 href="/author/He%2C+Xiuqiang" - Xiuqiang He | , 
 href="/author/Ma%2C+Chen" - Chen Ma 
 pp.289–297 
 Abstract 
 PDF 
 AbstractEstimating the individual treatment effect (ITE) from observational data is a crucial research topic that holds significant value across multiple domains. How to identify hidden confounders poses a key challenge in ITE estimation. Recent studies have incorporated the structural information of social networks to tackle this challenge, achieving notable advancements. However, these methods utilize graph neural networks to learn the representation of hidden confounders in Euclidean space, disregarding two critical issues: (1) the social networks often exhibit a scale-free structure, while Euclidean embeddings suffer from high distortion when used to embed such graphs, and (2) each ego-centric network within a social network manifests a treatment-related characteristic, implying significant patterns of hidden confounders. To address these issues, we propose a novel method called Treatment-Aware Hyperbolic Representation Learning (TAHyper). Firstly, TAHy-per employs the hyperbolic space to encode the social networks, thereby effectively reducing the distortion of confounder representation caused by Euclidean embeddings. Secondly, we design a treatment-aware relationship identification module that enhances the representation of hidden confounders by identifying whether an individual and her neighbors receive the same treatment. Extensive experiments on two benchmark datasets are conducted to demonstrate the superiority of our method. The code is available at https://github.com/ziqiangcui/TAHyper. 
 Full Access 
 EBV: Electronic Bee-Veterinarian for Principled Mining and Forecasting of Honeybee Time Series 
 href="/author/Hossain%2C+Mst+Shamima" - Mst. Shamima Hossain | , 
 href="/author/Faloutsos%2C+Christos" - Christos Faloutsos | , 
 href="/author/Baer%2C+Boris" - Boris Baer | , 
 href="/author/Kim%2C+Hyoseung" - Hyoseung Kim | , 
 href="/author/Tsotras%2C+Vassilis+J" - Vassilis J. Tsotras 
 pp.298–306 
 Abstract 
 PDF 
 AbstractHoneybees are vital for pollination and food production. Among many factors, extreme temperature (e.g., due to climate change) is particularly dangerous for bee health. Anticipating such extremities would allow beekeepers to take early preventive action. Thus, given sensor (temperature) time series data from beehives, how can we find patterns and do forecasting? Forecasting is crucial as it helps spot unexpected behavior and thus issue warnings to the beekeepers. In that case, what are the right models for forecasting? ARIMA, RNNs, or something else? 
 We propose the EBV (Electronic Bee-Veterinarian) method, which has the following desirable properties: (i)principled: it is based on a) diffusion equations from physics and b) control theory for feedback-loop controllers; (ii)effective: it works well on multiple, real-world time sequences, (iii)explainable: it needs only a handful of parameters (e.g., bee strength) that beekeepers can easily understand and trust, and (iv)scalable: it performs linearly in time. We applied our method to multiple real-world time sequences, and found that it yields accurate forecasting (up to49%improvement in RMSE compared to baselines), and segmentation. Specifically, discontinuities detected by EBV mostly coincide with domain expert's opinions, showcasing our approach's potential and practical feasibility. Moreover, EBV is scalable and fast, taking about20 minuteson a stock laptop for reconstructing two months of sensor data. 
 Full Access 
 Message Propagation Through Time: An Algorithm for Sequence Dependency Retention in Time Series Modeling 
 href="/author/Xu%2C+Shaoming" - Shaoming Xu | , 
 href="/author/Khandelwal%2C+Ankush" - Ankush Khandelwal | , 
 href="/author/Renganathan%2C+Arvind" - Arvind Renganathan | , 
 href="/author/Kumar%2C+Vipin" - Vipin Kumar 
 pp.307–315 
 Abstract 
 PDF 
 AbstractTime series modeling, a crucial area in science, often encounters challenges when training Machine Learning (ML) models like Recurrent Neural Networks (RNNs) using the conventional mini-batch training strategy that assumes independent and identically distributed (IID) samples and initializes RNNs with zero hidden states. The IID assumption ignores temporal dependencies among samples, resulting in poor performance. This paper proposes the Message Propagation Through Time (MPTT) algorithm to effectively incorporate long temporal dependencies while preserving faster training times relative to the stateful algorithms. MPTT utilizes two memory modules to asynchronously manage initial hidden states for RNNs, fostering seamless information exchange between samples and allowing diverse mini-batches throughout epochs. MPTT further implements three policies to filter outdated and preserve essential information in the hidden states to generate informative initial hidden states for RNNs, facilitating robust training. Experimental results demonstrate that MPTT outperforms seven strategies on four climate datasets with varying levels of temporal dependencies. 
 Full Access 
 Pattern-based Time Series Semantic Segmentation with Gradual State Transitions 
 href="/author/Carpentier%2C+Louis" - Louis Carpentier | , 
 href="/author/Feremans%2C+Len" - Len Feremans | , 
 href="/author/Meert%2C+Wannes" - Wannes Meert | , 
 href="/author/Verbeke%2C+Mathias" - Mathias Verbeke 
 pp.316–324 
 Abstract 
 PDF 
 AbstractTime series semantic segmentation is the task of extracting time intervals from the time series data that share a similar meaning within the application domain in an unsupervised manner. State-of-the-art algorithms typically treat this problem as change point detection, resulting in discrete state transitions. However, in real-world applications, states often transition gradually. This leads to a novel, more challenging variation of the traditional time series segmentation task, for which we present PaTSS, a novel, domain-agnostic algorithm to uncover those gradual state transitions. PaTSS learns a distribution over the semantic segments based on an embedding space derived from mined sequential patterns. An extensive experimental evaluation on 107 benchmark time series shows that PaTSS is capable of detecting gradual state transitions, a task current methods are unable to perform. 
 Full Access 
 Time-Transformer: Integrating Local and Global Features for Better Time Series Generation 
 href="/author/Liu%2C+Yuansan" - Yuansan Liu | , 
 href="/author/Wijewickrema%2C+Sudanthi" - Sudanthi Wijewickrema | , 
 href="/author/Li%2C+Ang" - Ang Li | , 
 href="/author/Bester%2C+Christofer" - Christofer Bester | , 
 href="/author/O%27Leary%2C+Stephen" - Stephen O'Leary | , 
 href="/author/Bailey%2C+James" - James Bailey 
 pp.325–333 
 Abstract 
 PDF 
 AbstractGenerating time series data is a promising approach to address data deficiency problems. However, it is also challenging due to the complex temporal properties of time series data, including local correlations as well as global dependencies. Most existing generative models have failed to effectively learn both the local and global properties of time series data. To address this open problem, we propose a novel time series generative model named ‘Time-Transformer AAE’, which consists of an adversarial autoencoder (AAE) and a newly designed architecture named ‘Time-Transformer’ within the decoder. The Time-Transformer first simultaneously learns local and global features in a layer-wise parallel design, combining the abilities of Temporal Convolutional Networks and Transformer in extracting local features and global dependencies respectively. Second, a bidirectional cross attention is proposed to provide complementary guidance across the two branches and achieve proper fusion between local and global features. Experimental results demonstrate that our model can outperform existing state-of-the-art models in 5 out of 6 datasets, specifically on those with data containing both global and local properties. Furthermore, we highlight our model's ability to handle this kind of data via an artificial dataset. Finally, we show how our model performs when applied to a real-world problem: data augmentation to support learning with small datasets and imbalanced datasets. 
 Full Access 
 Towards Entity-Aware Conditional Variational Inference for Heterogeneous Time-Series Prediction: An application to Hydrology 
 href="/author/Ghosh%2C+Rahul" - Rahul Ghosh | , 
 href="/author/Renganathan%2C+Arvind" - Arvind Renganathan | , 
 href="/author/McAliley%2C+Wallace" - Wallace McAliley | , 
 href="/author/Steinbach%2C+Michael" - Michael Steinbach | , 
 href="/author/Duffy%2C+Christopher" - Christopher Duffy | , 
 href="/author/Kumar%2C+Vipin" - Vipin Kumar 
 pp.334–342 
 Abstract 
 PDF 
 AbstractMany environmental systems (e.g., hydrology basins) can be modeled as entity whose response (e.g., streamflow) depends on drivers (e.g., weather) conditioned on their characteristics (e.g., soil properties). We introduce Entity-aware Conditional Variational Inference (EA-CVI), a novel probabilistic inverse modeling approach, to deduce entity characteristics from observed driver-response data. EA-CVI infers probabilistic latent representations that can accurately predict response for diverse entities, particularly in out-of-sample few-shot settings. EA-CVI's latent embeddings encapsulate diverse entity characteristics within compact, low-dimensional representations. EA-CVI proficiently identifies dominant modes of variation in responses and offers the opportunity to infer a physical interpretation of the underlying attributes that shape these responses. EA-CVI can also generate new data samples by sampling from the learned distribution, making it useful in zero-shot scenarios. EA-CVI addresses the need for uncertainty estimation, particularly during extreme events, rendering it essential for data-driven decision-making in real-world applications. Extensive evaluations on a renowned hydrology benchmark dataset, CAMELS-GB, validate EA-CVI's abilities. 
 Full Access 
 3D Molecular Geometry Analysis with 2D Graphs 
 href="/author/Xu%2C+Zhao" - Zhao Xu | , 
 href="/author/Xie%2C+Yaochen" - Yaochen Xie | , 
 href="/author/Luo%2C+Youzhi" - Youzhi Luo | , 
 href="/author/Zhang%2C+Xuan" - Xuan Zhang | , 
 href="/author/Xu%2C+Xinyi" - Xinyi Xu | , 
 href="/author/Liu%2C+Meng" - Meng Liu | , 
 href="/author/Dickerson%2C+Kaleb" - Kaleb Dickerson | , 
 href="/author/Deng%2C+Cheng" - Cheng Deng | , 
 href="/author/Nakata%2C+Maho" - Maho Nakata | , 
 href="/author/Ji%2C+Shuiwang" - Shuiwang Ji 
 pp.343–351 
 Abstract 
 PDF 
 AbstractGround-state 3D geometries of molecules are essential for many molecular analysis tasks. Modern quantum mechanical methods can compute accurate 3D geometries but are computationally prohibitive. Currently, an efficient alternative to computing ground-state 3D molecular geometries from 2D graphs is lacking. Here, we propose a novel deep learning framework to predict 3D geometries from molecular graphs. To this end, we develop an equilibrium message passing neural network (EMPNN) to better capture ground-state geometries from molecular graphs. To provide a testbed for 3D molecular geometry analysis, we develop a benchmark that includes a dataset with precise ground-state geometries of approximately 4 million molecules. Experimental results show that EMPNN can efficiently predict more accurate ground-state 3D geometries than RDKit and other deep learning methods. Results also show that the proposed framework outperforms self-supervised learning methods on property prediction tasks. 
 Full Access 
 A Novel Hybrid Graph Learning Method for Inbound Parcel Volume Forecasting in Logistics System 
 href="/author/Ye%2C+Lisha" - Lisha Ye | , 
 href="/author/Zhou%2C+Jianfeng" - Jianfeng Zhou | , 
 href="/author/Yin%2C+Zhe" - Zhe Yin | , 
 href="/author/Han%2C+Kunpeng" - Kunpeng Han | , 
 href="/author/Hu%2C+Haoyuan" - Haoyuan Hu | , 
 href="/author/Song%2C+Dongjin" - Dongjin Song 
 pp.352–360 
 Abstract 
 PDF 
 AbstractInbound parcel volume forecasting problem (IPVFP) plays an important role in the logistics system as it can facilitate various downstream applications. Despite the fact that a number of time series forecasting techniques have been developed, existing approaches fail to explicitly consider intrinsic characteristics of the logistics system,e.g., parcel transport patterns, operation patterns, and their spatial-temporal dependencies. To this end, we propose a novel hybrid inbound parcel volume forecasting model to analyze the logistic spatial-temporal graph that is constructed based on logistics data and the physical location of logistics stations. The graph includes engineered features such as the transition matrix and modified Dynamic Time Warping (DTW) distance matrix, which accurately depicts the parcel transfer patterns within the system. In addition, it incorporates a dedicated attention mechanism that introduces a novel bit-embedding representation method for integer tokens, enabling to capture of dynamic correlations among different timestamps. Finally, a collaborative module comprising dilated convolution layers and Gated Recurrent Units (GRU) is integrated to capture long-term dependencies. Extensive experiments on real-world data evaluate the effectiveness of the proposed graph and model, demonstrating its superiority over 16 other advanced baseline models. We release our code and data at https://github.com/YelsAlyssa/IPVFP. 
 Full Access 
 Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions 
 href="/author/Cui%2C+Suhan" - Suhan Cui | , 
 href="/author/Wang%2C+Jiaqi" - Jiaqi Wang | , 
 href="/author/Zhong%2C+Yuan" - Yuan Zhong | , 
 href="/author/Liu%2C+Han" - Han Liu | , 
 href="/author/Wang%2C+Ting" - Ting Wang | , 
 href="/author/Ma%2C+Fenglong" - Fenglong Ma 
 pp.361–369 
 Abstract 
 PDF 
 AbstractThe widespread adoption of Electronic Health Record (EHR) systems in healthcare institutes has generated vast amounts of medical data, offering significant opportunities for improving healthcare services through deep learning techniques. However, the complex and diverse modalities and feature structures in real-world EHR data pose great challenges for deep learning model design. To address the multi-modality challenge in EHR data, current approaches primarily rely on hand-crafted model architectures based on intuition and empirical experiences, leading to sub-optimal model architectures and limited performance. Therefore, to automate the process of model design for mining EHR data, we propose a novel neural architecture search (NAS) framework named AutoFM, which can automatically search for the optimal model architectures for encoding diverse input modalities and fusion strategies. We conduct thorough experiments on real-world multi-modal EHR data and prediction tasks, and the results demonstrate that our framework not only achieves significant performance improvement over existing state-of-the-art methods but also discovers meaningful network architectures effectively1. 
 1Source code can be found via the link: https://github.com/SH-Src/AUTOMF 
 Full Access 
 Dual-stage Flows-based Generative Modeling for Traceable Urban Planning 
 href="/author/Hu%2C+Xuanming" - Xuanming Hu | , 
 href="/author/Fan%2C+Wei" - Wei Fan | , 
 href="/author/Wang%2C+Dongjie" - Dongjie Wang | , 
 href="/author/Wang%2C+Pengyang" - Pengyang Wang | , 
 href="/author/Li%2C+Yong" - Yong Li | , 
 href="/author/Fu%2C+Yanjie" - Yanjie Fu 
 pp.370–378 
 Abstract 
 PDF 
 AbstractUrban planning, which aims to design feasible land-use configurations for target areas, has become increasingly essential due to the high-speed urbanization process in the modern era. However, the traditional urban planning conducted by human designers can be a complex and onerous task. Thanks to the advancement of deep learning algorithms, researchers have started to develop automated planning techniques. While these models have exhibited promising results, they still grapple with a couple of unresolved limitations: 1) Ignoring the relationship between urban functional zones and configurations and failing to capture the relationship among different functional zones. 2) Less interpretable and stable generation process. To overcome these limitations, we propose a novel generative framework based on normalizing flows, namely Dual-stage Urban Flows (DSUF) framework. Specifically, the first stage is to utilize zone-level urban planning flows to generate urban functional zones based on given surrounding contexts and human guidance. Then we employ an Information Fusion Module to capture the relationship among functional zones and fuse the information of different aspects. The second stage is to use configuration-level urban planning flows to obtain land-use configurations derived from fused information. We design several experiments to indicate that our framework can outperform for the urban planning task**. 
 **Please review the full edition, including the appendix, at https://arxiv.org/pdf/2310.02453.pdf. 
 Full Access 
 Graph-based Student Knowledge Profile for Online Intelligent Education 
 href="/author/Wu%2C+Jinze" - Jinze Wu | , 
 href="/author/Zhang%2C+Haotian" - Haotian Zhang | , 
 href="/author/Huang%2C+Zhenya" - Zhenya Huang | , 
 href="/author/Ding%2C+Liang" - Liang Ding | , 
 href="/author/Liu%2C+Qi" - Qi Liu | , 
 href="/author/Sha%2C+Jing" - Jing Sha | , 
 href="/author/Chen%2C+Enhong" - Enhong Chen | , 
 href="/author/Wang%2C+Shijin" - Shijin Wang 
 pp.379–387 
 Abstract 
 PDF 
 AbstractStudent knowledge profile is the basis for adaptive learning applications in online learning resulting from modeling the student mastery of knowledge concepts. In recent years, typical works based on knowledge tracing (KT) expect to profile students and have achieved significant success for the next performance prediction. However, in practical online learning scenarios, current methods tend to suffer from the following challenges: 1) Prediction inconsistency: The accuracy of the next performance prediction is inconsistent with the accuracy of student knowledge profile prediction, which is the more required result. 2) Cold start of knowledge: In online learning scenarios, it is often necessary to profile some knowledge concepts without learning records in advance. In this paper, we propose a novel Graph-based Student Knowledge Profile Model (GSKPM), along with a new end-to-end training objective, to tackle these challenges. We first define a new training objective to ensure the model is capable of inferring consistent student knowledge profiles. Then in this model, a two-stage hyper-aggregation process is employed to make full use of the topological relations between knowledge concepts and knowledge domains to provide information during profiling, especially for cold start knowledge concepts. Finally, through extensive experiments on real-world datasets, we will show that GSKPM achieves better prediction performances on student knowledge profiles and well deals with the cold start problem. 
 Full Access 
 Data Silences: How to Unsilence the Uncertainties in Data Science 
 href="/author/Muller%2C+Michael" - Michael Muller 
 pp.388–391 
 Abstract 
 PDF 
 AbstractWhen we wrangle the data in data science, we design the data to make it fit-for-analysis. Wrangling involves the removal or reduction of uncertainties, such as outliers, missing values, mal-distributions, and the details of feature engineering. Many of the steps of data wrangling go unrecorded or poorly recorded, in terms of bothwhat was doneand also the rationale forwhy it was done.In this way, we impose multiple types ofdata silenceson the data, and often on the sources (people) who are “behind” the data. In this paper, we articulate how we may perform multiple types of silencing. We challenge comfortable conceptions of the nature of data, and we call on the data-science community to devise and adopt methodologies to unsilence data. 
 Full Access 
 Foundation Models for Spatiotemporal Tasks in the Physical World 
 href="/author/Jiang%2C+Zhe" - Zhe Jiang | , 
 href="/author/Wang%2C+Yu" - Yu Wang | , 
 href="/author/Xu%2C+Zelin" - Zelin Xu 
 pp.392–395 
 Abstract 
 PDF 
 AbstractFoundation models such as ChatGPT are poised to transform society by providing general intelligence for problem-solving in healthcare, education, and law. They are also expected to make dramatic impacts in the way of AI solving spatiotemporal tasks in the physical world, such as smart manufacturing, intelligent transportation, and Earth system modeling. However, one major handicap is that existing foundation models do not understand the spatiotemporal knowledge of the physical world, leading to unexpected model behaviors and significant safety risks. This paper discusses emerging opportunities and unique challenges in integrating foundation models with physical components for solving spatiotemporal tasks. We also identify several new research directions to enhance the safety of such integrated models by spatiotemporal-knowledge-guided in-context-learning, verification, safety alignment, and the development of physics-informed geo-foundation models, as well as new benchmarking datasets and evaluation metrics. 
 Full Access 
 Blue Sky: Multilingual, Multimodal Domain Independent Deception Detection 
 href="/author/Boumber%2C+Dainis" - Dainis Boumber | , 
 href="/author/Verma%2C+Rakesh+M" - Rakesh M. Verma | , 
 href="/author/Qachfar%2C+Fatima+Zahra" - Fatima Zahra Qachfar 
 pp.396–399 
 Abstract 
 PDF 
 AbstractDeception, a pervasive aspect of communication, has undergone a significant transformation in the digital age. With the globalization of online interactions, individuals are communicating in multiple languages, mixing languages on social media. A variety of data is now available in many languages, while the techniques for detecting deception are similar across the board. Recent studies have shown the possibility of the existence of universal linguistic cues to deception across domains within the English language; however, the existence of such cues in other languages remains unknown. Furthermore, the practical task of deception detection in low-resource languages is not a well-studied problem due to the lack of labeled data. Another dimension of deception is multimodality. For example, in fake news or disinformation, there may be a picture with an altered caption. This paper calls for a comprehensive investigation into the complexities of deceptive language across linguistic boundaries and modalities, and raises the possibility of use of multilingual transformer models and labeled data in a variety of languages to universally address the task of deception detection. 
 *All authors are with the University of Houston 
 Full Access 
 Label Distribution Learning-Enhanced Dual-KNN for Text Classification 
 href="/author/Yuan%2C+Bo" - Bo Yuan | , 
 href="/author/Chen%2C+Yulin" - Yulin Chen | , 
 href="/author/Tan%2C+Zhen" - Zhen Tan | , 
 href="/author/Jinyan%2C+Wang" - Wang Jinyan | , 
 href="/author/Liu%2C+Huan" - Huan Liu | , 
 href="/author/Zhang%2C+Yin" - Yin Zhang 
 pp.400–408 
 Abstract 
 PDF 
 AbstractMany text classification methods usually introduce external information (e.g., label descriptions and knowledge bases) to improve the classification performance. Compared to external information, some internal information generated by the model itself during training, like text embeddings and predicted label probability distributions, are exploited poorly when predicting the outcomes of some texts. In this paper, we focus on leveraging this internal information, proposing a dualknearest neighbor (DkNN) framework with twokNN modules, to retrieve several neighbors from the training set and augment the distribution of labels. For thekNN module, it is easily confused and may cause incorrect predictions when retrieving some nearest neighbors from noisy datasets (datasets with labeling errors) or similar datasets (datasets with similar labels). To address this issue, we also introduce a label distribution learning module that can learn label similarity, and generate a better label distribution to help models distinguish texts more effectively. This module eases model overfitting and improves final classification performance, hence enhancing the quality of the retrieved neighbors bykNN modules during inference. Extensive experiments on the benchmark datasets verify the effectiveness of our method. 
 Full Access 
 Refining Pre-trained Language Models for Domain Adaptation with Entity-Aware Discriminative and Contrastive Learning 
 href="/author/Yang%2C+Jian" - Jian Yang | , 
 href="/author/Hu%2C+Xinyu" - Xinyu Hu | , 
 href="/author/Shen%2C+Yulong" - Yulong Shen | , 
 href="/author/Xiao%2C+Gang" - Gang xiao 
 pp.409–417 
 Abstract 
 PDF 
 AbstractWith the rapid advancement of pre-trained language models (PLMs), the adaptation of these models to specialized domains has emerged as an essential area of research. However, PLMs encounter substantial challenges when deployed in highly specialized fields, such as the Chinese military equipment domain. The intricate nature of the domain entities, characterized by multi-class character combinations and the dynamic variability of names, has exposed a significant deficiency in the ability of PLMs to accurately recognize and comprehend them. In response to this challenge, we introduce a novel method to augment PLMs with domain-specific entity knowledge through discriminative and con-trastive learning objectives. The discriminative objective guides the PLM in discerning domain entities by distinguishing between the subwords of common words and those of specific entities, while the contrastive objective strategically infuses domain entity semantics from a pre-established intermediate entity embedding vocabulary. By leveraging this methodology, we trained a unified military equipment-oriented PLM. To assess the model's performance, we construct a set of domain test datasets and conduct a comprehensive evaluation. The experimental results demonstrate that our model significantly surpasses baseline models in all evaluated metrics, thereby underscoring the effectiveness of the proposed method. 
 Full Access 
 An Image Dataset for Benchmarking Recommender Systems with Raw Pixels 
 href="/author/Cheng%2C+Yu" - Yu Cheng | , 
 href="/author/Pan%2C+Yunzhu" - Yunzhu Pan | , 
 href="/author/Zhang%2C+Jiaqi" - Jiaqi Zhang | , 
 href="/author/Ni%2C+Yongxin" - Yongxin Ni | , 
 href="/author/Sun%2C+Aixin" - Aixin Sun | , 
 href="/author/Yuan%2C+Fajie" - Fajie Yuan 
 pp.418–426 
 Abstract 
 PDF 
 AbstractThe advent of large language models has inspired active and promising research focused on developing text content-based recommendation models. Meanwhile, although image features are also key signals in recommender systems, there is currently a lack of research on recommendation models that are primarily based on raw image pixels. The lack of large-scale datasets containing raw images in visually driven recommendation scenarios has been a significant barrier to the development of this research direction. To address this challenge, we introduce PixelRec, a comprehensive dataset of cover images collected from a video streaming platform. With approximately 200 million user image interactions, 30 million users, and 400,000 high-resolution short video cover images, PixelRec facilitates the development, benchmarking, and analysis of various image pixel based recommendation models. Leveraging this dataset, we establish a accessible pipeline to implement a series of vision-based recommendation models, providing extensive benchmark results for them. Our contributions include the PixelRec dataset, baseline algorithms, operational pipeline, exploratory findings, and the PixelRec benchmark. We believe PixelRec will significantly advance research on recommendation models based on image content and foster fruitful collaboration between the fields of recommender systems and computer vision. The dataset, code, and documents are made available at https://github.com/westlake-repl/PixelRec. 
 Full Access 
 Disinformation Detection: An Evolving Challenge in the Age of LLMs 
 href="/author/Jiang%2C+Bohan" - Bohan Jiang | , 
 href="/author/Tan%2C+Zhen" - Zhen Tan | , 
 href="/author/Nirmal%2C+Ayushi" - Ayushi Nirmal | , 
 href="/author/Liu%2C+Huan" - Huan Liu 
 pp.427–435 
 Abstract 
 PDF 
 AbstractThe advent of generative Large Language Models (LLMs) such as ChatGPT has catalyzed transformative advancements across multiple domains. However, alongside these advancements, they have also introduced potential threats. One critical concern is the misuse of LLMs by disinformation spreaders, leveraging these models to generate highly persuasive yet misleading content that challenges the disinformation detection system. This work aims to address this issue by answering three research questions: (1) To what extent can the current disinformation detection technique reliably detect LLM-generated disinformation? (2) If traditional techniques prove less effective, can LLMs themself be exploited to serve as a robust defense against advanced disinformation? and, (3) Should both these strategies falter, what novel approaches can be proposed to counter this burgeoning threat effectively? A holistic exploration for the formation and detection of disinformation is conducted to foster this line of research. 
 Full Access 
 User Migration across Multiple Social Media Platforms 
 href="/author/Jeong%2C+Ujun" - Ujun Jeong | , 
 href="/author/Nirmal%2C+Ayushi" - Ayushi Nirmal | , 
 href="/author/Jha%2C+Kritshekhar" - Kritshekhar Jha | , 
 href="/author/Tang%2C+Susan+Xu" - Susan Xu Tang | , 
 href="/author/Bernard%2C+H+Russell" - H. Russell Bernard | , 
 href="/author/Liu%2C+Huan" - Huan Liu 
 pp.436–444 
 Abstract 
 PDF 
 AbstractAfter Twitter's ownership change and policy shifts, many users reconsidered their go-to social media outlets and platforms like Mastodon, Bluesky, and Threads became attractive alternatives in the battle for users. Based on the data from over 14,000 users who migrated to these platforms within the first eight weeks after the launch of Threads, our study examines: (1) distinguishing attributes of Twitter users who migrated, compared to non-migrants; (2) temporal migration patterns and associated challenges for sustainable migration faced by each platform; and (3) how these new platforms are perceived in relation to Twitter. Our research proceeds in three stages. First, we examine migration from a broad perspective, not just one-to-one migration. Second, we leverage behavioral analysis to pinpoint the distinct migration pattern of each platform. Last, we employ a Large Language Model (LLM) to discern stances towards each platform and correlate them with the platform usage. This in-depth analysis illuminates migration patterns amid competition across social media platforms. 
 Full Access 
 Combining Satellite and Weather Data for Crop Type Mapping: An Inverse Modelling Approach 
 href="/author/Ravirathinam%2C+Praveen" - Praveen Ravirathinam | , 
 href="/author/Ghosh%2C+Rahul" - Rahul Ghosh | , 
 href="/author/Khandelwal%2C+Ankush" - Ankush Khandelwal | , 
 href="/author/Jia%2C+Xiaowei" - Xiaowei Jia | , 
 href="/author/Mulla%2C+David" - David Mulla | , 
 href="/author/Kumar%2C+Vipin" - Vipin Kumar 
 pp.445–453 
 Abstract 
 PDF 
 AbstractAccurate and timely crop mapping is essential for yield estimation, insurance claims, and conservation efforts. Over the years, many successful machine learning models for crop mapping have been developed that use just the multi-spectral imagery from satellites to predict crop type over the area of interest. However, these traditional methods do not account for the physical processes that govern crop growth. At a high level, crop growth can be envisioned as physical parameters, such as weather and soil type, acting upon the plant leading to crop growth which can be observed via satellites. In this paper, we propose Weather-based Spatio-Temporal segmentation network with ATTention (WSTATT), a deep learning model that leverages this understanding of crop growth by formulating it as an inverse model that combines weather (Daymet) and satellite imagery (Sentinel-2) to generate accurate crop maps. We show that our approach provides significant improvements over existing algorithms that solely rely on spectral imagery by comparing segmentation maps and F1 classification scores. Furthermore, effective use of attention in WSTATT architecture enables detection of crop types earlier in the season (up to 5 months in advance), which is very useful for improving food supply projections. We finally discuss the impact of weather by correlating our results with crop phenology to show that WSTATT is able to capture physical properties of crop growth. 
 Full Access 
 CAMLO: Cross-Attentive Multi-View Network for Long-Term Origin-Destination Flow Prediction 
 href="/author/Wang%2C+Liang" - Liang Wang | , 
 href="/author/Fu%2C+Hao" - Hao Fu | , 
 href="/author/Wu%2C+Shu" - Shu Wu | , 
 href="/author/Liu%2C+Qiang" - Qiang Liu | , 
 href="/author/Tan%2C+Xuelei" - Xuelei Tan | , 
 href="/author/Huang%2C+Fangsheng" - Fangsheng Huang | , 
 href="/author/Zhang%2C+Mengdi" - Mengdi Zhang | , 
 href="/author/Wu%2C+Wei" - Wei Wu 
 pp.454–462 
 Abstract 
 PDF 
 AbstractPredicting the volume of flow from an origin to a destination is essential to understanding the mobility pattern and improving many transportation services, such as ride-hailing and food delivery. However, makinglong-termprediction for all possible pairs of origins and destinations is still a challenging problem. Existing works either suffer from cumulative error and high complexity of iterative computation on long sequence, or neglect the complex spatial correlation obscured by elongated time span. In this paper, we present CAMLO, a cross-attentive multi-view network for this task. Our model adopts a multi-view framework that separately models the asymmetric characteristics of origin and destination in origin- and destination-oriented view. In each view, a relational graph aggregation module captures the sparse and multi-relational correlation among origins and destinations. Subsequently, a Transformer-based forecasting module is applied to discover intricate temporal dynamics. The two views internally interact with each other via a cross-attention mechanism and are later fused for the final prediction. Extensive experiments conducted on two real-world datasets demonstrate the effectiveness of our model. 
 Full Access 
 Test-Time Training for Spatial-Temporal Forecasting 
 href="/author/Chen%2C+Changlu" - Changlu Chen | , 
 href="/author/Liu%2C+Yanbin" - Yanbin Liu | , 
 href="/author/Chen%2C+Ling" - Ling Chen | , 
 href="/author/Zhang%2C+Chengqi" - Chengqi Zhang 
 pp.463–471 
 Abstract 
 PDF 
 AbstractDespite the recent success of deep neural networks in spatial-temporal forecasting, existing methods suffer from distribution shifts between the training and test data, failing to address the non-stationary and abrupt changes at test time. To solve this problem, we propose a novel test-time training framework for spatial-temporal forecasting. Instead of employing a fixed trained model, we adapt the trained model with only one or a mini-batch of test examples to address the test data shifts. The unique spatial structure with hundreds of geographical locations offers an effective batch size to explore the test-time distribution and avoid overfitting. 
 To implement test-time training on spatial-temporal data, we devise a bidirectional cycle-consistent architecture consisting of a forward and a backward cyclic network. Each network has a shared encoder and two direction-aware decoders. At the test time, two self-supervised auxiliary tasks (forward→backwardandbackward→forwardreconstruction) are proposed to adapt the trained model without accessing the target labels. Besides, the bi-cyclic structure of our model can also improve the forecasting task at training time, and ensure consistency between the training and test time. Comprehensive experiments are performed on various spatial-temporal forecasting datasets, demonstrating the effectiveness of the test-time training framework and the bidirectional-cyclic structure. 
 Full Access 
 Geospatial Topological Relation Extraction from Text with Knowledge Augmentation 
 href="/author/Hu%2C+Wei" - Wei Hu | , 
 href="/author/Jin%2C+Bowen" - Bowen Jin | , 
 href="/author/Jiang%2C+Minhao" - Minhao Jiang | , 
 href="/author/Zhou%2C+Sizhe" - Sizhe Zhou | , 
 href="/author/Wang%2C+Zhaonan" - Zhaonan Wang | , 
 href="/author/Han%2C+Jiawei" - Jiawei Han | , 
 href="/author/Wang%2C+Shaowen" - Shaowen Wang 
 pp.472–480 
 Abstract 
 PDF 
 AbstractGeospatial topological relation extraction (GeoTopoRE) aims to extract topological relations between named geospatial entities (i.e., geo-entities) in text. It is a domain-specific relation extraction (RE) task essential in geospatial knowledge graph construction and spatial reasoning. Unlike general-purpose RE, which primarily depends on semantic and syntactic cues, GeoTopoRE requires integrating geometric knowledge about geo-entities. This is essential for accurately capturing or inferring the complex geospatial relationships among entities. GeoTopoRE is not studied systematically and lacks dedicated datasets for evaluation, posing significant challenges to developing and assessing effective models. This study presents two major contributions: (i) the introduction of a high-quality, human-labeled dataset WikiTopo for the GeoTopoRE task, and (ii) a novel framework GeoWISE designed to adapt existing RE models to the GeoTopoRE task, With Integrated Semantic and External geospatial domain knowledge. We leverage coarse-to-fine-grained natural language inference (NLI) to align externally sourced knowledge with the semantic text context, enhanced by geospatial expertise. This integrated knowledge is then conveyed to language models as geospatial cues, enabling a nuanced understanding of topological relations. Empirical results demonstrate the efficacy of our framework in few-shot settings, showing significant and consistent improvements in the GeoTopoRE task for diverse state-of-the-art RE models. 
 Full Access 
 Only Attending What Matter within Trajectories –Memory-Efficient Trajectory Attention 
 href="/author/Hu%2C+Mingzhi" - Mingzhi Hu | , 
 href="/author/Zhang%2C+Xin" - Xin Zhang | , 
 href="/author/Li%2C+Yanhua" - Yanhua Li | , 
 href="/author/Xie%2C+Yiqun" - Yiqun Xie | , 
 href="/author/Jia%2C+Xiaowei" - Xiaowei Jia | , 
 href="/author/Zhou%2C+Xun" - Xun Zhou | , 
 href="/author/Luo%2C+Jun" - Jun Luo 
 pp.481–489 
 Abstract 
 PDF 
 AbstractHuman-generated Spatial-Temporal Data (HSTD), represented as trajectory sequences, has undergone a data revolution, thanks to advances in mobile sensing, data mining, and AI. Previous studies have revealed the effectiveness of employing attention mechanisms to analyze massive HSTD. However, traditional attention models face challenges when managing lengthy and noisy trajectories as their computation comes with large memory overheads. Furthermore, attention scores within HSTD trajectories are sparse (i.e., most of the scores are zeros), and clustered with varying lengths (i.e., consecutive tokens clustered with similar scores). To address these challenges, we introduce an innovative strategy named Memory-efficient Trajectory Attention (MeTA). We leverage complicated spatial-temporal features (e.g., traffic speed, proximity to PoIs) and design an innovative feature-based trajectory partition technique to shrink trajectory length. Additionally, we present a learnable dynamic sorting mechanism, with which attention is only computed between sub-trajectories that have prominent correlations. Empirical validations using real-world HSTD demonstrate that our approach not only yields competitive results but also significantly lowers memory usage compared with state-of-the-art methods. Our approach presents innovative solutions for memory-efficient trajectory attention, offering valuable insights for handling HSTD efficiently. 
 Full Access 
 Lattice Convolutional Networks for Learning Ground States of Quantum Many-Body Systems 
 href="/author/Fu%2C+Cong" - Cong Fu | , 
 href="/author/Zhang%2C+Xuan" - Xuan Zhang | , 
 href="/author/Zhang%2C+Huixin" - Huixin Zhang | , 
 href="/author/Ling%2C+Hongyi" - Hongyi Ling | , 
 href="/author/Xu%2C+Shenglong" - Shenglong Xu | , 
 href="/author/Ji%2C+Shuiwang" - Shuiwang Ji 
 pp.490–498 
 Abstract 
 PDF 
 AbstractDeep learning methods have been shown to be effective in representing ground-state wave functions of quantum many-body systems. Existing methods use convolutional neural networks (CNNs) for square lattices due to their image-like structures. For non-square lattices, the existing method uses graph neural networks (GNNs) in which structure information is not precisely captured, thereby requiring additional hand-crafted sublattice encoding. In this work, we propose lattice convolutions in which a set of proposed operations are used to convert non-square lattices into gridlike augmented lattices on which regular convolution can be applied. Based on the proposed lattice convolutions, we design lattice convolutional networks (LCN) that use self-gating and attention mechanisms. Experimental results show that our method achieves performance on par or better than the GNN method on spin 1/2J1-J2Heisenberg model over the square, honeycomb, triangular, and kagome lattices while without using hand-crafted encoding. The code will be made publicly available at https://github.com/divelab/AIRS/tree/main/OpenQM/LCN. 
 Full Access 
 MedDiffusion: Boosting Health Risk Prediction via Diffusion-based Data Augmentation 
 href="/author/Zhong%2C+Yuan" - Yuan Zhong | , 
 href="/author/Cui%2C+Suhan" - Suhan Cui | , 
 href="/author/Wang%2C+Jiaqi" - Jiaqi Wang | , 
 href="/author/Wang%2C+Xiaochen" - Xiaochen Wang | , 
 href="/author/Yin%2C+Ziyi" - Ziyi Yin | , 
 href="/author/Wang%2C+Yaqing" - Yaqing Wang | , 
 href="/author/Xiao%2C+Houping" - Houping Xiao | , 
 href="/author/Huai%2C+Mengdi" - Mengdi Huai | , 
 href="/author/Wang%2C+Ting" - Ting Wang | , 
 href="/author/Ma%2C+Fenglong" - Fenglong Ma 
 pp.499–507 
 Abstract 
 PDF 
 AbstractHealth risk prediction aims to forecast the potential health risks that patients may face using their historical Electronic Health Records (EHR). Although several effective models have developed, data insufficiency is a key issue undermining their effectiveness. Various data generation and augmentation methods have been introduced to mitigate this issue by expanding the size of the training data set through learning underlying data distributions. However, the performance of these methods is often limited due to their task-unrelated design. To address these shortcomings, this paper introduces a novel, end-to-end diffusion-based risk prediction model, named MedDiffusion. It enhances risk prediction performance by creating synthetic patient data during training to enlarge sample space. Furthermore, MedDiffusion discerns hidden relationships between patient visits using a step-wise attention mechanism, enabling the model to automatically retain the most vital information for generating high-quality data. Experimental evaluation on four real-world medical datasets demonstrates that MedDiffusion outperforms 14 cutting-edge baselines in terms of PR-AUC, F1, and Cohen's Kappa. We also conduct ablation studies and benchmark our model against GAN-based alternatives to further validate the rationality and adaptability of our model design. Additionally, we analyze generated data to offer fresh insights into the model's interpretability. The source code is available via https://shorturl.at/aerT0. 
 Full Access 
 Meta-Adaptive Stock Movement Prediction with Two-Stage Representation Learning 
 href="/author/Zhan%2C+Donglin" - Donglin Zhan | , 
 href="/author/Dai%2C+Yusheng" - Yusheng Dai | , 
 href="/author/Dong%2C+Yiwei" - Yiwei Dong | , 
 href="/author/He%2C+Jinghai" - Jinghai He | , 
 href="/author/Wang%2C+Zhenyi" - Zhenyi Wang | , 
 href="/author/Anderson%2C+James" - James Anderson 
 pp.508–516 
 Abstract 
 PDF 
 AbstractStock movement prediction has always been a tough but attractive task for researchers in data mining and machine learning. Generally speaking, two challenges for stock time series prediction remain not well-explored. One is the over-fitting of deep learning models due to the limited data availability. The second one is potential domain shifts that may happen during the evolution of the stock time series. In this paper, we presentMeta-Adaptive Stock movement prediction with two-StagE Representation learning (MASSER), a framework for stock movement prediction based on self-supervised learning and meta-learning. Specifically, we first design two-stage encoders to learn representations, the first-stage encoder aims to learn unified embeddings, and the second-stage encoder, which is based on the first stage, is used for temporal domain shift detection in the training stage via self-supervised learning. We formalize the problem of stock movement prediction into a standard meta-learning setting. Inspired by importance sampling, we estimate the sampling probability for tasks to balance the domain discrepancy caused by evolving temporal domains. Extensive experiment results on two open source datasets show that our experimental framework with the classical ResNet as backbone achieves improvements of 5% - 9.5% on average accuracy, compared to state-of-the-art baselines. Furthermore, We extend the standard setting of stock movement prediction to a more challenging online paradigm, which is close to the realistic interday trading scenarios. MASSER outperforms baselines in both online setting and backtesting. 
 Full Access 
 Pretraining Molecules with Explicit Substructure Information 
 href="/author/Ma%2C+Yuting" - Yuting Ma | , 
 href="/author/Yu%2C+Shuo" - Shuo Yu | , 
 href="/author/Shen%2C+Yanming" - Yanming Shen 
 pp.517–525 
 Abstract 
 PDF 
 AbstractGenerative self-supervised learning has recently become popular in molecular modeling because it can improve accuracy and generalization. However, existing generative self-supervised tasks often have simplified designs that do not effectively use substructure information. Substructure information is important for molecules because it can provide local semantics and capture analogous semantic information on a graph-level scale. For example, -OH, as one of the substructures, is typically associated with hydrophilicity. To address this limitation, we propose a novel pretraining task that incorporates substructure information into generative self-supervised tasks. This integration involves creating a substructure-based vocabulary and fusing structural insights into the representation learning process. We evaluate our approach on 10 publicly available datasets, covering diverse molecular property prediction tasks. Our results consistently show the effectiveness of incorporating substructure information compared with both contrastive and generative self-supervised pretraining methodologies. 
 Full Access 
 RHINE: A Regime-Switching Model with Nonlinear Representation for Discovering and Forecasting Regimes in Financial Markets 
 href="/author/Xu%2C+Kunpeng" - Kunpeng Xu | , 
 href="/author/Chen%2C+Lifei" - Lifei Chen | , 
 href="/author/Patenaude%2C+Jean-Marc" - Jean-Marc Patenaude | , 
 href="/author/Wang%2C+Shengrui" - Shengrui Wang 
 pp.526–534 
 Abstract 
 PDF 
 AbstractWe investigate the problem of discovering and forecasting regular regime switches in a financial ecosystem comprising multiple time series. Such regime switches, indicative of varying market behaviors across distinct time intervals, are pivotal for a nuanced understanding of market dynamics, which in turn allows informed model selection for forecasting and enhanced interpretability of predictive outcomes. Despite strides in this domain, prevailing methodologies often falter due to: (1) an inability to effectively model the temporal behaviors inherent in financial series; and (2) neglecting the interdependencies among series when discovering regimes. In this paper, we propose RHINE, a Regime-switcHIng model with Nonlinear rEpresentation. RHINE stands out with its kernel-based representation, adept at capturing the dynamic shifts in market regimes. This representation encapsulates the nonlinear interplay across multiple financial time series. By leveraging the kernel representation, we introduce an eigengap thresholding measure, designed to automatically discern the optimal number of financial market regimes, enhancing the model's adaptability to market fluctuations. Empirical assessments on both synthetic and real-world stock market datasets underscore RHINE's prowess. The findings illuminate that the inherent structures governing financial market behaviors are dynamic, and harnessing these dynamics via RHINE leads to a regime-based model that outperforms both conventional and state-of-the-art neural network models in predictive capabilities. 
 Full Access 
 FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning 
 href="/author/Zhang%2C+Hongyu" - Hongyu Zhang | , 
 href="/author/Zheng%2C+Dongyi" - Dongyi Zheng | , 
 href="/author/Yang%2C+Xu" - Xu Yang | , 
 href="/author/Feng%2C+Jiyuan" - Jiyuan Feng | , 
 href="/author/Liao%2C+Qing" - Qing Liao 
 pp.535–543 
 Abstract 
 PDF 
 AbstractCross-domain Sequential Recommendation (CSR) which leverages user sequence data from multiple domains has received extensive attention in recent years. However, the existing CSR methods require sharing origin user data across domains, which violates the General Data Protection Regulation (GDPR). Thus, it is necessary to combine federated learning (FL) and CSR to fully utilize knowledge from different domains while preserving data privacy. Nonetheless, the sequence feature heterogeneity across different domains significantly impacts the overall performance of FL. In this paper, we propose FedDCSR, a novel federated cross-domain sequential recommendation framework via disentangled representation learning. Specifically, to address the sequence feature heterogeneity across domains, we introduce an approach called inter-intra domain sequence representation disentanglement (SRD) to disentangle the user sequence features into domain-shared and domain-exclusive features. In addition, we design an intra domain contrastive infomax (CIM) strategy to learn richer domain-exclusive features of users by performing data augmentation on user sequences. Extensive experiments on three real-world scenarios demonstrate that FedDCSR achieves significant improvements over existing baselines1. 
 1Code available at https://github.com/orion-orion/FedDCSR 
 Full Access 
 Denoising Long- and Short-term Interests for Sequential Recommendation 
 href="/author/Zhang%2C+Xinyu" - Xinyu Zhang | , 
 href="/author/Li%2C+Beibei" - Beibei Li | , 
 href="/author/Jin%2C+Beihong" - Beihong Jin 
 pp.544–552 
 Abstract 
 PDF 
 AbstractUser interests can be viewed over different time scales, mainly including stable long-term preferences and changing short-term intentions, and their combination facilitates the comprehensive sequential recommendation. However, existing work that focuses on different time scales of user modeling has ignored the negative effects ofdifferent time-scale noise, which hinders capturing actual user interests and cannot be resolved by conventional sequential denoising methods. In this paper, we propose a Long- and Short-term Interest Denoising Network (LSIDN), which employs different encoders and tailored denoising strategies to extract long- and short-term interests, respectively, achieving both comprehensive and robust user modeling. Specifically, we employ a session-level interest extraction and evolution strategy to avoid introducinginter-session behavioral noiseinto long-term interest modeling; we also adopt contrastive learning equipped with a homogeneous exchanging augmentation to alleviate the impact ofunintentional behavioral noiseon short-term interest modeling. Results of experiments on two public datasets show that LSIDN consistently outperforms state-of-the-art models and achieves significant robustness. 
 Full Access 
 CausalCDR: Causal Embedding Learning for Cross-domain Recommendation 
 href="/author/Li%2C+Fengxin" - Fengxin Li | , 
 href="/author/Liu%2C+Hongyan" - Hongyan Liu | , 
 href="/author/He%2C+Jun" - Jun He | , 
 href="/author/Du%2C+Xiaoyong" - Xiaoyong Du 
 pp.553–561 
 Abstract 
 PDF 
 AbstractCross-domain recommendation (CDR) methods achieve success in disentangling user preferences into domain-specific and domain-shared parts. However, recent research has shown that isolated domain-specific preference limits performance improvements. In this paper, we propose a new CDR framework, called CausalCDR, which identifies the limitations of existing methods and addresses existing issues. CausalCDR consists of two views: the causal view and the generative view. The causal view incorporates causality of variables into the CDR scenario, while the generative view implements the causal view by modeling the joint distribution of user interaction via encoding, causal, and generation stage. To optimize CausalCDR, we re-derive the Evidence Lower Bound (ELBO) and introduce a mutual information regularizer and an adversarial classifier. We evaluate CausalCDR on four real-world CDR scenarios and demonstrate its effectiveness in improving CDR performance. 
 Full Access 
 DimReg: Embedding Dimension Search via Regularization for Recommender Systems 
 href="/author/Zhao%2C+Mingjun" - Mingjun Zhao | , 
 href="/author/Jiang%2C+Liyao" - Liyao Jiang | , 
 href="/author/Yu%2C+Yakun" - Yakun Yu | , 
 href="/author/Wang%2C+Xinmin" - Xinmin Wang | , 
 href="/author/Yuan%2C+Yi" - Yi Yuan | , 
 href="/author/Wei%2C+Zheng" - Zheng Wei | , 
 href="/author/Niu%2C+Di" - Di Niu 
 pp.562–570 
 Abstract 
 PDF 
 AbstractModern recommender systems aim to identify items that are most pertinent to a particular user and are particularly useful when an overwhelming number of items are present. Feature embedding is essential to deep recommender systems, which constructs memory-efficient and semantically meaningful representations by mapping high-dimensional sparse feature vectors into low-dimensional dense vectors. Most existing systems assign a unified dimension to all feature fields, regardless of the diverse importance of different features, which usually results in sub-optimal performance and high memory usage. In this paper, we propose a low-cost embedding dimension search approach named DimReg for recommender systems, by assessing information overlapping between the dimensions within each feature field and pruning unimportant and redundant dimensions progressively during model training via a two-level polarization regularizer, while introducing minimum overhead. Moreover, our method does not require retraining after embedding dimension search, which significantly reduces the computational cost and is more friendly to deployment in real-world recommender systems. Extensive experiments conducted on multiple CTR (Click Through Rate) prediction tasks demonstrate that our method can efficiently reduce the model parameters up to 98.6%, and achieve strong recommendation performance outperforming existing automated embedding dimension search methods. 
 Full Access 
 DualVAE: Dual Disentangled Variational AutoEncoder for Recommendation 
 href="/author/Guo%2C+Zhiqiang" - Zhiqiang Guo | , 
 href="/author/Li%2C+Guohui" - Guohui Li | , 
 href="/author/Li%2C+Jianjun" - Jianjun Li | , 
 href="/author/Wang%2C+Chaoyang" - Chaoyang Wang | , 
 href="/author/Shi%2C+Si" - Si Shi 
 pp.571–579 
 Abstract 
 PDF 
 AbstractLearning precise representations of users and items to fit observed interaction data is the fundamental task of collaborative filtering. Existing studies usually infer entangled representations to fit such interaction data, neglecting to model the diverse matching relationships between users and items behind their interactions, leading to limited performance and weak interpretability. To address this problem, we propose a Dual Disentangled Variational AutoEncoder (DualVAE) for collaborative recommendation, which combines disentangled representation learning with variational inference to facilitate the generation of implicit interaction data. Specifically, we first implement the disentangling concept by unifying an attention-aware dual disentanglement and disentangled variational autoencoder to infer the disentangled latent representations of users and items. Further, to encourage the correspondence and independence of disentangled representations of users and items, we design a neighborhood-enhanced representation constraint with a customized contrastive mechanism to improve the representation quality. Extensive experiments on three real-world benchmarks show that our proposed model significantly outperforms several recent state-of-the-art baselines. Further empirical experimental results also illustrate the interpretability of the disentangled representations learned by DualVAE. 
 Full Access 
 Exploiting Multifaceted Nature of Items and Users for Session-based Recommendation 
 href="/author/Sun%2C+Tianqi" - Tianqi Sun | , 
 href="/author/Guo%2C+Hongrui" - Hongrui Guo | , 
 href="/author/Zhang%2C+Zihan" - Zihan Zhang | , 
 href="/author/Liu%2C+Hongzhi" - Hongzhi Liu | , 
 href="/author/Wu%2C+Zhonghai" - Zhonghai Wu 
 pp.580–588 
 Abstract 
 PDF 
 AbstractSession-based recommendation (SBR) aims to predict user behaviors based on anonymous sessions. Compared with traditional user-based recommendation, SBR has a wider range of applications, but also suffers from more severe data sparsity problems because of the absence of user-profiles and limited short-term interactions. Furthermore, both users and items in the real world have a multifaceted nature. Users may exhibit multiple intents within a session, while items may have different semantics in different contexts. Unfortunately, existing approaches often overlook or only consider one aspect of them. To address these issues, we propose a novel hypergraph-based framework for session-based recommendation, called Hyperedge Interactional Convolution Network (HICN). Each session is represented as a sequential hyperedge, and multiple modules are designed to model and make use of the multifaceted nature of items and users. In addition, two inter-hyperedge modeling modules are designed to leverage related auxiliary information from other sessions with consideration of the existence of noise, which can help alleviate the data sparsity problem. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed model HICN. 
 Full Access 
 Prescribed Fire Modeling using Knowledge-Guided Machine Learning for Land Management 
 href="/author/Chatterjee%2C+Somya+Sharma" - Somya Sharma Chatterjee | , 
 href="/author/Lindsay%2C+Kelly" - Kelly Lindsay | , 
 href="/author/Chatterjee%2C+Neel" - Neel Chatterjee | , 
 href="/author/Patil%2C+Rohan" - Rohan Patil | , 
 href="/author/Callafon%2C+Ilkay+Altintas+de" - Ilkay Altintas De Callafon | , 
 href="/author/Steinbach%2C+Michael" - Michael Steinbach | , 
 href="/author/Giron%2C+Daniel" - Daniel Giron | , 
 href="/author/Nguyen%2C+Mai+H" - Mai H. Nguyen | , 
 href="/author/Kumar%2C+Vipin" - Vipin Kumar 
 pp.589–597 
 Abstract 
 PDF 
 AbstractIn recent years, the increasing threat of devastating wildfires has underscored the need for effective prescribed fire management. Process-based computer simulations have traditionally been employed to plan prescribed fires for wildfire prevention. However, even simplified process models are too compute-intensive to be used for real-time decision-making. Traditional ML methods used for fire modeling offer computational speedup but struggle with physically inconsistent predictions, biased predictions due to class imbalance, biased estimates for fire spread metrics (e.g., burned area, rate of spread), and limited generalizability in out-of-distribution wind conditions. This paper introduces a novel machine learning (ML) framework that enables rapid emulation of prescribed fires while addressing these concerns. To overcome these challenges, the framework incorporates domain knowledge in the form of physical constraints, a hierarchical modeling structure to capture the interdependence among variables of interest, and also leverages pre-existing source domain data to augment training data and learn the spread of fire more effectively. Notably, improvement in fire metric (e.g., burned area) estimates offered by our framework makes it useful for fire managers, who often rely on these estimates to make decisions about prescribed burn management. Furthermore, our framework exhibits better generalization capabilities than the other ML-based fire modeling methods across diverse wind conditions and ignition patterns. 
 Full Access 
 Spatial-Temporal Augmented Adaptation via Cycle-Consistent Adversarial Network: An Application in Streamflow Prediction 
 href="/author/Kalanat%2C+Nasrin" - Nasrin Kalanat | , 
 href="/author/Xie%2C+Yiqun" - Yiqun Xie | , 
 href="/author/Li%2C+Yanhua" - Yanhua Li | , 
 href="/author/Jia%2C+Xiaowei" - Xiaowei Jia 
 pp.598–606 
 Abstract 
 PDF 
 AbstractAccurate prediction of water flow is of utmost importance, particularly for ensuring water supply and informing early actions for floods and droughts. Existing flow prediction methods rely on the input of weather drivers, which hinders their applicability to monitoring small headwater streams due to the limited spatial resolution of existing weather datasets. This paper introduces a new dataset with frequent imagery on streams for water monitoring tasks. Our objective is to automatically predict streamflow for each stream site using frequent images taken at a sub-hourly scale. To overcome the challenge of limited labels for certain stream sites, we employ knowledge transfer from well-observed sites to poorly-observed sites via domain adaptation. As each stream site involves highly variable time series data over long periods, we introduce a novel method STCGAN (Spatial-Temporal Cycle Generative Adversarial Network), which incorporates temporal context by conditioning on the sequence's time and learns overall trends of stream flow variation. It integrates the predictive modeling of streamflow with the cyclic generative process and enhances the prediction with data augmentation using generated synthetic samples. Our experiments demonstrate superior performance of the proposed method using data collected from the West Brook area located in western Massachusetts, US. The proposed method can be further extended to selectively combine information from multiple well-observed stream sites, leading to improved overall performance. 
 Full Access 
 Bridging Semantics: Mobility Analytics Framework for Knowledge Transfer 
 href="/author/Ghosh%2C+Shreya" - Shreya Ghosh | , 
 href="/author/Mitra%2C+Prasenjit" - Prasenjit Mitra 
 pp.607–615 
 Abstract 
 PDF 
 AbstractThis paper introduces MoveInsight, a novel framework, leveraging a Mobility Knowledge Graph and deep learning architecture to analyze individuals' GPS traces from sensor-equipped smartphones for extracting trip purposes and understanding spatio-temporal mobility patterns. Unlike traditional information retrieval methods, MoveInsight deciphers the motivations behind travels by examining relations among individuals' movement behaviors, locations, and semantic contexts. The framework employs a multi-task learning approach for annotating trajectories and a transfer learning method for extending analysis to different regions, utilizing insights from comparable areas. Through real-world dataset testing, MoveInsight outperformed baseline methods in trip-purpose extraction and Point-of-Interest annotations by around 18% to 30%, showcasing its promise in enhancing location-centric services by providing deeper insights into human mobility dynamics. 
 Full Access 
 Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data 
 href="/author/Farhadloo%2C+Majid" - Majid Farhadloo | , 
 href="/author/Sharma%2C+Arun" - Arun Sharma | , 
 href="/author/Gupta%2C+Jayant" - Jayant Gupta | , 
 href="/author/Leontovich%2C+Alexey" - Alexey Leontovich | , 
 href="/author/Markovic%2C+Svetomir+N" - Svetomir N. Markovic | , 
 href="/author/Shekhar%2C+Shashi" - Shashi Shekhar 
 pp.616–624 
 Abstract 
 PDF 
 AbstractGiven multi-category point sets from different place-types, our goal is to develop a spatially-lucid classifier that can distinguish between two classes based on the arrangements of their points. This problem is important for many applications, such as oncology, for analyzing immune-tumor relationships and designing new immunotherapies. It is challenging due to spatial variability and interpretability needs. Previously proposed techniques require dense training data or have limited ability to handle significant spatial variability within a single place-type. Most importantly, these deep neural network (DNN) approaches are not designed to work in non-Euclidean space, particularly point sets. Existing non-Euclidean DNN methods are limited to one-size-fits-all approaches. We explore a spatial ensemble framework that explicitly uses different training strategies, including weighted-distance learning rate and spatial domain adaptation, on various place-types for spatially-lucid classification. Experimental results on real-world datasets (e.g., MxIF oncology data) show that the proposed framework provides higher prediction accuracy than baseline methods. 
 Full Access 
 Unified Modeling and Clustering of Mobility Trajectories with Spatiotemporal Point Processes 
 href="/author/Lin%2C+Haowen" - Haowen Lin | , 
 href="/author/Chiang%2C+Yao-Yi" - Yao-Yi Chiang | , 
 href="/author/Xiong%2C+Li" - Li Xiong | , 
 href="/author/Shahabi%2C+Cyrus" - Cyrus Shahabi 
 pp.625–633 
 Abstract 
 PDF 
 AbstractIn various application domains like transportation, urban planning, and public health, analyzing human mobility, represented as a sequence of consecutive visits (aka trajectories), is crucial for uncovering essential mobility patterns. Current practices often discretize space and time to model trajectory data with sequence-analysis techniques like Transformers and LSTM, but this discretization tends to obscure the intrinsic spatial and temporal characteristics inherent in trajectories. Recent work shows the effectiveness of modeling trajectories directly in continuous space and time using the spatiotempo-ral point process (STPP). However, these approaches often assume that all observed trajectories originate from a single underlying dynamic. In reality, real-world trajectories exhibit varying dynamics or moving patterns. We hypothesize that grouping trajectories governed by similar dynamics into clusters before trajectory modeling could enhance modeling effectiveness. Thus, we present a novel approach that simultaneously models trajectories in continuous space and time using STPP while clustering them. Our method leverages a variational Expectation-Maximization (EM) framework to iteratively improve the learning of trajectory dynamics and refine cluster assignments within a single training phase. Extensive tests on synthetic and real-world data demonstrate its effectiveness in clustering and modeling trajectories. 
 Full Access 
 Ada-VAD: Domain Adaptable Video Anomaly Detection 
 href="/author/Guo%2C+Dongliang" - Dongliang Guo | , 
 href="/author/Fu%2C+Yun" - Yun Fu | , 
 href="/author/Li%2C+Sheng" - Sheng Li 
 pp.634–642 
 Abstract 
 PDF 
 AbstractVideo anomaly detection (VAD) aims at identifying unusual behaviors from videos. Most of the existing video anomaly detection methods can achieve promising performance in the scenarios where training and test samples are drawn from the same distribution. In real-world situation, however, it is intractable to collect and label sufficient training video samples that cover many possible test scenarios, and existing methods demonstrate limited generalization ability. Focusing on this issue, we present the few-shot cross-domain video anomaly detection (FC-VAD) problem, which aims to adapt anomaly detection model to target samples, with access to only a few target video frames. To solve the FC-VAD problem, we propose an adaptive video anomaly detection framework named Ada-VAD, which contains a pretraining stage and an adaptation stage. In the pretraining stage, we synthesize abnormal samples and design a self-supervision based prediction task to pretrain a domain invariant model. In the adaptation stage, we adapt the pre-trained model to target domain with few-shot samples by mitigating the distribution shift with an adversarial training approach. We conduct extensive experiments on three benchmark datasets, and results show that our Ada-VAD approach outperforms the state-of-the-art VAD methods in most cases. Our code is available at https://github.com/donglgcn/ADA-VAD 
 Full Access 
 COMBOOD: A Semiparametric Approach for Detecting Out-of-distribution Data for Image Classification 
 href="/author/Rajasekaran%2C+Magesh" - Magesh Rajasekaran | , 
 href="/author/Sajol%2C+Md+Saiful+Islam" - Md Saiful Islam Sajol | , 
 href="/author/Berglind%2C+Frej" - Frej Berglind | , 
 href="/author/Mukhopadhyay%2C+Supratik" - Supratik Mukhopadhyay | , 
 href="/author/Das%2C+Kamalika" - Kamalika Das 
 pp.643–651 
 Abstract 
 PDF 
 AbstractIdentifying out-of-distribution (OOD) data at inference time is crucial for many machine learning applications, especially for automation. We present a novel unsupervised semi-parametric framework COMBOOD for OOD detection with respect to image recognition. Our framework combines signals from two distance metrics, nearest-neighbor and Mahalanobis, to derive a confidence score for an inference point to be out-of-distribution. The former provides a non-parametric approach to OOD detection. The latter provides a parametric, simple, yet effective method for detecting OOD data points, especially, in thefar OODscenario, where the inference point is far apart from the training data set in the embedding space. However, its performance is not satisfactory in thenear OODscenarios that arise in practical situations. Our COMBOOD framework combines the two signals in a semi-parametric setting to provide a confidence score that is accurate both for the near-OOD and far-OOD scenarios. We show experimental results with the COMBOOD framework for different types of feature extraction strategies. We demonstrate experimentally that COMBOOD outperforms state-of-the-art OOD detection methods on the OpenOOD (both version 1 and most recent version 1.5) benchmark datasets (for both far-OOD and near-OOD) as well as on the documents dataset in terms of accuracy. 
 On a majority of the benchmark datasets, the improvements in accuracy resulting from the COMBOOD framework are statistically significant. COMBOOD scales linearly with the size of the embedding space, making it ideal for many real-life applications. 
 Full Access 
 Dimensionality-Aware Outlier Detection 
 href="/author/Anderberg%2C+Alastair" - Alastair Anderberg | , 
 href="/author/Bailey%2C+James" - James Bailey | , 
 href="/author/Campello%2C+Ricardo+J+G+B" - Ricardo J. G. B. Campello | , 
 href="/author/Houle%2C+Michael+E" - Michael E. Houle | , 
 href="/author/Marques%2C+Henrique+O" - Henrique O. Marques | , 
 href="/author/Radovanovi%C4%87%2C+Milo%C5%A1" - Miloš Radovanović | , 
 href="/author/Zimek%2C+Arthur" - Arthur Zimek 
 pp.652–660 
 Abstract 
 PDF 
 AbstractWe present a nonparametric method for outlier detection that takes full account of local variations in intrinsic dimensionality within the dataset. Using the theory of Local Intrinsic Dimensionality (LID), our ‘dimensionality-aware’ outlier detection method, DAO, is derived as an estimator of an asymptotic local expected density ratio involving the query point and a close neighbor drawn at random. The dimensionality-aware behavior of DAO is due to its use of local estimation of LID values in a theoretically-justified way. Through comprehensive experimentation on more than 800 synthetic and real datasets, we show that DAO significantly outperforms three popular and important benchmark outlier detection methods: Local Outlier Factor (LOF), Simplified LOF, andkNN. 
 *The full version of the paper can be accessed at https://arxiv.org/abs/2401.05453 
 Full Access 
 MultiNetAD: Multiplex Network-Based Anomaly Access Detection Featuring Semantic Hierarchies 
 href="/author/Yuan%2C+Ziqi" - Ziqi Yuan | , 
 href="/author/Sun%2C+Qingyun" - Qingyun Sun | , 
 href="/author/Zhou%2C+Haoyi" - Haoyi Zhou | , 
 href="/author/Zhu%2C+Zukun" - Zukun Zhu | , 
 href="/author/Li%2C+Jianxin" - Jianxin Li 
 pp.661–669 
 Abstract 
 PDF 
 AbstractConventional anomaly access detection frameworks typically utilize all attribute fields to collectively embed them into a unified space to detect various types of anomaly accesses. However, attributes inherently contain varying semantic hierarchies, and different anomaly types exhibit inconsistent characteristics at different semantic levels. Therefore, the unified embedding results in a blending of attributes that either exhibit or do not exhibit anomaly characteristics, impacting the detection performance. To address this issue, we conduct a formal analysis of the attribute blending problem and propose MultiNetAD, a novel multiplex network-based framework designed for anomaly access detection. By introducing the multiplex network, we partition the semantic hierarchy of attributes, thereby mitigating attribute blending and consequently achieving hierarchical and unified anomaly access detection. In experiments targeting intrusion and anonymous traffic detection scenarios, MultiNetAD solves the attribute blending problem, surpasses state-of-the-art methods, and remains adaptable even with minimal proportions of anomaly accesses and labeled anomalies. Further case studies provide in-depth insights into the hierarchy and detection results. 
 Full Access 
 Semi-Supervised Isolation Forest for Anomaly Detection 
 href="/author/Stradiotti%2C+Luca" - Luca Stradiotti | , 
 href="/author/Perini%2C+Lorenzo" - Lorenzo Perini | , 
 href="/author/Davis%2C+Jesse" - Jesse Davis 
 pp.670–678 
 Abstract 
 PDF 
 AbstractAnomaly detection algorithms attempt to find instances that deviate from the expected behavior. Because this is often tackled as an unsupervised task, anomaly detection models rely on exploiting intuitions about what constitutes anomalous behavior. These typically take the form of data-driven heuristics that measure the anomalousness of each instance. However, the effectiveness of unsupervised detectors are limited by the validity of their intuition. Because these are not universally true, one can improve the detectors' performance by using a semi-supervised approach that exploits a few labeled instances. This paper proposes a novel semi-supervised tree ensemble based anomaly detection framework. We compare our proposed approach to several baselines and show that it achieves comparable performance to state-of-the-art neural networks on six real-world and 14 benchmark datasets. 
 Full Access 
 Dual-disentangled Deep Multiple Clustering 
 href="/author/Yao%2C+Jiawei" - Jiawei Yao | , 
 href="/author/Hu%2C+Juhua" - Juhua Hu 
 pp.679–687 
 Abstract 
 PDF 
 AbstractMultiple clustering has gathered significant attention in recent years due to its potential to reveal multiple hidden structures of the data from different perspectives. Most of multiple clustering methods first derive feature representations by controlling the dissimilarity among them, subsequently employing traditional clustering methods (e.g., k-means) to achieve the final multiple clustering outcomes. However, the learned feature representations can exhibit a weak relevance to the ultimate goal of distinct clustering. Moreover, these features are often not explicitly learned for the purpose of clustering. Therefore, in this paper, we propose a novel Dual-Disentangled deep Multiple Clustering method named DDMC by learning disentangled representations. Specifically, DDMC is achieved by a variational Expectation-Maximization (EM) framework. In the E-step, the disentanglement learning module employs coarse-grained and fine-grained disentangled representations to obtain a more diverse set of latent factors from the data. In the M-step, the cluster assignment module utilizes a cluster objective function to augment the effectiveness of the cluster output. Our extensive experiments demonstrate that DDMC consistently outperforms state-of-the-art methods across seven commonly used tasks. Our code is available at https://github.com/Alexander-Yao/DDMC. 
 Full Access 
 DualToken-ViT: Position-aware Efficient Vision Transformer with Dual Token Fusion 
 href="/author/Chu%2C+Zhenzhen" - Zhenzhen Chu | , 
 href="/author/Chen%2C+Jiayu" - Jiayu Chen | , 
 href="/author/Chen%2C+Cen" - Cen Chen | , 
 href="/author/Wang%2C+Chengyu" - Chengyu Wang | , 
 href="/author/Wu%2C+Ziheng" - Ziheng Wu | , 
 href="/author/Huang%2C+Jun" - Jun Huang | , 
 href="/author/Qian%2C+Weining" - Weining Qian 
 pp.688–696 
 Abstract 
 PDF 
 AbstractSelf-attention-based vision transformers (ViTs) have emerged as a highly competitive architecture in computer vision. Unlike convo-lutional neural networks (CNNs), ViTs are capable of global information sharing. With the development of various structures of ViTs, ViTs are increasingly advantageous for many vision tasks. However, the quadratic complexity of self-attention renders ViTs computationally intensive, and their lack of inductive biases of locality and translation equivariance demands larger model sizes compared to CNNs to effectively learn visual features. In this paper, we propose a light-weight and efficient vision transformer model called DualToken-ViT that leverages the advantages of CNNs and ViTs. DualToken-ViT effectively fuses the token with local information obtained by convolution-based structure and the token with global information obtained by self-attention-based structure to achieve an efficient attention structure. In addition, we use position-aware global tokens throughout all stages to enrich the global information, which further strengthening the effect of DualToken-ViT. Position-aware global tokens also contain the position information of the image, which makes our model better for vision tasks. We conducted extensive experiments on image classification, object detection and semantic segmentation tasks to demonstrate the effectiveness of DualToken-ViT. On the ImageNet-1K dataset, our models of different scales achieve accuracies of 75.4% and 79.4% with only 0.5G and 1.0G FLOPs, respectively, and our model with 1.0G FLOPs outperforms LightViT-T using global tokens by 0.7%. 
 Full Access 
 Identification and Uses of Deep Learning Backbones via Pattern Mining 
 href="/author/Livanos%2C+Michael" - Michael Livanos | , 
 href="/author/Davidson%2C+Ian" - Ian Davidson 
 pp.697–705 
 Abstract 
 PDF 
 AbstractDeep learning is extensively used in many areas of data mining as a black-box method with impressive results. However, understanding the core mechanism of how deep learning makes predictions is a relatively understudied problem. Here we explore the notion of identifying a backbone of deep learning for a given group of instances. A group here can be instances of the same class or even misclassified instances of the same class. We view each instance for a given group as activating a subset of neurons and attempt to find a subgraph of neurons associated with a given concept/group. We formulate this problem as a set cover style problem and show it is intractable and presents a highly constrained integer linear programming (ILP) formulation. As an alternative, we explore a coverage-based heuristic approach related to pattern mining, and show it converges to a Pareto equilibrium point of the ILP formulation. Experimentally we explore these backbones to identify mistakes and improve performance, explanation, and visualization. We demonstrate application-based results using several challenging data sets, including Bird Audio Detection (BAD) Challenge and Labeled Faces in the Wild (LFW), as well as the classic MNIST data. 
 Full Access 
 GE-AdvGAN: Improving the transferability of adversarial samples by gradient editing-based adversarial generative model 
 href="/author/Zhu%2C+Zhiyu" - Zhiyu Zhu | , 
 href="/author/Chen%2C+Huaming" - Huaming Chen | , 
 href="/author/Wang%2C+Xinyi" - Xinyi Wang | , 
 href="/author/Zhang%2C+Jiayu" - Jiayu Zhang | , 
 href="/author/Jin%2C+Zhibo" - Zhibo Jin | , 
 href="/author/Choo%2C+Kim-Kwang+Raymond" - Kim-Kwang Raymond Choo | , 
 href="/author/Shen%2C+Jun" - Jun Shen | , 
 href="/author/Yuan%2C+Dong" - Dong Yuan 
 pp.706–714 
 Abstract 
 PDF 
 AbstractAdversarial generative models, such as Generative Adversarial Networks (GANs), are widely applied for generating various types of data, i.e., images, text, and audio. Accordingly, its promising performance has led to the GAN-based adversarial attack methods in the white-box and black-box attack scenarios. The importance of transferable black-box attacks lies in their ability to be effective across different models and settings, more closely aligning with real-world applications. However, it remains challenging to retain the performance in terms of transferable adversarial examples for such methods. Meanwhile, we observe that some enhanced gradient-based transferable adversarial attack algorithms require prolonged time for adversarial sample generation. Thus, in this work, we propose a novel algorithm named GE-AdvGAN to enhance the transferability of adversarial samples whilst improving the algorithm's efficiency. The main approach is via optimising the training process of the generator parameters. With the functional and characteristic similarity analysis, we introduce a novel gradient editing (GE) mechanism and verify its feasibility in generating transferable samples on various models. Moreover, by exploring the frequency domain information to determine the gradient editing direction, GE-AdvGAN can generate highly transferable adversarial samples while minimizing the execution time in comparison to the state-of-the-art transferable adversarial attack algorithms. The performance of GE-AdvGAN is comprehensively evaluated by large-scale experiments on different datasets, which results demonstrate the superiority of our algorithm. The code for our algorithm is available at: https://github.com/LMBTough/GE-advGAN. 
 Full Access 
 Knowledge Guided Machine Learning for Extracting, Preserving, and Adapting Physics-aware Features 
 href="/author/He%2C+Erhu" - Erhu He | , 
 href="/author/Xie%2C+Yiqun" - Yiqun Xie | , 
 href="/author/Liu%2C+Licheng" - Licheng Liu | , 
 href="/author/Jin%2C+Zhenong" - Zhenong Jin | , 
 href="/author/Zhang%2C+Dajun" - Dajun Zhang | , 
 href="/author/Jia%2C+Xiaowei" - Xiaowei Jia 
 pp.715–723 
 Abstract 
 PDF 
 AbstractTraining machine learning (ML) models for scientific problems is often challenging due to limited observation data. To overcome this challenge, prior works commonly pre-train ML models using simulated data before having them fine-tuned with small real data. Despite the promise shown in initial research across different domains, these methods cannot ensure improved performance after fine-tuning because (i) they are not designed for extracting generalizable physics-aware features during pre-training, (ii) the features learned from pre-training can be distorted by the fine-tuning process. In this paper, we propose a new learning method for extracting, preserving, and adapting physics-aware features. We build a knowledge-guided neural network (KGNN) model based on known dependencies amongst physical variables, which facilitate extracting physics-aware feature representation from simulated data. Then we fine-tune this model by alternately updating the encoder and decoder of the KGNN model to enhance the prediction while preserving the physics-aware features learned through pre-training. We further propose to adapt the model to new testing scenarios via a teacher-student learning framework based on the model uncertainty. The results demonstrate that the proposed method outperforms many baselines by a good margin, even using sparse training data or under out-of-sample testing scenarios. 
 Full Access 
 Light POI-Guided Conversational Recommender System based on Adaptive Space 
 href="/author/Yuan%2C+Meng" - Meng Yuan | , 
 href="/author/Zhang%2C+Fuwei" - Fuwei Zhang | , 
 href="/author/Tong%2C+Yiqi" - Yiqi Tong | , 
 href="/author/Ying%2C+Yuxin" - Yuxin Ying | , 
 href="/author/Zhuang%2C+Fuzhen" - Fuzhen Zhuang | , 
 href="/author/Wang%2C+Deqing" - Deqing Wang | , 
 href="/author/Huai%2C+Baoxing" - Baoxing Huai | , 
 href="/author/Zhang%2C+Yi" - Yi Zhang | , 
 href="/author/Su%2C+Jia" - Jia Su 
 pp.724–733 
 Abstract 
 PDF 
 AbstractConversational Recommender Systems (CRS) have recently attracted significant attention. Despite existing GNN-based CRS methods have been proven to be effective in exploiting knowledge graphs (KGs), we note that these methods are not suitable for modeling scenarios with geographic positional information, which encompass the two key issues that have not been adequately solved: 1) Data noise is ubiquitous in the real world due to a variety of factors, and existing methods are prone to amplifying data noise, which can lead to a deterioration in downstream tasks; 2) Existing CRS models are designed solely in Euclidean space without considering space curvature, which implies that they may suffer from significant distortion when representing real-world graph structures, leading to a decrease in the accuracy and reliability of geographical POIs. To this end, we propose a Light POI-Guided Conversational Recommender based on Adaptive Space, namely PCRA, aiming to address the above problems by enhancing both embedding spaces and graph structures. Specifically, PCRA introduces the unified space to obtain high-quality embeddings compatible with hyperbolic space, Euclidean space, and spherical space. On the other hand, to extract the most valuable neighbors, we adopt a graph denoising module to eliminate noisy entities and ensure light information propagation. Finally, we further fuse the embeddings of utterances and entities to bridge the semantic gap of recommendation and conversation. Extensive experiments on MultiWOZ 2.0 and MultiWOZ 2.1 datasets demonstrate that our proposed PCRA has a significant improvement over the state-of-the-art CRS methods. 
 Full Access 
 Multi-Interest Network with Simple Diffusion for Multi-Behavior Sequential Recommendation 
 href="/author/Li%2C+Qingfeng" - Qingfeng Li | , 
 href="/author/Ma%2C+Huifang" - Huifang Ma | , 
 href="/author/Jin%2C+Wangyu" - Wangyu Jin | , 
 href="/author/Ji%2C+Yugang" - Yugang Ji | , 
 href="/author/Li%2C+Zhixin" - Zhixin Li 
 pp.734–742 
 Abstract 
 PDF 
 AbstractMulti-behavior sequential recommendation (MBSR) aims to learn dynamic user preference from historical heterogeneous user interactions for identifying the next item under target behavior (i.e., purchase). Although significant efforts have been devoted to modeling users over observed multi-behavior interaction sequences, user modeling with dynamic behavior-aware multiple interests and elimination of inherent noises within these interactions are still underexplored. This limits user representations' awareness of true preference evolution and further constrains recommendation performance. To address the aforementioned issues, we propose a Multi-Interest Network with Simple Diffusion (MISD) via a combination of multi-interest learning and diffusion generative process for MBSR. Concretely, the dynamic multi-interest network is proposed to generate time-evolving personalized interests from the encoded dual-granularity user sequential patterns, leading to more accurate user preference learning. Additionally, simple diffusion is proposed to model the complex latent preference generation procedures in an iterative denoising manner, thereby alleviating the effect of noisy interactions. Extensive experiments on three real-world datasets demonstrate that MISD consistently outperforms various state-of-the-art recommendation methods under multiple settings (e.g., clean and noisy training). 
 Full Access 
 Towards More Robust and Accurate Sequential Recommendation with Cascade-guided Adversarial Training 
 href="/author/Tan%2C+Juntao" - Juntao Tan | , 
 href="/author/Heinecke%2C+Shelby" - Shelby Heinecke | , 
 href="/author/Liu%2C+Zhiwei" - Zhiwei Liu | , 
 href="/author/Chen%2C+Yongjun" - Yongjun Chen | , 
 href="/author/Zhang%2C+Yongfeng" - Yongfeng Zhang | , 
 href="/author/Wang%2C+Huan" - Huan Wang 
 pp.743–751 
 Abstract 
 PDF 
 AbstractSequential recommendation models, models that learn from chronological user-item interactions, outperform traditional recommendation models in many settings. Despite the success of sequential recommendation, their robustness has recently come into question. Two properties unique to the nature of sequential recommendation models may impair their robustness - the cascade effects induced during training and the model's tendency to rely too heavily on temporal information. To address these vulnerabilities, we propose Cascade-guided Adversarial training, a new adversarial training procedure that is specifically designed for sequential recommendation models. Our approach harnesses the intrinsic cascade effects present in sequential modeling to produce strategic adversarial perturbations to item embed-dings during training. Experiments on training state-of-the-art sequential models on four public datasets from different domains show that our training approach produces superior model ranking accuracy and superior model robustness to real item replacement perturbations when compared to both standard model training and generic adversarial training. 
 Full Access 
 Variational Invariant Representation Learning for Multimodal Recommendation 
 href="/author/Yang%2C+Wei" - Wei Yang | , 
 href="/author/Zhang%2C+Haoran" - Haoran Zhang | , 
 href="/author/Zhang%2C+Li" - Li Zhang 
 pp.752–760 
 Abstract 
 PDF 
 AbstractMultimodal recommendation systems are widely used in e-commerce and short video platforms. Compared with basic item attribute information, users are more likely to be attracted by item images and make purchases. Many researchers are beginning to explore the efficient use of multimodal information. Many studies have introduced multimodal information into the model as an auxiliary feature and achieved certain results. However, the extraction of critical information from multimodal data containing complex information needs to be optimized. The problem of false relation learning in multimodal recommendation has not been effectively solved. Therefore, we propose a Variational Invariant Representation Learning (VIRL) method for multimodal recommendation. Specifically, we first propose a variational autoencoder based invariant representation learning module. Based on the joint probability distribution of invariant and variant representations, we use variational autoencoders to learn implicit representations. We then design weakly self-supervised contrastive learning to optimize the invariant representations. Further, we introduce adversarial learning to achieve cross-modal invariant information alignment. We conducted a comprehensive experiment on three real-world data sets, and the experimental results show that our model performs best. Further ablation experiments confirm the validity of variational representation. 
 Full Access 
 Vietoris-Rips Complex: A New Direction for Cross-Domain Cold-Start Recommendation 
 href="/author/Vajjala%2C+Ajay+Krishna" - Ajay Krishna Vajjala | , 
 href="/author/Meher%2C+Dipak+Falgun" - Dipak Falgun Meher | , 
 href="/author/Pothagoni%2C+Shrunal" - Shrunal Pothagoni | , 
 href="/author/Zhu%2C+Ziwei" - Ziwei Zhu | , 
 href="/author/Rosenblum%2C+David+S" - David S. Rosenblum 
 pp.761–769 
 Abstract 
 PDF 
 AbstractCross-domain recommendation (CDR) has emerged as a promising solution to alleviating the cold-start problem by leveraging information from an auxiliary source domain to generate recommendations in a target domain. Most CDR techniques fall into a category known asbridge-based methods, but many of them fail to account for the structure and rating behavior of target users from the source domain into the recommendation process. Therefore, we present a novel framework called Vietoris-Rips Complex for Cross-Domain Recommendation (VRCDR), which utilizes the Vietoris-Rips Complex (a technique from computational geometry) to understand the underlying structure in user behavior from the source domain, and includes the learned information into recommendations in the target domain to make the recommendations more personalized to users' niche preferences. Extensive experiments on large, real-world datasets demonstrate that VRCDR consistently improves recommendations compared to state-of-the-art bridge-based CDR methods. 
 Full Access 
 Stable Synthetic Control with Anomaly Detection for Causal Inference 
 href="/author/Li%2C+Qiang" - Qiang Li | , 
 href="/author/Sun%2C+Yiqiao" - Yiqiao Sun | , 
 href="/author/Pang%2C+Linsey" - Linsey Pang | , 
 href="/author/Sun%2C+Liang" - Liang Sun | , 
 href="/author/Wen%2C+Qingsong" - Qingsong Wen 
 pp.770–778 
 Abstract 
 PDF 
 AbstractThe study of treatment effects is an essential area in causal inference that has received extensive attention in the sciences. When access to counterfactual groups and experimental settings is limited, the synthetic control method (SCM) emerges as a key approach for observational studies. However, conventional SCM techniques mainly concentrate on addressing confounding issues in the pre-treatment period, often overlooking the confounding effects of control groups in the post-treatment period. In this paper, we propose a new approach named Stable-SC, which integrates synthetic control with anomaly detection algorithms to mitigate the influence of confounding factors in both the pre- and post-treatment periods. Our algorithm incorporates an anomaly-detection process that identifies trends and distance anomalies within control groups, significantly impacting SCM estimation results. Subsequently, we employ a re-weighting schema to adjust the significance of these abnormal groups and utilize the Difference-in-Differences estimator to assess causal effects. Through extensive experimentation with multiple simulated and real-world datasets, we demonstrate that our Stable-SC approach yields more robust estimates compared to other existing methods in the literature. Furthermore, we have successfully applied our proposed framework in diverse business scenarios within a prominent retail company, where the need for stable and robust A/B testing is paramount in quantifying causal effects. 
 Full Access 
 CaMU: Disentangling Causal Effects in Deep Model Unlearning 
 href="/author/Shen%2C+Shaofei" - Shaofei Shen | , 
 href="/author/Zhang%2C+Chenhao" - Chenhao Zhang | , 
 href="/author/Bialkowski%2C+Alina" - Alina Bialkowski | , 
 href="/author/Chen%2C+Weitong" - Weitong Chen | , 
 href="/author/Xu%2C+Miao" - Miao Xu 
 pp.779–787 
 Abstract 
 PDF 
 AbstractMachine unlearning requires removing the information of forgetting data while keeping the necessary information of remaining data. Despite recent advancements in this area, existing methodologies mainly focus on the effect removal of forgetting data without considering the negative impact this can have on the information of the remaining data, resulting in significant performance degradation after data removal. Although some methods try to repair the performance of remaining data after removal, the forgotten information can also return after repair. Such an issue is due to the intricate intertwining of the forgetting and remaining data. Without adequately differentiating the influence of these two kinds of data on the model, existing algorithms take the risk of either inadequate removal of the forgetting data or unnecessary loss of valuable information from the remaining data. To address this shortcoming, the present study undertakes a causal analysis of the unlearning and introduces a novel framework termed Causal Machine Unlearning (CaMU). This framework adds intervention on the information of remaining data to disentangle the causal effects between forgetting data and remaining data. Then CaMU eliminates the causal impact associated with forgetting data while concurrently preserving the causal relevance of the remaining data. Comprehensive empirical results on various datasets and models suggest that CaMU enhances performance on the remaining data and effectively minimizes the influences of forgetting data. Notably, this work is the first to interpret deep model unlearning tasks from a new perspective of causality and provide a solution based on causal analysis, which opens up new possibilities for future research in deep model unlearning. 
 Full Access 
 Robust Estimation of Causal Heteroscedastic Noise Models 
 href="/author/Tran%2C+Quang-Duy" - Quang-Duy Tran | , 
 href="/author/Duong%2C+Bao" - Bao Duong | , 
 href="/author/Nguyen%2C+Phuoc" - Phuoc Nguyen | , 
 href="/author/Nguyen%2C+Thin" - Thin Nguyen 
 pp.788–796 
 Abstract 
 PDF 
 AbstractDistinguishing the cause and effect from bivariate observational data is the foundational problem that finds applications in many scientific disciplines. One solution to this problem is assuming that cause and effect are generated from a structural causal model, enabling identification of the causal direction after estimating the model in each direction. The heteroscedastic noise model is a type of structural causal model where the cause can contribute to both the mean and variance of the noise. Current methods for estimating heteroscedas-tic noise models choose the Gaussian likelihood as the optimization objective which can be suboptimal and unstable when the data has a non-Gaussian distribution. To address this limitation, we propose a novel approach to estimating this model with Student'st-distribution, which is known for its robustness in accounting for sampling variability with smaller sample sizes and extreme values without significantly altering the overall distribution shape. This adaptability is beneficial for capturing the parameters of the noise distribution in het-eroscedastic noise models. Our empirical evaluations demonstrate that our estimators are more robust and achieve better overall performance across synthetic and real benchmarks. 
 Full Access 
 Analysis of Causal and Non-Causal Convolution Networks for Time Series Classification 
 href="/author/Saini%2C+Uday+Singh" - Uday Singh Saini | , 
 href="/author/Zhuang%2C+Zhongfang" - Zhongfang Zhuang | , 
 href="/author/Yeh%2C+Chin-Chia+Michael" - Chin-Chia Michael Yeh | , 
 href="/author/Zhang%2C+Wei" - Wei Zhang | , 
 href="/author/Papalexakis%2C+Evangelos+E" - Evangelos E. Papalexakis 
 pp.797–805 
 Abstract 
 PDF 
 AbstractApplications of neural networks like MLPs and ResNets in temporal data mining has led to improvements on the problem of time series classification. Recently, a new class of networks called Temporal Convolution Networks (TCNs) have been proposed for various time series tasks. Instead of time invariant convolutions they use temporally causal convolutions, this makes them more constrained than ResNets but surprisingly good at generalization. This raises an important question: How does a network with causal convolution solve these tasks when compared to a network with acausal convolutions? As the first attempt at answering these questions, we analyze different architectures through a lens of representational subspace similarity. We demonstrate that the evolution of input representations in the layers of TCNs is markedly different from ResNets and MLPs. We find that acausal networks are prone to form groupings of similar layers and TCNs on the other hand learn representations that are much more diverse throughout the network. Next, we study the convergence properties of internal layers across different architecture families and discover that the behaviour of layers inside Acausal network is more homogeneous when compared to TCNs. Our extensive empirical studies offer new insights into internal mechanisms of convolution networks in the domain of time series analysis and may assist practitioners gaining deeper understanding of each network. 
 Full Access 
 Deep Efficient Private Neighbor Generation for Subgraph Federated Learning 
 href="/author/Zhang%2C+Ke" - Ke Zhang | , 
 href="/author/Sun%2C+Lichao" - Lichao Sun | , 
 href="/author/Ding%2C+Bolin" - Bolin Ding | , 
 href="/author/Yiu%2C+Siu+Ming" - Siu Ming Yiu | , 
 href="/author/Yang%2C+Carl" - Carl Yang 
 pp.806–814 
 Abstract 
 PDF 
 AbstractBehemoth graphs are often fragmented and separately stored by multiple data owners as distributed subgraphs in many realistic applications. Without harming data privacy, it is natural to consider thesubgraph federated learning(subgraph FL) scenario, where each local client holds a subgraph of the entire global graph, to obtain globally generalized graph mining models. To overcome the unique challenge of incomplete information propagation on local subgraphs due to missing cross-subgraph neighbors, previous works resort to the augmentation of local neighborhoods through the joint FL of missing neighbor generators and GNNs. Yet their technical designs have profound limitations regarding the utility, efficiency, and privacy goals of FL. In this work, we propose FedDEP to comprehensively tackle these challenges in subgraph FL. FedDEP consists of a series of novel technical designs: (1) Deep neighbor generation through leveraging the GNN embeddings of potential missing neighbors; (2) Efficient pseudo-FL for neighbor generation through embedding prototyping; and (3) Privacy protection through noiseless edge-local-differential-privacy. We analyze the correctness and efficiency of FedDEP, and provide theoretical guarantees on its privacy. Empirical results on four real-world datasets justify the clear benefits of proposed techniques. 
 Full Access 
 Distributed Collapsed Gibbs Sampler for Dirichlet Process Mixture Models in Federated Learning 
 href="/author/Khoufache%2C+Reda" - Reda Khoufache | , 
 href="/author/Lebbah%2C+Mustapha" - Mustapha Lebbah | , 
 href="/author/Azzag%2C+Hanene" - Hanene Azzag | , 
 href="/author/Goffinet%2C+Etienne" - Etienne Goffinet | , 
 href="/author/Bouchaffra%2C+Djamel" - Djamel Bouchaffra 
 pp.815–823 
 Abstract 
 PDF 
 AbstractDirichlet Process Mixture Models (DPMMs) are widely used to address clustering problems. Their main advantage lies in their ability to automatically estimate the number of clusters during the inference process through the Bayesian non-parametric framework. However, the inference becomes considerably slow as the dataset size increases. This paper proposes a new distributed Markov Chain Monte Carlo (MCMC) inference method for DPMMs (DisCGS) using sufficient statistics. Our approach uses the collapsed Gibbs sampler and is specifically designed to work on distributed data across independent and heterogeneous machines, which habilitates its use in horizontal federated learning. Our method achieves highly promising results and notable scalability. For instance, with a dataset of 100K data points, the centralized algorithm requires approximately 12 hours to complete 100 iterations while our approach achieves the same number of iterations in just 3 minutes, reducing the execution time by a factor of 200 without compromising clustering performance. The code source is publicly available at https://github.com/redakhoufache/DisCGS. 
 Full Access 
 HyperFLoRA: Federated Learning with Instantaneous Personalization 
 href="/author/Lu%2C+Qikai" - Qikai Lu | , 
 href="/author/Niu%2C+Di" - Di Niu | , 
 href="/author/Khoshkho%2C+Mohammadamin+Samadi" - Mohammadamin Samadi Khoshkho | , 
 href="/author/Li%2C+Baochun" - Baochun Li 
 pp.824–832 
 Abstract 
 PDF 
 AbstractFederated learning is a decentralized approach to training machine learning models while preserving data privacy. To accommodate data heterogeneity among clients, a longstanding issue in Federated Learning, many Personalized Federated Learning (PFL) strategies decompose each client model into global modules, which are collaboratively learned by all clients and the server, and local modules, which are only trained locally on private data. While these strategies require every client to participate in training, in reality, many client devices lack sufficient data or computing resources to perform meaningful local training, making it difficult to achieve personalization for every client. In this paper, we present HyperFLoRA, a PFL framework that leverages knowledge learned from training-capable clients to enable the immediate creation of personalized models for training-incapable or new clients. HyperFLoRA uses adapters for personalization to minimize communication costs and client training workload while employing a trainable hypernetwork to generate personalized adapter weights for each client using minimal client statistical information. From experiments conducted on both convolutional and Transformer neural networks, HyperFLoRA can achieve superior model personalization performance for new clients that did not participate in training than conventional PFL methods, while significantly reducing training-related communication costs and client workload. 
 Full Access 
 AEDFL: Efficient Asynchronous Decentralized Federated Learning with Heterogeneous Devices 
 href="/author/Liu%2C+Ji" - Ji Liu | , 
 href="/author/Che%2C+Tianshi" - Tianshi Che | , 
 href="/author/Zhou%2C+Yang" - Yang Zhou | , 
 href="/author/Jin%2C+Ruoming" - Ruoming Jin | , 
 href="/author/Dai%2C+Huaiyu" - Huaiyu Dai | , 
 href="/author/Dou%2C+Dejing" - Dejing Dou | , 
 href="/author/Valduriez%2C+Patrick" - Patrick Valduriez 
 pp.833–841 
 Abstract 
 PDF 
 AbstractFederated Learning (FL) has achieved significant achievements recently, enabling collaborative model training on distributed data over edge devices. Iterative gradient or model exchanges between devices and the centralized server in the standard FL paradigm suffer from severe efficiency bottlenecks on the server. While enabling collaborative training without a central server, existing decentralized FL approaches either focus on the synchronous mechanism that deteriorates FL convergence or ignore device staleness with an asynchronous mechanism, resulting in inferior FL accuracy. In this paper, we propose an Asynchronous Efficient Decentralized FL framework, i.e., AEDFL, in heterogeneous environments with three unique contributions. First, we propose an asynchronous FL system model with an efficient model aggregation method for improving the FL convergence. Second, we propose a dynamic staleness-aware model update approach to achieve superior accuracy. Third, we propose an adaptive sparse training method to reduce communication and computation costs without significant accuracy degradation. Extensive experimentation on four public datasets and four models demonstrates the strength of AEDFL in terms of accuracy (up to 16.3% higher), efficiency (up to 92.9% faster), and computation costs (up to 42.3% lower). 
 Full Access 
 Personalized Federated Learning with Contextual Modulation and Meta-Learning 
 href="/author/Vettoruzzo%2C+Anna" - Anna Vettoruzzo | , 
 href="/author/Bouguelia%2C+Mohamed-Rafik" - Mohamed-Rafik Bouguelia | , 
 href="/author/R%C3%B6gnvaldsson%2C+Thorsteinn" - Thorsteinn Rögnvaldsson 
 pp.842–850 
 Abstract 
 PDF 
 AbstractFederated learning has emerged as a promising approach for training machine learning models on decentralized data sources while preserving data privacy. However, challenges such as communication bottlenecks, heterogeneity of client devices, and non-i.i.d. data distribution pose significant obstacles to achieving optimal model performance. We propose a novel framework that combines federated learning with meta-learning techniques to enhance both efficiency and generalization capabilities. Our approach introduces a federated modulator that learns contextual information from data batches and uses this knowledge to generate modulation parameters. These parameters dynamically adjust the activations of a base model, which operates using a MAML-based approach for model personalization. Experimental results across diverse datasets highlight the improvements in convergence speed and model performance compared to existing federated learning approaches. These findings highlight the potential of incorporating contextual information and meta-learning techniques into federated learning, paving the way for advancements in distributed machine learning paradigms. 
 Full Access 
 UPFL: Unsupervised Personalized Federated Learning towards New Clients 
 href="/author/Ye%2C+Tiandi" - Tiandi Ye | , 
 href="/author/Chen%2C+Cen" - Cen Chen | , 
 href="/author/Wang%2C+Yinggui" - Yinggui Wang | , 
 href="/author/Li%2C+Xiang" - Xiang Li | , 
 href="/author/Gao%2C+Ming" - Ming Gao 
 pp.851–859 
 Abstract 
 PDF 
 AbstractPersonalized federated learning (pFL) has gained significant attention as a promising approach to address the challenge of data heterogeneity. In this paper, we address a relatively unexplored problem in federated learning. When a federated model has been trained and deployed, and an unla-beled new client joins, providing a personalized model for the new client becomes a highly challenging task. To address this challenge, we extend the adaptive risk minimization technique into the unsupervised pFL setting and propose our method, FedTTA. We further improve FedTTA with two simple yet highly effective optimization strategies: enhancing the training of the adaptation model with proxy regularization and early-stopping the adaptation through entropy. Moreover, we propose a knowledge distillation loss specifically designed for FedTTA to address the device heterogeneity. Extensive experiments on five datasets against eleven baselines demonstrate the effectiveness of our proposed FedTTA and its variants. The code is available at: https://github.com/anonymous-federated-learning/code. 
 Full Access 
 HADT: Human-AI Diagnostic Team via Hierarchical Reinforcement Learning 
 href="/author/Zhao%2C+Xuehan" - Xuehan Zhao | , 
 href="/author/Liu%2C+Jiaqi" - Jiaqi Liu | , 
 href="/author/Yu%2C+Zhiwen" - Zhiwen Yu | , 
 href="/author/Guo%2C+Bin" - Bin Guo 
 pp.860–868 
 Abstract 
 PDF 
 AbstractMedical online consultation is important to healthcare worldwide, with hundreds of millions of participants each year. However, expert-level online consultations are expensive due to the shortage of medical professionals, while AI models are unreliable because they have unpredictable risks. Therefore, we introduce human-machine collaboration to medical online consultation and focus on symptom inquiry, as the basis for disease diagnosis. There are two key issues: 1) how to design an intelligent assignment strategy that can determine whether doctors or models participate in each turn? 2) how to design an effective execution strategy that can improve the machine's inquiry ability among considerable symptoms? To address the above issues, we propose the Human-AI Diagnostic Team (HADT) framework based on Hierarchical Reinforcement Learning (HRL), which aims to achieve high accuracy with low manpower. Specifically, HADT has two layers. The upper one is responsible for assignment, in which we propose a module called master that enables intelligent human-machine assignments through the masked RL with reward shaping. The lower one is responsible for execution, consisting of a doctor and a proposed module called machine. This module can effectively ask about symptoms through the masked HRL with bottom-up training. Experiments on the public datasets show that HADT can achieve up to 89.4% accuracy with only 10.9% human effort, as confirmed by real clinical doctors using our online interface. 
 Full Access 
 Spatial-Aware Deep Reinforcement Learning for the Traveling Officer Problem 
 href="/author/Strau%C3%9F%2C+Niklas" - Niklas Strauß | , 
 href="/author/Schubert%2C+Matthias" - Matthias Schubert 
 pp.869–877 
 Abstract 
 PDF 
 AbstractThe traveling officer problem (TOP) is a challenging stochastic optimization task. In this problem, a parking officer is guided through a city equipped with parking sensors to fine as many parking offenders as possible. A major challenge in TOP is the dynamic nature of parking offenses, which randomly appear and disappear after some time, regardless of whether they have been fined. Thus, solutions need to dynamically adjust to currently fineable parking offenses while also planning ahead to increase the likelihood that the officer arrives during the offense taking place. Though various solutions exist, these methods often struggle to take the implications of actions on the ability to fine future parking violations into account. This paper proposes SATOP, a novel spatial-aware deep reinforcement learning approach for TOP. Our novel state encoder creates a representation of each action, leveraging the spatial relationships between parking spots, the agent, and the action. Furthermore, we propose a novel message-passing module for learning future inter-action correlations in the given environment. Thus, the agent can estimate the potential to fine further parking violations after executing an action. We evaluate our method using an environment based on real-world data from Melbourne. Our results show that SATOP consistently outperforms state-of-the-art TOP agents and is able to fine up to 22% more parking offenses. 
 Full Access 
 Feature Interaction Aware Automated Data Representation Transformation 
 href="/author/Azim%2C+Ehtesamul" - Ehtesamul Azim | , 
 href="/author/Wang%2C+Dongjie" - Dongjie Wang | , 
 href="/author/Liu%2C+Kunpeng" - Kunpeng Liu | , 
 href="/author/Zhang%2C+Wei" - Wei Zhang | , 
 href="/author/Fu%2C+Yanjie" - Yanjie Fu 
 pp.878–886 
 Abstract 
 PDF 
 AbstractCreating an effective representation space is crucial for mitigating the curse of dimensionality, enhancing model generalization, addressing data sparsity, and leveraging classical models more effectively. Recent advancements in automated feature engineering (AutoFE) have made significant progress in addressing various challenges associated with representation learning, issues such as heavy reliance on intensive labor and empirical experiences, lack of explainable explic-itness, and inflexible feature space reconstruction embedded into downstream tasks. However, these approaches are constrained by: 1) generation of potentially unintelligible and illogical reconstructed feature spaces, stemming from the neglect of expert-level cognitive processes; 2) lack of systematic exploration, which subsequently results in slower model convergence for identification of optimal feature space. To address these, we introduce an interaction-aware reinforced generation perspective. We redefine feature space reconstruction as a nested process of creating meaningful features and controlling feature set size through selection. We develop a hierarchical reinforcement learning structure with cascading Markov Decision Processes to automate feature and operation selection, as well as feature crossing. By incorporating statistical measures, we reward agents based on the interaction strength between selected features, resulting in intelligent and efficient exploration of the feature space that emulates human decision-making. Extensive experiments are conducted to validate our proposed approach. 
 *The release code can be found in https://github.com/ehtesam3154/InHRecon 
 Full Access 
 Neural Locality Sensitive Hashing for Entity Blocking 
 href="/author/Wang%2C+Runhui" - Runhui Wang | , 
 href="/author/Kong%2C+Luyang" - Luyang Kong | , 
 href="/author/Tao%2C+Yefan" - Yefan Tao | , 
 href="/author/Borthwick%2C+Andrew" - Andrew Borthwick | , 
 href="/author/Golac%2C+Davor" - Davor Golac | , 
 href="/author/Johnson%2C+Henrik" - Henrik Johnson | , 
 href="/author/Hijazi%2C+Shadie" - Shadie Hijazi | , 
 href="/author/Deng%2C+Dong" - Dong Deng | , 
 href="/author/Zhang%2C+Yongfeng" - Yongfeng Zhang 
 pp.887–895 
 Abstract 
 PDF 
 AbstractLocality-sensitive hashing (LSH) is a fundamental algorithmic technique widely employed in large-scale data processing applications, such as nearest-neighbor search, entity resolution, and clustering. However, its applicability in some real-world scenarios is limited due to the need for careful design of hashing functions that align with specific metrics. Existing LSH-based Entity Blocking solutions primarily rely on generic similarity metrics such as Jaccard similarity, whereas practical use cases often demand complex and customized similarity rules surpassing the capabilities of generic similarity metrics. Consequently, designing LSH functions for these customized similarity rules presents considerable challenges. In this research, we propose a neuralization approach to enhance locality-sensitive hashing by training deep neural networks to serve as hashing functions for complex metrics. We assess the effectiveness of this approach within the context of the entity resolution problem, which frequently involves the use of task-specific metrics in real-world applications. Specifically, we introduce NLSHBlock (Neural-LSH Block), a novel blocking methodology that leverages pre-trained language models, fine-tuned with a novel LSH-based loss function. Through extensive evaluations conducted on a diverse range of real-world datasets, we demonstrate the superiority of NLSHBlock over existing methods, exhibiting significant performance improvements. Furthermore, we showcase the efficacy of NLSHBlock in enhancing the performance of the entity matching phase, particularly within the semi-supervised setting. 
 Full Access 
 Word Embedding with Neural Probabilistic Prior 
 href="/author/Ren%2C+Shaogang" - Shaogang Ren | , 
 href="/author/Li%2C+Dingcheng" - Dingcheng Li | , 
 href="/author/Li%2C+Ping" - Ping Li 
 pp.896–904 
 Abstract 
 PDF 
 AbstractTo improve word representation learning, we propose a probabilistic prior which can be seamlessly integrated with word embedding models. Different from previous methods, word embedding is taken as a probabilistic generative model, and it enables us to impose a prior regularizing word representation learning. The proposed prior not only enhances the representation of embedding vectors but also improves the model's robustness and stability. The structure of the proposed prior is simple and effective, and it can be easily implemented and flexibly plugged in most existing word embedding models. Extensive experiments show the proposed method improves word representation on various tasks. 
 Book Details | Published:2024 
 eISBN:978-1-61197-803-2 
 https://doi.org/10.1137/1.9781611978032 
 Book Series Name:Proceedings 
 Book Code:PRDT24 
 Book Pages:xii - 904 
 BibTex 
 Recommended Content 
 Society for Industrial and 
 Applied Mathematics 
 Society for Industrial and Applied Mathematics 
 3600 Market Street, 6th Floor 
 Philadelphia, PA 19104 
 USA 
 © 2025 Society for Industrial and Applied Mathematics 
 Browse | Browse | Journals 
 E-books 
 Bookstore 
 Proceedings 
 Alerts | Alerts | Sign up/Manage Email Alerts 
 Information | Information | href="/journal-authors" - For Journal Authors 
 href="/book-authors" - For Book Authors 
 For Librarians 
 Help 
 Terms of Use & Privacy Policy 
 About | About | SIAM 
 Join SIAM 
 Donate to SIAM 
 Request Username 
 Can't sign in? Forgot your username? 
 Enter your email address below and we will send you your username 
 EmailClose 
 If the address matches an existing account you will receive an email with instructions to retrieve your username 
 Register 
 Email*Already have an account?Change Password 
 Old PasswordNew PasswordToo ShortWeakMediumStrongVery StrongToo LongYour password must have 2 characters or more and contain 3 of the following: 
 a lower case character, 
 an upper case character, 
 a special character 
 or a digit 
 Too ShortPassword Changed Successfully 
 Your password has been changed 
 Login 
 Email*Password*Forgot your password?Create AccountKeep me logged inCreate AccountLog in via your institutionCan't sign in? Forgot your password? 
 Enter your email address below and we will send you the reset instructions 
 EmailCancelIf the address matches an existing account you will receive an email with instructions to reset your password 
 CloseVerify Phone 
 Enter the verification codeCancelCongrats! 
 Your Phone has been verified 
 close

3. Website of SDM_2: https://research.com/conference/siam-international-conference-on-data-mining
Website information of SDM_2:

Most Affordable CollegesMost Affordable CollegesAffordable PhD ProgramsAffordable Online Masters ProgramsAffordable Online Bachelor Degree ProgramsAffordable Online CollegesAffordable Online Colleges for MilitaryBusiness & ManagementAffordable Online MBA ProgramsAffordable Online Business DegreeAffordable Online Accounting Degree ProgramsAffordable Online Master's in AccountingAffordable Doctoral Programs in LeadershipTechnology ProgramsAffordable Online Computer Science DegreeAffordable Online Engineering DegreeAffordable Online Data Science MastersAffordable Online Cyber Security DegreeCheapest MLIS Degree OnlineEducation ProgramsAffordable Online Education DegreeAffordable Online Master's in TeachingAffordable Online Elementary Education DegreeAffordable Online Colleges for Early Childhood EducationHealthcare ProgramsCheapest Online MHA ProgramsAffordable Online MBA in Healthcare ManagementAffordable Online Healthcare Administration DegreeAffordable Online Public Health DegreeMore Affordable Online ProgramsAffordable Online Speech Pathology ProgramsAffordable Online MSW ProgramsAffordable MFA OnlineAffordable Online Criminal Justice DegreeNursing programsCheapest RN to BSN OnlineAffordable Online Nursing ProgramsAffordable Online Nurse Practitioner ProgramsAffordable Online FNP ProgramsMore Affordable Online ProgramsAffordable Online Psychology DegreeAffordable Online Counseling DegreeAffordable Online Substance Abuse Counseling DegreeAffordable Online MBA Programs No GMATCheapest Online Master's in Human ResourcesAffordable Online Executive MBA ProgramsCheapest BCBA Online ProgramsAffordable Online Master's Programs in CounselingAffordable Christian Counseling DegreeCollege RankingsOnline CollegesBest College MajorsOnline PhD ProgramsHighest Paying Bachelor DegreesEasy Degrees That Pay WellMasters DegreeComputer ScienceAccelerated Online Computer Science DegreeBest Online Computer Science DegreeBest Cyber Security Courses OnlineMIS DegreeIs a Computer Science Degree Worth It?PsychologyForensic Psychology DegreeBest Online Psychology DegreeOnline PsyD ProgramsOnline Masters in PsychologyDoctorate in PsychologySubstance Abuse Counselor DegreeMasters in Educational PsychologyIs a Psychology Degree Worth It?Criminal Psychology DegreeBest Accelerated Psychology Degree OnlineNursingBest Online LPN ProgramsBest Online Nursing ProgramsLPN to RN ProgramsADN to NP ProgramsAccelerated Nurse Practitioner ProgramsBest Online Nurse Practitioner ProgramsBusinessBest Business Masters DegreesOnline Business DegreeBest Online Construction Management DegreeOnline Masters in Finance1 Year Master's Programs OnlineTypes of Business Masters DegreesEducationBest Online Masters in EducationDoctorate Degree in EducationMaster's Degree in EducationEducational Leadership Doctoral Programs OnlineBest Online Physical Education DegreeSocial WorkAccelerated MSW ProgramsBest Online Social Work DegreeLCSW Online ProgramsOnline MSW Programs No GRE RequiredMasters Degree in Social Work OnlineBest Online MBA ProgramsBest Accelerated MBA ProgramsOnline MBA Programs CostBest MBA Acceptance RatesHow Hard is it to Get an MBAMBA in Information TechnologyIs an Online MBA Worth It?Best Accelerated MBA Programs OnlineBest Online Executive MBA ProgramsEasiest Online MBA ProgramsPopular Degree ProgramsBest Doctorate Degree Online no DissertationBest Degrees That Make the Most MoneyBest Online Certificate Programs That Pay WellBest Online Degree ProgramsAccelerated Online Degree Programs for Working AdultsAccredited Self-Paced Online Colleges?Easiest Online Degrees That Pay WellEasiest College MajorsBest Associate DegreesAdditional DegreesLibrary Science DegreeSupply Chain Management DegreeFinance DegreeAccredited Online Counseling ProgramsCyber Security DegreeBest Online Graphic Design DegreeHistory DegreeHuman Resources DegreeBest Online Nutrition DegreeNutrition DegreeLogistics DegreeBest Library Science Degree OnlineHuman Services DegreeBookkeeping CertificationMasters in Forensic AccountingCareer ResourcesCareer PlanningLogistics CareersDo You Need a Psychology Degree to Be a TherapistHighest Paying Psychology JobsCriminal Justice CareersLCSW Salary by StateNursingAccredited Online Medical Billing And Coding SchoolsBecome A Medical Assistant In 6 WeeksBest States For NursesForensic NurseHow Much Does Nursing School CostBusiness CareersAccounting CareersForensic Accounting CareersBusiness Administration CareersHealthcare Administration CareersBusiness Management CareersPsychology CareersCognitive Psychology CareersBehavioral Psychology CareersOrganizational Psychology CareersCareers in Addiction RecoveryChild and Adolescent PsychologyComputer Science CareersInformation Systems CareersSoftware Engineering Career PathBest Online Medical Coding CoursesLibrary Science CareersData Scientist Career PathCareers in EducationEducational Leadership CareersChild Development CareersCareers in Special EducationCareers in Higher EducationTeaching CareersMBA CareersMBA in Healthcare Management SalaryMBA Career Paths and SalariesWhat Can I Do With a Business Degree in HealthcareIs an MBA Worth It in 2024?Can I Get an MBA Without a Business DegreeCounseling CareersHow to Become a Christian CounselorHow to Become a Mental Health CounselorSocial Work vs. CounselingCareer In Substance Abuse And Addictions CounselingHow to Become a CounselorPopular CareersBiotechnology CareersSustainability CareersGerontology CareersCriminology CareersBiology CareersEKG TechnicianTrade School Programs That Pay WellSocial Work CareersHow to Become a School Social WorkerMacro Social Work CareersHow to Become a Medical Social WorkerHow to Become a Social WorkerSocial Worker Career PathColleges by StateBest Business SchoolsBusiness Schools in TexasBusiness Schools in CaliforniaBusiness Schools in FloridaBusiness Schools in GeorgiaBusiness Schools in OhioBest Online MBA ProgramsOnline MBA Programs in TexasOnline MBA Programs in CaliforniaOnline MBA Programs in FloridaOnline MBA Programs in MichiganOnline MBA Programs in OhioBest MSW ProgramsMSW Programs in TexasMSW Programs in CaliforniaMSW Programs in FloridaMSW Programs in New YorkMSW Programs in OhioBest Psychology SchoolsPsychology Schools in TexasPsychology Schools in CaliforniaPsychology Schools in FloridaPsychology Schools in GeorgiaPsychology Schools in OhioBest Online Psychology DegreesOnline Psychology Degree in TexasOnline Psychology Degree in CaliforniaOnline Psychology Degree in FloridaOnline Psychology Degree in GeorgiaOnline Psychology Degree in OhioHow to Become a PsychologistHow to Become a Psychologist in TexasHow to Become a Psychologist in CaliforniaHow to Become a Psychologist in FloridaHow to Become a Psychologist in GeorgiaHow to Become a Psychologist in OhioBest Nursing SchoolsNursing Schools in TexasNursing Schools in CaliforniaNursing Schools in FloridaNursing Schools in GeorgiaNursing Schools in OhioBest Online Nursing ProgramsOnline Nursing Programs in TexasOnline Nursing Programs in CaliforniaOnline Nursing Programs in FloridaOnline Nursing Programs in GeorgiaOnline Nursing Programs in OhioHow to Become a Social WorkerHow to Become a Social Worker in TexasHow to Become a Social Worker in CaliforniaHow to Become a Social Worker in FloridaHow to Become a Social Worker in New YorkHow to Become a Social Worker in MassachusettsBest Accounting SchoolsAccounting Schools in TexasAccounting Schools in CaliforniaAccounting Schools in FloridaAccounting Schools in GeorgiaAccounting Schools in OhioBest Nurse Practitioner ProgramsNurse Practitioner Programs in TexasNurse Practitioner Programs in CaliforniaNurse Practitioner Programs in FloridaNurse Practitioner Programs in GeorgiaNurse Practitioner Programs in OhioBest Online LPN/LVN ProgramsOnline LPN Programs in DelawareOnline LPN Programs in FloridaOnline LPN Programs in MissouriOnline LPN Programs in NCOnline LPN Programs in New JerseyOnline LPN Programs in NYOnline LPN Programs in OhioOnline LPN Programs in PAOnline LPN Programs in South CarolinaOnline LPN Programs in VirginiaOnline LVN Programs in CaliforniaOnline LVN Programs in TexasHow to Become a CounselorHow to Become a Counselor in TexasHow to Become a Counselor in CaliforniaHow to Become a Counselor in FloridaHow to Become a Counselor in GeorgiaHow to Become a Counselor in OhioHow to Become a Counselor in ArizonaHow to Become a Counselor in ColoradoHow to Become a Counselor in IndianaHow to Become a Counselor in MichiganHow to Become a Counselor in MissouriHow to Become a Counselor in NevadaHow to Become a Counselor in New JerseyHow to Become a Counselor in New MexicoHow to Become a Counselor in OregonHow to Become a Counselor in South CarolinaHow to Become a Counselor in UtahHow to Become a Counselor in WashingtonBest ScholarsBEST SCIENTISTS BY DISCIPLINEAnimal Science and VeterinaryBiology and BiochemistryBusiness and ManagementChemistryComputer ScienceEarth ScienceEcology and EvolutionEconomics and FinanceElectronics and Electrical EngineeringEngineering and TechnologyEnvironmental SciencesGeneticsImmunologyLawMaterials ScienceMathematicsMechanical and Aerospace EngineeringMedicineMicrobiologyMolecular BiologyNeurosciencePhysicsPlant Science and AgronomyPolitical SciencePsychologySocial Sciences and HumanitiesTOP GLOBALSBest Female ScientistsBest ScientistsRising StarsBest UniversitiesBEST UNIVERSITIES BY DISCIPLINEAnimal Science and VeterinaryBiology and BiochemistryBusiness and ManagementChemistryComputer ScienceEarth ScienceEcology and EvolutionEconomics and FinanceElectronics and Electrical EngineeringEngineering and TechnologyEnvironmental SciencesGeneticsImmunologyLawMaterials ScienceMathematicsMechanical and Aerospace EngineeringMedicineMicrobiologyMolecular BiologyNeurosciencePhysicsPlant Science and AgronomyPolitical SciencePsychologySocial Sciences and HumanitiesGLOBAL RANKINGSBest UniversitiesBest Universities in AustraliaBest Universities in CanadaBest Universities in GermanyBest Universities in JapanBest Universities in United KingdomBest Universities in FranceBest Universities in IndiaBest Universities in ChinaBest Universities in BrazilRanking & Metricshref="#tab-2" - Conference Call for Papers
Home 
 Best Conferences - Computer Science 
 SIAM International Conference on Data Mining 
 SIAM International Conference on Data Mining 
 Alexandria, VA, United States 
 Submission Deadline:Friday 17 Dec 2021Conference Dates:Apr 28, 2022 - Apr 30, 2022Research 
 Impact Score4.10 
 href="https://www.siam.org/conferences/cm/conference/sdm22" - OFFICIAL WEBSITE
Conference Organizers: Deadline extended? 
 Click here to editRanking & MetricsImpact Score is a novel metric devised to rank conferences based on the number of contributing the best scientists in addition to the h-index estimated from the scientific papers published by the best scientists. See more details onour methodology page.Research Impact Score:4.10Contributing Best Scientists:124H5-index:Papers published by Best Scientists155Research Ranking(Computer Science)118Research Ranking(Computer Science)115Research Ranking(Computer Science)158Conference Call for Papers 
 The SDM conference provides a venue for researchers who are addressing these problems to present their work in a peer-reviewed forum. It also provides an ideal setting for graduate students to network and get feedback for their work (as part of the doctoral forum) and everyone new to the field to learn about cutting-edge research by hearing outstanding invited speakers and attending presentations and tutorials (included with conference registration). A set of focused workshops is also held on the last day of the conference. The proceedings of the conference are published in archival form and are also made available on the SIAM web site. 
 Overview 
 Top Research Topics at SIAM International Conference on Data Mining? 
 Artificial intelligence (12.69%) 
 Optoelectronics (8.45%) 
 Data mining (8.20%) 
 The conference is organized to address concerns in the fields of Artificial intelligence, Optoelectronics, Data mining, Machine learning and Pattern recognition. The works on Artificial intelligence deal in particular with Cluster analysis. 
 What are the most cited papers published at the conference? 
 Clustering with Bregman Divergences (1347 citations) 
 R-MAT: A Recursive Model for Graph Mining (975 citations) 
 Learning from Time-Changing Data with Adaptive Windowing (829 citations) 
 Research areas of the most cited articles at SIAM International Conference on Data Mining: 
 The published articles tackle a plethora of topics, such as Data mining, Artificial intelligence, Cluster analysis, Machine learning and Pattern recognition. The published articles with studies in Data mining featured incorporate elements of Data stream, Set (abstract data type) and Data set. The published papers explore issues in Artificial intelligence which can be linked to other research areas like Exploit and Natural language processing. 
 What topics the last edition of the conference is best known for? 
 Artificial intelligence 
 Statistics 
 Machine learning 
 The previous edition focused in particular on these issues: 
 The conference primarily tackles Artificial intelligence, Machine learning, Pattern recognition, Algorithm and Data mining. Artificial intelligence research featured in it incorporates concerns from various other topics such as Task (project management) and Natural language processing. While work presented in the conference provided substantial information on Machine learning, it also covered topics in Crowdsourcing and Layer (object-oriented design). 
 SIAM International Conference on Data Mining facilitates discussions on Pattern recognition that incorporate concepts from other fields like Series (mathematics) and Curse of dimensionality. The Algorithm works featured in SIAM International Conference on Data Mining incorporate elements from Variable (computer science), Principal component analysis, Clustering high-dimensional data and Dimension (vector space). The subject of Deep learning, which is connected to the field of Consistency (database systems), serves as the foundation of the Artificial neural network research featured in it. 
 The most cited articles from the last conference are: 
 Deep Anomaly Detection on Attributed Networks. (84 citations) 
 Physics Guided RNNs for Modeling Dynamical Systems: A Case Study in Simulating Lake Temperature Profiles (83 citations) 
 Hierarchical attention networks for cyberbullying detection on the instagram social network (42 citations) 
 Papers citation over time 
 A key indicator for each conference is its effectiveness in reaching other researchers with the papers published at that venue. 
 The chart below presents the interquartile range (first quartile 25%, median 50% and third quartile 75%) of the number of citations of articles over time. 
 Research.com 
 Top authors and change over time 
 The top authors publishing at SIAM International Conference on Data Mining (based on the number of publications) are: 
 Philip S. Yu | (48 papers) | published 1 paper at the last edition the same number as at the previous edition, 
 Charu C. Aggarwal | (31 papers) | absent at the last edition, 
 俊郎 平本 | (31 papers) | absent at the last edition, 
 Christos Faloutsos | (28 papers) | published 2 papers at the last edition, 2 less than at the previous edition, 
 重佳 渡辺 | (27 papers) | absent at the last edition. 
 The overall trend for top authors publishing at this conference is outlined below. The chart shows the number of publications at each edition of the conference for top authors. 
 Research.com 
 Top affiliations and change over time 
 Only papers with recognized affiliations are considered 
 The top affiliations publishing at SIAM International Conference on Data Mining (based on the number of publications) are: 
 IBM | (124 papers) | published 5 papers at the last edition, 7 less than at the previous edition, 
 Carnegie Mellon University | (62 papers) | published 3 papers at the last edition, 3 less than at the previous edition, 
 Tohoku University | (55 papers) | absent at the last edition, 
 University of Illinois at Chicago | (49 papers) | published 1 paper at the last edition the same number as at the previous edition, 
 University of Minnesota | (45 papers) | published 4 papers at the last edition, 1 more than at the previous edition. 
 The overall trend for top affiliations publishing at this conference is outlined below. The chart shows the number of publications at each edition of the conference for top affiliations. 
 Research.com 
 Publication chance based on affiliation 
 The publication chance index shows the ratio of articles published by the best research institutions at the conference edition to all articles published within that conference. The best research institutions were selected based on the largest number of articles published during all editions of the conference. 
 The chart below presents the percentage ratio of articles from top institutions (based on their ranking of total papers).Top affiliations were grouped by their rank into the following tiers: top 1-10, top 11-20, top 21-50, and top 51+. Only articles with a recognized affiliation are considered. 
 Research.com 
 During the most recent 2019 edition,4.55%of publications had an unrecognized affiliation. Out of the publications with recognized affiliations,25.00%were posted by at least one author from the top 10 institutions publishing at the conference. Another11.90%included authors affiliated with research institutions from the top 11-20 affiliations. Institutions from the 21-50 range included23.81%of all publications and39.29%were from other institutions. 
 Returning Authors Index 
 A very common phenomenon observed among researchers publishing scientific articles is the intentional selection of conferences they have already attended in the past. In particular, it is worth analyzing the case when the authors participate in the same conference from year to year. 
 The Returning Authors Index presented below illustrates the ratio of authors who participated in both a given as well as the previous edition of the conference in relation to all participants in a given year. 
 Research.com 
 Returning Institution Index 
 The graph below shows the Returning Institution Index, illustrating the ratio of institutions that participated in both a given and the previous edition of the conference in relation to all affiliations present in a given year. 
 Research.com 
 The experience to innovation index 
 Our experience to innovation index was created to show a cross-section of the experience level of authors publishing at a conference. The index includes the authors publishing at thelast edition of a conference, grouped by total number of publications throughout their academic career (P) and the total number of citations of these publications ever received (C). 
 The group intervals were selected empirically to best show the diversity of the authors' experiences, their labels were selected as a convenience, not as judgment. The authors were divided into the following groups: 
 Novice - P < 5 or C < 25 (the number of publications less than 5 or the number of citations less than 25), 
 Competent - P < 10 or C < 100 (the number of publications less than 10 or the number of citations less than 100), 
 Experienced - P < 25 or C < 625 (the number of publications less than 25 or the number of citations less than 625), 
 Master - P < 50 or C < 2500 (the number of publications less than 50 or the number of citations less than 2500), 
 Star - P ≥ 50 and C ≥ 2500 (both the number of publications greater than 50 and the number of citations greater than 2500). 
 The chart below illustrates experience levels of first authors in cases of publications with multiple authors. 
 Previous Editions 
 href="/conference/sdm-2021-siam-international-conference-on-data-mining-sdm" - SDM 2021 : SIAM International Conference on Data Mining (SDM)
href="https://www.siam.org/conferences/cm/conference/sdm21" - https://www.siam.org/conferences/cm/conference/sdm21
Mar 25, 2021 - Mar 25, 2021 
 Alexandria, Virginia, United States 
 SIAM International Conference on Data Mining 
 Apr 28, 2022 - Apr 30, 2022 
 Alexandria, VA, United States 
 Related Computer Science Rankings & Guides 
 Is a Computer Science Degree Worth It in 2024? ROI, Cost, Career Outlook, & Morehref="/degrees/fastest-online-technology-degree-programs" - Fastest Online Technology Degree Programs for 2025
Best Online Bachelor’s Degrees in Web Design: Guide to Online Programs for 2024Best Online Master’s in Software Engineering in 2024What Can You Do With a Computer Science Degree in 2024href="/degrees/best-online-coding-bootcamps" - Best Online Coding Bootcamps for 2025
Engineering Majors Explained: Cost, Requirements, Careers & Salary in 2024href="/degrees/most-affordable-online-masters-degrees-in-engineering-management" - Most Affordable Online Master's Degrees in Engineering Management for 2025
Is Management Information Systems a Good Major in 2024?Student’s Guide to Jump-Starting a Software QA Engineer Career in 2024Computer Programming Careers: 2024 Guide to Career Paths & Salaryhref="/degrees/most-affordable-online-associate-degrees-in-computer-science-programs" - Most Affordable Online Associate Degrees in Computer Science Programs for 2025
How to Become a Computer Hardware Engineer: Step-By-Step Guide for 2024Most Affordable Online Master’s in Data Science Programs in 2024How to Become a Data Scientist in 2024Best Online Accelerated Computer Science Degree Programs in 202415 Best Coding Bootcamps in 2024Best Online Master’s in Industrial Engineering Programs for 2024Industrial Engineering Degree in 2024: Requirements, Career, Cost & SalaryBest Online Computer Programming Degree Programs in 2024Software Engineering Careers: 2024 Guide to Career Paths, Options & SalaryWhat Can You Do with an Information Technology Degree: 2024 Costs & Job OpportunitiesBest Online Bachelor’s Degrees in Web Development: Guide to Online Programs for 2024href="/degrees/most-affordable-online-graphic-design-degrees" - Most Affordable Online Graphic Design Degrees for 2025
Best Online Software Engineering Degrees: Guide to Online Graduate Programs for 2024Best Online Associate in Computer Programming Programs in 2024Best Online Graphic Design Degree Programs of 2024Recently Published Articles 
 href="/degrees/most-affordable-online-mba-no-gmat-required" - Most Affordable Online MBA - No GMAT Required for 2025
href="/degrees/best-4-week-online-course-for-medical-coding-and-billing" - Best 4-Week Online Course for Medical Coding and Billing for 2025
href="/degrees/best-shortest-online-dnp-programs" - 25 Best Shortest Online DNP Programs for 2025
href="/careers/how-to-become-a-licensed-counselor-lpc-in-illinois" - How to Become a Licensed Counselor (LPC) in Illinois for 2025
href="/careers/illinois-psychology-licensure-requirements" - Illinois Psychology Licensure Requirements – How to Become a Psychologist in Illinois for 2025
href="/degrees/best-online-data-analytics-degree-programs" - Best Online Data Analytics Degree Programs for 2025
href="/degrees/best-diagnostic-medical-sonography-programs" - Best Diagnostic Medical Sonography Programs for 2025
href="/careers/how-to-become-a-board-certified-behavior-analyst-bcba" - How to Become a Board Certified Behavior Analyst (BCBA) for 2025
href="/careers/highest-paying-jobs-for-women" - Highest Paying Jobs for Women for 2025: Salary, Job Outlook, Duties, & Requirements
href="/degrees/best-online-healthcare-management-degrees" - Best Online Healthcare Management Degrees for 2025
href="/degrees/best-online-bachelors-degrees-in-nutritional-science" - Best Online Bachelor’s Degrees in Nutritional Science: Guide to Online Programs for 2025
href="/degrees/best-online-masters-program-in-forensic-psychology" - Best Online Master’s in Forensic Psychology Degree Programs for 2025
href="/degrees/best-masters-in-genetics-programs" - Best Master’s in Genetics Programs for 2025
href="/degrees/easiest-dnp-programs" - 10 Easiest DNP Programs for 2025
href="/careers/how-to-become-a-christian-counselor" - How to Become a Christian Counselor for 2025
href="/degrees/easiest-nurse-practitioner-specialty-programs-to-get-into" - Easiest Nurse Practitioner Specialty Programs to Get Into for 2025
href="/degrees/best-1-year-nurse-practitioner-online-programs" - Best 1-Year Nurse Practitioner Online Programs for 2025
href="/degrees/ms-vs-ma-in-counseling" - MS vs. MA in Counseling: What's the Difference and Which Degree Should You Choose for 2025?
href="/careers/how-to-become-a-licensed-counselor-lpc-in-missouri" - How to Become a Licensed Counselor (LPC) in Missouri for 2025
href="/degrees/online-masters-in-computer-science-programs-for-non-cs-majors" - Online Master’s in Computer Science Programs for Non-CS Majors for 2025
href="/careers/minnesota-psychology-licensure-requirements" - Minnesota Psychology Licensure Requirements – How to Become a Psychologist in Minnesota for 2025
Edit Submission Deadline 
 SIAM International Conference on Data Mining 
 Your email addressNew submission deadlineFurther informationSEND MESSAGEThank you for information! 
 Something went wrong. Please try again later. 
 href="https://www.facebook.com/guide2research/" - 
href="https://twitter.com/guide2research" - 
Copyright © 2025 Research.com. All rights reserved. 
 Release: 14081484203RankingsMethodologyBlogAboutOur ExpertsContactPress RoomEditorial PolicyPrivacy Policy

