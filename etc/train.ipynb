{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Đang xử lý file input: ./src/conference/evaluate/batch2.csv ---\n",
      "Đã đọc thành công 47 dòng.\n",
      "\n",
      "--- Đang xử lý file input: ./src/conference/evaluate/batch3.csv ---\n",
      "Đã đọc thành công 46 dòng.\n",
      "\n",
      "--- Đang xử lý file input: ./src/conference/evaluate/batch8.csv ---\n",
      "Đã đọc thành công 48 dòng.\n",
      "\n",
      "--- Đang xử lý file input: ./src/conference/evaluate/batch12.csv ---\n",
      "Đã đọc thành công 38 dòng.\n",
      "\n",
      "--- Đang xử lý file input: ./src/conference/evaluate/batch13.csv ---\n",
      "Đã đọc thành công 46 dòng.\n",
      "\n",
      "--- Đang xử lý file input: ./src/conference/evaluate/batch16.csv ---\n",
      "Đã đọc thành công 46 dòng.\n",
      "\n",
      "--- Đang xử lý file input: ./src/conference/evaluate/batch19.csv ---\n",
      "Đã đọc thành công 46 dòng.\n",
      "\n",
      "--- Đang tổng hợp kết quả từ các file input ---\n",
      "Tìm thấy 21 dòng có ghi chú. Di chuyển sang danh sách recrawl.\n",
      "\n",
      "--- Đang đối chiếu với kết quả đã recrawl ---\n",
      "Đã đọc file đã recrawl: ./src/conference/evaluate/evaluate_recrawl_batch_2_3_lan_1.csv\n",
      "Đã đọc file đã recrawl: ./src/conference/evaluate/evaluate_recrawl_batch_8_lan_1.csv\n",
      "Tìm thấy 21 dòng đã được sửa đúng sau khi recrawl.\n",
      "\n",
      "--- Hoàn tất và lưu file tổng hợp cuối cùng ---\n",
      "Đã lưu tổng cộng 143 dòng đúng vào './src/conference/evaluate/ALL_BATCHES_correct_final.csv'\n",
      "Đã lưu tổng cộng 174 dòng cần crawl lại vào './src/conference/evaluate/ALL_BATCHES_recrawl_final.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Hàm split_dataframe giữ nguyên, không cần thay đổi.\n",
    "def split_dataframe(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Nhận một DataFrame, tách nó thành hai phần (đúng và cần crawl lại)\n",
    "    dựa trên các điều kiện đã xác định và trả về hai DataFrame đã được\n",
    "    loại bỏ trùng lặp.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # --- CẢI TIẾN: Chuẩn hóa dữ liệu trước khi so sánh ---\n",
    "    main_link_correct = df_copy['MainLinkCorrect'].fillna('').astype(str).str.strip().str.upper()\n",
    "    date_correct = df_copy['ConferenceDateCorrect'].fillna('').astype(str).str.strip().str.upper()\n",
    "    location_correct = df_copy['LocationCorrect'].fillna('').astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Điều kiện 1: Sử dụng các cột đã được chuẩn hóa\n",
    "    condition1 = (\n",
    "        (main_link_correct == 'FALSE') |\n",
    "        (date_correct == 'FALSE') |\n",
    "        (location_correct == 'FALSE')\n",
    "    )\n",
    "\n",
    "    # Điều kiện 2: Một trong các trường Percent khác 100 VÀ KHÔNG TRỐNG\n",
    "    percent_cols = ['Percent', 'Percent_1', 'Percent_2', 'Percent_3', 'Percent_4']\n",
    "    \n",
    "    for col in percent_cols:\n",
    "        df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "\n",
    "    condition2_parts = [df_copy[col].notna() & (df_copy[col] != 100) for col in percent_cols]\n",
    "    \n",
    "    condition2 = False\n",
    "    for part in condition2_parts:\n",
    "        condition2 = condition2 | part\n",
    "\n",
    "    # Kết hợp hai điều kiện để tìm ra tất cả các dòng cần crawl lại\n",
    "    recrawl_condition = condition1 | condition2\n",
    "\n",
    "    # Tách DataFrame\n",
    "    recrawl_df = df_copy[recrawl_condition]\n",
    "    correct_df = df_copy[~recrawl_condition]\n",
    "\n",
    "    # Loại bỏ trùng lặp cho mỗi phần\n",
    "    subset_cols = ['title', 'acronym']\n",
    "    unique_recrawl_df = recrawl_df.drop_duplicates(subset=subset_cols, keep='first')\n",
    "    unique_correct_df = correct_df.drop_duplicates(subset=subset_cols, keep='first')\n",
    "\n",
    "    return unique_correct_df, unique_recrawl_df\n",
    "\n",
    "\n",
    "# --- HÀM NÀY ĐƯỢC CẬP NHẬT ĐỂ NHẬN THÊM THAM SỐ ---\n",
    "def process_file_list(\n",
    "    input_files: list, \n",
    "    output_dir: str,\n",
    "    aggregated_correct_path: str, \n",
    "    aggregated_recrawl_path: str,\n",
    "    recrawled_files: list = None # Thêm tham số cho các file đã recrawl\n",
    "):\n",
    "    \"\"\"\n",
    "    Xử lý một danh sách các file CSV, đối chiếu với kết quả đã recrawl,\n",
    "    và tạo ra hai file tổng hợp cuối cùng.\n",
    "    \"\"\"\n",
    "    all_correct_dfs = []\n",
    "    all_recrawl_dfs = []\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # --- BƯỚC 1: XỬ LÝ CÁC FILE INPUT BAN ĐẦU ---\n",
    "    for file_path in input_files:\n",
    "        print(f\"\\n--- Đang xử lý file input: {file_path} ---\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig', na_values=['', ' '], dtype=str)\n",
    "            print(f\"Đã đọc thành công {len(df)} dòng.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Lỗi: Không tìm thấy file '{file_path}'. Bỏ qua file này.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi khi đọc file '{file_path}': {e}. Bỏ qua file này.\")\n",
    "            continue\n",
    "\n",
    "        correct_df, recrawl_df = split_dataframe(df)\n",
    "        all_correct_dfs.append(correct_df)\n",
    "        all_recrawl_dfs.append(recrawl_df)\n",
    "\n",
    "    # --- BƯỚC 2: GỘP VÀ XỬ LÝ BỔ SUNG BAN ĐẦU ---\n",
    "    if not all_correct_dfs and not all_recrawl_dfs:\n",
    "        print(\"\\nKhông có dữ liệu từ các file input để xử lý. Kết thúc.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Đang tổng hợp kết quả từ các file input ---\")\n",
    "    master_correct_df = pd.concat(all_correct_dfs, ignore_index=True) if all_correct_dfs else pd.DataFrame()\n",
    "    master_recrawl_df = pd.concat(all_recrawl_dfs, ignore_index=True) if all_recrawl_dfs else pd.DataFrame()\n",
    "\n",
    "    # Di chuyển các dòng có ghi chú (Note)\n",
    "    if 'Note' in master_correct_df.columns:\n",
    "        note_exists_condition = master_correct_df['Note'].notna()\n",
    "        rows_to_move = master_correct_df[note_exists_condition]\n",
    "        if not rows_to_move.empty:\n",
    "            print(f\"Tìm thấy {len(rows_to_move)} dòng có ghi chú. Di chuyển sang danh sách recrawl.\")\n",
    "            master_recrawl_df = pd.concat([master_recrawl_df, rows_to_move], ignore_index=True)\n",
    "            master_correct_df = master_correct_df[~note_exists_condition]\n",
    "\n",
    "    # --- BƯỚC 3 (MỚI): ĐỐI CHIẾU VỚI CÁC FILE ĐÃ RECRAWL ---\n",
    "    if recrawled_files:\n",
    "        print(\"\\n--- Đang đối chiếu với kết quả đã recrawl ---\")\n",
    "        recrawled_dfs_list = []\n",
    "        for r_file in recrawled_files:\n",
    "            try:\n",
    "                df = pd.read_csv(r_file, encoding='utf-8-sig', na_values=['', ' '], dtype=str)\n",
    "                recrawled_dfs_list.append(df)\n",
    "                print(f\"Đã đọc file đã recrawl: {r_file}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Cảnh báo: Không tìm thấy file đã recrawl '{r_file}'. Bỏ qua.\")\n",
    "        \n",
    "        if recrawled_dfs_list:\n",
    "            # Gộp tất cả các file đã recrawl thành một DataFrame lớn\n",
    "            recrawled_master_df = pd.concat(recrawled_dfs_list, ignore_index=True)\n",
    "            \n",
    "            # Dùng lại hàm split_dataframe để xác định những dòng nào giờ đã ĐÚNG\n",
    "            newly_correct_df, _ = split_dataframe(recrawled_master_df)\n",
    "            \n",
    "            if not newly_correct_df.empty:\n",
    "                print(f\"Tìm thấy {len(newly_correct_df)} dòng đã được sửa đúng sau khi recrawl.\")\n",
    "                \n",
    "                # Tạo một set các khóa (title, acronym) của các dòng đã được sửa đúng để tra cứu nhanh\n",
    "                corrected_keys = set(zip(\n",
    "                    newly_correct_df['title'].str.strip(), \n",
    "                    newly_correct_df['acronym'].str.strip()\n",
    "                ))\n",
    "                \n",
    "                # Loại bỏ các dòng đã được sửa đúng khỏi danh sách recrawl tổng\n",
    "                # Tạo một mask boolean để xác định dòng nào cần loại bỏ\n",
    "                recrawl_keys = zip(\n",
    "                    master_recrawl_df['title'].str.strip(),\n",
    "                    master_recrawl_df['acronym'].str.strip()\n",
    "                )\n",
    "                is_now_correct_mask = [key in corrected_keys for key in recrawl_keys]\n",
    "                \n",
    "                # Giữ lại những dòng KHÔNG có trong danh sách đã sửa đúng\n",
    "                master_recrawl_df = master_recrawl_df[~pd.Series(is_now_correct_mask).values]\n",
    "                \n",
    "                # Thêm các dòng vừa được sửa đúng vào danh sách correct tổng\n",
    "                master_correct_df = pd.concat([master_correct_df, newly_correct_df], ignore_index=True)\n",
    "            else:\n",
    "                print(\"Không có dòng nào được sửa đúng trong các file đã recrawl.\")\n",
    "\n",
    "    # --- BƯỚC 4: LOẠI BỎ TRÙNG LẶP LẦN CUỐI VÀ LƯU FILE ---\n",
    "    print(\"\\n--- Hoàn tất và lưu file tổng hợp cuối cùng ---\")\n",
    "    \n",
    "    # Xử lý và lưu file CORRECT tổng\n",
    "    if not master_correct_df.empty:\n",
    "        final_correct_df = master_correct_df.drop_duplicates(subset=['title', 'acronym'], keep='first')\n",
    "        final_correct_df.to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_correct_df)} dòng đúng vào '{aggregated_correct_path}'\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'đúng' nào. Đã tạo file rỗng '{aggregated_correct_path}'\")\n",
    "\n",
    "    # Xử lý và lưu file RECRAWL tổng\n",
    "    if not master_recrawl_df.empty:\n",
    "        final_recrawl_df = master_recrawl_df.drop_duplicates(subset=['title', 'acronym'], keep='first')\n",
    "        final_recrawl_df.to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_recrawl_df)} dòng cần crawl lại vào '{aggregated_recrawl_path}'\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'cần recrawl' nào. Đã tạo file rỗng '{aggregated_recrawl_path}'\")\n",
    "\n",
    "\n",
    "# --- Cách sử dụng ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Danh sách các file input ban đầu\n",
    "    input_csv_files = [\n",
    "        './src/conference/evaluate/batch2.csv',\n",
    "        './src/conference/evaluate/batch3.csv',\n",
    "        './src/conference/evaluate/batch8.csv',\n",
    "        './src/conference/evaluate/batch12.csv',\n",
    "        './src/conference/evaluate/batch13.csv',\n",
    "        './src/conference/evaluate/batch16.csv',\n",
    "        './src/conference/evaluate/batch19.csv',\n",
    "    ]\n",
    "\n",
    "    # 2. (MỚI) Danh sách các file là kết quả của lần recrawl trước đó\n",
    "    # Để trống danh sách này nếu đây là lần chạy đầu tiên: recrawled_results_files = []\n",
    "    recrawled_results_files = [\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_2_3_lan_1.csv',\n",
    "        './src/conference/evaluate/evaluate_recrawl_batch_8_lan_1.csv',\n",
    "        # Thêm các file kết quả recrawl khác vào đây\n",
    "    ]\n",
    "\n",
    "    # 3. Thư mục để chứa các file output riêng lẻ (không thay đổi)\n",
    "    individual_output_directory = './src/conference/evaluate/individual_outputs'\n",
    "\n",
    "    # 4. Đường dẫn cho 2 file tổng hợp cuối cùng (không thay đổi)\n",
    "    aggregated_correct_file = './src/conference/evaluate/ALL_BATCHES_correct_final.csv'\n",
    "    aggregated_recrawl_file = './src/conference/evaluate/ALL_BATCHES_recrawl_final.csv'\n",
    "\n",
    "    # 5. Gọi hàm xử lý chính với tham số mới\n",
    "    process_file_list(\n",
    "        input_files=input_csv_files,\n",
    "        output_dir=individual_output_directory,\n",
    "        aggregated_correct_path=aggregated_correct_file,\n",
    "        aggregated_recrawl_path=aggregated_recrawl_file,\n",
    "        recrawled_files=recrawled_results_files # Truyền danh sách file đã recrawl\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Đang xử lý file: ./src/conference/evaluate/recrawl_batch_4_check.csv ---\n",
      "Đã đọc thành công 26 dòng.\n",
      "Cảnh báo: Không tìm thấy cột 'Note'. Coi như tất cả các dòng đều 'đúng'.\n",
      "Kết quả tách: 26 dòng không có ghi chú (đúng), 0 dòng có ghi chú (cần recrawl).\n",
      "Đã lưu output riêng lẻ vào thư mục './src/conference/evaluate/tri_check_outputs'\n",
      "\n",
      "--- Đang xử lý file: ./src/conference/evaluate/recrawl_batch_5_check.csv ---\n",
      "Đã đọc thành công 27 dòng.\n",
      "Cảnh báo: Không tìm thấy cột 'Note'. Coi như tất cả các dòng đều 'đúng'.\n",
      "Kết quả tách: 27 dòng không có ghi chú (đúng), 0 dòng có ghi chú (cần recrawl).\n",
      "Đã lưu output riêng lẻ vào thư mục './src/conference/evaluate/tri_check_outputs'\n",
      "\n",
      "--- Đang xử lý file: ./src/conference/evaluate/recrawl_batch_9_check.csv ---\n",
      "Đã đọc thành công 24 dòng.\n",
      "Cảnh báo: Không tìm thấy cột 'Note'. Coi như tất cả các dòng đều 'đúng'.\n",
      "Kết quả tách: 24 dòng không có ghi chú (đúng), 0 dòng có ghi chú (cần recrawl).\n",
      "Đã lưu output riêng lẻ vào thư mục './src/conference/evaluate/tri_check_outputs'\n",
      "\n",
      "--- Đang tổng hợp tất cả kết quả ---\n",
      "Đã lưu tổng cộng 72 dòng đúng (không có ghi chú) vào './src/conference/evaluate/tri_all_correct.csv'\n",
      "Không có dòng 'cần recrawl' nào. Đã tạo file rỗng './src/conference/evaluate/tri_all_recrawl.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_df_by_note(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Tách một DataFrame thành hai phần dựa trên sự tồn tại của giá trị trong cột 'Note'.\n",
    "\n",
    "    - Dữ liệu \"cần recrawl\": Các dòng có giá trị trong cột 'Note'.\n",
    "    - Dữ liệu \"đúng\": Các dòng không có giá trị trong cột 'Note' (trống hoặc NaN).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame đầu vào.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.DataFrame]: Một tuple chứa (correct_df, recrawl_df).\n",
    "    \"\"\"\n",
    "    # Kiểm tra an toàn để đảm bảo cột 'Note' tồn tại\n",
    "    if 'note' not in df.columns:\n",
    "        print(\"Cảnh báo: Không tìm thấy cột 'Note'. Coi như tất cả các dòng đều 'đúng'.\")\n",
    "        # Trả về toàn bộ DataFrame là 'correct' và một DataFrame rỗng là 'recrawl'\n",
    "        return df.copy(), pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    # Điều kiện: cột 'Note' có giá trị (không phải NaN và không phải chuỗi rỗng)\n",
    "    # .notna() là cách kiểm tra tốt nhất cho NaN/None.\n",
    "    # Thêm điều kiện .str.strip() != '' để loại bỏ các ô chỉ chứa khoảng trắng.\n",
    "    condition_recrawl = df['Note'].notna() & (df['Note'].astype(str).str.strip() != '')\n",
    "\n",
    "    # Tách DataFrame dựa trên điều kiện\n",
    "    recrawl_df = df[condition_recrawl].copy()\n",
    "    correct_df = df[~condition_recrawl].copy()\n",
    "\n",
    "    return correct_df, recrawl_df\n",
    "\n",
    "def process_files_by_note(\n",
    "    input_files: list, \n",
    "    output_dir: str,\n",
    "    aggregated_correct_path: str, \n",
    "    aggregated_recrawl_path: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Xử lý một danh sách file, lọc từng file dựa trên cột 'Note',\n",
    "    lưu output riêng lẻ và hai file tổng hợp cuối cùng.\n",
    "\n",
    "    Args:\n",
    "        input_files (list): Danh sách đường dẫn đến các file CSV đầu vào.\n",
    "        output_dir (str): Thư mục để lưu các file output riêng lẻ.\n",
    "        aggregated_correct_path (str): Đường dẫn file tổng hợp dữ liệu đúng.\n",
    "        aggregated_recrawl_path (str): Đường dẫn file tổng hợp dữ liệu cần crawl lại.\n",
    "    \"\"\"\n",
    "    all_correct_dfs = []\n",
    "    all_recrawl_dfs = []\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for file_path in input_files:\n",
    "        print(f\"\\n--- Đang xử lý file: {file_path} ---\")\n",
    "        try:\n",
    "            # Đọc file với dtype=str để đảm bảo cột 'Note' được đọc đúng dạng chuỗi\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig', na_values=[''], dtype=str).fillna('')\n",
    "            print(f\"Đã đọc thành công {len(df)} dòng.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Lỗi: Không tìm thấy file '{file_path}'. Bỏ qua file này.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi khi đọc file '{file_path}': {e}. Bỏ qua file này.\")\n",
    "            continue\n",
    "\n",
    "        # Gọi hàm logic cốt lõi để tách dữ liệu\n",
    "        correct_df, recrawl_df = split_df_by_note(df)\n",
    "        \n",
    "        print(f\"Kết quả tách: {len(correct_df)} dòng không có ghi chú (đúng), {len(recrawl_df)} dòng có ghi chú (cần recrawl).\")\n",
    "\n",
    "        # Thêm các DataFrame đã xử lý vào danh sách tổng hợp\n",
    "        if not correct_df.empty:\n",
    "            all_correct_dfs.append(correct_df)\n",
    "        if not recrawl_df.empty:\n",
    "            all_recrawl_dfs.append(recrawl_df)\n",
    "\n",
    "        # --- Lưu các file output riêng lẻ ---\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        individual_correct_path = os.path.join(output_dir, f\"{base_name}_note_correct.csv\")\n",
    "        individual_recrawl_path = os.path.join(output_dir, f\"{base_name}_note_recrawl.csv\")\n",
    "\n",
    "        correct_df.to_csv(individual_correct_path, index=False, encoding='utf-8-sig')\n",
    "        recrawl_df.to_csv(individual_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu output riêng lẻ vào thư mục '{output_dir}'\")\n",
    "\n",
    "    # --- Gộp và lưu các file tổng hợp ---\n",
    "    print(\"\\n--- Đang tổng hợp tất cả kết quả ---\")\n",
    "    \n",
    "    # Gộp, loại bỏ trùng lặp và lưu file CORRECT tổng\n",
    "    if all_correct_dfs:\n",
    "        master_correct_df = pd.concat(all_correct_dfs, ignore_index=True)\n",
    "        final_correct_df = master_correct_df.drop_duplicates(subset=['title', 'acronym'], keep='first')\n",
    "        final_correct_df.to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_correct_df)} dòng đúng (không có ghi chú) vào '{aggregated_correct_path}'\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_correct_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'đúng' nào. Đã tạo file rỗng '{aggregated_correct_path}'\")\n",
    "\n",
    "    # Gộp, loại bỏ trùng lặp và lưu file RECRAWL tổng\n",
    "    if all_recrawl_dfs:\n",
    "        master_recrawl_df = pd.concat(all_recrawl_dfs, ignore_index=True)\n",
    "        final_recrawl_df = master_recrawl_df.drop_duplicates(subset=['title', 'acronym'], keep='first')\n",
    "        final_recrawl_df.to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Đã lưu tổng cộng {len(final_recrawl_df)} dòng cần recrawl (có ghi chú) vào '{aggregated_recrawl_path}'\")\n",
    "    else:\n",
    "        pd.DataFrame().to_csv(aggregated_recrawl_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Không có dòng 'cần recrawl' nào. Đã tạo file rỗng '{aggregated_recrawl_path}'\")\n",
    "\n",
    "\n",
    "# --- Cách sử dụng ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Danh sách các file input cần xử lý\n",
    "    input_csv_files_for_note_check = [\n",
    "        './src/conference/evaluate/recrawl_batch_4_check.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_5_check.csv',\n",
    "        './src/conference/evaluate/recrawl_batch_9_check.csv',\n",
    "    ]\n",
    "\n",
    "    # 2. Thư mục để chứa các file output riêng lẻ\n",
    "    individual_output_directory_note = './src/conference/evaluate/tri_check_outputs'\n",
    "\n",
    "    # 3. Đường dẫn cho 2 file tổng hợp cuối cùng\n",
    "    aggregated_correct_file_note = './src/conference/evaluate/tri_all_correct.csv'\n",
    "    aggregated_recrawl_file_note = './src/conference/evaluate/tri_all_recrawl.csv'\n",
    "\n",
    "    # 4. Gọi hàm xử lý chính\n",
    "    process_files_by_note(\n",
    "        input_files=input_csv_files_for_note_check,\n",
    "        output_dir=individual_output_directory_note,\n",
    "        aggregated_correct_path=aggregated_correct_file_note,\n",
    "        aggregated_recrawl_path=aggregated_recrawl_file_note\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tìm thấy 19 khóa (title, acronym) duy nhất từ file './src/conference/evaluate/individual_outputs/batch12_recrawl.csv'.\n",
      "Đã lọc và ghi 16 conference vào file './src/conference/evaluate/file_to_recrawl_batch_12_lan_1.csv'.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# --- Cấu hình tên file ---\n",
    "file_danh_gia = './src/conference/evaluate/individual_outputs/batch12_recrawl.csv'\n",
    "file_core_2023 = './src/conference/csv/CORE_2023.csv'\n",
    "output_file = './src/conference/evaluate/file_to_recrawl_batch_12_lan_1.csv'\n",
    "\n",
    "# --- Bước 1: Đọc file \"đánh giá\" và tạo một set các khóa (title, acronym) để tra cứu ---\n",
    "# Sử dụng set để tra cứu nhanh hơn rất nhiều so với list\n",
    "lookup_keys = set()\n",
    "\n",
    "try:\n",
    "    # Mở file với encoding='utf-8' để đảm bảo đọc được tiếng Việt\n",
    "    with open(file_danh_gia, mode='r', newline='', encoding='utf-8') as f_danhgia:\n",
    "        # Dùng DictReader để dễ dàng truy cập cột bằng tên header\n",
    "        reader = csv.DictReader(f_danhgia)\n",
    "        for row in reader:\n",
    "            # Lấy title và acronym, loại bỏ khoảng trắng thừa ở đầu và cuối\n",
    "            title = row.get('title', '').strip()\n",
    "            acronym = row.get('acronym', '').strip()\n",
    "            \n",
    "            # Chỉ thêm vào set nếu cả title và acronym đều có giá trị\n",
    "            if title and acronym:\n",
    "                lookup_keys.add((title, acronym))\n",
    "    print(f\"Đã tìm thấy {len(lookup_keys)} khóa (title, acronym) duy nhất từ file '{file_danh_gia}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file '{file_danh_gia}'. Vui lòng kiểm tra lại tên và đường dẫn file.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Bước 2: Đọc file CORE_2023, lọc và ghi ra file mới ---\n",
    "matching_rows = []\n",
    "\n",
    "try:\n",
    "    with open(file_core_2023, mode='r', newline='', encoding='utf-8') as f_core:\n",
    "        # File CORE không có header, dùng csv.reader bình thường\n",
    "        reader = csv.reader(f_core)\n",
    "        for row in reader:\n",
    "            # Đảm bảo dòng có đủ cột để tránh lỗi IndexError\n",
    "            if len(row) > 2:\n",
    "                # Cột 2 là title (index 1), Cột 3 là acronym (index 2)\n",
    "                core_title = row[1].strip()\n",
    "                core_acronym = row[2].strip()\n",
    "                \n",
    "                # Tạo khóa từ file CORE\n",
    "                current_key = (core_title, core_acronym)\n",
    "                \n",
    "                # Kiểm tra xem khóa này có trong set đã tạo ở bước 1 không\n",
    "                if current_key in lookup_keys:\n",
    "                    matching_rows.append(row)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file '{file_core_2023}'. Vui lòng kiểm tra lại tên và đường dẫn file.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Bước 3: Ghi các dòng đã lọc vào file output ---\n",
    "if matching_rows:\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as f_output:\n",
    "        writer = csv.writer(f_output)\n",
    "        writer.writerows(matching_rows)\n",
    "    print(f\"Đã lọc và ghi {len(matching_rows)} conference vào file '{output_file}'.\")\n",
    "else:\n",
    "    print(\"Không tìm thấy conference nào trùng khớp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add Extract System Instruction Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu xử lý file: ./src/conference/train/extract_infor_train_data_formatted_filtered.csv ---\n",
      "Đã đọc thành công system instruction từ 'extract_system_instruction.txt' (độ dài: 3832)\n",
      "Các cột trong file: input:, output:\n",
      "Giới hạn độ dài kiểm tra (sau khi thêm instruction và prefix): input: > 40000, output: > 5000\n",
      "File đầu ra sẽ là: ./src/conference/train/extract_infor_train_data_formatted_filtered_with_instruction_prefix.csv\n",
      "------------------------------\n",
      "Dòng 127: Bỏ qua vì vượt giới hạn - input: (41137/40000)\n",
      "Dòng 143: Bỏ qua vì vượt giới hạn - input: (42952/40000)\n",
      "Dòng 178: Bỏ qua vì vượt giới hạn - input: (42386/40000)\n",
      "Dòng 231: Bỏ qua vì vượt giới hạn - input: (42758/40000)\n",
      "Dòng 241: Bỏ qua vì vượt giới hạn - input: (40726/40000)\n",
      "Dòng 255: Bỏ qua vì vượt giới hạn - input: (40652/40000)\n",
      "------------------------------\n",
      "--- Kết thúc xử lý file CSV ---\n",
      "\n",
      "--- Báo cáo kết quả xử lý ---\n",
      "Tổng số dòng trong file gốc (không bao gồm header): 282\n",
      "Số dòng bị loại bỏ (vượt quá giới hạn sau khi thêm instruction và prefix): 6\n",
      "Số dòng được ghi vào file mới './src/conference/train/extract_infor_train_data_formatted_filtered_with_instruction_prefix.csv': 276\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Định nghĩa các giới hạn độ dài để dễ thay đổi\n",
    "GIOI_HAN_INPUT = 40000\n",
    "GIOI_HAN_OUTPUT = 5000\n",
    "DO_DAI_CHUOI_NGAN = 80 # Số ký tự hiển thị khi báo lỗi\n",
    "\n",
    "def them_system_instruction_va_prefix_va_loc_csv(duong_dan_file_csv_input, duong_dan_file_csv_output, duong_dan_file_txt_instruction):\n",
    "    \"\"\"\n",
    "    Đọc nội dung từ file instruction.txt.\n",
    "    Đọc file CSV, thêm nội dung instruction.txt, sau đó thêm dòng \"Page content:\"\n",
    "    và cuối cùng mới tới nội dung gốc của cột 'input:'.\n",
    "    Kiểm tra độ dài của cột 'input:' (sau khi thêm instruction và prefix).\n",
    "    Nếu bất kỳ dòng nào có cột 'input:' vượt quá GIOI_HAN_INPUT\n",
    "    hoặc cột 'output:' vượt quá GIOI_HAN_OUTPUT, dòng đó sẽ bị bỏ qua.\n",
    "    Các dòng hợp lệ (với instruction và prefix đã thêm) sẽ được ghi vào một file CSV mới.\n",
    "\n",
    "    Args:\n",
    "        duong_dan_file_csv_input (str): Đường dẫn đến file CSV gốc.\n",
    "        duong_dan_file_csv_output (str): Đường dẫn đến file CSV mới sẽ được tạo.\n",
    "        duong_dan_file_txt_instruction (str): Đường dẫn đến file .txt chứa system instruction.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (so_dong_goc, so_dong_vuot_gioi_han, so_dong_ghi_ra_file_moi, co_loi_doc_instruction).\n",
    "               Trả về (-1, -1, -1, True) nếu có lỗi nghiêm trọng.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"--- Bắt đầu xử lý file: {duong_dan_file_csv_input} ---\")\n",
    "    so_dong_goc = 0\n",
    "    so_dong_vuot_gioi_han = 0\n",
    "    so_dong_ghi_ra_file_moi = 0\n",
    "    cac_loi_xu_ly_dong = []\n",
    "    system_instruction = \"\"\n",
    "    co_loi_doc_instruction = False\n",
    "    prefix_content = \"\" # Chuỗi sẽ được thêm vào sau instruction\n",
    "\n",
    "    # Bước 1: Đọc nội dung từ file instruction.txt\n",
    "    try:\n",
    "        with open(duong_dan_file_txt_instruction, 'r', encoding='utf-8') as file_instruction:\n",
    "            system_instruction = file_instruction.read()\n",
    "        print(f\"Đã đọc thành công system instruction từ '{duong_dan_file_txt_instruction}' (độ dài: {len(system_instruction)})\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file instruction tại '{duong_dan_file_txt_instruction}'.\")\n",
    "        co_loi_doc_instruction = True\n",
    "        # Tiếp tục xử lý CSV nhưng với instruction rỗng\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định khi đọc file instruction: {e}\")\n",
    "        co_loi_doc_instruction = True\n",
    "        # Tiếp tục xử lý CSV nhưng với instruction rỗng\n",
    "\n",
    "    # Bước 2: Xử lý file CSV\n",
    "    try:\n",
    "        with open(duong_dan_file_csv_input, 'r', encoding='utf-8') as file_csv_in:\n",
    "            doc_csv = csv.DictReader(file_csv_in)\n",
    "            ten_cac_cot = doc_csv.fieldnames\n",
    "\n",
    "            if not ten_cac_cot:\n",
    "                 print(\"Lỗi: File CSV trống hoặc không có header.\")\n",
    "                 return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "            if 'input:' not in ten_cac_cot or 'output:' not in ten_cac_cot:\n",
    "                 print(\"Lỗi: File CSV phải có cả cột 'input:' và 'output:'.\")\n",
    "                 return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "            print(f\"Các cột trong file: {', '.join(ten_cac_cot)}\")\n",
    "            print(f\"Giới hạn độ dài kiểm tra (sau khi thêm instruction và prefix): input: > {GIOI_HAN_INPUT}, output: > {GIOI_HAN_OUTPUT}\")\n",
    "            print(f\"File đầu ra sẽ là: {duong_dan_file_csv_output}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Tạo thư mục chứa file output nếu chưa tồn tại\n",
    "            thu_muc_output = os.path.dirname(duong_dan_file_csv_output)\n",
    "            if thu_muc_output and not os.path.exists(thu_muc_output):\n",
    "                os.makedirs(thu_muc_output)\n",
    "                print(f\"Đã tạo thư mục đầu ra: {thu_muc_output}\")\n",
    "\n",
    "            with open(duong_dan_file_csv_output, 'w', encoding='utf-8', newline='') as file_csv_out:\n",
    "                ghi_csv = csv.DictWriter(file_csv_out, fieldnames=ten_cac_cot)\n",
    "                ghi_csv.writeheader() # Ghi header vào file mới\n",
    "\n",
    "                for so_dong_hien_tai, dong in enumerate(doc_csv, start=2): # Bắt đầu từ dòng 2 (sau header)\n",
    "                    so_dong_goc += 1\n",
    "                    vuot_gioi_han = False\n",
    "                    chi_tiet_vuot = [] # Lưu chi tiết cột nào vượt giới hạn\n",
    "\n",
    "                    try:\n",
    "                        # Lấy giá trị input gốc và thêm instruction + prefix\n",
    "                        gia_tri_input_goc = dong.get('input:', '') # Sử dụng get với giá trị mặc định\n",
    "                        # Nối theo thứ tự: instruction -> prefix -> input gốc\n",
    "                        gia_tri_input_moi = system_instruction + prefix_content + gia_tri_input_goc\n",
    "\n",
    "                        # Cập nhật giá trị input trong dictionary của dòng\n",
    "                        dong['input:'] = gia_tri_input_moi\n",
    "                        do_dai_input_moi = len(gia_tri_input_moi)\n",
    "\n",
    "                        # Kiểm tra độ dài input mới\n",
    "                        if do_dai_input_moi > GIOI_HAN_INPUT:\n",
    "                            vuot_gioi_han = True\n",
    "                            chi_tiet_vuot.append(f\"input: ({do_dai_input_moi}/{GIOI_HAN_INPUT})\")\n",
    "\n",
    "                        # Kiểm tra độ dài output (không thay đổi)\n",
    "                        gia_tri_output = dong.get('output:', '')\n",
    "                        do_dai_output = len(gia_tri_output)\n",
    "                        if do_dai_output > GIOI_HAN_OUTPUT:\n",
    "                            vuot_gioi_han = True\n",
    "                            chi_tiet_vuot.append(f\"output: ({do_dai_output}/{GIOI_HAN_OUTPUT})\")\n",
    "\n",
    "\n",
    "                        if vuot_gioi_han:\n",
    "                            so_dong_vuot_gioi_han += 1\n",
    "                            print(f\"Dòng {so_dong_hien_tai}: Bỏ qua vì vượt giới hạn - {' & '.join(chi_tiet_vuot)}\")\n",
    "                        else:\n",
    "                            # Dòng hợp lệ, ghi vào file mới (với giá trị input đã cập nhật)\n",
    "                            ghi_csv.writerow(dong)\n",
    "                            so_dong_ghi_ra_file_moi += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                         # Xử lý lỗi đọc hoặc ghi dòng cụ thể\n",
    "                         print(f\"Lỗi không xác định khi xử lý dòng {so_dong_hien_tai}: {e}\")\n",
    "                         cac_loi_xu_ly_dong.append(f\"Dòng {so_dong_hien_tai}: {e}\")\n",
    "                         # Không tăng so_dong_vuot_gioi_han hoặc so_dong_ghi_ra_file_moi cho dòng lỗi này\n",
    "\n",
    "            print(\"-\" * 30)\n",
    "            print(\"--- Kết thúc xử lý file CSV ---\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file CSV tại '{duong_dan_file_csv_input}'.\")\n",
    "        return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định trong quá trình xử lý file CSV: {e}\")\n",
    "        return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "    if cac_loi_xu_ly_dong:\n",
    "        print(\"\\nCác lỗi xử lý dòng cụ thể:\")\n",
    "        for loi in cac_loi_xu_ly_dong:\n",
    "            print(f\"- {loi}\")\n",
    "\n",
    "    return (so_dong_goc, so_dong_vuot_gioi_han, so_dong_ghi_ra_file_moi, co_loi_doc_instruction)\n",
    "\n",
    "\n",
    "# --- Phần ví dụ sử dụng ---\n",
    "duong_dan_file_goc = \"./src/conference/train/extract_infor_train_data_formatted_filtered.csv\"       # Thay đổi đường dẫn file CSV gốc của bạn\n",
    "duong_dan_file_moi = \"./src/conference/train/extract_infor_train_data_formatted_filtered_with_instruction_prefix.csv\" # Tên file mới sẽ được tạo\n",
    "duong_dan_instruction = \"extract_system_instruction.txt\"     # Thay đổi đường dẫn file instruction.txt\n",
    "\n",
    "so_dong_goc, so_dong_vuot, so_dong_moi, co_loi_instruction = them_system_instruction_va_prefix_va_loc_csv(\n",
    "    duong_dan_file_goc,\n",
    "    duong_dan_file_moi,\n",
    "    duong_dan_instruction\n",
    ")\n",
    "\n",
    "print(\"\\n--- Báo cáo kết quả xử lý ---\")\n",
    "if co_loi_instruction:\n",
    "    print(\"Cảnh báo: Có lỗi khi đọc file system instruction. Quá trình xử lý CSV tiếp tục nhưng không thêm instruction.\")\n",
    "\n",
    "if so_dong_goc != -1:\n",
    "    print(f\"Tổng số dòng trong file gốc (không bao gồm header): {so_dong_goc}\")\n",
    "    print(f\"Số dòng bị loại bỏ (vượt quá giới hạn sau khi thêm instruction và prefix): {so_dong_vuot}\")\n",
    "    print(f\"Số dòng được ghi vào file mới '{duong_dan_file_moi}': {so_dong_moi}\")\n",
    "else:\n",
    "    print(\"\\nKhông thể tạo báo cáo chi tiết do có lỗi nghiêm trọng trong quá trình xử lý.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add Determine System Instruction Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu xử lý file: ./src/conference/train/determine_links_train_data_formatted_filtered.csv ---\n",
      "Đã đọc thành công system instruction từ 'determine_system_instruction.txt' (độ dài sau thay thế: 5291)\n",
      "Năm được sử dụng trong instruction: Ưu tiên 2025, dự phòng 2024\n",
      "Các cột trong file: input:, output:\n",
      "Giới hạn độ dài kiểm tra (sau khi thêm instruction và prefix): input: > 40000, output: > 5000\n",
      "File đầu ra sẽ là: ./src/conference/train/determine_links_train_data_formatted_filtered_with_instruction_prefix.csv\n",
      "------------------------------\n",
      "Dòng 118: Bỏ qua vì vượt giới hạn - input: (40395/40000)\n",
      "    [Đoạn input vượt giới hạn]: '...ef=\"/cfp/about.jsp\" - About Us\n",
      "|href=\"mailto:wikicfp@gmail.com\" - Contact Us\n",
      "|href=\"/cfp/data.jsp\" - Data\n",
      "|href=\"/cfp/privacy.jsp\" - Privacy Policy\n",
      "|href=\"/cfp/...'\n",
      "Dòng 148: Bỏ qua vì vượt giới hạn - input: (43769/40000)\n",
      "    [Đoạn input vượt giới hạn]: '...e=WikiCFP&utm_medium=Display&utm_term=home&utm_content=semantic-scholar-rail-try-it&utm_campaign=WikiCFP%20Test\" - AI2's Semantic Scholar \n",
      " This wiki is license...'\n",
      "Dòng 166: Bỏ qua vì vượt giới hạn - input: (40539/40000)\n",
      "    [Đoạn input vượt giới hạn]: '...apers submissions.href=\"https://sigspatial2025.sigspatial.org/short-paper-submission/\" - [details] | Jan 30, 2025 | Call for industry papers submissions.href=\"h...'\n",
      "Dòng 178: Bỏ qua vì vượt giới hạn - input: (42991/40000)\n",
      "    [Đoạn input vượt giới hạn]: '...fp/servlet/event.showcfp?eventid=182521\" - IJRAP 2025\n",
      "International Journal of Recent advances in Physics | href=\"/cfp/servlet/event.showcfp?eventid=183317\" - D...'\n",
      "Dòng 188: Bỏ qua vì vượt giới hạn - input: (43835/40000)\n",
      "    [Đoạn input vượt giới hạn]: '...sored byEY \n",
      " 14:15 – 15:45 | RecTour | Room E \n",
      " href=\"https://healthrecsys.github.io/\" - HealthRecSys | Room D \n",
      " href=\"https://altrecsys.github.io/\" - AltRecSys...'\n",
      "Dòng 190: Bỏ qua vì vượt giới hạn - input: (40534/40000)\n",
      "    [Đoạn input vượt giới hạn]: '...campaign=WikiCFP%20Test\" - AI2's Semantic Scholar | This wiki is licensed under aCreative Commons Attribution-Share Alike 3.0 License. \n",
      " href=\"/cfp/about.jsp\" -...'\n",
      "Dòng 218: Bỏ qua vì vượt giới hạn - input: (43294/40000)\n",
      "    [Đoạn input vượt giới hạn]: '...Image Processing, Communications and Machine Learning (IPCML 2025) | href=\"/cfp/servlet/event.showcfp?eventid=187687\" - SANER 2026\n",
      "The 33rd IEEE International C...'\n",
      "------------------------------\n",
      "--- Kết thúc xử lý file CSV ---\n",
      "\n",
      "--- Báo cáo kết quả xử lý ---\n",
      "Tổng số dòng trong file gốc (không bao gồm header): 244\n",
      "Số dòng bị loại bỏ (vượt quá giới hạn sau khi thêm instruction và prefix): 7\n",
      "Số dòng được ghi vào file mới './src/conference/train/determine_links_train_data_formatted_filtered_with_instruction_prefix.csv': 237\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# --- Định nghĩa các biến năm tùy chỉnh ---\n",
    "NAM_HIEN_TAI = 2025  # Năm bạn muốn ưu tiên tìm kiếm\n",
    "NAM_TRUOC_DO = 2024  # Năm dự phòng nếu năm hiện tại không có\n",
    "\n",
    "# Định nghĩa các giới hạn độ dài để dễ thay đổi\n",
    "GIOI_HAN_INPUT = 40000\n",
    "GIOI_HAN_OUTPUT = 5000\n",
    "DO_DAI_CHUOI_NGAN = 80 # Số ký tự hiển thị khi báo lỗi cho đoạn vượt quá\n",
    "\n",
    "def them_system_instruction_va_prefix_va_loc_csv(duong_dan_file_csv_input, duong_dan_file_csv_output, duong_dan_file_txt_instruction, nam_hien_tai_config, nam_truoc_do_config):\n",
    "    \"\"\"\n",
    "    Đọc nội dung từ file instruction.txt.\n",
    "    Đọc file CSV, thêm nội dung instruction.txt, sau đó thêm dòng \"Page content:\"\n",
    "    và cuối cùng mới tới nội dung gốc của cột 'input:'.\n",
    "    Kiểm tra độ dài của cột 'input:' (sau khi thêm instruction và prefix).\n",
    "    Nếu bất kỳ dòng nào có cột 'input:' vượt quá GIOI_HAN_INPUT\n",
    "    hoặc cột 'output:' vượt quá GIOI_HAN_OUTPUT, dòng đó sẽ bị bỏ qua.\n",
    "    Các dòng hợp lệ (với instruction và prefix đã thêm) sẽ được ghi vào một file CSV mới.\n",
    "\n",
    "    Args:\n",
    "        duong_dan_file_csv_input (str): Đường dẫn đến file CSV gốc.\n",
    "        duong_dan_file_csv_output (str): Đường dẫn đến file CSV mới sẽ được tạo.\n",
    "        duong_dan_file_txt_instruction (str): Đường dẫn đến file .txt chứa system instruction.\n",
    "        nam_hien_tai_config (int): Năm ưu tiên tìm kiếm (ví dụ: 2025).\n",
    "        nam_truoc_do_config (int): Năm dự phòng nếu năm hiện tại không có (ví dụ: 2024).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (so_dong_goc, so_dong_vuot_gioi_han, so_dong_ghi_ra_file_moi, co_loi_doc_instruction).\n",
    "               Trả về (-1, -1, -1, True) nếu có lỗi nghiêm trọng.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"--- Bắt đầu xử lý file: {duong_dan_file_csv_input} ---\")\n",
    "    so_dong_goc = 0\n",
    "    so_dong_vuot_gioi_han = 0\n",
    "    so_dong_ghi_ra_file_moi = 0\n",
    "    cac_loi_xu_ly_dong = []\n",
    "    system_instruction = \"\"\n",
    "    co_loi_doc_instruction = False\n",
    "    prefix_content = \"\\n\\n\" # Chuỗi sẽ được thêm vào sau instruction\n",
    "\n",
    "    # Bước 1: Đọc nội dung từ file instruction.txt\n",
    "    try:\n",
    "        with open(duong_dan_file_txt_instruction, 'r', encoding='utf-8') as file_instruction:\n",
    "            system_instruction_raw = file_instruction.read()\n",
    "            # Thay thế năm trong instruction\n",
    "            system_instruction = system_instruction_raw.replace(\"2025\", str(nam_hien_tai_config))\n",
    "            system_instruction = system_instruction.replace(\"2024\", str(nam_truoc_do_config))\n",
    "\n",
    "        print(f\"Đã đọc thành công system instruction từ '{duong_dan_file_txt_instruction}' (độ dài sau thay thế: {len(system_instruction)})\")\n",
    "        print(f\"Năm được sử dụng trong instruction: Ưu tiên {nam_hien_tai_config}, dự phòng {nam_truoc_do_config}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file instruction tại '{duong_dan_file_txt_instruction}'.\")\n",
    "        co_loi_doc_instruction = True\n",
    "        # Tiếp tục xử lý CSV nhưng với instruction rỗng\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định khi đọc file instruction: {e}\")\n",
    "        co_loi_doc_instruction = True\n",
    "        # Tiếp tục xử lý CSV nhưng với instruction rỗng\n",
    "\n",
    "    # Bước 2: Xử lý file CSV\n",
    "    try:\n",
    "        with open(duong_dan_file_csv_input, 'r', encoding='utf-8') as file_csv_in:\n",
    "            doc_csv = csv.DictReader(file_csv_in)\n",
    "            ten_cac_cot = doc_csv.fieldnames\n",
    "\n",
    "            if not ten_cac_cot:\n",
    "                 print(\"Lỗi: File CSV trống hoặc không có header.\")\n",
    "                 return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "            if 'input:' not in ten_cac_cot or 'output:' not in ten_cac_cot:\n",
    "                 print(\"Lỗi: File CSV phải có cả cột 'input:' và 'output:'.\")\n",
    "                 return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "            print(f\"Các cột trong file: {', '.join(ten_cac_cot)}\")\n",
    "            print(f\"Giới hạn độ dài kiểm tra (sau khi thêm instruction và prefix): input: > {GIOI_HAN_INPUT}, output: > {GIOI_HAN_OUTPUT}\")\n",
    "            print(f\"File đầu ra sẽ là: {duong_dan_file_csv_output}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Tạo thư mục chứa file output nếu chưa tồn tại\n",
    "            thu_muc_output = os.path.dirname(duong_dan_file_csv_output)\n",
    "            if thu_muc_output and not os.path.exists(thu_muc_output):\n",
    "                os.makedirs(thu_muc_output)\n",
    "                print(f\"Đã tạo thư mục đầu ra: {thu_muc_output}\")\n",
    "\n",
    "            with open(duong_dan_file_csv_output, 'w', encoding='utf-8', newline='') as file_csv_out:\n",
    "                ghi_csv = csv.DictWriter(file_csv_out, fieldnames=ten_cac_cot)\n",
    "                ghi_csv.writeheader() # Ghi header vào file mới\n",
    "\n",
    "                for so_dong_hien_tai, dong in enumerate(doc_csv, start=2): # Bắt đầu từ dòng 2 (sau header)\n",
    "                    so_dong_goc += 1\n",
    "                    vuot_gioi_han = False\n",
    "                    chi_tiet_vuot = [] # Lưu chi tiết cột nào vượt giới hạn\n",
    "                    doan_vuot_input = \"\" # Lưu đoạn input vượt giới hạn\n",
    "                    doan_vuot_output = \"\" # Lưu đoạn output vượt giới hạn\n",
    "\n",
    "                    try:\n",
    "                        # Lấy giá trị input gốc và thêm instruction + prefix\n",
    "                        gia_tri_input_goc = dong.get('input:', '') # Sử dụng get với giá trị mặc định\n",
    "                        # Nối theo thứ tự: instruction -> prefix -> input gốc\n",
    "                        gia_tri_input_moi = system_instruction + prefix_content + gia_tri_input_goc\n",
    "\n",
    "                        # Cập nhật giá trị input trong dictionary của dòng\n",
    "                        dong['input:'] = gia_tri_input_moi\n",
    "                        do_dai_input_moi = len(gia_tri_input_moi)\n",
    "\n",
    "                        # Kiểm tra độ dài input mới\n",
    "                        if do_dai_input_moi > GIOI_HAN_INPUT:\n",
    "                            vuot_gioi_han = True\n",
    "                            chi_tiet_vuot.append(f\"input: ({do_dai_input_moi}/{GIOI_HAN_INPUT})\")\n",
    "                            # Lấy một đoạn chuỗi để kiểm tra\n",
    "                            doan_vuot_input = gia_tri_input_moi[GIOI_HAN_INPUT - DO_DAI_CHUOI_NGAN : GIOI_HAN_INPUT + DO_DAI_CHUOI_NGAN]\n",
    "                            if doan_vuot_input: # Thêm dấu ba chấm nếu chuỗi bị cắt\n",
    "                                doan_vuot_input = f\"...{doan_vuot_input}...\"\n",
    "\n",
    "\n",
    "                        # Kiểm tra độ dài output (không thay đổi)\n",
    "                        gia_tri_output = dong.get('output:', '')\n",
    "                        do_dai_output = len(gia_tri_output)\n",
    "                        if do_dai_output > GIOI_HAN_OUTPUT:\n",
    "                            vuot_gioi_han = True\n",
    "                            chi_tiet_vuot.append(f\"output: ({do_dai_output}/{GIOI_HAN_OUTPUT})\")\n",
    "                            # Lấy một đoạn chuỗi để kiểm tra\n",
    "                            doan_vuot_output = gia_tri_output[GIOI_HAN_OUTPUT - DO_DAI_CHUOI_NGAN : GIOI_HAN_OUTPUT + DO_DAI_CHUOI_NGAN]\n",
    "                            if doan_vuot_output: # Thêm dấu ba chấm nếu chuỗi bị cắt\n",
    "                                doan_vuot_output = f\"...{doan_vuot_output}...\"\n",
    "\n",
    "\n",
    "                        if vuot_gioi_han:\n",
    "                            so_dong_vuot_gioi_han += 1\n",
    "                            print(f\"Dòng {so_dong_hien_tai}: Bỏ qua vì vượt giới hạn - {' & '.join(chi_tiet_vuot)}\")\n",
    "                            if doan_vuot_input:\n",
    "                                print(f\"    [Đoạn input vượt giới hạn]: '{doan_vuot_input}'\")\n",
    "                            if doan_vuot_output:\n",
    "                                print(f\"    [Đoạn output vượt giới hạn]: '{doan_vuot_output}'\")\n",
    "                        else:\n",
    "                            # Dòng hợp lệ, ghi vào file mới (với giá trị input đã cập nhật)\n",
    "                            ghi_csv.writerow(dong)\n",
    "                            so_dong_ghi_ra_file_moi += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                         # Xử lý lỗi đọc hoặc ghi dòng cụ thể\n",
    "                         print(f\"Lỗi không xác định khi xử lý dòng {so_dong_hien_tai}: {e}\")\n",
    "                         cac_loi_xu_ly_dong.append(f\"Dòng {so_dong_hien_tai}: {e}\")\n",
    "                         # Không tăng so_dong_vuot_gioi_han hoặc so_dong_ghi_ra_file_moi cho dòng lỗi này\n",
    "\n",
    "            print(\"-\" * 30)\n",
    "            print(\"--- Kết thúc xử lý file CSV ---\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file CSV tại '{duong_dan_file_csv_input}'.\")\n",
    "        return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định trong quá trình xử lý file CSV: {e}\")\n",
    "        return (-1, -1, -1, False) # Trả về lỗi nghiêm trọng\n",
    "\n",
    "    if cac_loi_xu_ly_dong:\n",
    "        print(\"\\nCác lỗi xử lý dòng cụ thể:\")\n",
    "        for loi in cac_loi_xu_ly_dong:\n",
    "            print(f\"- {loi}\")\n",
    "\n",
    "    return (so_dong_goc, so_dong_vuot_gioi_han, so_dong_ghi_ra_file_moi, co_loi_doc_instruction)\n",
    "\n",
    "\n",
    "# --- Phần ví dụ sử dụng ---\n",
    "duong_dan_file_goc = \"./src/conference/train/determine_links_train_data_formatted_filtered.csv\"       # Thay đổi đường dẫn file CSV gốc của bạn\n",
    "duong_dan_file_moi = \"./src/conference/train/determine_links_train_data_formatted_filtered_with_instruction_prefix.csv\" # Tên file mới sẽ được tạo\n",
    "duong_dan_instruction = \"determine_system_instruction.txt\"     # Thay đổi đường dẫn file instruction.txt\n",
    "\n",
    "so_dong_goc, so_dong_vuot, so_dong_moi, co_loi_instruction = them_system_instruction_va_prefix_va_loc_csv(\n",
    "    duong_dan_file_goc,\n",
    "    duong_dan_file_moi,\n",
    "    duong_dan_instruction,\n",
    "    NAM_HIEN_TAI,  # Truyền biến năm vào hàm\n",
    "    NAM_TRUOC_DO   # Truyền biến năm vào hàm\n",
    ")\n",
    "\n",
    "print(\"\\n--- Báo cáo kết quả xử lý ---\")\n",
    "if co_loi_instruction:\n",
    "    print(\"Cảnh báo: Có lỗi khi đọc file system instruction. Quá trình xử lý CSV tiếp tục nhưng không thêm instruction.\")\n",
    "\n",
    "if so_dong_goc != -1:\n",
    "    print(f\"Tổng số dòng trong file gốc (không bao gồm header): {so_dong_goc}\")\n",
    "    print(f\"Số dòng bị loại bỏ (vượt quá giới hạn sau khi thêm instruction và prefix): {so_dong_vuot}\")\n",
    "    print(f\"Số dòng được ghi vào file mới '{duong_dan_file_moi}': {so_dong_moi}\")\n",
    "else:\n",
    "    print(\"\\nKhông thể tạo báo cáo chi tiết do có lỗi nghiêm trọng trong quá trình xử lý.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import json\n",
    "# import io\n",
    "# import sys\n",
    "\n",
    "# # --- Phần 1: Tăng giới hạn kích thước trường CSV ---\n",
    "# max_int = sys.maxsize\n",
    "# print(\"Đang tìm giới hạn kích thước trường CSV tối đa mà hệ thống hỗ trợ...\")\n",
    "# while True:\n",
    "#     try:\n",
    "#         csv.field_size_limit(max_int)\n",
    "#         print(f\"Đã đặt giới hạn kích thước trường CSV thành: {max_int}\")\n",
    "#         break\n",
    "#     except OverflowError:\n",
    "#         max_int = int(max_int / 10)\n",
    "\n",
    "# # --- Phần 2: Đặt tên file và xử lý ---\n",
    "# input_filename = './src/conference/examples/determine_links_train_data.csv' # Tên file CSV đầu vào của bạn\n",
    "# # Đổi tên file output một lần nữa\n",
    "# output_filename = 'output_transformed_final.csv'\n",
    "\n",
    "# print(f\"Đang xử lý file: {input_filename}\")\n",
    "\n",
    "# try:\n",
    "#     with open(input_filename, 'r', newline='', encoding='utf-8') as infile, \\\n",
    "#          open(output_filename, 'w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "#         csv_reader = csv.reader(infile)\n",
    "#         csv_writer = csv.writer(outfile)\n",
    "\n",
    "#         try:\n",
    "#             header = next(csv_reader)\n",
    "#             csv_writer.writerow(header)\n",
    "#             print(f\"Đã đọc header: {header}\")\n",
    "\n",
    "#             for i, row in enumerate(csv_reader):\n",
    "#                 current_line_num = i + 2\n",
    "#                 if len(row) == 2:\n",
    "#                     input_text = row[0]\n",
    "#                     output_json_str = row[1]\n",
    "#                     transformed_output = \"\"\n",
    "\n",
    "#                     try:\n",
    "#                         data_dict = json.loads(output_json_str)\n",
    "\n",
    "#                         if isinstance(data_dict, dict):\n",
    "#                             # ---- THAY ĐỔI Ở ĐÂY ----\n",
    "#                             lines = [] # Danh sách để lưu các dòng đã định dạng\n",
    "#                             num_items = len(data_dict) # Lấy số lượng cặp key-value\n",
    "\n",
    "#                             # Sử dụng enumerate để có chỉ số (idx)\n",
    "#                             for idx, (key, value) in enumerate(data_dict.items()):\n",
    "#                                 # Tạo dòng cơ bản\n",
    "#                                 line = f'\"{key}\": \"{value}\"'\n",
    "#                                 # Nếu không phải là mục cuối cùng, thêm dấu phẩy\n",
    "#                                 if idx < num_items - 1:\n",
    "#                                     line += \",\"\n",
    "#                                 lines.append(line) # Thêm dòng vào danh sách\n",
    "\n",
    "#                             # Nối các dòng trong danh sách bằng ký tự xuống dòng\n",
    "#                             transformed_output = \"\\n\".join(lines)\n",
    "#                             # ---- KẾT THÚC THAY ĐỔI ----\n",
    "#                         else:\n",
    "#                             print(f\"Cảnh báo dòng {current_line_num}: Cột output không phải là JSON object: {output_json_str[:100]}...\")\n",
    "#                             transformed_output = output_json_str\n",
    "\n",
    "#                     except json.JSONDecodeError:\n",
    "#                         print(f\"Cảnh báo dòng {current_line_num}: Không thể parse JSON từ cột output: {output_json_str[:100]}...\")\n",
    "#                         transformed_output = output_json_str\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Lỗi xử lý JSON ở dòng {current_line_num}: {e}\")\n",
    "#                         transformed_output = output_json_str\n",
    "\n",
    "#                     csv_writer.writerow([input_text, transformed_output])\n",
    "\n",
    "#                 else:\n",
    "#                     print(f\"Cảnh báo dòng {current_line_num}: Dòng không có đúng 2 cột. Bỏ qua: {row}\")\n",
    "\n",
    "#         except csv.Error as e:\n",
    "#             print(f\"Lỗi CSV ở dòng {csv_reader.line_num}: {e}\")\n",
    "#             print(\"Kiểm tra lại cấu trúc file CSV hoặc tăng 'field_size_limit' nếu cần.\")\n",
    "#         except StopIteration:\n",
    "#              print(\"File CSV không có dữ liệu sau header.\")\n",
    "#         except Exception as e:\n",
    "#              line_num_info = f\" (possibly near line {csv_reader.line_num})\" if 'csv_reader' in locals() and hasattr(csv_reader, 'line_num') else \"\"\n",
    "#              print(f\"Đã xảy ra lỗi không mong muốn trong quá trình xử lý file{line_num_info}: {e}\")\n",
    "\n",
    "#     print(f\"\\nXử lý hoàn tất. Dữ liệu đã được ghi vào file: {output_filename}\")\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Lỗi: Không tìm thấy file '{input_filename}'\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Đã xảy ra lỗi không mong muốn bên ngoài quá trình đọc CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import re\n",
    "# import sys\n",
    "\n",
    "# # --- Tăng giới hạn CSV nếu cần ---\n",
    "# max_int = sys.maxsize\n",
    "# print(\"Đang tìm giới hạn kích thước trường CSV tối đa...\")\n",
    "# while True:\n",
    "#     try:\n",
    "#         csv.field_size_limit(max_int)\n",
    "#         print(f\"Đã đặt giới hạn kích thước trường CSV thành: {max_int}\")\n",
    "#         break\n",
    "#     except OverflowError:\n",
    "#         max_int = int(max_int / 10)\n",
    "\n",
    "# # --- Đặt tên file ---\n",
    "# input_filename = 'output_transformed_final.csv' # File input từ bước trước\n",
    "# # File output mới, tên rõ ràng hơn\n",
    "# output_filename = 'final_truncated_input_at_4.csv'\n",
    "\n",
    "# # --- Biểu thức chính quy để tìm điểm cắt (CHỈ SỐ 4) ---\n",
    "# # Thay đổi ở đây: thay \\d+ bằng số 4 cụ thể\n",
    "# pattern_to_find = re.compile(r\"\\s*4\\.\\s+Website of \") # Tìm \"4. Website of \"\n",
    "\n",
    "# print(f\"Đang đọc file: {input_filename}\")\n",
    "# print(f\"Sẽ ghi kết quả vào: {output_filename}\")\n",
    "\n",
    "# try:\n",
    "#     with open(input_filename, 'r', newline='', encoding='utf-8') as infile, \\\n",
    "#          open(output_filename, 'w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "#         csv_reader = csv.reader(infile)\n",
    "#         csv_writer = csv.writer(outfile)\n",
    "\n",
    "#         try:\n",
    "#             # Đọc và ghi header\n",
    "#             header = next(csv_reader)\n",
    "#             csv_writer.writerow(header)\n",
    "#             print(f\"Đã đọc header: {header}\")\n",
    "\n",
    "#             # Xử lý từng dòng dữ liệu CSV\n",
    "#             for i, row in enumerate(csv_reader):\n",
    "#                 current_csv_line_num = i + 2 # Số dòng trong file CSV\n",
    "\n",
    "#                 if len(row) == 2:\n",
    "#                     input_text_original = row[0]\n",
    "#                     output_text = row[1] # Giữ nguyên cột output\n",
    "\n",
    "#                     # Tìm vị trí đầu tiên của pattern \"4. Website of \"\n",
    "#                     match = pattern_to_find.search(input_text_original)\n",
    "\n",
    "#                     if match:\n",
    "#                         # Nếu tìm thấy, lấy vị trí bắt đầu\n",
    "#                         start_index = match.start()\n",
    "#                         # Cắt chuỗi từ đầu đến vị trí đó\n",
    "#                         input_text_cleaned = input_text_original[:start_index].rstrip()\n",
    "#                         # Thêm dấu xuống hàng ở cuối sau khi cắt\n",
    "#                         input_text_cleaned += '\\n'\n",
    "#                         # print(f\"  (CSV Line {current_csv_line_num}) Đã cắt bỏ từ '4. Website of ' tại vị trí {start_index}.\")\n",
    "#                     else:\n",
    "#                         # Nếu không tìm thấy \"4. Website of \", giữ nguyên và thêm dấu xuống hàng\n",
    "#                         input_text_cleaned = input_text_original + '\\n'\n",
    "\n",
    "\n",
    "#                     # Ghi dòng đã xử lý\n",
    "#                     csv_writer.writerow([input_text_cleaned, output_text])\n",
    "\n",
    "#                 else:\n",
    "#                     print(f\"Cảnh báo dòng CSV {current_csv_line_num}: Dòng không có đúng 2 cột. Bỏ qua: {row}\")\n",
    "\n",
    "#         except csv.Error as e:\n",
    "#             print(f\"Lỗi CSV ở dòng {csv_reader.line_num}: {e}\")\n",
    "#         except StopIteration:\n",
    "#              print(\"File CSV không có dữ liệu sau header.\")\n",
    "#         except Exception as e:\n",
    "#              line_num_info = f\" (possibly near line {csv_reader.line_num})\" if 'csv_reader' in locals() and hasattr(csv_reader, 'line_num') else \"\"\n",
    "#              print(f\"Đã xảy ra lỗi không mong muốn trong quá trình xử lý file{line_num_info}: {e}\")\n",
    "\n",
    "#     print(f\"\\nXử lý hoàn tất. Dữ liệu đã được cắt (chỉ tại '4. Website of ') và ghi vào file: {output_filename}\")\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Lỗi: Không tìm thấy file '{input_filename}'. Hãy đảm bảo file input có tên này.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Đã xảy ra lỗi không mong muốn bên ngoài quá trình đọc CSV: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check giới hạn 40000 và 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu xử lý file: ./src/conference/train/determine_links_train_data_formatted.csv ---\n",
      "Các cột trong file: input:, output:\n",
      "Giới hạn độ dài kiểm tra: input: > 40000, output: > 5000\n",
      "File đầu ra sẽ là: ./src/conference/train/determine_links_train_data_formatted_filtered.csv\n",
      "------------------------------\n",
      "------------------------------\n",
      "--- Kết thúc xử lý file ---\n",
      "\n",
      "--- Báo cáo kết quả lọc ---\n",
      "Tổng số dòng trong file gốc (không bao gồm header): 244\n",
      "Số dòng bị loại bỏ (vượt quá giới hạn): 0\n",
      "Số dòng được ghi vào file mới './src/conference/train/determine_links_train_data_formatted_filtered.csv': 244\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Định nghĩa các giới hạn độ dài để dễ thay đổi\n",
    "GIOI_HAN_INPUT = 40000\n",
    "GIOI_HAN_OUTPUT = 5000\n",
    "DO_DAI_CHUOI_NGAN = 80 # Số ký tự hiển thị khi báo lỗi\n",
    "\n",
    "def xoa_dong_vuot_gioi_han_csv(duong_dan_file_csv_input, duong_dan_file_csv_output):\n",
    "    \"\"\"\n",
    "    Đọc file CSV, kiểm tra độ dài của cột 'input:' và 'output:'.\n",
    "    Nếu bất kỳ dòng nào có cột 'input:' vượt quá GIOI_HAN_INPUT\n",
    "    hoặc cột 'output:' vượt quá GIOI_HAN_OUTPUT, dòng đó sẽ bị bỏ qua.\n",
    "    Các dòng hợp lệ sẽ được ghi vào một file CSV mới.\n",
    "\n",
    "    Args:\n",
    "        duong_dan_file_csv_input (str): Đường dẫn đến file CSV gốc.\n",
    "        duong_dan_file_csv_output (str): Đường dẫn đến file CSV mới sẽ được tạo.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (so_dong_goc, so_dong_vuot_gioi_han, so_dong_ghi_ra_file_moi).\n",
    "               Trả về (-1, -1, -1) nếu có lỗi xảy ra.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"--- Bắt đầu xử lý file: {duong_dan_file_csv_input} ---\")\n",
    "    so_dong_goc = 0\n",
    "    so_dong_vuot_gioi_han = 0\n",
    "    so_dong_ghi_ra_file_moi = 0\n",
    "    cac_loi_xu_ly = []\n",
    "\n",
    "    try:\n",
    "        with open(duong_dan_file_csv_input, 'r', encoding='utf-8') as file_csv_in:\n",
    "            doc_csv = csv.DictReader(file_csv_in)\n",
    "            ten_cac_cot = doc_csv.fieldnames\n",
    "\n",
    "            if not ten_cac_cot:\n",
    "                 print(\"Lỗi: File CSV trống hoặc không có header.\")\n",
    "                 return (-1, -1, -1)\n",
    "\n",
    "            print(f\"Các cột trong file: {', '.join(ten_cac_cot)}\")\n",
    "            print(f\"Giới hạn độ dài kiểm tra: input: > {GIOI_HAN_INPUT}, output: > {GIOI_HAN_OUTPUT}\")\n",
    "            print(f\"File đầu ra sẽ là: {duong_dan_file_csv_output}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Tạo thư mục chứa file output nếu chưa tồn tại\n",
    "            thu_muc_output = os.path.dirname(duong_dan_file_csv_output)\n",
    "            if thu_muc_output and not os.path.exists(thu_muc_output):\n",
    "                os.makedirs(thu_muc_output)\n",
    "                print(f\"Đã tạo thư mục đầu ra: {thu_muc_output}\")\n",
    "\n",
    "\n",
    "            with open(duong_dan_file_csv_output, 'w', encoding='utf-8', newline='') as file_csv_out:\n",
    "                ghi_csv = csv.DictWriter(file_csv_out, fieldnames=ten_cac_cot)\n",
    "                ghi_csv.writeheader() # Ghi header vào file mới\n",
    "\n",
    "                for so_dong_hien_tai, dong in enumerate(doc_csv, start=2): # Bắt đầu từ dòng 2 (sau header)\n",
    "                    so_dong_goc += 1\n",
    "                    vuot_gioi_han = False\n",
    "                    chi_tiet_vuot = [] # Lưu chi tiết cột nào vượt giới hạn\n",
    "\n",
    "                    try:\n",
    "                        # Kiểm tra từng cột cần giới hạn\n",
    "                        if 'input:' in dong:\n",
    "                            gia_tri_input = dong.get('input:')\n",
    "                            do_dai_input = len(gia_tri_input) if gia_tri_input is not None else 0\n",
    "                            if do_dai_input > GIOI_HAN_INPUT:\n",
    "                                vuot_gioi_han = True\n",
    "                                chi_tiet_vuot.append(f\"input: ({do_dai_input}/{GIOI_HAN_INPUT})\")\n",
    "\n",
    "                        if 'output:' in dong:\n",
    "                            gia_tri_output = dong.get('output:')\n",
    "                            do_dai_output = len(gia_tri_output) if gia_tri_output is not None else 0\n",
    "                            if do_dai_output > GIOI_HAN_OUTPUT:\n",
    "                                vuot_gioi_han = True\n",
    "                                chi_tiet_vuot.append(f\"output: ({do_dai_output}/{GIOI_HAN_OUTPUT})\")\n",
    "\n",
    "                        if vuot_gioi_han:\n",
    "                            so_dong_vuot_gioi_han += 1\n",
    "                            print(f\"Dòng {so_dong_hien_tai}: Bỏ qua vì vượt giới hạn - {' & '.join(chi_tiet_vuot)}\")\n",
    "                        else:\n",
    "                            # Dòng hợp lệ, ghi vào file mới\n",
    "                            ghi_csv.writerow(dong)\n",
    "                            so_dong_ghi_ra_file_moi += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                         # Xử lý lỗi đọc hoặc ghi dòng cụ thể\n",
    "                         print(f\"Lỗi không xác định khi xử lý dòng {so_dong_hien_tai}: {e}\")\n",
    "                         cac_loi_xu_ly.append(f\"Dòng {so_dong_hien_tai}: {e}\")\n",
    "                         # Không tăng so_dong_vuot_gioi_han hoặc so_dong_ghi_ra_file_moi cho dòng lỗi này\n",
    "\n",
    "            print(\"-\" * 30)\n",
    "            print(\"--- Kết thúc xử lý file ---\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file CSV tại '{duong_dan_file_csv_input}'.\")\n",
    "        return (-1, -1, -1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định trong quá trình xử lý file: {e}\")\n",
    "        return (-1, -1, -1)\n",
    "\n",
    "    if cac_loi_xu_ly:\n",
    "        print(\"\\nCác lỗi xử lý dòng cụ thể:\")\n",
    "        for loi in cac_loi_xu_ly:\n",
    "            print(f\"- {loi}\")\n",
    "\n",
    "    return (so_dong_goc, so_dong_vuot_gioi_han, so_dong_ghi_ra_file_moi)\n",
    "\n",
    "\n",
    "# --- Phần ví dụ sử dụng ---\n",
    "duong_dan_file_goc = \"./src/conference/train/determine_links_train_data_formatted.csv\" # Thay đổi đường dẫn file gốc của bạn\n",
    "duong_dan_file_moi = \"./src/conference/train/determine_links_train_data_formatted_filtered.csv\" # Tên file mới sẽ được tạo\n",
    "\n",
    "so_dong_goc, so_dong_vuot, so_dong_moi = xoa_dong_vuot_gioi_han_csv(duong_dan_file_goc, duong_dan_file_moi)\n",
    "\n",
    "if so_dong_goc != -1:\n",
    "    print(\"\\n--- Báo cáo kết quả lọc ---\")\n",
    "    print(f\"Tổng số dòng trong file gốc (không bao gồm header): {so_dong_goc}\")\n",
    "    print(f\"Số dòng bị loại bỏ (vượt quá giới hạn): {so_dong_vuot}\")\n",
    "    print(f\"Số dòng được ghi vào file mới '{duong_dan_file_moi}': {so_dong_moi}\")\n",
    "else:\n",
    "    print(\"\\nKhông thể tạo báo cáo do có lỗi trong quá trình xử lý.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Kiểm tra JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Không có lỗi nào được tìm thấy.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def kiem_tra_csv_va_json(duong_dan_file_csv, context_size=50):\n",
    "    \"\"\"\n",
    "    Đọc file CSV, kiểm tra xem cột \"output:\" có phải là JSON hợp lệ hay không,\n",
    "    và log dòng lỗi ra cùng với context xung quanh vị trí lỗi.\n",
    "\n",
    "    Args:\n",
    "        duong_dan_file_csv (str): Đường dẫn đến file CSV.\n",
    "        context_size (int): Số lượng ký tự trước và sau vị trí lỗi để hiển thị.\n",
    "\n",
    "    Returns:\n",
    "        list: Một danh sách các thông báo lỗi. Mỗi thông báo lỗi là một tuple\n",
    "              (so_dong, cot, thong_tin_loi). Trả về danh sách rỗng nếu không có lỗi.\n",
    "    \"\"\"\n",
    "\n",
    "    cac_loi = []\n",
    "\n",
    "    try:\n",
    "        with open(duong_dan_file_csv, 'r', encoding='utf-8') as file_csv:\n",
    "            doc_csv = csv.DictReader(file_csv)\n",
    "            for so_dong, dong in enumerate(doc_csv, start=2):  # Bắt đầu từ dòng 2 (bỏ qua header)\n",
    "                try:\n",
    "                    input_text = dong.get('input:')\n",
    "                    output_text = dong.get('output:')\n",
    "\n",
    "                    # Kiểm tra JSON\n",
    "                    if output_text is not None:\n",
    "                        try:\n",
    "                            json.loads(output_text)\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            # Log dòng lỗi ra và context\n",
    "                            position = e.pos\n",
    "                            start = max(0, position - context_size)\n",
    "                            end = min(len(output_text), position + context_size)\n",
    "                            context = output_text[start:end]\n",
    "\n",
    "                            print(f\"Lỗi JSON ở dòng {so_dong}: {e}\")\n",
    "                            print(f\"Vị trí lỗi: {position}\")\n",
    "                            print(f\"Context: ...{context}...\")\n",
    "                            cac_loi.append((so_dong, 'output:', f\"Lỗi JSON: {e}\"))\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi khi xử lý dòng {so_dong}: {e}\")\n",
    "                    cac_loi.append((so_dong, 'Lỗi xử lý dòng', str(e)))  # Thêm thông tin lỗi vào danh sách\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file CSV tại '{duong_dan_file_csv}'.\")\n",
    "        return [(\"File\", \"Không tìm thấy file\", duong_dan_file_csv)]  # Trả về một list với thông báo lỗi\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định khi đọc file CSV: {e}\")\n",
    "        return [(\"File\", \"Lỗi đọc file\", str(e))]\n",
    "\n",
    "    return cac_loi\n",
    "\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "duong_dan_file = 'D:/NEW-SERVER-TS/src/conference/train/determine_links_train_data_formatted_filtered.csv'  # Thay đổi đường dẫn file của bạn ở đây\n",
    "cac_loi = kiem_tra_csv_va_json(duong_dan_file)\n",
    "\n",
    "if cac_loi:\n",
    "    print(\"Các lỗi được tìm thấy:\")\n",
    "    for so_dong, cot, thong_tin_loi in cac_loi:\n",
    "        print(f\"  - Dòng {so_dong}, cột '{cot}': {thong_tin_loi}\")\n",
    "else:\n",
    "    print(\"Không có lỗi nào được tìm thấy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Transform determine links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "\n",
    "def transform_single_input(old_input_text):\n",
    "    \"\"\"\n",
    "    Transforms a single 'input:' string from the old format to the new format.\n",
    "    \"\"\"\n",
    "    new_input_parts = []\n",
    "\n",
    "    # 1. Extract Conference Info\n",
    "    conf_title = \"Unknown Conference\"\n",
    "    conf_acronym = \"N/A\" # Default value\n",
    "\n",
    "    # Try to find full name and acronym in parentheses\n",
    "    conf_name_match = re.search(\n",
    "        r\"Conference full name:\\s*(.*?)(?:\\s*\\((.*?)\\))?\\n\",\n",
    "        old_input_text,\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    if conf_name_match:\n",
    "        conf_title = conf_name_match.group(1).strip()\n",
    "        if conf_name_match.group(2): # Acronym was in parentheses\n",
    "            conf_acronym = conf_name_match.group(2).strip()\n",
    "\n",
    "    # 2. Extract Website Contents\n",
    "    # Regex to find each website block\n",
    "    # Group 1: Number (e.g., \"1\")\n",
    "    # Group 2: Acronym part from \"Website of ACRONYM_X\" (e.g., \"CARDIS\")\n",
    "    # Group 3: Number suffix from \"_X\" (e.g., \"0\")\n",
    "    # Group 4: URL\n",
    "    # Group 5: Content\n",
    "    website_pattern = re.compile(\n",
    "        r\"(\\d+)\\.\\s+Website of\\s+(.*?)_(\\d*):\\s*(https?://[^\\s]+)\\s*\"\n",
    "        r\"Website information of [^:]*:\\s*\\n\" # Match \"Website information of ANYTHING:\"\n",
    "        r\"([\\s\\S]*?)\"\n",
    "        r\"(?=(?:\\n\\s*\\d+\\.\\s+Website of)|\\Z)\", # Positive lookahead for next block or end of string\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    websites = []\n",
    "    first_site_acronym_candidate = None\n",
    "\n",
    "    for match in website_pattern.finditer(old_input_text):\n",
    "        # site_number_text = match.group(1) # e.g., \"1\"\n",
    "        site_acronym_candidate = match.group(2).strip() # e.g., \"CARDIS\"\n",
    "        # site_suffix_num = match.group(3) # e.g., \"0\"\n",
    "        url = match.group(4).strip()\n",
    "        content = match.group(5).strip()\n",
    "        websites.append({\"url\": url, \"content\": content})\n",
    "\n",
    "        if not first_site_acronym_candidate and site_acronym_candidate:\n",
    "            first_site_acronym_candidate = site_acronym_candidate\n",
    "\n",
    "    # If acronym wasn't found with conference name, try to use one from website blocks\n",
    "    # Only override if conf_acronym is still the default \"N/A\"\n",
    "    if conf_acronym == \"N/A\" and first_site_acronym_candidate:\n",
    "        conf_acronym = first_site_acronym_candidate\n",
    "\n",
    "    # 3. Build the new input string\n",
    "    new_input_parts.append(\"Conference Info:\")\n",
    "    new_input_parts.append(f\"Title: {conf_title}\")\n",
    "    new_input_parts.append(f\"Acronym: {conf_acronym}\\n\") # Extra newline for separation\n",
    "\n",
    "    new_input_parts.append(\"Candidate Website Contents:\")\n",
    "    for i, site in enumerate(websites):\n",
    "        new_input_parts.append(f\"Source Link [{i+1}]: {site['url']}\")\n",
    "        new_input_parts.append(f\"Content [{i+1}]:\\n{site['content']}\")\n",
    "        if i < len(websites) - 1:\n",
    "            new_input_parts.append(\"\\n---\\n\")\n",
    "\n",
    "    return \"\\n\".join(new_input_parts)\n",
    "\n",
    "\n",
    "def process_csv_file(input_csv_filepath):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, transforms the 'input:' column,\n",
    "    and parses the 'output:' column.\n",
    "    Returns a list of dictionaries, where each dictionary represents a row\n",
    "    with transformed 'input:' and parsed 'output:'.\n",
    "    \"\"\"\n",
    "    processed_rows = []\n",
    "    \n",
    "    try:\n",
    "        with open(input_csv_filepath, 'r', encoding='utf-8', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            if 'input:' not in reader.fieldnames or 'output:' not in reader.fieldnames:\n",
    "                print(f\"Error: CSV file must contain 'input:' and 'output:' columns. Found: {reader.fieldnames}\")\n",
    "                return []\n",
    "\n",
    "            for row_num, row_dict in enumerate(reader):\n",
    "                try:\n",
    "                    old_input = row_dict.get('input:', '') # Use .get for safety\n",
    "                    output_str = row_dict.get('output:', '{}')\n",
    "\n",
    "                    new_input = transform_single_input(old_input)\n",
    "                    \n",
    "                    try:\n",
    "                        output_json = json.loads(output_str)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Warning: Row {row_num+2} (line number in file) - Could not parse JSON in 'output:' column: {e}\")\n",
    "                        print(f\"Original output string: {output_str}\")\n",
    "                        output_json = {\"error\": \"JSON parsing failed\", \"original_output\": output_str}\n",
    "\n",
    "                    processed_rows.append({\n",
    "                        'input:': new_input,\n",
    "                        'output:': output_json\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing row {row_num+2} (line number in file): {e}\")\n",
    "                    # Add a placeholder or skip the row if critical error\n",
    "                    processed_rows.append({\n",
    "                        'input:': f\"Error processing original input: {row_dict.get('input:', '')}\",\n",
    "                        'output:': {\"error\": \"Row processing failed\", \"original_input\": old_input}\n",
    "                    })\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input CSV file not found at '{input_csv_filepath}'\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading the CSV: {e}\")\n",
    "        return []\n",
    "        \n",
    "    return processed_rows\n",
    "\n",
    "def write_transformed_csv(output_csv_filepath, data_to_write):\n",
    "    \"\"\"\n",
    "    Writes the processed data to a new CSV file.\n",
    "    Each row in data_to_write should be a dictionary with 'input:' and 'output:' keys.\n",
    "    The 'output:' value (which is a Python dict) will be converted to a JSON string.\n",
    "    \"\"\"\n",
    "    if not data_to_write:\n",
    "        print(\"No data to write.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(output_csv_filepath, 'w', encoding='utf-8', newline='') as outfile:\n",
    "            # Ensure 'input:' and 'output:' are the desired column names\n",
    "            fieldnames = ['input:', 'output:']\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for p_row in data_to_write:\n",
    "                # Convert output dict back to JSON string for CSV\n",
    "                row_to_write = {\n",
    "                    'input:': p_row.get('input:', ''), # Use .get for safety\n",
    "                    'output:': json.dumps(p_row.get('output:', {}))\n",
    "                }\n",
    "                writer.writerow(row_to_write)\n",
    "        print(f\"\\nProcessed data successfully written to '{output_csv_filepath}'\")\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not write to output file '{output_csv_filepath}'. Check permissions or path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while writing the CSV: {e}\")\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # !!! THAY ĐỔI TÊN FILE CHO PHÙ HỢP !!!\n",
    "    input_file_path = \"D:/NEW-SERVER-TS/src/conference/examples/determine_links_train_data.csv\"  # <<<< ---- THAY ĐỔI TÊN FILE NÀY\n",
    "    output_file_path = \"D:/NEW-SERVER-TS/src/conference/examples/transformed_data.csv\" # <<<< ---- TÊN FILE CSV ĐẦU RA\n",
    "\n",
    "    print(f\"Processing CSV file: {input_file_path}\")\n",
    "    processed_data = process_csv_file(input_file_path)\n",
    "\n",
    "    if processed_data:\n",
    "        # Tùy chọn: In một vài bản ghi đầu tiên để kiểm tra\n",
    "        print(\"\\n--- Sample of Processed Data ---\")\n",
    "        for i, item in enumerate(processed_data[:2]): # In 2 bản ghi đầu\n",
    "            print(f\"\\n--- Record {i+1} ---\")\n",
    "            print(\"Transformed Input:\")\n",
    "            print(item['input:'])\n",
    "            print(\"\\nParsed Output:\")\n",
    "            print(json.dumps(item['output:'], indent=2, ensure_ascii=False)) # ensure_ascii=False để hiển thị tiếng Việt\n",
    "            print(\"=\"*40)\n",
    "\n",
    "        # Ghi kết quả ra file CSV mới\n",
    "        write_transformed_csv(output_file_path, processed_data)\n",
    "    else:\n",
    "        print(\"No data was processed. Output file will not be created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Transform extract info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transformation for D:/NEW-SERVER-TS/src/conference/train/extract_infor_done_300_shrink.csv...\n",
      "Successfully transformed 'D:/NEW-SERVER-TS/src/conference/train/extract_infor_done_300_shrink.csv' and saved to 'transformed_second_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def transform_single_input_v2(old_input_text):\n",
    "    \"\"\"\n",
    "    Transforms a single 'input:' string from the old format (v2) to the new format (v2).\n",
    "    Old format example:\n",
    "    Conference Applied Computing Conference (ACC):\n",
    "    Skip to content...\n",
    "\n",
    "    New format example:\n",
    "    Conference Title: Applied Computing Conference\n",
    "    Conference Acronym: ACC\n",
    "\n",
    "    Main Website Content:\n",
    "    Skip to content...\n",
    "    \"\"\"\n",
    "    new_parts = []\n",
    "    conference_title = \"N/A\"\n",
    "    conference_acronym = \"N/A\"\n",
    "    main_content = old_input_text # Default to original if pattern doesn't match\n",
    "\n",
    "    # Regex to capture title and optional acronym from the first line\n",
    "    # ^Conference\\s+ : Starts with \"Conference \"\n",
    "    # (.*?)          : Captures the title (non-greedy) - Group 1\n",
    "    # (?:\\s*\\((.*?)\\))? : Optional group for acronym:\n",
    "    #   \\s*\\(        : Optional space then (\n",
    "    #   (.*?)        : Captures acronym (non-greedy) - Group 2\n",
    "    #   \\)           : Closing )\n",
    "    # ?:             : Non-capturing group for the whole acronym part\n",
    "    # ?              : Makes the acronym part optional\n",
    "    # :\\s*\\n?        : Colon, optional space, optional newline (to separate header from content)\n",
    "    match = re.match(r\"^Conference\\s+(.*?)(?:\\s*\\((.*?)\\))?:\\s*(\\n|$)\", old_input_text, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        conference_title = match.group(1).strip()\n",
    "        if match.group(2): # Acronym was found\n",
    "            conference_acronym = match.group(2).strip()\n",
    "        \n",
    "        # The rest of the string after the matched first line is the main content\n",
    "        # match.end() gives the index after the matched part (including the newline if captured by \\n)\n",
    "        content_start_index = match.end()\n",
    "        main_content = old_input_text[content_start_index:].strip()\n",
    "    else:\n",
    "        # If the first line doesn't match, we might try a simpler split\n",
    "        # or just use defaults and the whole text as content.\n",
    "        # For now, let's assume if it doesn't match, the whole thing is content,\n",
    "        # and title/acronym remain N/A or you can add more sophisticated parsing.\n",
    "        print(f\"Warning: Could not parse conference title/acronym from first line: {old_input_text.splitlines()[0] if old_input_text else 'Empty Input'}\")\n",
    "        # Keep main_content as old_input_text.strip() in this case\n",
    "        main_content = old_input_text.strip()\n",
    "\n",
    "\n",
    "    new_parts.append(f\"Conference Title: {conference_title}\")\n",
    "    new_parts.append(f\"Conference Acronym: {conference_acronym}\")\n",
    "    new_parts.append(\"\") # Blank line\n",
    "    new_parts.append(\"Main Website Content:\")\n",
    "    new_parts.append(main_content)\n",
    "\n",
    "    return \"\\n\".join(new_parts)\n",
    "\n",
    "def process_and_write_csv_v2(input_filepath, output_filepath):\n",
    "    \"\"\"\n",
    "    Reads a CSV, transforms its 'input:' column using transform_single_input_v2,\n",
    "    and writes the result to a new CSV, preserving other columns.\n",
    "    \"\"\"\n",
    "    transformed_rows = []\n",
    "    fieldnames = []\n",
    "\n",
    "    try:\n",
    "        with open(input_filepath, 'r', encoding='utf-8', newline='') as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "            fieldnames = reader.fieldnames\n",
    "            if not fieldnames:\n",
    "                print(f\"Error: CSV file '{input_filepath}' appears to be empty or has no header.\")\n",
    "                return\n",
    "            if 'input:' not in fieldnames:\n",
    "                print(f\"Error: CSV file '{input_filepath}' must contain an 'input:' column. Found columns: {fieldnames}\")\n",
    "                return\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                # Make a copy to modify\n",
    "                new_row = row.copy()\n",
    "                old_input_content = row.get('input:', '') # Get content of 'input:' column\n",
    "\n",
    "                if old_input_content:\n",
    "                    transformed_content = transform_single_input_v2(old_input_content)\n",
    "                    new_row['input:'] = transformed_content\n",
    "                else:\n",
    "                    # Handle empty input: column if necessary, or leave as is\n",
    "                    new_row['input:'] = \"\" \n",
    "                    print(f\"Warning: Row {i+2} has empty 'input:' field.\")\n",
    "\n",
    "                transformed_rows.append(new_row)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input CSV file not found at '{input_filepath}'\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading the CSV '{input_filepath}': {e}\")\n",
    "        return\n",
    "\n",
    "    if not transformed_rows:\n",
    "        print(\"No data was processed. Output file will not be created.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(output_filepath, 'w', encoding='utf-8', newline='') as outfile:\n",
    "            # Use the fieldnames from the original CSV\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(transformed_rows)\n",
    "        print(f\"Successfully transformed '{input_filepath}' and saved to '{output_filepath}'\")\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not write to output file '{output_filepath}'. Check permissions or path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while writing the CSV '{output_filepath}': {e}\")\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # !!! THAY ĐỔI TÊN FILE CHO PHÙ HỢP !!!\n",
    "    input_csv_file = \"D:/NEW-SERVER-TS/src/conference/train/extract_infor_done_300_shrink.csv\"  # <<<< ---- THAY ĐỔI TÊN FILE CSV ĐẦU VÀO\n",
    "    output_csv_file = \"transformed_second_data.csv\" # <<<< ---- TÊN FILE CSV ĐẦU RA MONG MUỐN\n",
    "\n",
    "    print(f\"Starting transformation for {input_csv_file}...\")\n",
    "    process_and_write_csv_v2(input_csv_file, output_csv_file)\n",
    "\n",
    "    # Để kiểm tra, bạn có thể tạo một file CSV mẫu tên là 'your_second_input_file.csv'\n",
    "    # với nội dung như sau:\n",
    "    \"\"\"\n",
    "input:,other_column\n",
    "\"Conference Applied Computing Conference (ACC):\n",
    "\n",
    "Skip to contentsecretariat@computing-conf.org \n",
    "Connect With Us:Applied Computing2025MenuEvent | Committees \n",
    "Publication Ethics Statement \n",
    "Publications \n",
    "........\",\"Some other data 1\"\n",
    "\"Conference International Symposium on Advanced Security and Privacy (ASAP):\n",
    "Main content for ASAP\n",
    "More lines\n",
    "Even more lines\",\"Another value\"\n",
    "\"Conference Another Conference with no Acronym:\n",
    "Content for no acronym conference.\n",
    "Still going.\",\"Data3\"\n",
    "\"This is an unmatched line:\n",
    "It will be treated as content.\",\"Error case\"\n",
    "    \"\"\"\n",
    "    # Sau khi chạy, 'transformed_second_data.csv' sẽ được tạo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
